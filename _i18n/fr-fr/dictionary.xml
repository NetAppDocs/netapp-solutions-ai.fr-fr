<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">Lisez les blogs IA/ML qui mettent en évidence les tendances du secteur, les innovations et l’impact réel, ainsi que les ressources pour les développeurs, les informations sur la communauté et les outils pratiques pour travailler avec les solutions d’IA NetApp .</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">Lisez les blogs sur les solutions d'IA des experts NetApp</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">Lisez les blogs AI/ML qui mettent en évidence les tendances du secteur, les innovations et l’impact réel, ainsi que les ressources pour les développeurs, les informations sur la communauté et les outils pratiques pour travailler avec les solutions d’IA NetApp .</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">Tendances de l'IA et perspectives du secteur</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">English</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">Explorez les tendances de l’industrie, les innovations et l’impact réel de l’IA dans divers secteurs. <block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[IA,Analytique,intelligence-artificielle]++[Lire les blogs sur l'IA sur NetApp.com^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">Ressources et communauté pour les développeurs</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">Lisez les blogs sur l'IA sur le Pub</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">Informations techniques, outils pratiques et contenu communautaire pour les praticiens de l'IA/ML.<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">L'article fournit un guide pour créer un pipeline MLOps avec les services AWS, en se concentrant sur le recyclage automatisé des modèles, le déploiement et l'optimisation des coûts.</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">Partie 3 - Création d'un pipeline MLOps simplifié (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">Cet article fournit un guide pour créer un pipeline MLOps avec les services AWS, en se concentrant sur le recyclage automatisé des modèles, le déploiement et l'optimisation des coûts.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introduction</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">Dans ce didacticiel, vous apprendrez à exploiter divers services AWS pour créer un pipeline MLOps simple qui englobe l'intégration continue (CI), la formation continue (CT) et le déploiement continu (CD).  Contrairement aux pipelines DevOps traditionnels, MLOps nécessite des considérations supplémentaires pour terminer le cycle opérationnel.  En suivant ce tutoriel, vous obtiendrez des informations sur l'intégration de CT dans la boucle MLOps, permettant une formation continue de vos modèles et un déploiement transparent pour l'inférence.  Le didacticiel vous guidera tout au long du processus d’utilisation des services AWS pour établir ce pipeline MLOps de bout en bout.</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">Manifeste</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">Fonctionnalité</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Nom</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Commentaire</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">Stockage de données</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">Partie 1 - Intégration Amazon FSx for NetApp ONTAP (FSx ONTAP) en tant que compartiment S3 privé dans AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">IDE de science des données</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">Partie 2 - Exploiter Amazon FSx for NetApp ONTAP (FSx ONTAP) comme source de données pour la formation de modèles dans SageMaker</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">Ce tutoriel est basé sur le notebook Jupyter présenté dans<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">Fonction pour déclencher le pipeline MLOps</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">Fonction AWS Lambda</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Déclencheur de tâche Cron</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">Cadre d'apprentissage profond</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">Kit de développement logiciel (SDK) AWS Python</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">Langage de programmation</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Python</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">Condition préalable</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">Un système de fichiers FSx ONTAP préconfiguré.  Ce didacticiel utilise les données stockées dans FSx ONTAP pour le processus de formation.</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">Une *instance SageMaker Notebook* configurée pour partager le même VPC que le système de fichiers FSx ONTAP mentionné ci-dessus.</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">Avant de déclencher la *fonction AWS Lambda*, assurez-vous que l'*instance SageMaker Notebook* est à l'état *arrêté*.</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">Le type d'instance *ml.g4dn.xlarge* est requis pour tirer parti de l'accélération GPU nécessaire aux calculs des réseaux neuronaux profonds.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">Architecture</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">Ce pipeline MLOps est une implémentation pratique qui utilise une tâche cron pour déclencher une fonction sans serveur, qui à son tour exécute un service AWS enregistré auprès d'une fonction de rappel de cycle de vie.  *AWS EventBridge* agit comme une tâche cron.  Il appelle périodiquement une *fonction AWS Lambda* chargée de recycler et de redéployer le modèle.  Ce processus implique de lancer l’instance *AWS SageMaker Notebook* pour effectuer les tâches nécessaires.</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">Configuration étape par étape</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">Configurations du cycle de vie</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">Pour configurer la fonction de rappel du cycle de vie pour l'instance AWS SageMaker Notebook, vous devez utiliser *Configurations du cycle de vie*.  Ce service vous permet de définir les actions nécessaires à effectuer lors du démarrage de l'instance du notebook.  Plus précisément, un script shell peut être implémenté dans les *configurations du cycle de vie* pour arrêter automatiquement l'instance du notebook une fois les processus de formation et de déploiement terminés.  Il s’agit d’une configuration obligatoire car le coût est l’une des principales considérations dans MLOps.</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">Il est important de noter que la configuration des *configurations du cycle de vie* doit être définie à l'avance.  Par conséquent, il est recommandé de prioriser la configuration de cet aspect avant de procéder à l’autre configuration du pipeline MLOps.</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">Pour configurer un cycle de vie, ouvrez le panneau *Sagemaker* et accédez à *Configurations du cycle de vie* sous la section *Configurations d'administration*.</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">Panneau SageMaker</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">Sélectionnez l'onglet *Instance de bloc-notes* et cliquez sur le bouton *Créer une configuration*</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">Page d'accueil de la configuration du cycle de vie</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">Collez le code ci-dessous dans la zone de saisie.</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">Ce script exécute le Jupyter Notebook, qui gère le recyclage et le redéploiement du modèle pour l'inférence.  Une fois l'exécution terminée, le notebook s'éteindra automatiquement dans les 5 minutes.  Pour en savoir plus sur l'énoncé du problème et l'implémentation du code, veuillez vous référer à<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">Créer une configuration du cycle de vie</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">Après la création, accédez aux instances de Notebook, sélectionnez l'instance cible et cliquez sur *Mettre à jour les paramètres* sous la liste déroulante Actions.</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">Mettre à jour les paramètres déroulants</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">Sélectionnez la *Configuration du cycle de vie* créée et cliquez sur *Mettre à jour l'instance du bloc-notes*.</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">Mettre à jour la configuration du cycle de vie du notebook</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">Fonction sans serveur AWS Lambda</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">Comme mentionné précédemment, la *fonction AWS Lambda* est responsable du démarrage de l'*instance AWS SageMaker Notebook*.</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">Pour créer une *fonction AWS Lambda*, accédez au panneau correspondant, passez à l'onglet *Fonctions* et cliquez sur *Créer une fonction*.</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">Page d'accueil de la fonction AWS lambda</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">Veuillez déposer toutes les entrées requises sur la page et n'oubliez pas de passer le Runtime à *Python 3.10*.</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">Créer une fonction AWS lambda</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">Veuillez vérifier que le rôle désigné dispose de l'autorisation requise *AmazonSageMakerFullAccess* et cliquez sur le bouton *Créer une fonction*.</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">Sélectionner le rôle d'exécution</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">Sélectionnez la fonction Lambda créée.  Dans l’onglet code, copiez et collez le code suivant dans la zone de texte.  Ce code démarre l'instance de notebook nommée *fsxn-ontap*.</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">Cliquez sur le bouton *Déployer* pour appliquer cette modification de code.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">Déploiement</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">Pour spécifier comment déclencher cette fonction AWS Lambda, cliquez sur le bouton Ajouter un déclencheur.</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">Ajouter un déclencheur de fonction AWS</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">Sélectionnez EventBridge dans le menu déroulant, puis cliquez sur le bouton radio intitulé Créer une nouvelle règle.  Dans le champ d'expression de planification, saisissez<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block> , et cliquez sur le bouton Ajouter pour créer et appliquer cette nouvelle règle de tâche cron à la fonction AWS Lambda.</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">Finaliser le déclencheur</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">Une fois la configuration en deux étapes terminée, la fonction *AWS Lambda* lancera quotidiennement le *SageMaker Notebook*, effectuera un recyclage du modèle à l'aide des données du référentiel *FSx ONTAP*, redéployera le modèle mis à jour dans l'environnement de production et arrêtera automatiquement l'instance *SageMaker Notebook* pour optimiser les coûts.  Cela garantit que le modèle reste à jour.</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">Ceci conclut le tutoriel sur le développement d’un pipeline MLOps.</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">Ceci est la page d'introduction à la section FSx ONTAP MLOps.</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">Amazon FSx for NetApp ONTAP (FSx ONTAP) pour MLOps</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">Cette section se penche sur l'application pratique du développement de l'infrastructure d'IA, en fournissant une procédure pas à pas de bout en bout de la construction d'un pipeline MLOps à l'aide de FSx ONTAP.  Composé de trois exemples complets, il vous guide pour répondre à vos besoins MLOps via cette puissante plateforme de gestion de données.</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">Ces articles portent sur :</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">À la fin de cette section, vous aurez acquis une solide compréhension de la manière d’utiliser FSx ONTAP pour rationaliser les processus MLOps.</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">Cet article fournit un guide sur la configuration de FSx ONTAP en tant que bucket S3 privé à l'aide d'AWS SageMaker.</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">Cette section fournit un guide sur la configuration de FSx ONTAP en tant que bucket S3 privé à l'aide d'AWS SageMaker.</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">En utilisant SageMaker comme exemple, cette page fournit des conseils sur la configuration de FSx ONTAP en tant que bucket S3 privé.</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">Lien vidéo</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">Pour plus d'informations sur FSx ONTAP, veuillez consulter cette présentation (<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">Guide de l'utilisateur</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">Création de serveur</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">Créer une instance de bloc-notes SageMaker</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">Ouvrez la console AWS.  Dans le panneau de recherche, recherchez SageMaker et cliquez sur le service *Amazon SageMaker*.</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">Ouvrir la console AWS</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">Ouvrez les *Instances de bloc-notes* sous l'onglet Bloc-notes, cliquez sur le bouton orange *Créer une instance de bloc-notes*.</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">Console d'instance AWS SageMaker Notebook</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">Dans la page de création, saisissez le *Nom de l'instance du notebook*. Développez le panneau *Réseau*. Laissez les autres entrées par défaut et sélectionnez un *VPC*, un *Sous-réseau* et un ou plusieurs *Groupes de sécurité*.  (Ce *VPC* et *Sous-réseau* seront utilisés pour créer ultérieurement le système de fichiers FSx ONTAP ) Cliquez sur le bouton orange *Créer une instance de notebook* en bas à droite.</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">Créer une instance de bloc-notes</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">Créer un système de fichiers FSx ONTAP</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">Ouvrez la console AWS.  Dans le panneau de recherche, recherchez Fsx et cliquez sur le service *FSx*.</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">Panneau FSx</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">Cliquez sur *Créer un système de fichiers*.</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">Créer un système de fichiers</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">Sélectionnez la première carte *FSx ONTAP* et cliquez sur *Suivant*.</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">Sélectionnez le type de système de fichiers</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">Dans la page de configuration des détails.</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">Sélectionnez l'option *Création standard*.</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">Créer un panneau de système de fichiers</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">Saisissez le *Nom du système de fichiers* et la *Capacité de stockage SSD*.</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">Spécifier les détails du système de fichiers</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">Assurez-vous d'utiliser le *VPC* et le *sous-réseau* identiques à l'instance *SageMaker Notebook*.</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">Configuration du réseau et de la sécurité</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">Saisissez le nom de la *machine virtuelle de stockage* et *Spécifiez un mot de passe* pour votre SVM (machine virtuelle de stockage).</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">Configuration par défaut de la machine virtuelle de stockage</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">Laissez les autres entrées par défaut et cliquez sur le bouton orange *Suivant* en bas à droite.</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">Confirmer la configuration</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">Cliquez sur le bouton orange *Créer un système de fichiers* en bas à droite de la page de révision.</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">Vérifiez la configuration et confirmez la création</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">Le démarrage du système de fichiers FSx peut prendre environ *20 à 40 minutes*.</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">Inspecter la console FSx</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">Configuration du serveur</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">Configuration ONTAP</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">Ouvrez le système de fichiers FSx créé.  Veuillez vous assurer que le statut est *Disponible*.</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">Attendez la création du backend</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">Sélectionnez l'onglet *Administration* et conservez le *Point de terminaison de gestion - Adresse IP* et le *Nom d'utilisateur de l'administrateur ONTAP *.</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">Console de détails du système de fichiers</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">Ouvrez l'instance *SageMaker Notebook* créée et cliquez sur *Ouvrir JupyterLab*.</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">Console d'instance AWS SageMaker Notebook</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">Dans la page Jupyter Lab, ouvrez un nouveau *Terminal*.</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Page d'accueil de Jupyter Lab</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">Entrez la commande ssh ssh &lt;nom d'utilisateur administrateur&gt;@&lt;IP du serveur ONTAP &gt; pour vous connecter au système de fichiers FSx ONTAP .  (Le nom d'utilisateur et l'adresse IP sont récupérés à l'étape 2) Veuillez utiliser le mot de passe utilisé lors de la création de la *machine virtuelle de stockage*.</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Terminal Jupyter Lab</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">Exécutez les commandes dans l’ordre suivant.  Nous utilisons *fsxn-ontap* comme nom pour le *nom du bucket S3 privé FSx ONTAP *.  Veuillez utiliser le *nom de la machine virtuelle de stockage* pour l'argument *-vserver*.</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Sortie du terminal Jupyter Lab</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">Exécutez les commandes ci-dessous pour récupérer l'adresse IP et les informations d'identification du point de terminaison pour FSx ONTAP privé S3.</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">Conservez l’adresse IP et les informations d’identification du point de terminaison pour une utilisation ultérieure.</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">Configuration du client</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">Dans l’instance SageMaker Notebook, créez un nouveau notebook Jupyter.</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">Ouvrir un nouveau notebook Jupyter</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">Utilisez le code ci-dessous comme solution de contournement pour télécharger des fichiers vers le bucket S3 privé FSx ONTAP .  Pour un exemple de code complet, veuillez vous référer à ce bloc-notes.<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">Ceci conclut l'intégration entre FSx ONTAP et l'instance SageMaker.</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">Liste de contrôle de débogage utile</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">Assurez-vous que l’instance SageMaker Notebook et le système de fichiers FSx ONTAP se trouvent dans le même VPC.</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">N'oubliez pas d'exécuter la commande *set dev* sur ONTAP pour définir le niveau de privilège sur *dev*.</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">FAQ (au 27 septembre 2023)</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">Q : Pourquoi est-ce que j'obtiens l'erreur « *Une erreur s'est produite (NotImplemented) lors de l'appel de l'opération CreateMultipartUpload : la commande s3 que vous avez demandée n'est pas implémentée* » lors du téléchargement de fichiers vers FSx ONTAP?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">R : En tant que bucket S3 privé, FSx ONTAP prend en charge le téléchargement de fichiers jusqu'à 100 Mo.  Lors de l'utilisation du protocole S3, les fichiers de plus de 100 Mo sont divisés en morceaux de 100 Mo et la fonction « CreateMultipartUpload » est appelée.  Cependant, l'implémentation actuelle de FSx ONTAP private S3 ne prend pas en charge cette fonction.</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">Q : Pourquoi est-ce que j'obtiens l'erreur « *Une erreur s'est produite (AccessDenied) lors de l'appel des opérations PutObject : Accès refusé* » lors du téléchargement de fichiers vers FSx ONTAP?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">R : Pour accéder au compartiment S3 privé FSx ONTAP à partir d'une instance SageMaker Notebook, remplacez les informations d'identification AWS par les informations d'identification FSx ONTAP .  Cependant, l'octroi d'une autorisation d'écriture à l'instance nécessite une solution de contournement qui implique le montage du bucket et l'exécution de la commande shell « chmod » pour modifier les autorisations.</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">Q : Comment puis-je intégrer le bucket S3 privé FSx ONTAP avec d’autres services SageMaker ML ?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">R : Malheureusement, le SDK des services SageMaker ne fournit pas de moyen de spécifier le point de terminaison du bucket S3 privé.  Par conséquent, FSx ONTAP S3 n'est pas compatible avec les services SageMaker tels que Sagemaker Data Wrangler, Sagemaker Clarify, Sagemaker Glue, Sagemaker Athena, Sagemaker AutoML et autres.</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">L'article est un didacticiel sur l'utilisation Amazon FSx for NetApp ONTAP (FSx ONTAP) pour la formation de modèles PyTorch dans SageMaker, en particulier pour un projet de classification de la qualité des pneus.</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">Partie 2 - Exploiter AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) comme source de données pour la formation de modèles dans SageMaker</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">Cet article est un didacticiel sur l’utilisation Amazon FSx for NetApp ONTAP (FSx ONTAP) pour la formation de modèles PyTorch dans SageMaker, en particulier pour un projet de classification de la qualité des pneus.</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">Ce didacticiel propose un exemple pratique d'un projet de classification de vision par ordinateur, offrant une expérience pratique dans la création de modèles ML qui utilisent FSx ONTAP comme source de données dans l'environnement SageMaker.  Le projet se concentre sur l’utilisation de PyTorch, un framework d’apprentissage en profondeur, pour classer la qualité des pneus en fonction des images de pneus.  Il met l’accent sur le développement de modèles d’apprentissage automatique utilisant FSx ONTAP comme source de données dans Amazon SageMaker.</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">Qu'est-ce que FSx ONTAP</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP est en effet une solution de stockage entièrement gérée proposée par AWS.  Il exploite le système de fichiers ONTAP de NetApp pour fournir un stockage fiable et hautes performances.  Avec la prise en charge de protocoles tels que NFS, SMB et iSCSI, il permet un accès transparent à partir de différentes instances de calcul et conteneurs.  Le service est conçu pour offrir des performances exceptionnelles, garantissant des opérations de données rapides et efficaces.  Il offre également une haute disponibilité et une durabilité élevée, garantissant que vos données restent accessibles et protégées.  De plus, la capacité de stockage d' Amazon FSx ONTAP est évolutive, ce qui vous permet de l'ajuster facilement en fonction de vos besoins.</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">Environnement réseau</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">Environnement réseau</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP) est un service de stockage AWS.  Il comprend un système de fichiers exécuté sur le système NetApp ONTAP et une machine virtuelle système gérée par AWS (SVM) qui s'y connecte.  Dans le diagramme fourni, le serveur NetApp ONTAP géré par AWS est situé en dehors du VPC.  Le SVM sert d'intermédiaire entre SageMaker et le système NetApp ONTAP , recevant les demandes d'opération de SageMaker et les transmettant au stockage sous-jacent.  Pour accéder à FSx ONTAP, SageMaker doit être placé dans le même VPC que le déploiement FSx ONTAP .  Cette configuration assure la communication et l'accès aux données entre SageMaker et FSx ONTAP.</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">Accès aux données</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">Dans les scénarios réels, les scientifiques des données utilisent généralement les données existantes stockées dans FSx ONTAP pour créer leurs modèles d’apprentissage automatique.  Cependant, à des fins de démonstration, étant donné que le système de fichiers FSx ONTAP est initialement vide après sa création, il est nécessaire de télécharger manuellement les données de formation.  Cela peut être réalisé en montant FSx ONTAP en tant que volume sur SageMaker.  Une fois le système de fichiers monté avec succès, vous pouvez télécharger votre ensemble de données vers l'emplacement monté, le rendant ainsi accessible pour la formation de vos modèles dans l'environnement SageMaker.  Cette approche vous permet d’exploiter la capacité de stockage et les capacités de FSx ONTAP tout en travaillant avec SageMaker pour le développement et la formation de modèles.</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">Partie 1 - Intégration Amazon FSx for NetApp ONTAP (FSx ONTAP) en tant que compartiment S3 privé dans AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">Le processus de lecture des données implique la configuration de FSx ONTAP en tant que bucket S3 privé.  Pour connaître les instructions de configuration détaillées, veuillez vous référer à<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">Présentation de l'intégration</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">Flux de travail de formation</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">Le flux de travail d'utilisation des données de formation dans FSx ONTAP pour créer un modèle d'apprentissage en profondeur dans SageMaker peut être résumé en trois étapes principales : définition du chargeur de données, formation du modèle et déploiement.  À un niveau élevé, ces étapes constituent la base d’un pipeline MLOps.  Cependant, chaque étape implique plusieurs sous-étapes détaillées pour une mise en œuvre complète.  Ces sous-étapes englobent diverses tâches telles que le prétraitement des données, le fractionnement des ensembles de données, la configuration du modèle, le réglage des hyperparamètres, l’évaluation du modèle et le déploiement du modèle.  Ces étapes garantissent un processus complet et efficace pour la création et le déploiement de modèles d’apprentissage en profondeur à l’aide de données de formation de FSx ONTAP dans l’environnement SageMaker.</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">Intégration étape par étape</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">Loader de données</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">Afin de former un réseau d'apprentissage profond PyTorch avec des données, un chargeur de données est créé pour faciliter l'alimentation des données.  Le chargeur de données définit non seulement la taille du lot, mais détermine également la procédure de lecture et de prétraitement de chaque enregistrement au sein du lot.  En configurant le chargeur de données, nous pouvons gérer le traitement des données par lots, permettant ainsi la formation du réseau d'apprentissage en profondeur.</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">Le chargeur de données se compose de 3 parties.</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">Fonction de prétraitement</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">L'extrait de code ci-dessus illustre la définition des transformations de prétraitement d'image à l'aide du module *torchvision.transforms*.  Dans ce tutoriel, l'objet de prétraitement est créé pour appliquer une série de transformations.  Tout d’abord, la transformation *ToTensor()* convertit l’image en une représentation tensorielle.  Par la suite, la transformation *Resize((224,224))* redimensionne l'image à une taille fixe de 224x224 pixels.  Enfin, la transformation *Normalize()* normalise les valeurs du tenseur en soustrayant la moyenne et en divisant par l'écart type le long de chaque canal.  Les valeurs moyennes et d’écart type utilisées pour la normalisation sont couramment utilisées dans les modèles de réseaux neuronaux pré-entraînés.  Dans l’ensemble, ce code prépare les données d’image pour un traitement ultérieur ou une entrée dans un modèle pré-entraîné en les convertissant en tenseur, en les redimensionnant et en normalisant les valeurs des pixels.</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">La classe de jeu de données PyTorch</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">Cette classe fournit des fonctionnalités permettant d'obtenir le nombre total d'enregistrements dans l'ensemble de données et définit la méthode de lecture des données pour chaque enregistrement.  Dans la fonction *__getitem__*, le code utilise l'objet bucket S3 boto3 pour récupérer les données binaires de FSx ONTAP.  Le style de code permettant d'accéder aux données de FSx ONTAP est similaire à la lecture des données d'Amazon S3.  L'explication suivante approfondit le processus de création de l'objet S3 privé *bucket*.</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP comme référentiel S3 privé</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">Pour lire les données de FSx ONTAP dans SageMaker, un gestionnaire est créé qui pointe vers le stockage FSx ONTAP à l'aide du protocole S3.  Cela permet à FSx ONTAP d'être traité comme un bucket S3 privé.  La configuration du gestionnaire inclut la spécification de l'adresse IP du SVM FSx ONTAP , du nom du bucket et des informations d'identification nécessaires.  Pour une explication complète sur l'obtention de ces éléments de configuration, veuillez vous référer au document à l'adresse<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">Dans l'exemple mentionné ci-dessus, l'objet bucket est utilisé pour instancier l'objet de jeu de données PyTorch.  L'objet de jeu de données sera expliqué plus en détail dans la section suivante.</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">Le Loader de données PyTorch</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">Dans l'exemple fourni, une taille de lot de 64 est spécifiée, indiquant que chaque lot contiendra 64 enregistrements.  En combinant la classe PyTorch *Dataset*, la fonction de prétraitement et la taille du lot d'entraînement, nous obtenons le chargeur de données pour l'entraînement.  Ce chargeur de données facilite le processus d’itération de l’ensemble de données par lots pendant la phase de formation.</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">Formation de modèle</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">Ce code implémente un processus de formation PyTorch standard.  Il définit un modèle de réseau neuronal appelé *TyreQualityClassifier* utilisant des couches convolutives et une couche linéaire pour classer la qualité des pneus.  La boucle de formation parcourt les lots de données, calcule la perte et met à jour les paramètres du modèle à l'aide de la rétropropagation et de l'optimisation.  De plus, il imprime l'heure actuelle, l'époque, le lot et la perte à des fins de surveillance.</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">Déploiement du modèle</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">Le code enregistre le modèle PyTorch sur *Amazon S3* car SageMaker exige que le modèle soit stocké dans S3 pour le déploiement.  En téléchargeant le modèle sur *Amazon S3*, il devient accessible à SageMaker, permettant le déploiement et l'inférence sur le modèle déployé.</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">Ce code facilite le déploiement d'un modèle PyTorch sur SageMaker.  Il définit un sérialiseur personnalisé, *TyreQualitySerializer*, qui prétraite et sérialise les données d'entrée sous forme de tenseur PyTorch.  La classe *TyreQualityPredictor* est un prédicteur personnalisé qui utilise le sérialiseur défini et un *JSONDeserializer*.  Le code crée également un objet *PyTorchModel* pour spécifier l'emplacement S3 du modèle, le rôle IAM, la version du framework et le point d'entrée pour l'inférence.  Le code génère un horodatage et construit un nom de point de terminaison basé sur le modèle et l'horodatage.  Enfin, le modèle est déployé à l’aide de la méthode deploy, en spécifiant le nombre d’instances, le type d’instance et le nom du point de terminaison généré.  Cela permet au modèle PyTorch d'être déployé et accessible pour l'inférence sur SageMaker.</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">Inférence</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">Voici l’exemple d’utilisation du point de terminaison déployé pour effectuer l’inférence.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Cette section résume ce document concernant les solutions de stockage NetApp pour Apache Spark.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusion</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">Dans ce document, nous discutons de l'architecture Apache Spark, des cas d'utilisation des clients et du portefeuille de stockage NetApp en relation avec le Big Data, l'analyse moderne et l'IA, le ML et le DL.  Lors de nos tests de validation des performances basés sur des outils d'analyse comparative standard du secteur et sur la demande des clients, les solutions NetApp Spark ont démontré des performances supérieures par rapport aux systèmes Hadoop natifs.  Une combinaison des cas d’utilisation client et des résultats de performances présentés dans ce rapport peut vous aider à choisir une solution Spark appropriée pour votre déploiement.</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Ce document se concentre sur l’architecture Apache Spark, les cas d’utilisation des clients et le portefeuille de stockage NetApp liés à l’analyse du Big Data et à l’intelligence artificielle.  Il présente également divers résultats de tests utilisant des outils d'IA, d'apprentissage automatique et d'apprentissage en profondeur standard de l'industrie par rapport à un système Hadoop typique afin que vous puissiez choisir la solution Spark appropriée.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570 : Solutions de stockage NetApp pour Apache Spark : architecture, cas d'utilisation et résultats de performance</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Ce document se concentre sur l’architecture Apache Spark, les cas d’utilisation des clients et le portefeuille de stockage NetApp liés à l’analyse du Big Data et à l’intelligence artificielle (IA).  Il présente également divers résultats de tests utilisant des outils d'IA, d'apprentissage automatique (ML) et d'apprentissage profond (DL) standard de l'industrie par rapport à un système Hadoop typique afin que vous puissiez choisir la solution Spark appropriée.  Pour commencer, vous avez besoin d’une architecture Spark, de composants appropriés et de deux modes de déploiement (cluster et client).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Ce document fournit également des cas d’utilisation client pour résoudre les problèmes de configuration et présente un aperçu du portefeuille de stockage NetApp pertinent pour l’analyse du Big Data et l’IA, le ML et le DL avec Spark.  Nous terminons ensuite avec les résultats des tests dérivés des cas d’utilisation spécifiques à Spark et du portefeuille de solutions NetApp Spark.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">Les défis des clients</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Cette section se concentre sur les défis des clients en matière d'analyse de Big Data et d'IA/ML/DL dans les secteurs de croissance des données tels que la vente au détail, le marketing numérique, la banque, la fabrication discrète, la fabrication de processus, le gouvernement et les services professionnels.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Des performances imprévisibles</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Les déploiements Hadoop traditionnels utilisent généralement du matériel standard.  Pour améliorer les performances, vous devez ajuster le réseau, le système d’exploitation, le cluster Hadoop, les composants de l’écosystème tels que Spark et le matériel.  Même si vous ajustez chaque couche, il peut être difficile d'atteindre les niveaux de performances souhaités, car Hadoop s'exécute sur du matériel standard qui n'a pas été conçu pour des performances élevées dans votre environnement.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Pannes de médias et de nœuds</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Même dans des conditions normales, le matériel informatique de base est sujet à des pannes.  Si un disque sur un nœud de données tombe en panne, le maître Hadoop considère par défaut que ce nœud est défectueux.  Il copie ensuite des données spécifiques de ce nœud sur le réseau à partir de répliques vers un nœud sain.  Ce processus ralentit les paquets réseau pour tous les travaux Hadoop.  Le cluster doit ensuite recopier les données et supprimer les données sur-répliquées lorsque le nœud défectueux revient à un état sain.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Verrouillage du fournisseur Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Les distributeurs Hadoop ont leur propre distribution Hadoop avec leur propre versionnage, ce qui verrouille le client sur ces distributions.  Cependant, de nombreux clients ont besoin d’une prise en charge des analyses en mémoire qui ne lie pas le client à des distributions Hadoop spécifiques.  Ils ont besoin de la liberté de modifier les distributions tout en conservant leurs analyses avec eux.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Manque de support pour plus d'une langue</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Les clients ont souvent besoin de la prise en charge de plusieurs langues en plus des programmes Java MapReduce pour exécuter leurs tâches.  Des options telles que SQL et les scripts offrent plus de flexibilité pour obtenir des réponses, plus d'options pour organiser et récupérer des données, et des moyens plus rapides de déplacer des données dans un cadre d'analyse.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Difficulté d'utilisation</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Depuis un certain temps, les gens se plaignent de la difficulté d’utilisation d’Hadoop.  Même si Hadoop est devenu plus simple et plus puissant à chaque nouvelle version, cette critique a persisté.  Hadoop exige que vous compreniez les modèles de programmation Java et MapReduce, un défi pour les administrateurs de bases de données et les personnes possédant des compétences de script traditionnelles.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Cadres et outils complexes</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">Les équipes d’IA des entreprises sont confrontées à de multiples défis.  Même avec des connaissances spécialisées en science des données, les outils et les cadres pour différents écosystèmes de déploiement et applications peuvent ne pas être facilement transposables de l’un à l’autre.  Une plateforme de science des données doit s'intégrer de manière transparente aux plateformes Big Data correspondantes construites sur Spark avec une facilité de déplacement des données, des modèles réutilisables, du code prêt à l'emploi et des outils qui prennent en charge les meilleures pratiques de prototypage, de validation, de versionnage, de partage, de réutilisation et de déploiement rapide des modèles en production.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Pourquoi choisir NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp peut améliorer votre expérience Spark des manières suivantes :</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">L'accès direct NetApp NFS (illustré dans la figure ci-dessous) permet aux clients d'exécuter des tâches d'analyse de Big Data sur leurs données NFSv3 ou NFSv4 existantes ou nouvelles sans déplacer ni copier les données.  Il empêche les copies multiples de données et élimine le besoin de synchroniser les données avec une source.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Stockage plus efficace et moins de réplication de serveur.  Par exemple, la solution Hadoop NetApp E-Series nécessite deux répliques de données au lieu de trois, et la solution Hadoop FAS nécessite une source de données mais aucune réplication ni copie de données.  Les solutions de stockage NetApp génèrent également moins de trafic de serveur à serveur.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Meilleur comportement des tâches et des clusters Hadoop en cas de panne de lecteur et de nœud.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Meilleures performances d’ingestion de données.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Configurations alternatives d'Apache Spark.</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Par exemple, dans le secteur financier et de la santé, le déplacement de données d’un endroit à un autre doit répondre à des obligations légales, ce qui n’est pas une tâche facile.  Dans ce scénario, l’accès direct NetApp NFS analyse les données financières et de santé à partir de leur emplacement d’origine.  Un autre avantage clé est que l’utilisation de l’accès direct NetApp NFS simplifie la protection des données Hadoop en utilisant des commandes Hadoop natives et en activant les flux de travail de protection des données avec le riche portefeuille de gestion des données de NetApp.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">L'accès direct NetApp NFS offre deux types d'options de déploiement pour les clusters Hadoop/Spark :</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Par défaut, les clusters Hadoop ou Spark utilisent le système de fichiers distribué Hadoop (HDFS) pour le stockage des données et le système de fichiers par défaut.  L'accès direct NetApp NFS peut remplacer le HDFS par défaut par le stockage NFS comme système de fichiers par défaut, permettant ainsi des analyses directes sur les données NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">Dans une autre option de déploiement, l’accès direct NetApp NFS prend en charge la configuration de NFS comme stockage supplémentaire avec HDFS dans un seul cluster Hadoop ou Spark.  Dans ce cas, le client peut partager des données via des exportations NFS et y accéder à partir du même cluster avec les données HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Les principaux avantages de l’utilisation de l’accès direct NetApp NFS sont les suivants :</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analyse des données à partir de leur emplacement actuel, ce qui évite la tâche fastidieuse et coûteuse en performances consistant à déplacer les données d'analyse vers une infrastructure Hadoop telle que HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Réduction du nombre de répliques de trois à une.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Permettre aux utilisateurs de découpler le calcul et le stockage pour les faire évoluer indépendamment.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Assurer la protection des données d'entreprise en exploitant les riches capacités de gestion des données d' ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certification avec la plateforme de données Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Permettre des déploiements d’analyse de données hybrides.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Réduction du temps de sauvegarde en exploitant la capacité multithread dynamique.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657 : Solutions de données cloud hybrides NetApp - Spark et Hadoop basées sur des cas d'utilisation client</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">Voir<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block> pour la sauvegarde des données Hadoop, la sauvegarde et la reprise après sinistre du cloud vers les locaux, permettant DevTest sur les données Hadoop existantes, la protection des données et la connectivité multicloud, et l'accélération des charges de travail d'analyse.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">Les sections suivantes décrivent les capacités de stockage importantes pour les clients Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">hiérarchisation du stockage</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Avec la hiérarchisation du stockage Hadoop, vous pouvez stocker des fichiers avec différents types de stockage conformément à une politique de stockage.  Les types de stockage incluent<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block> ,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> , et<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block> .</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">Nous avons effectué la validation de la hiérarchisation du stockage Hadoop sur un contrôleur de stockage NetApp AFF et un contrôleur de stockage E-Series avec des disques SSD et SAS avec différentes politiques de stockage.  Le cluster Spark avec AFF-A800 dispose de quatre nœuds de calcul, tandis que le cluster avec la série E en a huit.  Il s’agit principalement de comparer les performances des disques SSD (Solid State Drives) par rapport aux disques durs (HDD).</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">La figure suivante montre les performances des solutions NetApp pour un SSD Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Il est temps de trier 1 To de données.</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 Solution NetApp E-Series pour Hadoop</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">La configuration NL-SAS de base utilisait huit nœuds de calcul et 96 lecteurs NL-SAS.  Cette configuration a généré 1 To de données en 4 minutes et 38 secondes.  Voir<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block> pour plus de détails sur la configuration du cluster et du stockage.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Grâce à TeraGen, la configuration SSD a généré 1 To de données 15,66 fois plus rapidement que la configuration NL-SAS.  De plus, la configuration SSD utilisait la moitié du nombre de nœuds de calcul et la moitié du nombre de lecteurs de disque (24 lecteurs SSD au total).  En fonction du temps d’exécution du travail, il était presque deux fois plus rapide que la configuration NL-SAS.</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">Grâce à TeraSort, la configuration SSD a trié 1 To de données 1 138,36 fois plus rapidement que la configuration NL-SAS.  De plus, la configuration SSD utilisait la moitié du nombre de nœuds de calcul et la moitié du nombre de lecteurs de disque (24 lecteurs SSD au total).  Par conséquent, par lecteur, il était environ trois fois plus rapide que la configuration NL-SAS.</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">Le point à retenir est que la transition des disques rotatifs vers le tout flash améliore les performances.  Le nombre de nœuds de calcul n’était pas le goulot d’étranglement.  Avec le stockage entièrement flash de NetApp, les performances d'exécution évoluent bien.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Avec NFS, les données étaient fonctionnellement équivalentes à un regroupement complet, ce qui peut réduire le nombre de nœuds de calcul en fonction de votre charge de travail.  Les utilisateurs du cluster Apache Spark n’ont pas besoin de rééquilibrer manuellement les données lors du changement du nombre de nœuds de calcul.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Mise à l'échelle des performances - Évolution horizontale</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Lorsque vous avez besoin de plus de puissance de calcul à partir d’un cluster Hadoop dans une solution AFF , vous pouvez ajouter des nœuds de données avec un nombre approprié de contrôleurs de stockage.  NetApp recommande de commencer avec quatre nœuds de données par baie de contrôleurs de stockage et d'augmenter le nombre à huit nœuds de données par contrôleur de stockage, en fonction des caractéristiques de la charge de travail.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF et FAS sont parfaits pour les analyses sur place.  En fonction des exigences de calcul, vous pouvez ajouter des gestionnaires de nœuds et des opérations non perturbatrices vous permettent d'ajouter un contrôleur de stockage à la demande sans temps d'arrêt.  Nous proposons des fonctionnalités riches avec AFF et FAS, telles que la prise en charge des médias NVME, l'efficacité garantie, la réduction des données, la qualité de service, l'analyse prédictive, la hiérarchisation du cloud, la réplication, le déploiement du cloud et la sécurité.  Pour aider les clients à répondre à leurs besoins, NetApp propose des fonctionnalités telles que l'analyse du système de fichiers, les quotas et l'équilibrage de charge sur site sans frais de licence supplémentaires.  NetApp offre de meilleures performances en termes de nombre de tâches simultanées, de latence plus faible, d'opérations plus simples et de débit en gigaoctets par seconde plus élevé que nos concurrents.  De plus, NetApp Cloud Volumes ONTAP fonctionne sur les trois principaux fournisseurs de cloud.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Mise à l'échelle des performances - Mise à l'échelle</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Les fonctionnalités de mise à l'échelle vous permettent d'ajouter des lecteurs de disque aux systèmes AFF, FAS et E-Series lorsque vous avez besoin d'une capacité de stockage supplémentaire.  Avec Cloud Volumes ONTAP, la mise à l'échelle du stockage au niveau Po est une combinaison de deux facteurs : la hiérarchisation des données rarement utilisées vers le stockage d'objets à partir du stockage en blocs et l'empilement de licences Cloud Volumes ONTAP sans calcul supplémentaire.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Protocoles multiples</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">Les systèmes NetApp prennent en charge la plupart des protocoles pour les déploiements Hadoop, notamment SAS, iSCSI, FCP, InfiniBand et NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Solutions opérationnelles et supportées</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">certification</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">partenaire</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">Les solutions Hadoop décrites dans ce document sont prises en charge par NetApp.  Ces solutions sont également certifiées auprès des principaux distributeurs Hadoop.  Pour plus d'informations, consultez le<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> site et Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> et<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> sites.</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">Cette section décrit la nature et les composants d’Apache Spark et comment ils contribuent à cette solution.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">Technologie des solutions</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark est un framework de programmation populaire pour l'écriture d'applications Hadoop qui fonctionne directement avec le système de fichiers distribué Hadoop (HDFS).  Spark est prêt pour la production, prend en charge le traitement des données en streaming et est plus rapide que MapReduce.  Spark dispose d'une mise en cache de données en mémoire configurable pour une itération efficace, et le shell Spark est interactif pour l'apprentissage et l'exploration des données.  Avec Spark, vous pouvez créer des applications en Python, Scala ou Java.  Les applications Spark se composent d’un ou plusieurs travaux comportant une ou plusieurs tâches.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Chaque application Spark dispose d'un pilote Spark.  En mode YARN-Client, le pilote s'exécute localement sur le client.  En mode YARN-Cluster, le pilote s'exécute dans le cluster sur le maître d'application.  En mode cluster, l'application continue de s'exécuter même si le client se déconnecte.</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">Figure montrant une boîte de dialogue d'entrée/sortie ou représentant un contenu écrit</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Il existe trois gestionnaires de clusters :</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Autonome.*  Ce gestionnaire fait partie de Spark, ce qui facilite la configuration d'un cluster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.*  Il s’agit d’un gestionnaire de cluster général qui exécute également MapReduce et d’autres applications.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*FIL Hadoop.*  Il s’agit d’un gestionnaire de ressources dans Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">L'ensemble de données distribué résilient (RDD) est le composant principal de Spark.  RDD recrée les données perdues et manquantes à partir des données stockées en mémoire dans le cluster et stocke les données initiales provenant d'un fichier ou créées par programmation.  Les RDD sont créés à partir de fichiers, de données en mémoire ou d'un autre RDD.  La programmation Spark effectue deux opérations : la transformation et les actions.  La transformation crée un nouveau RDD basé sur un RDD existant.  Les actions renvoient une valeur à partir d’un RDD.</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">Les transformations et les actions s’appliquent également aux ensembles de données et aux DataFrames Spark.  Un ensemble de données est une collection distribuée de données qui offre les avantages des RDD (typage fort, utilisation de fonctions lambda) avec les avantages du moteur d'exécution optimisé de Spark SQL.  Un ensemble de données peut être construit à partir d'objets JVM, puis manipulé à l'aide de transformations fonctionnelles (map, flatMap, filter, etc.).  Un DataFrame est un ensemble de données organisé en colonnes nommées.  Il est conceptuellement équivalent à une table dans une base de données relationnelle ou à un cadre de données dans R/Python.  Les DataFrames peuvent être construits à partir d'un large éventail de sources telles que des fichiers de données structurés, des tables dans Hive/HBase, des bases de données externes sur site ou dans le cloud, ou des RDD existants.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Les applications Spark incluent une ou plusieurs tâches Spark.  Les tâches exécutent des tâches dans des exécuteurs, et les exécuteurs s'exécutent dans des conteneurs YARN.  Chaque exécuteur s'exécute dans un seul conteneur et les exécuteurs existent tout au long de la vie d'une application.  Un exécuteur est corrigé après le démarrage de l'application et YARN ne redimensionne pas le conteneur déjà alloué.  Un exécuteur peut exécuter des tâches simultanément sur des données en mémoire.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">Cette section décrit qui pourrait être intéressé par le contenu de cette solution.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">Public cible</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">Le monde de l'analyse et de la science des données touche de multiples disciplines de l'informatique et des affaires :</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">Le data scientist a besoin de la flexibilité nécessaire pour utiliser les outils et les bibliothèques de son choix.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">L'ingénieur de données doit savoir comment les données circulent et où elles résident.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Un ingénieur DevOps a besoin d’outils pour intégrer de nouvelles applications d’IA et de ML dans ses pipelines CI et CD.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Les administrateurs et architectes cloud doivent être capables de configurer et de gérer les ressources cloud hybrides.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Les utilisateurs professionnels souhaitent avoir accès aux applications d’analyse, d’IA, de ML et de DL.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">Dans ce rapport technique, nous décrivons comment NetApp AFF, E-Series, StorageGRID, l'accès direct NFS, Apache Spark, Horovod et Keras aident chacun de ces rôles à apporter de la valeur à l'entreprise.</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Nous avons utilisé les scripts TeraSort et TeraValidate dans l'outil d'analyse comparative TeraGen pour mesurer la validation des performances de Spark avec les configurations E5760, E5724 et AFF-A800.  De plus, trois cas d'utilisation majeurs ont été testés : les pipelines Spark NLP et la formation distribuée TensorFlow, la formation distribuée Horovod et l'apprentissage en profondeur multi-travailleurs à l'aide de Keras pour la prédiction CTR avec DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Résultats des tests</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Nous avons utilisé les scripts TeraSort et TeraValidate dans l'outil d'analyse comparative TeraGen pour mesurer la validation des performances de Spark avec les configurations E5760, E5724 et AFF-A800.  De plus, trois cas d'utilisation majeurs ont été testés : les pipelines Spark NLP et la formation distribuée TensorFlow, la formation distribuée Horovod et l'apprentissage profond multi-travailleurs utilisant Keras pour la prédiction CTR avec DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Pour la validation des séries E et StorageGRID , nous avons utilisé le facteur de réplication Hadoop 2.  Pour la validation AFF , nous n’avons utilisé qu’une seule source de données.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">Le tableau suivant répertorie la configuration matérielle pour la validation des performances de Spark.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Type</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nœuds de travail Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Type de lecteur</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Lecteurs par nœud</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Contrôleur de stockage</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Paire unique à haute disponibilité (HA)</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Paire HA unique</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">Le tableau suivant répertorie les exigences logicielles.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Logiciels</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Version</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7,9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Environnement d'exécution OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">Machine virtuelle serveur OpenJDK 64 bits</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25,302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Étincelle</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Analyse du sentiment financier</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910 : Analyse des sentiments à partir des communications clients avec NetApp AI</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">Boîte à outils NetApp DataOps</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">Kit de développement logiciel NVIDIA Riva</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Cadre Tao</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">Nous avons publié<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block> , dans lequel un pipeline d'IA conversationnelle de bout en bout a été construit en utilisant le<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> , Stockage AFF et système NVIDIA DGX.  Le pipeline effectue le traitement du signal audio par lots, la reconnaissance automatique de la parole (ASR), l'apprentissage par transfert et l'analyse des sentiments en exploitant la boîte à outils DataOps,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> , et le<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block> .  En étendant le cas d'utilisation de l'analyse des sentiments au secteur des services financiers, nous avons créé un flux de travail SparkNLP, chargé trois modèles BERT pour diverses tâches NLP, telles que la reconnaissance d'entités nommées, et obtenu un sentiment au niveau des phrases pour les appels de résultats trimestriels des 10 premières entreprises du NASDAQ.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">Le script suivant<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> utilise le modèle FinBERT pour traiter les transcriptions dans HDFS et produire des décomptes de sentiments positifs, neutres et négatifs, comme indiqué dans le tableau suivant :</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">Le tableau suivant répertorie l'analyse des sentiments au niveau des phrases et des appels aux résultats pour les 10 premières sociétés du NASDAQ de 2016 à 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Nombre et pourcentage de sentiments</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Les 10 entreprises</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">DMLA</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Comptes positifs</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Comptes neutres</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Comptes négatifs</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Comptes non classés</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(nombre total de comptes)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">En termes de pourcentages, la plupart des phrases prononcées par les PDG et les directeurs financiers sont factuelles et véhiculent donc un sentiment neutre.  Lors d’une conférence téléphonique sur les résultats, les analystes posent des questions qui peuvent transmettre un sentiment positif ou négatif.  Il vaut la peine d’étudier plus en détail quantitativement la manière dont le sentiment négatif ou positif affecte les cours des actions le jour même ou le jour suivant la négociation.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">Le tableau suivant répertorie l'analyse des sentiments au niveau des phrases pour les 10 premières sociétés du NASDAQ, exprimée en pourcentage.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Pourcentage de sentiment</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positif</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10,13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18,06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8,69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5,24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9,07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12,08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11,44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13,25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6,23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutre</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87,17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79,02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88,82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91,87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88,42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86,50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84,65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83,77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92,44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Négatif</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2,43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2,92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2,49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1,52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2,51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1,42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3,91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2,96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1,33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Non classé</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0,27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1,37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0,01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">En termes de temps d'exécution du flux de travail, nous avons constaté une amélioration significative de 4,78x par rapport à<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> mode vers un environnement distribué dans HDFS, et une amélioration supplémentaire de 0,14 % en exploitant NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Comme le montre la figure suivante, le parallélisme des données et du modèle a amélioré le traitement des données et la vitesse d’inférence du modèle TensorFlow distribué.  L'emplacement des données dans NFS a donné un temps d'exécution légèrement meilleur, car le goulot d'étranglement du flux de travail est le téléchargement de modèles pré-entraînés.  Si nous augmentons la taille de l’ensemble de données de transcription, l’avantage de NFS est plus évident.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Exécution du workflow de bout en bout de l'analyse des sentiments Spark NLP.</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Formation distribuée avec performance Horovod</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">Scripts Python pour chaque cas d'utilisation majeur</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">La commande suivante a produit des informations d'exécution et un fichier journal dans notre cluster Spark à l'aide d'un seul<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nœud avec 160 exécuteurs chacun avec un cœur.  La mémoire de l'exécuteur a été limitée à 5 Go pour éviter une erreur de mémoire insuffisante.  Voir la section<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block> pour plus de détails concernant le traitement des données, la formation du modèle et le calcul de la précision du modèle dans<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">Le temps d'exécution résultant avec dix époques d'entraînement était le suivant :</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Il a fallu plus de 43 minutes pour traiter les données d'entrée, former un modèle DNN, calculer la précision et produire des points de contrôle TensorFlow et un fichier CSV pour les résultats de prédiction.  Nous avons limité le nombre d'époques d'entraînement à 10, qui dans la pratique est souvent fixé à 100 pour garantir une précision satisfaisante du modèle.  Le temps de formation évolue généralement de manière linéaire avec le nombre d’époques.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Nous avons ensuite utilisé les quatre nœuds de travail disponibles dans le cluster et exécuté le même script dans<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> mode avec données dans HDFS :</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">Le temps d'exécution résultant a été amélioré comme suit :</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">Avec le modèle d'Horovod et le parallélisme des données dans Spark, nous avons constaté une accélération d'exécution de 5,29x<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> contre<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> mode avec dix époques d'entraînement.  Ceci est illustré dans la figure suivante avec les légendes<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> et<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block> .  La formation du modèle DNN TensorFlow sous-jacent peut être encore accélérée avec des GPU s'ils sont disponibles.  Nous prévoyons de réaliser ces tests et de publier les résultats dans un futur rapport technique.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Notre prochain test a comparé les temps d’exécution avec des données d’entrée résidant dans NFS par rapport à HDFS.  Le volume NFS sur l' AFF A800 a été monté sur<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> sur les cinq nœuds (un maître, quatre travailleurs) de notre cluster Spark.  Nous avons exécuté une commande similaire à celle des tests précédents, avec le<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> paramètre pointant désormais vers le montage NFS :</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">Le temps d'exécution résultant avec NFS était le suivant :</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Il y a eu une accélération supplémentaire de 1,43x, comme le montre la figure suivante.  Par conséquent, avec un stockage entièrement flash NetApp connecté à leur cluster, les clients bénéficient des avantages d'un transfert et d'une distribution rapides des données pour les flux de travail Horovod Spark, atteignant une accélération de 7,55 fois par rapport à l'exécution sur un seul nœud.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Exécution du flux de travail Horovod Spark.</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modèles d'apprentissage profond pour les performances de prédiction du CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Pour les systèmes de recommandation conçus pour maximiser le CTR, vous devez apprendre les interactions sophistiquées des fonctionnalités derrière les comportements des utilisateurs qui peuvent être calculées mathématiquement d'un ordre faible à un ordre élevé.  Les interactions entre les caractéristiques d’ordre faible et d’ordre élevé doivent être tout aussi importantes pour un bon modèle d’apprentissage en profondeur, sans biaiser vers l’une ou l’autre.  Deep Factorization Machine (DeepFM), un réseau neuronal basé sur une machine de factorisation, combine des machines de factorisation pour la recommandation et l'apprentissage en profondeur pour l'apprentissage des fonctionnalités dans une nouvelle architecture de réseau neuronal.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Modèles larges et profonds</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">Bien que les machines de factorisation conventionnelles modélisent les interactions de caractéristiques par paires comme un produit interne de vecteurs latents entre les caractéristiques et puissent théoriquement capturer des informations d'ordre élevé, dans la pratique, les praticiens de l'apprentissage automatique n'utilisent généralement que des interactions de caractéristiques de second ordre en raison de la complexité élevée du calcul et du stockage.  Variantes de réseaux neuronaux profonds comme celui de Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> d'autre part, apprend les interactions de fonctionnalités sophistiquées dans une structure de réseau hybride en combinant un modèle linéaire large et un modèle profond.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Ce modèle large et profond comporte deux entrées, l'une pour le modèle large sous-jacent et l'autre pour le modèle profond, cette dernière partie nécessitant encore une ingénierie des fonctionnalités experte et rendant ainsi la technique moins généralisable à d'autres domaines.  Contrairement au modèle large et profond, DeepFM peut être efficacement formé avec des fonctionnalités brutes sans aucune ingénierie de fonctionnalités, car sa partie large et sa partie profonde partagent la même entrée et le même vecteur d'intégration.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Scripts Python pour chaque cas d'utilisation majeur.</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">Nous avons d'abord traité le Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 Go) dans un fichier CSV nommé<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> stocké dans un montage NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> en utilisant<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> de la section<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Dans ce script, la fonction<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> exécute plusieurs méthodes de chaîne pour supprimer les tabulations et insérer<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block> comme délimiteur et<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block> comme nouvelle ligne.  Notez que vous n'avez besoin de traiter que l'original<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> une fois, afin que le bloc de code soit affiché sous forme de commentaires.</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">Pour les tests suivants de différents modèles DL, nous avons utilisé<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> comme fichier d'entrée.  Lors des tests ultérieurs, le fichier CSV d'entrée a été lu dans un Spark DataFrame avec un schéma contenant un champ de<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block> , caractéristiques denses en nombres entiers<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block> , et des fonctionnalités éparses<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block> .  Ce qui suit<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> la commande prend un fichier CSV d'entrée, entraîne les modèles DeepFM avec une répartition de 20 % pour la validation croisée et sélectionne le meilleur modèle après dix époques d'entraînement pour calculer la précision de prédiction sur l'ensemble de test :</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Notez que puisque le fichier de données<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> est supérieur à 11 Go, vous devez définir une valeur suffisante<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> supérieur à la taille de l'ensemble de données pour éviter les erreurs.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Apache Arrow</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">Dans ce qui précède<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> configuration que nous avons également activée<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block> , qui convertit un Spark DataFrame en Pandas DataFrame avec le<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> méthode.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Après une division aléatoire, il y a plus de 36 millions de lignes dans l'ensemble de données d'entraînement et 9 millions d'échantillons dans l'ensemble de test :</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">Étant donné que ce rapport technique se concentre sur les tests de processeur sans utiliser de GPU, il est impératif de créer TensorFlow avec les indicateurs de compilateur appropriés.  Cette étape évite d’appeler des bibliothèques accélérées par GPU et tire pleinement parti des instructions AVX (Advanced Vector Extensions) et AVX2 de TensorFlow.  Ces fonctionnalités sont conçues pour les calculs algébriques linéaires tels que l'addition vectorisée, les multiplications matricielles dans un entraînement DNN à propagation directe ou à rétropropagation.  L'instruction Fused Multiply Add (FMA) disponible avec AVX2 utilisant des registres à virgule flottante (FP) 256 bits est idéale pour le code entier et les types de données, ce qui permet une accélération jusqu'à 2x.  Pour le code FP et les types de données, AVX2 atteint une accélération de 8 % par rapport à AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Pour créer TensorFlow à partir de la source, NetApp recommande d'utiliser<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> .  Pour notre environnement, nous avons exécuté les commandes suivantes dans l'invite du shell pour installer<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> ,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> , et Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Vous devez activer GCC 5 ou une version plus récente pour utiliser les fonctionnalités C++17 pendant le processus de génération, qui est fourni par RHEL avec Software Collections Library (SCL).  Les commandes suivantes installent<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> et GCC 11.2.1 sur notre cluster RHEL 7.9 :</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">article</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Notez que les deux dernières commandes permettent<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block> , qui utilise<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (CCG 11.2.1).  Assurez-vous également que votre<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> la version est supérieure à 1.8.3 (celle-ci est fournie avec RHEL 7.9).  Se référer à ceci<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> pour la mise à jour<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> à 2.24.1.</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">Scripts Python pour chaque cas d'utilisation majeur,</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">Nous supposons que vous avez déjà cloné le dernier référentiel maître TensorFlow.  Créez ensuite un<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> répertoire avec un<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> fichier pour créer TensorFlow à partir de la source avec AVX, AVX2 et FMA.  Exécutez le<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> fichier et spécifiez l'emplacement binaire Python correct.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> est désactivé pour nos tests car nous n'avons pas utilisé de GPU.  UN<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> le fichier est généré en fonction de vos paramètres.  De plus, nous avons édité le fichier et défini<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> pour activer la prise en charge HDFS.  Se référer à<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> dans la section<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block> pour une liste complète des paramètres et des indicateurs.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Après avoir créé TensorFlow avec les indicateurs appropriés, exécutez le script suivant pour traiter l'ensemble de données Criteo Display Ads, entraîner un modèle DeepFM et calculer l'aire sous la courbe caractéristique de fonctionnement du récepteur (ROC AUC) à partir des scores de prédiction.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Après dix périodes d'entraînement, nous avons obtenu le score AUC sur l'ensemble de données de test :</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">D’une manière similaire aux cas d’utilisation précédents, nous avons comparé l’exécution du workflow Spark avec des données résidant dans différents emplacements.  La figure suivante montre une comparaison de la prédiction CTR d’apprentissage profond pour un environnement d’exécution de workflows Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Comparaison de la prédiction du CTR d'apprentissage profond pour un environnement d'exécution de workflows Spark.</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Cette page décrit les différents domaines dans lesquels cette solution peut être utilisée.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Résumé du cas d'utilisation</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Données en streaming</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark peut traiter des données en streaming, qui sont utilisées pour les processus d'extraction, de transformation et de chargement (ETL) en streaming ; l'enrichissement des données ; la détection d'événements déclencheurs ; et l'analyse de sessions complexes :</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.*  Les données sont continuellement nettoyées et agrégées avant d’être transférées dans les magasins de données.  Netflix utilise Kafka et Spark Streaming pour créer une solution de recommandation de films en ligne et de surveillance des données en temps réel capable de traiter des milliards d'événements par jour à partir de différentes sources de données.  L'ETL traditionnel pour le traitement par lots est toutefois traité différemment.  Ces données sont d’abord lues, puis converties dans un format de base de données avant d’être écrites dans la base de données.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Enrichissement des données.*  Le streaming Spark enrichit les données en direct avec des données statiques pour permettre une analyse des données en temps réel.  Par exemple, les annonceurs en ligne peuvent diffuser des publicités personnalisées et ciblées en fonction des informations sur le comportement des clients.</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*Détection d'événement déclencheur.*  Le streaming Spark vous permet de détecter et de réagir rapidement à un comportement inhabituel qui pourrait indiquer des problèmes potentiellement graves.  Par exemple, les institutions financières utilisent des déclencheurs pour détecter et arrêter les transactions frauduleuses, et les hôpitaux utilisent des déclencheurs pour détecter les changements de santé dangereux détectés dans les signes vitaux d'un patient.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Analyse de session complexe.*  Spark Streaming collecte des événements tels que l'activité de l'utilisateur après la connexion à un site Web ou à une application, qui sont ensuite regroupés et analysés.  Par exemple, Netflix utilise cette fonctionnalité pour fournir des recommandations de films en temps réel.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912 : Recommandations de bonnes pratiques pour le stockage hiérarchisé Confluent Kafka avec NetApp</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">Pour plus de configuration de données en streaming, de vérification de Confluent Kafka et de tests de performances, consultez<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> .</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">Apprentissage automatique</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Le framework intégré Spark vous aide à exécuter des requêtes répétées sur des ensembles de données à l'aide de la bibliothèque d'apprentissage automatique (MLlib).  MLlib est utilisé dans des domaines tels que le clustering, la classification et la réduction de dimensionnalité pour certaines fonctions courantes du Big Data telles que l'intelligence prédictive, la segmentation des clients à des fins de marketing et l'analyse des sentiments.  MLlib est utilisé dans la sécurité des réseaux pour effectuer des inspections en temps réel des paquets de données à la recherche d'indications d'activité malveillante.  Il aide les fournisseurs de sécurité à se renseigner sur les nouvelles menaces et à garder une longueur d'avance sur les pirates tout en protégeant leurs clients en temps réel.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Apprentissage profond</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow est un framework d’apprentissage profond populaire utilisé dans l’ensemble du secteur.  TensorFlow prend en charge la formation distribuée sur un cluster CPU ou GPU.  Cette formation distribuée permet aux utilisateurs de l'exécuter sur une grande quantité de données avec de nombreuses couches profondes.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Jusqu'à récemment, si nous voulions utiliser TensorFlow avec Apache Spark, nous devions effectuer tous les ETL nécessaires pour TensorFlow dans PySpark, puis écrire les données dans le stockage intermédiaire.  Ces données seraient ensuite chargées sur le cluster TensorFlow pour le processus de formation réel.  Ce flux de travail nécessitait que l'utilisateur maintienne deux clusters différents, un pour l'ETL et un pour la formation distribuée de TensorFlow.  L’exécution et la maintenance de plusieurs clusters étaient généralement fastidieuses et prenaient beaucoup de temps.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">Les DataFrames et RDD des versions antérieures de Spark n'étaient pas bien adaptés à l'apprentissage en profondeur car l'accès aléatoire était limité.  Dans Spark 3.0 avec le projet Hydrogen, la prise en charge native des frameworks d'apprentissage en profondeur est ajoutée.  Cette approche permet une planification non basée sur MapReduce sur le cluster Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Analyse interactive</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark est suffisamment rapide pour effectuer des requêtes exploratoires sans échantillonnage avec des langages de développement autres que Spark, notamment SQL, R et Python.  Spark utilise des outils de visualisation pour traiter des données complexes et les visualiser de manière interactive.  Spark avec streaming structuré exécute des requêtes interactives sur des données en direct dans les analyses Web qui vous permettent d'exécuter des requêtes interactives sur la session actuelle d'un visiteur Web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Système de recommandation</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Au fil des ans, les systèmes de recommandation ont apporté d’énormes changements à nos vies, car les entreprises et les consommateurs ont réagi aux changements spectaculaires dans les achats en ligne, le divertissement en ligne et de nombreux autres secteurs.  En effet, ces systèmes comptent parmi les réussites les plus évidentes de l’IA en production.  Dans de nombreux cas d'utilisation pratiques, les systèmes de recommandation sont combinés à une IA conversationnelle ou à des chatbots interfacés avec un backend NLP pour obtenir des informations pertinentes et produire des inférences utiles.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Aujourd'hui, de nombreux détaillants adoptent de nouveaux modèles commerciaux tels que l'achat en ligne et le retrait en magasin, le retrait en bordure de rue, le paiement en libre-service, le scan-and-go, etc.  Ces modèles sont devenus importants pendant la pandémie de COVID-19 en rendant les achats plus sûrs et plus pratiques pour les consommateurs.  L’IA est essentielle à ces tendances numériques croissantes, qui sont influencées par le comportement des consommateurs et vice versa.  Pour répondre aux demandes croissantes des consommateurs, améliorer l'expérience client, améliorer l'efficacité opérationnelle et augmenter les revenus, NetApp aide ses clients et entreprises à utiliser des algorithmes d'apprentissage automatique et d'apprentissage profond pour concevoir des systèmes de recommandation plus rapides et plus précis.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Il existe plusieurs techniques populaires utilisées pour fournir des recommandations, notamment le filtrage collaboratif, les systèmes basés sur le contenu, le modèle de recommandation d'apprentissage profond (DLRM) et les techniques hybrides.  Les clients utilisaient auparavant PySpark pour mettre en œuvre un filtrage collaboratif afin de créer des systèmes de recommandation.  Spark MLlib implémente les moindres carrés alternés (ALS) pour le filtrage collaboratif, un algorithme très populaire parmi les entreprises avant l'essor du DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Traitement du langage naturel</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">L’IA conversationnelle, rendue possible par le traitement du langage naturel (TALN), est la branche de l’IA qui aide les ordinateurs à communiquer avec les humains.  La PNL est répandue dans tous les secteurs d'activité et dans de nombreux cas d'utilisation, des assistants intelligents et des chatbots à la recherche Google et au texte prédictif.  Selon un<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Selon les prévisions, d'ici 2022, 70 % des personnes interagiront quotidiennement avec des plateformes d'IA conversationnelles.  Pour une conversation de haute qualité entre un humain et une machine, les réponses doivent être rapides, intelligentes et naturelles.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Les clients ont besoin d’une grande quantité de données pour traiter et former leurs modèles de PNL et de reconnaissance automatique de la parole (ASR).  Ils doivent également déplacer des données à travers la périphérie, le cœur et le cloud, et ils ont besoin de la puissance nécessaire pour effectuer des inférences en quelques millisecondes afin d’établir une communication naturelle avec les humains.  NetApp AI et Apache Spark constituent une combinaison idéale pour le calcul, le stockage, le traitement des données, la formation des modèles, le réglage fin et le déploiement.</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">L'analyse des sentiments est un domaine d'étude de la PNL dans lequel des sentiments positifs, négatifs ou neutres sont extraits du texte.  L'analyse des sentiments a une variété de cas d'utilisation, allant de la détermination des performances des employés du centre d'assistance dans les conversations avec les appelants à la fourniture de réponses de chatbot automatisées appropriées.  Il a également été utilisé pour prédire le cours de l'action d'une entreprise en fonction des interactions entre les représentants de l'entreprise et le public lors des conférences téléphoniques trimestrielles sur les résultats.  De plus, l’analyse des sentiments peut être utilisée pour déterminer l’opinion d’un client sur les produits, les services ou l’assistance fournis par la marque.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark PNL</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">Laboratoires John Snow</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">sentiment des nouvelles financières</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">Nous avons utilisé le<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> bibliothèque de<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> pour charger des pipelines pré-entraînés et des représentations d'encodeurs bidirectionnels à partir de modèles de transformateurs (BERT), y compris<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block> et<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block> , effectuant la tokenisation, la reconnaissance d'entités nommées, la formation de modèles, l'ajustement et l'analyse des sentiments à grande échelle.  Spark NLP est la seule bibliothèque NLP open source en production qui propose des transformateurs de pointe tels que BERT, ALBERT, ELECTRA, XLNet, DistilBERT, RoBERTa, DeBERTa, XLM-RoBERTa, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT et GPT2.  La bibliothèque fonctionne non seulement en Python et R, mais également dans l'écosystème JVM (Java, Scala et Kotlin) à grande échelle en étendant Apache Spark de manière native.</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Abstrait</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">Ce document décrit comment déplacer les données des systèmes d’analyse de Big Data et de calcul haute performance (HPC) afin qu’elles puissent être utilisées dans les flux de travail d’intelligence artificielle (IA).  L'IA traite généralement les données NFS via des exportations NFS.  Cependant, vos données d’IA peuvent être stockées sur une plateforme d’analyse de Big Data et de calcul haute performance (HPC).  Il peut s'agir du système de fichiers distribué Hadoop (HDFS), d'un objet binaire volumineux (Blob), d'un stockage S3 ou du système de fichiers parallèle général d'IBM (GPFS).  Dans ce document, nous décrivons comment déplacer des données d'une plate-forme d'analyse Big Data et GPFS vers NFS à l'aide de commandes natives Hadoop, du module d'analyse NetApp In-Place (NIPAM) et de NetApp XCP.  Ce document aborde également les avantages commerciaux du déplacement des données du Big Data et du HPC vers l’IA.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Où trouver des informations supplémentaires</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Pour en savoir plus sur les informations décrites dans ce document, consultez les documents et/ou sites Web suivants :</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">Guide de mise en œuvre et des meilleures pratiques NetApp FlexGroup Volume</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentation produit NetApp</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">Cette section décrit les avantages commerciaux de cette solution.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Avantages commerciaux</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Le transfert de données de l’analyse Big Data vers l’IA offre les avantages suivants :</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">La capacité d'extraire des données de différents systèmes de fichiers Hadoop et GPFS dans un système de stockage NFS unifié</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Un moyen intégré et automatisé de transférer des données</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Une réduction du coût de développement de bibliothèques pour déplacer des données à partir de systèmes de fichiers Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Performances maximales grâce au débit agrégé de plusieurs interfaces réseau à partir d'une seule source de données en utilisant NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Méthodes planifiées et à la demande pour transférer des données</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Efficacité du stockage et capacité de gestion d'entreprise pour les données NFS unifiées à l'aide du logiciel de gestion de données ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Coût nul pour le déplacement des données avec la méthode Hadoop pour le transfert de données</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Cette page décrit les défis auxquels un client peut être confronté lorsqu’il tente d’accéder aux données issues d’analyses de Big Data pour les opérations d’IA.</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Les clients peuvent être confrontés aux défis suivants lorsqu'ils tentent d'accéder aux données issues d'analyses de Big Data pour les opérations d'IA :</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Les données client se trouvent dans un référentiel de lac de données.  Le lac de données peut contenir différents types de données telles que des données structurées, non structurées, semi-structurées, des journaux et des données machine à machine.  Tous ces types de données doivent être traités dans les systèmes d’IA.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">L'IA n'est pas compatible avec les systèmes de fichiers Hadoop.  Une architecture d’IA typique n’est pas en mesure d’accéder directement aux données HDFS et HCFS, qui doivent être déplacées vers un système de fichiers compréhensible par l’IA (NFS).</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Le transfert des données du lac de données vers l’IA nécessite généralement des processus spécialisés.  La quantité de données dans le lac de données peut être très importante.  Un client doit disposer d’un moyen efficace, à haut débit et rentable pour déplacer des données vers des systèmes d’IA.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Synchronisation des données.  Si un client souhaite synchroniser les données entre la plateforme Big Data et l’IA, les données traitées par l’IA peuvent parfois être utilisées avec le Big Data pour le traitement analytique.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">Dans un cluster Big Data, les données sont stockées dans HDFS ou HCFS, comme MapR-FS, Windows Azure Storage Blob, S3 ou le système de fichiers Google.  Nous avons effectué des tests avec HDFS, MapR-FS et S3 comme source pour copier les données vers l'exportation NetApp ONTAP NFS à l'aide de NIPAM en utilisant la commande hadoop distcp de la source.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">Solution de transfert de données</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">Dans un cluster Big Data, les données sont stockées dans HDFS ou HCFS, comme MapR-FS, Windows Azure Storage Blob, S3 ou le système de fichiers Google.  Nous avons effectué des tests avec HDFS, MapR-FS et S3 comme source pour copier les données vers l'exportation NetApp ONTAP NFS à l'aide de NIPAM en utilisant le<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> commande de la source.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">Le diagramme suivant illustre le déplacement de données typique d'un cluster Spark exécuté avec un stockage HDFS vers un volume NetApp ONTAP NFS afin que NVIDIA puisse traiter les opérations d'IA.</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Le<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> La commande utilise le programme MapReduce pour copier les données.  NIPAM fonctionne avec MapReduce pour agir comme pilote pour le cluster Hadoop lors de la copie des données.  NIPAM peut distribuer une charge sur plusieurs interfaces réseau pour une seule exportation.  Ce processus maximise le débit du réseau en distribuant les données sur plusieurs interfaces réseau lorsque vous copiez les données de HDFS ou HCFS vers NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM n'est pas pris en charge ou certifié avec MapR.</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">La solution de transfert de données pour l'IA est basée sur les besoins des clients pour traiter les données Hadoop issues des opérations d'IA.  NetApp déplace les données de HDFS vers NFS à l'aide de NIPAM.  Dans un cas d'utilisation, le client avait besoin de déplacer des données vers NFS sur site et un autre client avait besoin de déplacer des données du blob de stockage Windows Azure vers les Google Cloud NetApp Volumes afin de traiter les données des instances cloud GPU dans le cloud.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Solution de transfert de données pour l'IA</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">Le diagramme suivant illustre les détails de la solution de transfert de données.</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Les étapes suivantes sont nécessaires pour créer la solution de transfert de données :</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN fournit HDFS et NAS fournit le volume NFS via NIPAM au cluster de lac de données de production.</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">Les données du client sont en HDFS et NFS.  Les données NFS peuvent être des données de production provenant d’autres applications utilisées pour l’analyse de Big Data et les opérations d’IA.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">La technologie NetApp FlexClone crée un clone du volume NFS de production et le provisionne sur le cluster AI sur site.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Les données d'un LUN SAN HDFS sont copiées dans un volume NFS avec NIPAM et le<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> commande.  NIPAM utilise la bande passante de plusieurs interfaces réseau pour transférer des données.  Ce processus réduit le temps de copie des données afin que davantage de données puissent être transférées.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Les deux volumes NFS sont provisionnés sur le cluster AI pour les opérations AI.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Pour traiter les données NFS sur site avec des GPU dans le cloud, les volumes NFS sont mis en miroir sur NetApp Private Storage (NPS) avec la technologie NetApp SnapMirror et montés sur des fournisseurs de services cloud pour les GPU.</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">Le client souhaite traiter des données dans les services EC2/EMR, HDInsight ou DataProc dans des GPU provenant de fournisseurs de services cloud.  Le moteur de transfert de données Hadoop déplace les données des services Hadoop vers les Google Cloud NetApp Volumes avec NIPAM et le<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> commande.</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Les données Google Cloud NetApp Volumes sont provisionnées sur AI via le protocole NFS. Les données traitées via AI peuvent être envoyées sur un emplacement local pour l'analyse de Big Data en plus du cluster NVIDIA via NIPAM, SnapMirror et NPS.</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">Dans ce scénario, le client dispose de données de nombre de fichiers important dans le système NAS à un emplacement distant qui sont nécessaires au traitement de l'IA sur le contrôleur de stockage NetApp sur site.  Dans ce scénario, il est préférable d’utiliser l’outil de migration XCP pour migrer les données à une vitesse plus rapide.</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">Le client utilisant un cas d'utilisation hybride peut utiliser BlueXP Copy and Sync pour migrer les données locales des données NFS, CIFS et S3 vers le cloud et vice versa pour le traitement de l'IA en utilisant des GPU tels que ceux d'un cluster NVIDIA .  BlueXP Copy and Sync et l'outil de migration XCP sont tous deux utilisés pour la migration des données NFS vers NetApp ONTAP NFS.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">Dans cette validation, nous avons utilisé quatre serveurs comme serveurs de disques partagés en réseau (NSD) pour fournir des disques physiques pour GPFS.  GPFS est créé sur les disques NSD pour les exporter en tant qu'exportations NFS afin que les clients NFS puissent y accéder, comme illustré dans la figure ci-dessous.  Nous avons utilisé XCP pour copier les données du NFS exporté par GPFS vers un volume NFS NetApp .</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS vers NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">L'essentiel du GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Les types de nœuds suivants sont utilisés dans GPFS :</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Nœud d'administration.*  Spécifie un champ facultatif contenant un nom de nœud utilisé par les commandes d'administration pour communiquer entre les nœuds.  Par exemple, le nœud d’administration<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> pourrait transmettre un contrôle réseau à tous les autres nœuds du cluster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Nœud de quorum.*  Détermine si un nœud est inclus dans le pool de nœuds à partir duquel le quorum est dérivé.  Vous avez besoin d’au moins un nœud comme nœud de quorum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Nœud gestionnaire.*  Indique si un nœud fait partie du pool de nœuds à partir duquel les gestionnaires de systèmes de fichiers et les gestionnaires de jetons peuvent être sélectionnés.  C'est une bonne idée de définir plusieurs nœuds comme nœud gestionnaire.  Le nombre de nœuds que vous désignez comme gestionnaire dépend de la charge de travail et du nombre de licences de serveur GPFS dont vous disposez.  Si vous exécutez des tâches parallèles volumineuses, vous aurez peut-être besoin de plus de nœuds de gestionnaire que dans un cluster à quatre nœuds prenant en charge une application Web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*Serveur NSD.*  Le serveur qui prépare chaque disque physique pour une utilisation avec GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Nœud de protocole.*  Le nœud qui partage les données GPFS directement via n'importe quel protocole Secure Shell (SSH) avec le NFS.  Ce nœud nécessite une licence de serveur GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Liste des opérations pour GPFS, NFS et XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Cette section fournit la liste des opérations qui créent GPFS, exportent GPFS en tant qu'exportation NFS et transfèrent les données à l'aide de XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Créer GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Pour créer GPFS, procédez comme suit :</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Téléchargez et installez l'accès aux données à l'échelle du spectre pour la version Linux sur l'un des serveurs.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Installez le package prérequis (chef par exemple) dans tous les nœuds et désactivez Security-Enhanced Linux (SELinux) dans tous les nœuds.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Configurez le nœud d’installation et ajoutez le nœud d’administration et le nœud GPFS au fichier de définition du cluster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Ajoutez le nœud gestionnaire, le nœud quorum, les serveurs NSD et le nœud GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Ajoutez les nœuds GUI, administrateur et GPFS, et ajoutez un serveur GUI supplémentaire si nécessaire.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Ajoutez un autre nœud GPFS et vérifiez la liste de tous les nœuds.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Spécifiez un nom de cluster, un profil, un binaire de shell distant, un binaire de copie de fichier distant et une plage de ports à définir sur tous les nœuds GPFS dans le fichier de définition de cluster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Affichez les paramètres de configuration GPFS et ajoutez un nœud d’administration supplémentaire.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Désactivez la collecte de données et téléchargez le package de données vers le centre de support IBM.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Activez NTP et pré-vérifiez les configurations avant l'installation.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configurer, créer et vérifier les disques NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Créez le GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Montez le GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Vérifiez et fournissez les autorisations requises au GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Vérifiez la lecture et l'écriture GPFS en exécutant le<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Exporter GPFS vers NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Pour exporter le GPFS vers NFS, procédez comme suit :</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exporter GPFS en NFS via le<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> déposer.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Installez les packages de serveur NFS requis.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Démarrez le service NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Répertoriez les fichiers dans le GPFS pour valider le client NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configurer le client NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Pour configurer le client NFS, procédez comme suit :</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exporter le GPFS en NFS via le<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> déposer.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Démarrez les services client NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Montez le GPFS via le protocole NFS sur le client NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Valider la liste des fichiers GPFS dans le dossier monté NFS.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Déplacez les données de GPFS exportées NFS vers NetApp NFS à l'aide de XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Validez les fichiers GPFS sur le client NFS.</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">Cette section fournit les étapes détaillées nécessaires pour configurer GPFS et déplacer des données vers NFS à l'aide de NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">Conversion GPFS vers NFS : étapes détaillées</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configurer GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Téléchargez et installez Spectrum Scale Data Access pour Linux sur l’un des serveurs.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Installez le package prérequis (y compris chef et les en-têtes du noyau) sur tous les nœuds.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Désactiver SELinux dans tous les nœuds.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configurer le nœud d’installation.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Ajoutez le nœud d’administration et le nœud GPFS au fichier de définition du cluster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Ajoutez le nœud gestionnaire et le nœud GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Ajoutez le nœud quorum et le nœud GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Ajoutez les serveurs NSD et le nœud GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Ajoutez les nœuds GUI, admin et GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Ajoutez un autre serveur GUI.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Ajoutez un autre nœud GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Vérifiez et répertoriez tous les nœuds.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Spécifiez un nom de cluster dans le fichier de définition de cluster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Spécifiez le profil.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Spécifiez le binaire du shell distant à utiliser par GPFS ; utilisez<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> .</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Spécifiez le binaire de copie de fichier distant à utiliser par GPFS ; utilisez<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> .</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Spécifiez la plage de ports à définir sur tous les nœuds GPFS ; utilisez<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> .</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Afficher les paramètres de configuration GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Ajouter un nœud d'administration.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Activer NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Pré-vérifiez les configurations avant l'installation.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configurer les disques NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Créez les disques NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Vérifiez l’état du disque NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Vérifiez et fournissez les autorisations requises au GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Vérifiez la lecture et l'écriture GPFS en exécutant le<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Pour exporter GPFS vers NFS, procédez comme suit :</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Répertoriez les fichiers dans GPFS pour valider le client NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configurer le client NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Installer les packages dans le client NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Validez la liste des fichiers GPFS dans le dossier monté NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Déplacez les données du NFS exporté GPFS vers le NFS NetApp à l'aide de XCP.</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Pour cette solution, NetApp a validé la migration des données du lac de données (HDFS) et des données du cluster MapR vers ONTAP NFS.  Les données résidaient dans MapR-FS et HDFS.  NetApp XCP a introduit une nouvelle fonctionnalité qui migre directement les données d'un système de fichiers distribué tel que HDFS et MapR-FS vers ONTAP NFS.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS et MapR-FS vers ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">Pour cette solution, NetApp a validé la migration des données du lac de données (HDFS) et des données du cluster MapR vers ONTAP NFS.  Les données résidaient dans MapR-FS et HDFS.  NetApp XCP a introduit une nouvelle fonctionnalité qui migre directement les données d'un système de fichiers distribué tel que HDFS et MapR-FS vers ONTAP NFS.  XCP utilise des threads asynchrones et des appels API C HDFS pour communiquer et transférer des données depuis MapR-FS ainsi que HDFS.</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">La figure ci-dessous montre la migration des données du lac de données (HDFS) et de MapR-FS vers ONTAP NFS.  Avec cette nouvelle fonctionnalité, vous n’avez pas besoin d’exporter la source sous forme de partage NFS.</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Pourquoi les clients passent-ils de HDFS et MapR-FS à NFS ?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">La plupart des distributions Hadoop telles que Cloudera et Hortonworks utilisent HDFS et les distributions MapR utilisent leur propre système de fichiers appelé Mapr-FS pour stocker les données.  Les données HDFS et MapR-FS fournissent aux scientifiques des informations précieuses qui peuvent être exploitées dans l'apprentissage automatique (ML) et l'apprentissage profond (DL).  Les données dans HDFS et MapR-FS ne sont pas partagées, ce qui signifie qu'elles ne peuvent pas être utilisées par d'autres applications.  Les clients recherchent des données partagées, en particulier dans le secteur bancaire où les données sensibles des clients sont utilisées par plusieurs applications.  La dernière version de Hadoop (3.x ou ultérieure) prend en charge la source de données NFS, accessible sans logiciel tiers supplémentaire.  Avec la nouvelle fonctionnalité NetApp XCP, les données peuvent être déplacées directement de HDFS et MapR-FS vers NetApp NFS afin de fournir un accès à plusieurs applications</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Des tests ont été effectués dans Amazon Web Services (AWS) pour transférer les données de MapR-FS vers NFS pour le test de performance initial avec 12 nœuds MAPR et 4 serveurs NFS.</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Quantité</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Taille</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Mémoire</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">Stockage</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Réseau</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">serveur NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x SSD NVMe 7500</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nœuds MapR</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x SSD NVMe 7500</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Sur la base des tests initiaux, nous avons obtenu un débit de 20 Gbit/s et avons pu transférer 2 Po de données par jour.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863 : TR-4863 : Directives de bonnes pratiques pour NetApp XCP : transfert de données, migration de fichiers et analyse</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">Pour plus d'informations sur la migration de données HDFS sans exporter HDFS vers NFS, consultez la section « Étapes de déploiement - NAS » dans<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> .</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Cet article fournit des directives pour déplacer les données d'analyse de Big Data et les données HPC vers l'IA en utilisant NetApp XCP et NIPAM.  Nous discutons également des avantages commerciaux du déplacement des données du Big Data et du HPC vers l’IA.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732 : Analyse de données volumineuses vers l'intelligence artificielle</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Ce document décrit comment déplacer les données d’analyse Big Data et les données HPC vers l’IA.  L'IA traite les données NFS via des exportations NFS, tandis que les clients ont souvent leurs données d'IA dans une plate-forme d'analyse de Big Data, telle que le stockage HDFS, Blob ou S3 ainsi que des plates-formes HPC telles que GPFS.  Cet article fournit des directives pour déplacer les données d'analyse de Big Data et les données HPC vers l'IA en utilisant NetApp XCP et NIPAM.  Nous discutons également des avantages commerciaux du déplacement des données du Big Data et du HPC vers l’IA.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Concepts et composants</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Stockage d'analyse de Big Data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">L'analyse de Big Data est le principal fournisseur de stockage pour HDFS.  Un client utilise souvent un système de fichiers compatible Hadoop (HCFS) tel que Windows Azure Blob Storage, MapR File System (MapR-FS) et le stockage d’objets S3.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Système de fichiers parallèle général</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">GPFS d'IBM est un système de fichiers d'entreprise qui offre une alternative à HDFS.  GPFS offre aux applications la flexibilité nécessaire pour décider de la taille des blocs et de la disposition de réplication, ce qui offre de bonnes performances et une bonne efficacité.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">Module d'analyse sur place NetApp</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">Le module NetApp In-Place Analytics (NIPAM) sert de pilote aux clusters Hadoop pour accéder aux données NFS.  Il comporte quatre composants : un pool de connexions, un flux d'entrée NFS, un cache de gestion de fichiers et un flux de sortie NFS. Pour plus d'informations, consultez la section <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> .</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Copie distribuée Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) est un outil de copie distribué utilisé pour les tâches de copie inter-cluster et intra-cluster de grande taille.  Cet outil utilise MapReduce pour la distribution des données, la gestion des erreurs et la création de rapports.  Il étend la liste des fichiers et des répertoires et les saisit dans des tâches de mappage pour copier les données de la liste source.  L'image ci-dessous montre l'opération DistCp dans HDFS et non HDFS.</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp déplace les données entre les deux systèmes HDFS sans utiliser de pilote supplémentaire.  NetApp fournit le pilote pour les systèmes non HDFS.  Pour une destination NFS, NIPAM fournit le pilote pour copier les données que Hadoop DistCp utilise pour communiquer avec les destinations NFS lors de la copie des données.</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes est un service de fichiers cloud natif avec des performances extrêmes.  Ce service aide les clients à accélérer leur mise sur le marché en augmentant et en diminuant rapidement les ressources et en utilisant les fonctionnalités NetApp pour améliorer la productivité et réduire les temps d'arrêt du personnel.  Google Cloud NetApp Volumes est la bonne alternative pour la reprise après sinistre et la sauvegarde dans le cloud, car il réduit l'empreinte globale du centre de données et consomme moins de stockage cloud public natif.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP est un logiciel client qui permet une migration rapide et fiable des données vers NetApp et NetApp vers NetApp .  Cet outil est conçu pour copier une grande quantité de données NAS non structurées de n’importe quel système NAS vers un contrôleur de stockage NetApp .  L'outil de migration XCP utilise un moteur de streaming d'E/S multicœur et multicanal qui peut traiter de nombreuses requêtes en parallèle, telles que la migration de données, les listes de fichiers ou de répertoires et les rapports d'espace.  Il s’agit de l’outil de migration de données NetApp par défaut.  Vous pouvez utiliser XCP pour copier des données d’un cluster Hadoop et HPC vers un stockage NetApp NFS.  Le diagramme ci-dessous montre le transfert de données d'un cluster Hadoop et HPC vers un volume NetApp NFS à l'aide de XCP.</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">Copie et synchronisation NetApp BlueXP</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync est un logiciel de réplication de données hybride en tant que service qui transfère et synchronise les données NFS, S3 et CIFS de manière transparente et sécurisée entre le stockage sur site et le stockage cloud.  Ce logiciel est utilisé pour la migration de données, l'archivage, la collaboration, l'analyse et bien plus encore.  Une fois les données transférées, BlueXP Copy and Sync synchronise en continu les données entre la source et la destination.  À l’avenir, il transfère ensuite le delta.  Il sécurise également les données au sein de votre propre réseau, dans le cloud ou sur site.  Ce logiciel est basé sur un modèle de paiement à l'utilisation, qui fournit une solution rentable et offre des capacités de surveillance et de reporting pour votre transfert de données.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Cette section fournit les étapes détaillées nécessaires pour déplacer les données MapR-FS vers ONTAP NFS à l'aide de NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS vers ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Fournissez trois LUN pour chaque nœud MapR et attribuez aux LUN la propriété de tous les nœuds MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Lors de l'installation, choisissez les LUN nouvellement ajoutés pour les disques de cluster MapR utilisés pour MapR-FS.</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">Installez un cluster MapR conformément à la documentation MapR 6.1.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Vérifiez les opérations Hadoop de base à l'aide de commandes MapReduce telles que<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> .</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Conservez les données client dans MapR-FS.  Par exemple, nous avons généré environ un téraoctet de données d’échantillon dans MapR-FS en utilisant Teragen.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configurer MapR-FS comme exportation NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Désactivez le service nlockmgr sur tous les nœuds MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exporter des dossiers spécifiques de MapR-FS sur tous les nœuds MapR dans le<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> déposer.  N'exportez pas le dossier parent avec des autorisations différentes lorsque vous exportez des sous-dossiers.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Actualisez le service NFS MapR-FS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Attribuez une plage d’adresses IP virtuelles à un serveur spécifique ou à un ensemble de serveurs dans le cluster MapR.  Ensuite, le cluster MapR attribue une adresse IP à un serveur spécifique pour l’accès aux données NFS.  Les IP permettent une haute disponibilité, ce qui signifie que, si un serveur ou un réseau avec une IP particulière subit une panne, l'IP suivante de la plage d'IP peut être utilisée pour l'accès NFS.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Si vous souhaitez fournir un accès NFS à partir de tous les nœuds MapR, vous pouvez attribuer un ensemble d'adresses IP virtuelles à chaque serveur et utiliser les ressources de chaque nœud MapR pour l'accès aux données NFS.</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Vérifiez les adresses IP virtuelles attribuées sur chaque nœud MapR et utilisez-les pour l’accès aux données NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Montez le MapR-FS exporté par NFS à l'aide de l'IP virtuelle attribuée pour vérifier le fonctionnement du NFS.  Cependant, cette étape n’est pas requise pour le transfert de données à l’aide de NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configurez NetApp XCP pour transférer des données de la passerelle NFS MapR-FS vers ONTAP NFS.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configurez l’emplacement du catalogue pour XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copiez le fichier de licence dans<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block> .</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Activez XCP en utilisant le<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> commande.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Vérifiez la source pour l'exportation NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Transférez les données à l'aide de XCP à partir de plusieurs nœuds MapR à partir de plusieurs IP sources et de plusieurs IP de destination (ONTAP LIF).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Vérifiez la répartition de la charge sur le contrôleur de stockage.</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">Sur la base de cette validation, les scientifiques et ingénieurs des données peuvent accéder aux données NFS des notebooks AWS SageMaker Jupyter via les buckets S3 de NetApp Cloud Volumes ONTAP.  Cette approche permet un accès et un partage faciles des mêmes données à partir de NFS et de S3 sans avoir besoin de logiciel supplémentaire.</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">Classification de texte avec SageMaker BlazingText</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">Prise en charge de la version ONTAP pour le stockage d'objets S3</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">Les données sont disponibles dans NFS et accessibles depuis S3 depuis AWS SageMaker.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">Dualité des données pour les data scientists et autres applications</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Exigences technologiques</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">Vous avez besoin de NetApp BlueXP, NetApp Cloud Volumes ONTAP et AWS SageMaker Notebooks pour le cas d'utilisation de la dualité des données.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Configuration logicielle requise</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">Le tableau suivant répertorie les composants logiciels nécessaires à la mise en œuvre du cas d’utilisation.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">Bloc-notes AWS SageMaker</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">Procédures de déploiement</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">Le déploiement de la solution de dualité des données implique les tâches suivantes :</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">Connecteur BlueXP</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">Données pour l'apprentissage automatique</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Apprentissage automatique validé à partir de Jupyter Notebooks</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">Connecteur BlueXP</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">Dans cette validation, nous avons utilisé AWS.  Il est également applicable à Azure et Google Cloud.  Pour créer un connecteur BlueXP dans AWS, procédez comme suit :</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">Nous avons utilisé les informations d'identification basées sur mcarl-marketplace-subscription dans BlueXP.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">Choisissez la région adaptée à votre environnement (par exemple, us-east-1 [N. Virginia]) et sélectionnez la méthode d'authentification (par exemple, Assumer le rôle ou les clés AWS).  Dans cette validation, nous utilisons des clés AWS.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">Fournissez le nom du connecteur et créez un rôle.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">Fournissez les détails du réseau tels que le VPC, le sous-réseau ou la paire de clés, selon que vous avez besoin ou non d'une IP publique.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">Fournissez les détails du groupe de sécurité, tels que l'accès HTTP, HTTPS ou SSH à partir du type de source, tels que les informations sur n'importe quel emplacement et la plage IP.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">Révisez et créez le connecteur BlueXP .</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">Vérifiez que l'état de l'instance BlueXP EC2 est en cours d'exécution dans la console AWS et vérifiez l'adresse IP dans l'onglet *Réseau*.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">Connectez-vous à l'interface utilisateur du connecteur à partir du portail BlueXP ou vous pouvez utiliser l'adresse IP pour accéder à partir du navigateur.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">Pour créer une instance Cloud Volumes ONTAP dans BlueXP, procédez comme suit :</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">Créez un nouvel environnement de travail, sélectionnez le fournisseur de cloud et sélectionnez le type d'instance Cloud Volumes ONTAP (par exemple, single-CVO, HA ou Amazon FSx ONTAP pour ONTAP).</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Fournissez des détails tels que le nom et les informations d’identification du cluster Cloud Volumes ONTAP .  Dans cette validation, nous avons créé une instance Cloud Volumes ONTAP appelée<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> .</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Sélectionnez les services nécessaires pour Cloud Volumes ONTAP.  Dans cette validation, nous choisissons de surveiller uniquement, nous avons donc désactivé *Data Sense &amp; Compliance* et *Backup to Cloud Services*.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">Dans la section *Emplacement et connectivité*, sélectionnez la région AWS, le VPC, le sous-réseau, le groupe de sécurité, la méthode d'authentification SSH et un mot de passe ou une paire de clés.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">Choisissez la méthode de chargement.  Nous avons utilisé *Professionnel* pour cette validation.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">Vous pouvez choisir un package préconfiguré, tel que *POC et petites charges de travail*, *Charges de travail de production de données de base de données et d'application*, *DR rentable* ou *Charges de travail de production les plus performantes*.  Dans cette validation, nous choisissons *Poc et Petites charges de travail*.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">Créez un volume avec une taille spécifique, des protocoles autorisés et des options d’exportation.  Dans cette validation, nous avons créé un volume appelé<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">Choisissez un type de disque de profil et une politique de hiérarchisation.  Dans cette validation, nous avons désactivé *Efficacité du stockage* et *SSD à usage général – Performances dynamiques*.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">Enfin, examinez et créez l’instance Cloud Volumes ONTAP .  Attendez ensuite 15 à 20 minutes pour que BlueXP crée l’environnement de travail Cloud Volumes ONTAP .</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Configurez les paramètres suivants pour activer le protocole Duality.  Le protocole Duality (NFS/S3) est pris en charge à partir d' ONTAP 9.  12.1 et versions ultérieures.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">Dans cette validation, nous avons créé un SVM appelé<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> et le volume<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">Vérifiez que le SVM prend en charge les protocoles NFS et S3.  Sinon, modifiez le SVM pour les prendre en charge.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">Créez et installez un certificat CA si nécessaire.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">Créez une politique de données de service.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">Vérifiez les détails agrégés.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">Créez un utilisateur et un groupe.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">Créez un bucket sur le volume NFS.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">Pour créer un bloc-notes AWS à partir d'AWS SageMaker, procédez comme suit :</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Assurez-vous que l'utilisateur qui crée l'instance Notebook dispose d'une stratégie IAM AmazonSageMakerFullAccess ou fait partie d'un groupe existant disposant des droits AmazonSageMakerFullAccess.  Dans cette validation, l'utilisateur fait partie d'un groupe existant.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">Fournissez les informations suivantes :</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">Nom de l'instance du bloc-notes.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">Type d'instance.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">Identifiant de la plateforme.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">Sélectionnez le rôle IAM disposant des droits AmazonSageMakerFullAccess.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">Accès root – activer.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">Clé de cryptage - Ne sélectionnez aucun cryptage personnalisé.</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">Conservez les options par défaut restantes.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">Dans cette validation, les détails de l'instance SageMaker sont les suivants :</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">Capture d'écran illustrant l'étape.</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">Démarrez le bloc-notes AWS.</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Ouvrez le laboratoire Jupyter.</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">Connectez-vous au terminal et montez le volume Cloud Volumes ONTAP .</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">Vérifiez le bucket créé sur le volume Cloud Volumes ONTAP à l’aide des commandes AWS CLI.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">Dans cette validation, nous avons utilisé un ensemble de données de DBpedia, un effort communautaire participatif, pour extraire du contenu structuré à partir des informations créées dans divers projets Wikimedia.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">Téléchargez les données depuis l’emplacement GitHub de DBpedia et extrayez-les.  Utilisez le même terminal que celui utilisé dans la section précédente.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">Copiez les données vers l’emplacement Cloud Volumes ONTAP et vérifiez-les à partir du compartiment S3 à l’aide de l’AWS CLI.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">Effectuez une validation de base pour vous assurer que la fonctionnalité de lecture/écriture fonctionne sur le bucket S3.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Valider l'apprentissage automatique à partir des notebooks Jupyter</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">La validation suivante fournit la création, l'entraînement et le déploiement de modèles d'apprentissage automatique via la classification de texte en utilisant l'exemple SageMaker BlazingText ci-dessous :</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">Installez les packages boto3 et SageMaker.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">Sortir:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">Dans l'étape suivante, les données<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block> ) est téléchargé depuis le bucket s3<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> à une instance Jupyter Notebook utilisée dans l'apprentissage automatique.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">Le code suivant crée le mappage des indices entiers vers les étiquettes de classe qui sont utilisées pour récupérer le nom de classe réel pendant l'inférence.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">La sortie répertorie les fichiers et les dossiers dans le<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> bucket qui sont utilisés comme données pour la validation de l'apprentissage automatique AWS SageMaker.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">Démarrez la phase de prétraitement des données pour prétraiter les données de formation dans un format de texte tokenisé et séparé par des espaces qui peut être consommé par l'algorithme BlazingText et la bibliothèque nltk pour tokeniser les phrases d'entrée de l'ensemble de données DBPedia.  Téléchargez le tokenizer nltk et d'autres bibliothèques.  Le<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> appliqué à chaque instance de données en parallèle utilise le module multitraitement Python.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">Téléchargez l'ensemble de données formaté et de formation sur S3 afin qu'il puisse être utilisé par SageMaker pour exécuter des tâches de formation.  Téléchargez ensuite deux fichiers dans le bucket et préfixez l'emplacement à l'aide du SDK Python.</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">Configurez un emplacement de sortie sur S3 où l'artefact du modèle est chargé afin que les artefacts puissent être la sortie du travail de formation de l'algorithme.  Créer un<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> objet pour lancer le travail de formation.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">Définir le SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> avec des configurations de ressources et des hyperparamètres pour former la classification de texte sur l'ensemble de données DBPedia en utilisant le mode supervisé sur une instance c4.4xlarge.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">Préparez une poignée de main entre les canaux de données et l’algorithme.  Pour ce faire, créez le<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> objets des canaux de données et les conserver dans un dictionnaire pour que l'algorithme les consomme.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">Une fois le travail terminé, un message « Travail terminé » s'affiche.  Le modèle formé peut être trouvé dans le bucket S3 qui a été configuré comme<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> dans l'estimateur.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">Une fois la formation terminée, déployez le modèle formé en tant que point de terminaison hébergé en temps réel Amazon SageMaker pour effectuer des prédictions.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">Par défaut, le modèle renvoie une prédiction avec la probabilité la plus élevée.  Pour récupérer le haut<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> prédictions, ensemble<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> dans le fichier de configuration.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">Supprimez le point de terminaison avant de fermer le bloc-notes.</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">Les scientifiques et les ingénieurs de données ont souvent besoin d'accéder aux données stockées au format NFS, mais accéder à ces données directement à partir du protocole S3 dans AWS SageMaker peut être difficile car AWS ne prend en charge que l'accès au compartiment S3.  Cependant, NetApp ONTAP fournit une solution en permettant l’accès à double protocole pour NFS et S3.  Avec cette solution, les scientifiques et ingénieurs de données peuvent accéder aux données NFS des blocs-notes AWS SageMaker via les compartiments S3 de NetApp Cloud Volumes ONTAP.  Cette approche permet un accès et un partage faciles des mêmes données à partir de NFS et de S3 sans avoir besoin de logiciel supplémentaire.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967 : Gestion des données cloud avec la dualité fichier-objet NetApp et AWS SageMaker</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">Un cas d’utilisation potentiel pour l’accès au double protocole NFS et S3 se situe dans les domaines de l’apprentissage automatique et de la science des données.  Par exemple, une équipe de scientifiques des données peut travailler sur un projet d’apprentissage automatique utilisant AWS SageMaker, qui nécessite l’accès aux données stockées au format NFS.  Cependant, les données peuvent également devoir être consultées et partagées via des compartiments S3 pour collaborer avec d'autres membres de l'équipe ou pour s'intégrer à d'autres applications qui utilisent S3.</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">Cette solution utilise les technologies suivantes :</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*Bloc-notes AWS SageMaker.*  Offre des capacités d'apprentissage automatique aux développeurs et aux scientifiques des données pour créer, former et déployer efficacement des modèles ML de haute qualité.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP.*  Permet la découverte, le déploiement et l’exploitation du stockage sur site ainsi que sur AWS, Azure et Google Cloud.  Il offre une protection des données contre la perte de données, les cybermenaces et les pannes imprévues et optimise le stockage et l'infrastructure des données.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP.*  Fournit des volumes de stockage de niveau entreprise avec les protocoles NFS, SMB/CIFS, iSCSI et S3 sur AWS, Azure et Google Cloud, offrant aux utilisateurs une plus grande flexibilité dans l'accès et la gestion de leurs données dans le cloud.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP créé à partir de BlueXP pour stocker les données ML.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">La figure suivante montre les composants techniques de la solution.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">Cette figure montre les composants techniques de la solution.</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">En utilisant NetApp Cloud Volumes ONTAP, l’équipe peut stocker ses données dans un emplacement unique et les rendre accessibles avec les protocoles NFS et S3.  Les scientifiques des données peuvent accéder aux données au format NFS directement depuis AWS SageMaker, tandis que d'autres membres de l'équipe ou applications peuvent accéder aux mêmes données via des buckets S3.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">Cette approche permet d’accéder aux données et de les partager facilement et efficacement sans avoir besoin de logiciels supplémentaires ou de migration de données entre différentes solutions de stockage.  Il permet également un flux de travail et une collaboration plus rationalisés entre les membres de l’équipe, ce qui se traduit par un développement plus rapide et plus efficace des modèles d’apprentissage automatique.</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Ce document fournit des directives sur les meilleures pratiques pour l'utilisation de Kafka avec le stockage NetApp , y compris les tests de certification Confluent Kafka, les résultats de performances, le réglage, les connecteurs Kafka et la fonction de rééquilibrage automatique.</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Ce document fournit des directives sur les meilleures pratiques pour l'utilisation de Confluent Tiered Storage avec le stockage NetApp , y compris les tests de vérification, les résultats des performances du stockage hiérarchisé, le réglage, les connecteurs Confluent S3 et la fonction d'auto-équilibrage.  Compte tenu des politiques ILM, des performances de Confluent avec plusieurs tests de performances pour la vérification et des API S3 standard du secteur, le stockage d'objets NetApp StorageGRID est un choix optimal pour le stockage hiérarchisé de Confluent.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Qu'est-ce qu'Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Détails des paramètres du puits S3</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Stockage infini sur la plateforme Confluent</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Stockage hiérarchisé Confluent : bonnes pratiques et dimensionnement</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Connecteur de récepteur Amazon S3 pour la plateforme Confluent</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Dimensionnement Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Dimensionnement de StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Cas d'utilisation de Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Clusters Kafka auto-équilibrés sur la plateforme confluente 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Ce document décrit les meilleures pratiques pour l’utilisation de Kafka sur un contrôleur de stockage NetApp .</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka est une plateforme de streaming d'événements distribuée par la communauté, capable de gérer des milliards d'événements par jour.  Initialement conçu comme une file d'attente de messagerie, Kafka est basé sur une abstraction d'un journal de validation distribué.  Depuis sa création et sa publication en open source par LinkedIn en 2011, Kafka est passé d'une simple file d'attente de messages à une plateforme de streaming d'événements à part entière.  Confluent fournit la distribution d'Apache Kafka avec la plateforme Confluent.  La plateforme Confluent complète Kafka avec des fonctionnalités communautaires et commerciales supplémentaires conçues pour améliorer l'expérience de streaming des opérateurs et des développeurs en production à grande échelle.</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">Ce document décrit les meilleures pratiques pour l'utilisation du stockage hiérarchisé Confluent sur une offre de stockage d'objets NetApp en fournissant le contenu suivant :</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Vérification confluente avec le stockage d'objets NetApp – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Tests de performances de stockage hiérarchisé</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Lignes directrices sur les meilleures pratiques pour Confluent sur les systèmes de stockage NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Pourquoi choisir le stockage hiérarchisé Confluent ?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">cet article de Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent est devenu la plateforme de streaming en temps réel par défaut pour de nombreuses applications, en particulier pour les charges de travail de Big Data, d'analyse et de streaming.  Le stockage hiérarchisé permet aux utilisateurs de séparer le calcul du stockage sur la plateforme Confluent.  Il rend le stockage des données plus rentable, vous permet de stocker des quantités pratiquement infinies de données et d'augmenter (ou de réduire) les charges de travail à la demande, et facilite les tâches administratives telles que le rééquilibrage des données et des locataires.  Les systèmes de stockage compatibles S3 peuvent tirer parti de toutes ces fonctionnalités pour démocratiser les données avec tous les événements en un seul endroit, éliminant ainsi le besoin d'une ingénierie de données complexe.  Pour plus d'informations sur les raisons pour lesquelles vous devriez utiliser le stockage hiérarchisé pour Kafka, consultez<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> .</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Pourquoi NetApp StorageGRID pour le stockage hiérarchisé ?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID est une plate-forme de stockage d'objets leader du secteur de NetApp.  StorageGRID est une solution de stockage basée sur des objets définie par logiciel qui prend en charge les API d'objets standard du secteur, notamment l'API Amazon Simple Storage Service (S3).  StorageGRID stocke et gère les données non structurées à grande échelle pour fournir un stockage d'objets sécurisé et durable.  Le contenu est placé au bon endroit, au bon moment et sur le bon niveau de stockage, optimisant ainsi les flux de travail et réduisant les coûts des médias riches distribués à l'échelle mondiale.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">Le principal facteur de différenciation de StorageGRID est son moteur de politique de gestion du cycle de vie des informations (ILM) qui permet une gestion du cycle de vie des données basée sur des politiques.  Le moteur de politique peut utiliser les métadonnées pour gérer la manière dont les données sont stockées tout au long de leur durée de vie afin d'optimiser initialement les performances et d'optimiser automatiquement les coûts et la durabilité à mesure que les données vieillissent.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Activation du stockage hiérarchisé Confluent</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">L’idée de base du stockage hiérarchisé est de séparer les tâches de stockage des données du traitement des données.  Grâce à cette séparation, il devient beaucoup plus facile pour le niveau de stockage des données et le niveau de traitement des données de s'adapter indépendamment.</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Une solution de stockage à plusieurs niveaux pour Confluent doit tenir compte de deux facteurs.  Tout d’abord, il doit contourner ou éviter les propriétés courantes de cohérence et de disponibilité du magasin d’objets, telles que les incohérences dans les opérations LIST et l’indisponibilité occasionnelle des objets.  Deuxièmement, il doit gérer correctement l'interaction entre le stockage hiérarchisé et le modèle de réplication et de tolérance aux pannes de Kafka, y compris la possibilité que les leaders zombies continuent à hiérarchiser les plages de décalage.  Le stockage d'objets NetApp offre à la fois une disponibilité d'objet cohérente et un modèle HA qui rend le stockage fatigué disponible pour les plages de décalage de niveaux.  Le stockage d'objets NetApp offre une disponibilité d'objet cohérente et un modèle HA pour rendre le stockage fatigué disponible pour les plages de décalage de niveaux.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Avec le stockage hiérarchisé, vous pouvez utiliser des plates-formes hautes performances pour les lectures et écritures à faible latence près de la fin de vos données en streaming, et vous pouvez également utiliser des magasins d'objets évolutifs et moins chers comme NetApp StorageGRID pour les lectures historiques à haut débit.  Nous avons également une solution technique pour Spark avec le contrôleur de stockage NetApp et les détails sont ici.  La figure suivante montre comment Kafka s’intègre dans un pipeline d’analyse en temps réel.</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">La figure suivante illustre comment NetApp StorageGRID s’intègre en tant que niveau de stockage d’objets de Confluent Kafka.</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Cette section couvre le matériel et les logiciels utilisés pour la certification Confluent.  Ces informations s’appliquent au déploiement de Kafka avec le stockage NetApp .</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">Dimensionnement</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Le dimensionnement de Kafka peut être effectué avec quatre modes de configuration : simple, granulaire, inversé et partitions.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Simple</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">Le mode simple convient aux nouveaux utilisateurs d'Apache Kafka ou aux premiers cas d'utilisation.  Pour ce mode, vous fournissez des exigences telles que le débit en Mo/s, la diffusion en lecture, la rétention et le pourcentage d'utilisation des ressources (60 % par défaut).  Vous entrez également dans l'environnement, tel que sur site (bare-metal, VMware, Kubernetes ou OpenStack) ou dans le cloud.  Sur la base de ces informations, le dimensionnement d'un cluster Kafka fournit le nombre de serveurs requis pour le courtier, le zookeeper, les travailleurs de connexion Apache Kafka, le registre de schémas, un proxy REST, ksqlDB et le centre de contrôle Confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Pour le stockage hiérarchisé, envisagez le mode de configuration granulaire pour dimensionner un cluster Kafka.  Le mode granulaire convient aux utilisateurs expérimentés d'Apache Kafka ou aux cas d'utilisation bien définis.  Cette section décrit le dimensionnement des producteurs, des processeurs de flux et des consommateurs.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Producteurs</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Pour décrire les producteurs d'Apache Kafka (par exemple un client natif, un proxy REST ou un connecteur Kafka), fournissez les informations suivantes :</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nom.*  Étincelle.</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*Type de producteur.*  Application ou service, proxy (REST, MQTT, autre) et base de données existante (RDBMS, NOSQL, autre).  Vous pouvez également sélectionner « Je ne sais pas ».</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Débit moyen.*  En événements par seconde (1 000 000 par exemple).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Débit maximal.*  En événements par seconde (4 000 000 par exemple).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Taille moyenne des messages.*  En octets, non compressé (max 1 Mo ; 1000 par exemple).</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*Format du message.*  Les options incluent Avro, JSON, les tampons de protocole, le binaire, le texte, « Je ne sais pas » et autres.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Facteur de réplication.*  Les options sont 1, 2, 3 (recommandation Confluent), 4, 5 ou 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Temps de rétention.*  Un jour (par exemple).  Combien de temps souhaitez-vous que vos données soient stockées dans Apache Kafka ?  Entrez -1 avec n'importe quelle unité pour un temps infini.  Le calculateur suppose une durée de rétention de 10 ans pour une rétention infinie.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Cochez la case « Activer le stockage à plusieurs niveaux pour réduire le nombre de courtiers et autoriser un stockage infini ? »</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Lorsque le stockage hiérarchisé est activé, les champs de rétention contrôlent l'ensemble de données chaudes stockées localement sur le courtier.  Les champs de conservation des archives contrôlent la durée pendant laquelle les données sont stockées dans le stockage d'objets d'archives.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Conservation des archives.*  Un an (par exemple).  Combien de temps souhaitez-vous que vos données soient stockées dans un stockage d'archives ?  Entrez -1 avec n'importe quelle unité pour une durée infinie.  Le calculateur suppose une conservation de 10 ans pour une conservation infinie.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Multiplicateur de croissance.*  1 (par exemple).  Si la valeur de ce paramètre est basée sur le débit actuel, définissez-la sur 1.  Pour dimensionner en fonction de la croissance supplémentaire, définissez ce paramètre sur un multiplicateur de croissance.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Nombre d'instances de producteurs.*  10 (par exemple).  Combien d'instances de producteurs seront exécutées ?  Cette entrée est nécessaire pour intégrer la charge du processeur dans le calcul de dimensionnement.  Une valeur vide indique que la charge du processeur n'est pas intégrée au calcul.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Sur la base de cet exemple d’entrée, le dimensionnement a l’effet suivant sur les producteurs :</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Débit moyen en octets non compressés : 1 Go/s.  Débit maximal en octets non compressés : 4 Go/s.  Débit moyen en octets compressés : 400 Mo/s.  Débit maximal en octets compressés : 1,6 Go/s.  Ceci est basé sur un taux de compression par défaut de 60 % (vous pouvez modifier cette valeur).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Stockage total de hotset sur courtier requis : 31 104 To, y compris la réplication, compressée.  Stockage d'archives hors courtier total requis : 378 432 To, compressé.  Utiliser<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> pour le dimensionnement de StorageGRID .</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Les processeurs de flux doivent décrire leurs applications ou services qui consomment des données d'Apache Kafka et les reproduisent dans Apache Kafka.  Dans la plupart des cas, ils sont intégrés à ksqlDB ou à Kafka Streams.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nom.*  Streamer Spark.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Temps de traitement.*  Combien de temps ce processeur prend-il pour traiter un seul message ?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (transformation simple et sans état) [exemple], 10 ms (opération avec état en mémoire).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (opération réseau ou disque avec état), 1 000 ms (appel REST tiers).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">J'ai évalué ce paramètre et je sais exactement combien de temps cela prend.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Rétention de sortie.*  1 jour (exemple).  Un processeur de flux renvoie sa sortie à Apache Kafka.  Combien de temps souhaitez-vous que ces données de sortie soient stockées dans Apache Kafka ?  Entrez -1 avec n'importe quelle unité pour une durée infinie.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Cochez la case « Activer le stockage à plusieurs niveaux pour réduire le nombre de courtiers et autoriser un stockage infini ? »</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Conservation des archives.*  1 an (par exemple).  Combien de temps souhaitez-vous que vos données soient stockées dans un stockage d'archives ?  Entrez -1 avec n'importe quelle unité pour une durée infinie.  Le calculateur suppose une conservation de 10 ans pour une conservation infinie.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Pourcentage de transmission de sortie.*  100 (par exemple).  Un processeur de flux renvoie sa sortie à Apache Kafka.  Quel pourcentage du débit entrant sera renvoyé vers Apache Kafka ?  Par exemple, si le débit entrant est de 20 Mo/s et que cette valeur est de 10, le débit de sortie sera de 2 Mo/s.</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">À partir de quelles applications cela est-il lu ?  Sélectionnez « Spark », le nom utilisé dans le dimensionnement basé sur le type de producteur.  Sur la base des données ci-dessus, vous pouvez vous attendre aux effets suivants du dimensionnement sur les instances de processeur de flux et les estimations de partition de sujet :</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Cette application de traitement de flux nécessite le nombre d'instances suivant.  Les sujets entrants nécessitent probablement également autant de partitions.  Contactez Confluent pour confirmer ce paramètre.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1 000 pour un débit moyen sans multiplicateur de croissance</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4 000 pour un débit maximal sans multiplicateur de croissance</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1 000 pour un débit moyen avec un multiplicateur de croissance</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4 000 pour un débit maximal avec un multiplicateur de croissance</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consommateurs</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Décrivez vos applications ou services qui consomment des données d'Apache Kafka et ne les réinjectent pas dans Apache Kafka ; par exemple, un client natif ou un connecteur Kafka.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nom.*  Consommateur Spark.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Temps de traitement.*  Combien de temps faut-il à ce consommateur pour traiter un seul message ?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (par exemple, une tâche simple et sans état comme la journalisation)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (écritures rapides dans une banque de données)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (écritures lentes dans une banque de données)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (appel REST tiers)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Un autre processus de référence de durée connue.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Type de consommateur.*  Application, proxy ou récepteur vers un magasin de données existant (SGBDR, NoSQL, autre).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">À partir de quelles applications cela est-il lu ?  Connectez ce paramètre au dimensionnement du producteur et du flux déterminé précédemment.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Sur la base des données ci-dessus, vous devez déterminer le dimensionnement des instances de consommateur et les estimations de partition de sujet.  Une application consommateur nécessite le nombre d’instances suivant.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2 000 pour un débit moyen, sans multiplicateur de croissance</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8 000 pour un débit maximal, sans multiplicateur de croissance</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2 000 pour un débit moyen, multiplicateur de croissance inclus</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8 000 pour un débit maximal, multiplicateur de croissance inclus</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Les sujets entrants ont probablement également besoin de ce nombre de partitions.  Contactez Confluent pour confirmer.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">En plus des exigences pour les producteurs, les processeurs de flux et les consommateurs, vous devez fournir les exigences supplémentaires suivantes :</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Il est temps de reconstruire.*  Par exemple, 4 heures.  Si un hôte de courtier Apache Kafka tombe en panne, ses données sont perdues et un nouvel hôte est provisionné pour remplacer l'hôte défaillant, à quelle vitesse ce nouvel hôte doit-il se reconstruire ?  Laissez ce paramètre vide si la valeur est inconnue.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Objectif d'utilisation des ressources (pourcentage).*  Par exemple, 60.  Dans quelle mesure souhaitez-vous que vos hôtes soient utilisés pendant le débit moyen ?  Confluent recommande une utilisation de 60 %, sauf si vous utilisez des clusters auto-équilibrés Confluent, auquel cas l'utilisation peut être plus élevée.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Décrivez votre environnement</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*Dans quel environnement votre cluster fonctionnera-t-il ?*  Amazon Web Services, Microsoft Azure, plateforme cloud Google, bare-metal sur site, VMware sur site, OpenStack sur site ou Kubernates sur site ?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Détails de l'hôte.*  Nombre de cœurs : 48 (par exemple), type de carte réseau (10 GbE, 40 GbE, 16 GbE, 1 GbE ou autre type).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Volumes de stockage.*  Hôte : 12 (par exemple).  Combien de disques durs ou SSD sont pris en charge par hôte ?  Confluent recommande 12 disques durs par hôte.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacité/volume de stockage (en Go).*  1000 (par exemple).  Quelle quantité de stockage un seul volume peut-il stocker en gigaoctets ?  Confluent recommande des disques de 1 To.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configuration de stockage.*  Comment les volumes de stockage sont-ils configurés ?  Confluent recommande RAID10 pour profiter de toutes les fonctionnalités de Confluent.  JBOD, SAN, RAID 1, RAID 0, RAID 5 et d'autres types sont également pris en charge.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Débit d'un volume unique (Mbit/s).*  125 (par exemple).  À quelle vitesse un seul volume de stockage peut-il lire ou écrire en mégaoctets par seconde ?  Confluent recommande des disques durs standard, qui ont généralement un débit de 125 Mo/s.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacité de mémoire (Go).*  64 (par exemple).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Après avoir déterminé vos variables environnementales, sélectionnez Dimensionner mon cluster.  Sur la base des paramètres d'exemple indiqués ci-dessus, nous avons déterminé le dimensionnement suivant pour Confluent Kafka :</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.*  Nombre de courtiers : 22.  Votre cluster est lié au stockage.  Envisagez d’activer le stockage hiérarchisé pour réduire le nombre d’hôtes et permettre un stockage infini.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper.*  Nombre : 5 ; Apache Kafka Connect Workers : Nombre : 2 ; Registre de schémas : Nombre : 2 ; Proxy REST : Nombre : 2 ; ksqlDB : Nombre : 2 ; Centre de contrôle Confluent : Nombre : 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Utilisez le mode inversé pour les équipes de plateforme sans cas d’utilisation en tête.  Utilisez le mode partitions pour calculer le nombre de partitions requises par une seule rubrique.  Voir<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> pour le dimensionnement basé sur les modes inverse et partitions.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">Détails de l'architecture de la solution</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Cette section couvre le matériel et les logiciels utilisés pour la vérification Confluent.  Ces informations s’appliquent au déploiement de la plateforme Confluent avec le stockage NetApp .  Le tableau suivant couvre l’architecture de la solution testée et les composants de base.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Composants de la solution</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Détails</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka version 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Trois gardiens de zoo</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinq serveurs de courtage</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinq serveurs d'outils</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Un Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Un centre de contrôle</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (Ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Tous les serveurs</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID pour le stockage hiérarchisé</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Logiciel StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (équilibreur de charge)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocole S3</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (connectivité réseau entre le courtier et les instances StorageGRID )</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 serveurs Fujitsu PRIMERGY RX2540</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Chacun équipé de : * 2 CPU, 16 cœurs physiques au total * Intel Xeon * 256 Go de mémoire physique * Port double 100 GbE</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">Ce document fournit des directives de bonnes pratiques pour l'utilisation de Dremio avec le stockage NetApp , y compris les tests de certification TPCDS, le réglage et les détails des cas d'utilisation client.</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">En conclusion, ce rapport technique a fourni des détails de déploiement complets de q Hybrid Iceberg Lakehouse avec Dremio en conjonction avec diverses sources de données provenant de contrôleurs de stockage NetApp , notamment ONTAP S3, NAS et StorageGRID.  Le processus de déploiement a été exécuté avec succès et l’outil d’analyse comparative TPC-DS a été utilisé pour effectuer 99 requêtes SQL sur les différentes sources de données.  Le rapport a également exploré les cas d’utilisation des clients au sein de NetApp, démontrant la polyvalence et l’efficacité de Dremio pour répondre à diverses exigences commerciales.  De plus, un cas d’utilisation spécifique impliquant un client de vente de pièces automobiles a été examiné, mettant en évidence l’application pratique et les avantages de l’exploitation de Dremio pour l’analyse et la compréhension des données.</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">Dans l’ensemble, ce document constitue une ressource précieuse pour comprendre le déploiement et l’utilisation de Dremio avec les contrôleurs de stockage NetApp , en présentant ses capacités et son potentiel pour favoriser la prise de décision et l’optimisation basées sur les données dans divers secteurs.</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Installation du gardien de zoo</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">Dremio</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">Configuration de Dremio avec storageGRID</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">Cas d'utilisation de NetApp</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">Nous avons réalisé la certification avec Dremio Platform avec validation lakehouse dans le stockage d'objets NetApp .</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">Procédure de déploiement</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">Figure montrant l'architecture dremio avec le contrôleur de stockage NetApp</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">Dans cette validation d'architecture de référence, nous avons utilisé une configuration Dremio composée d'un coordinateur et de quatre exécuteurs<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">Configuration de NetApp</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">Initialisation du système de stockage</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">Création d'une machine virtuelle de stockage (SVM)</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">Affectation des interfaces réseau logiques</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">Configuration et licence NFS, S3</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">Veuillez suivre les étapes ci-dessous pour NFS (Network File System) : 1.  Créez un volume Flex Group pour NFSv4 ou NFSv3.  Dans notre configuration pour cette validation, nous avons utilisé 48 SSD, 1 SSD dédié au volume racine du contrôleur et 47 SSD répartis pour NFSv4]].  Vérifiez que la stratégie d’exportation NFS pour le volume Flex Group dispose d’autorisations de lecture/écriture pour le réseau des serveurs Dremio.</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">Sur tous les serveurs Dremio, créez un dossier et montez le volume Flex Group sur ce dossier via une interface logique (LIF) sur chaque serveur Dremio.</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">Veuillez suivre les étapes ci-dessous pour S3 (Simple Storage Service) :</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">Configurez un serveur de magasin d'objets avec HTTP activé et le statut d'administrateur défini sur « up » à l'aide de la commande « vserver object-store-server create ».  Vous avez la possibilité d'activer HTTPS et de définir un port d'écoute personnalisé.</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">Créez un utilisateur object-store-server à l'aide de la commande « vserver object-store-server user create -user &lt;username&gt; ».</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">Pour obtenir la clé d'accès et la clé secrète, vous pouvez exécuter la commande suivante : « set diag; vserver object-store-server user show -user &lt;username&gt; ».  Cependant, à l’avenir, ces clés seront fournies lors du processus de création de l’utilisateur ou pourront être récupérées à l’aide d’appels d’API REST.</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">Créez un groupe object-store-server à l’aide de l’utilisateur créé à l’étape 2 et accordez l’accès.  Dans cet exemple, nous avons fourni « FullAccess ».</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">Créez deux compartiments S3 en définissant leur type sur « S3 ».  Un pour la configuration Dremio et un pour les données client.</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Configuration du gardien de zoo</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Vous pouvez utiliser la configuration zookeeper fournie par Dremio.  Dans cette validation, nous avons utilisé un zookeeper distinct. Nous avons suivi les étapes mentionnées dans ce lien Web.<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Configuration de Dremio</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">Nous avons suivi ce lien Web pour installer Dremio via tar ball.</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Créez un groupe Dremio.</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">Créez un utilisateur dremio.</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Créez des répertoires Dremio.</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">Téléchargez le fichier tar depuis<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Décompressez Dremio dans le répertoire /opt/dremio.</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">Créez un lien symbolique pour le dossier de configuration.</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">Configurez votre configuration de service (configuration SystemD).</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">Copiez le fichier d'unité pour le démon dremio de /opt/dremio/share/dremio.service vers /etc/systemd/system/dremio.service.</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">Redémarrer le système</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">Activer dremio pour démarrer au démarrage.</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">Configurer Dremio sur le coordinateur.  Voir Configuration Dremio pour plus d'informations</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">Core-site.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">La configuration Dremio est stockée dans le stockage d'objets NetApp .  Dans notre validation, le bucket « dremioconf » réside dans un bucket S3 ontap.  L'image ci-dessous montre quelques détails des dossiers « scratch » et « uploads » du bucket S3 « dremioconf ».</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">Figure montrant Dremio avec le stockage d'objets NetApp</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">Configurer Dremio sur les exécuteurs.  Dans notre configuration, nous avons 3 exécuteurs.</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – identique à la configuration du coordinateur.</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp recommande StorageGRID comme solution de stockage d’objets principale pour les environnements Datalake et Lakehouse.  De plus, NetApp ONTAP est utilisé pour la dualité fichier/objet.  Dans le cadre de ce document, nous avons effectué des tests sur ONTAP S3 en réponse à une demande client, et il fonctionne avec succès comme source de données.</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">Configuration de sources multiples</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Configurez ONTAP S3 et storageGRID comme source s3 dans Dremio.</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Tableau de bord Dremio -&gt; ensembles de données -&gt; sources -&gt; ajouter une source.</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">Dans la section générale, veuillez mettre à jour l'accès AWS et la clé secrète</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">Dans l'option avancée, activez le mode de compatibilité, mettez à jour les propriétés de connexion avec les détails ci-dessous.  L'adresse IP/le nom du point de terminaison du contrôleur de stockage NetApp provenant d'ontap S3 ou de storageGRID.</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">Activer la mise en cache locale lorsque cela est possible, pourcentage maximal du cache total disponible à utiliser lorsque cela est possible = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">Figure montrant la liste des fichiers du stockage d'objets NetApp</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">Affichez ensuite la liste des buckets du stockage d’objets NetApp .<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">Exemple de vue des détails du bucket storageGRID<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Configurer NAS (en particulier NFS) comme source dans Dremio.</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">Dans la section générale, entrez le nom et le chemin de montage NFS.  Assurez-vous que le chemin de montage NFS est monté sur le même dossier sur tous les nœuds du cluster Dremio.</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">Ce document décrit les meilleures pratiques pour l’utilisation de Dremio sur un contrôleur de stockage NetApp .</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">La solution hybride Iceberg Lakehouse de nouvelle génération de NetApp et Dremio</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">Dans ce document, nous discutons des détails de déploiement de Dremio avec différentes sources de données provenant de contrôleurs de stockage NetApp , notamment ONTAP S3, NAS et StorageGRID.  Au cours du déploiement, nous avons utilisé l’outil d’analyse comparative TPC-DS pour exécuter 99 requêtes SQL sur diverses sources.  Le document explore également les cas d’utilisation des clients au sein de NetApp, ainsi qu’un cas d’utilisation impliquant un client de vente de pièces automobiles.</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">Cette section couvre le matériel et les logiciels utilisés pour la certification dremio.  Ces informations s’appliquent au déploiement de dremio avec le stockage NetApp .</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Présentation de la solution</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">La solution Hybrid Iceberg Lakehouse offre des avantages uniques pour répondre aux défis auxquels sont confrontés les clients du lac de données.  En tirant parti de la plate-forme Dremio Unified Lakehouse et des solutions NetApp ONTAP, StorageGRID et NetApp Cloud, les entreprises peuvent ajouter une valeur significative à leurs opérations commerciales.  La solution fournit non seulement un accès à plusieurs sources de données, y compris les sources NetApp , mais améliore également les performances analytiques globales et aide les entreprises à générer des informations commerciales qui conduisent à la croissance de l'entreprise.</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Présentation de NetApp</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">Les offres de NetApp, telles que ONTAP et StorageGRID, permettent la séparation du stockage et du calcul, permettant une utilisation optimale des ressources en fonction d'exigences spécifiques.  Cette flexibilité permet aux clients de faire évoluer leur stockage de manière indépendante à l'aide des solutions de stockage NetApp</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">En exploitant les contrôleurs de stockage de NetApp, les clients peuvent efficacement fournir des données à leur base de données vectorielle à l'aide des protocoles NFS et S3.  Ces protocoles facilitent le stockage des données client et gèrent l'index de la base de données vectorielle, éliminant ainsi le besoin de plusieurs copies de données accessibles via des méthodes de fichiers et d'objets.</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP fournit une prise en charge native du stockage NAS et d'objets auprès des principaux fournisseurs de services cloud tels qu'AWS, Azure et Google Cloud.  Cette large compatibilité garantit une intégration transparente, permettant la mobilité des données client, l'accessibilité globale, la reprise après sinistre, l'évolutivité dynamique et des performances élevées.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">Notre stockage d'objets de pointe, storageGRID, offre un moteur de politique puissant pour le placement automatisé des données, des options de déploiement flexibles et une durabilité inégalée avec un codage d'effacement en couches.  Il dispose d'une architecture évolutive prenant en charge des milliards d'objets et des pétaoctets de données dans un seul espace de noms.  La solution permet l'intégration du cloud hybride, permettant la hiérarchisation des données vers les principales plates-formes cloud.  Il a été reconnu comme leader dans l'évaluation mondiale des fournisseurs basés sur les objets IDC Marketscape 2019.</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">De plus, storageGRID excelle dans la gestion de données non structurées à grande échelle avec un stockage d'objets défini par logiciel, une géo-redondance et des capacités multisites.  Il intègre une gestion du cycle de vie des informations basée sur des politiques et offre des fonctionnalités d'intégration dans le cloud telles que la mise en miroir et la recherche.  Elle dispose de diverses certifications, notamment Common Criteria, NF203 Digital Safe Component, ISO/IEC 25051, KPMG et Cohasset Compliance Assessment.</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">En résumé, NetApp storageGRID offre des fonctionnalités puissantes, une évolutivité, une intégration cloud hybride et des certifications de conformité pour une gestion efficace des données non structurées à grande échelle.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP est une solution de stockage robuste qui offre une large gamme de fonctionnalités d'entreprise.  Il inclut Snapshot, qui fournit des sauvegardes instantanées cohérentes avec les applications et inviolables.  SnapRestore permet une restauration quasi instantanée des sauvegardes à la demande, tandis que SnapMirror offre des fonctionnalités intégrées de sauvegarde à distance et de reprise après sinistre.  La solution intègre également la protection autonome contre les ransomwares (ARP), garantissant la sécurité des données avec des fonctionnalités telles que la vérification multi-administrateur, le cryptage des données au repos avec certification FIPS, le cryptage des données en transit, l'authentification multifacteur (MFA) et le contrôle d'accès basé sur les rôles (RBAC).  La journalisation complète, l'audit, la gestion des clés intégrées et externes, la purge sécurisée et la gestion sécurisée de plusieurs locataires améliorent encore la sécurité et la conformité des données.</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP propose également SnapLock, qui offre une conservation des données conforme à la réglementation avec des niveaux élevés d'intégrité, de performances et de conservation à un faible coût total de possession.  Il est entièrement intégré à NetApp ONTAP 9 et offre une protection contre les actes malveillants, les administrateurs malveillants et les ransomwares.</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">La solution comprend le cryptage NSE/NVE pour le cryptage en vol et des données au repos, l'accès administrateur multifacteur et la vérification multi-administrateur.  Active IQ fournit des analyses prédictives et des mesures correctives basées sur l'IA, tandis que QoS garantit la qualité du contrôle de la charge de travail.  L'intégration de la gestion et de l'automatisation est intuitive via SysMgr/GUI/CLI/API.  FabricPool permet la hiérarchisation automatique des données et la solution offre une efficacité grâce à la compression, la déduplication et le compactage des données en ligne.  NetApp garantit l'atteinte des objectifs d'efficacité de la charge de travail sans frais pour le client.</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP prend en charge divers protocoles, notamment NVMe/FC, FC, NVMe/TCP, iSCSI, NFS, SMB et S3, ce qui en fait une solution de stockage unifiée.  Dans l’ensemble, NetApp ONTAP offre des fonctionnalités d’entreprise étendues, une sécurité robuste, une conformité, une efficacité et une polyvalence pour répondre à divers besoins de stockage.</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Présentation de Dremio</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio est la plateforme Lakehouse unifiée pour l'analyse en libre-service et l'IA.  La plateforme d'analyse unifiée Dremio rapproche les utilisateurs des données avec la flexibilité, l'évolutivité et les performances du Lakehouse à une fraction du coût des solutions d'entrepôt de données existantes.  Dremio permet des analyses « shift-left » pour éliminer l'intégration de données et l'ETL complexes et coûteux, offrant ainsi des analyses transparentes à l'échelle de l'entreprise sans aucun mouvement de données.  Dremio propose également :</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">Analyses en libre-service faciles à utiliser, activées grâce à une couche sémantique universelle et à un moteur de requête SQL hautement performant et étroitement intégré, facilitant la connexion, la gouvernance et l'analyse de toutes les données, à la fois dans le cloud et sur site.</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Les capacités de gestion de lakehouse natives d'Apache Iceberg de Dremio simplifient la découverte de données et automatisent l'optimisation des données, offrant des analyses hautes performances avec un versionnage de données inspiré de Git.</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Fondamentalement construit sur l'open source et les normes ouvertes, Dremio permet aux entreprises d'éviter le verrouillage et de rester positionnées pour l'innovation.  Les entreprises font confiance à Dremio comme étant la plateforme lakehouse la plus simple à utiliser avec le meilleur rapport qualité-prix pour toutes les charges de travail.</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Quelle valeur la solution Dremio et NetApp Hybrid Iceberg Lakehouse apporte-t-elle aux clients ?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*Gestion et accessibilité des données améliorées* : Dremio est bien connu pour sa plateforme de data lakehouse qui permet aux organisations d'interroger les données directement à partir de leurs lacs de données à grande vitesse.  NetApp, quant à lui, est un fournisseur leader de services de données cloud et de solutions de stockage de données.  L'offre conjointe offre aux clients une solution complète pour stocker, gérer, accéder et analyser les données de leur entreprise de manière efficace et efficiente.</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*Optimisation des performances* : Grâce à l'expertise de NetApp en matière de stockage de données et aux capacités de Dremio en matière de traitement et d'optimisation des données, le partenariat offre une solution qui améliore les performances des opérations de données, réduit la latence et augmente la vitesse d'accès aux informations commerciales.  Dremio a même apporté des avantages en termes de performances à l'infrastructure analytique informatique interne de NetApp.</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*Évolutivité* : Dremio et NetApp proposent tous deux une solution conçue pour évoluer.  La solution commune offre aux clients des environnements de stockage de données, de gestion de données et d’analyse hautement évolutifs.  Dans un environnement Hybrid Iceberg Lakehouse, le moteur de requête Dremio SQL associé à NetApp StorageGRID offre une évolutivité, une concurrence et des performances de requête inégalées, capables de gérer les besoins analytiques de toute entreprise.</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*Sécurité et gouvernance des données* : Les deux entreprises mettent fortement l’accent sur la sécurité et la gouvernance des données.  Ensemble, ils offrent des fonctionnalités robustes de sécurité et de gouvernance des données, garantissant que les données sont protégées et que les exigences de gouvernance des données sont respectées.  Des fonctionnalités telles que les contrôles d'accès basés sur les rôles et à granularité fine, l'audit complet, la lignée de données de bout en bout, la gestion unifiée des identités et l'authentification unique avec un cadre de conformité et de sécurité étendu garantissent que les environnements de données analytiques des entreprises sont sécurisés et gouvernés.</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*Efficacité des coûts* : En intégrant le moteur de lac de données de Dremio aux solutions de stockage de NetApp, les clients peuvent réduire les coûts associés à la gestion et au déplacement des données.  Les organisations peuvent également passer d’environnements de lac de données hérités à une solution lakehouse plus moderne composée de NetApp et Dremio.  Cette solution Hybrid Iceberg Lakehouse offre des performances de requête à grande vitesse et une concurrence de requêtes à la pointe du marché qui réduit le coût total de possession et le temps d'analyse de l'entreprise.</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">Cette section décrit la technologie utilisée dans cette solution.</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">Exigences technologiques</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">Les configurations matérielles et logicielles décrites ci-dessous ont été utilisées pour les validations effectuées dans ce document.  Ces configurations servent de guide pour vous aider à configurer votre environnement. Cependant, veuillez noter que les composants spécifiques peuvent varier en fonction des exigences individuelles des clients.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Configuration matérielle requise</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Matériel</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">Paire de baies de stockage NetApp AFF HA</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 x 3,49 To SSD-NVM</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">Deux compartiments S3 : métadonnées Dremio et données client.</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 processeurs</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">Processeur Intel Xeon Gold 6142 à 2,60 GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM de mémoire physique</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 port réseau 100 GbE</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Réseautage</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7,68 To * Deux compartiments S3 : métadonnées Dremio et données client.</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">version - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">Édition Entreprise</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">Sur site</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">Cluster Dremio à 5 nœuds</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 maître coordinateur et 4 exécuteurs</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">Cette section couvre les détails du cas d'utilisation client de Dremio avec le stockage d'objets NetApp.</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">Cas d'utilisation client</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">Cas d'utilisation de NetApp ActiveIQ</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">Ancienne architecture ActiveIQ</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*Défi* : La solution interne Active IQ de NetApp, initialement conçue pour prendre en charge de nombreux cas d'utilisation, a évolué vers une offre complète destinée aux utilisateurs internes et aux clients.  Cependant, l'infrastructure back-end sous-jacente basée sur Hadoop/MapR posait des problèmes de coût et de performance, en raison de la croissance rapide des données et du besoin d'un accès efficace aux données.  La mise à l’échelle du stockage impliquait l’ajout de ressources informatiques inutiles, ce qui entraînait une augmentation des coûts.</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">De plus, la gestion du cluster Hadoop prenait du temps et nécessitait une expertise spécialisée.  Les problèmes de performance et de gestion des données ont encore compliqué la situation, les requêtes prenant en moyenne 45 minutes et les ressources étant limitées en raison de mauvaises configurations.  Pour relever ces défis, NetApp a cherché une alternative à l'environnement Hadoop existant et a déterminé qu'une nouvelle solution moderne basée sur Dremio réduirait les coûts, découplerait le stockage et le calcul, améliorerait les performances, simplifierait la gestion des données, offrirait des contrôles précis et fournirait des capacités de reprise après sinistre.</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">Nouvelle architecture ActiveIQ avec dremio</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*Solution*:<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio a permis à NetApp de moderniser son infrastructure de données basée sur Hadoop selon une approche progressive, fournissant une feuille de route pour une analyse unifiée.  Contrairement à d’autres fournisseurs qui nécessitaient des modifications importantes du traitement des données, Dremio s’est parfaitement intégré aux pipelines existants, économisant ainsi du temps et des dépenses lors de la migration.  En passant à un environnement entièrement conteneurisé, NetApp a réduit les frais de gestion, amélioré la sécurité et renforcé la résilience.  L'adoption par Dremio d'écosystèmes ouverts tels qu'Apache Iceberg et Arrow a assuré la pérennité, la transparence et l'extensibilité.</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">En remplacement de l'infrastructure Hadoop/Hive, Dremio offrait des fonctionnalités pour les cas d'utilisation secondaires via la couche sémantique.  Bien que les mécanismes d'ETL et d'ingestion de données basés sur Spark existants soient restés, Dremio a fourni une couche d'accès unifiée pour faciliter la découverte et l'exploration des données sans duplication.  Cette approche a considérablement réduit les facteurs de réplication des données et découplé le stockage et le calcul.</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*Avantages* : Avec Dremio, NetApp a réalisé des réductions de coûts significatives en minimisant la consommation de calcul et les besoins en espace disque dans ses environnements de données.  Le nouveau lac de données Active IQ est composé de 8 900 tables contenant 3 pétaoctets de données, contre plus de 7 pétaoctets pour l'infrastructure précédente.  La migration vers Dremio impliquait également la transition de 33 mini-clusters et 4 000 cœurs vers 16 nœuds exécuteurs sur des clusters Kubernetes.  Même avec des diminutions significatives des ressources informatiques, NetApp a connu des améliorations de performances remarquables.  En accédant directement aux données via Dremio, le temps d'exécution des requêtes est passé de 45 minutes à 2 minutes, ce qui a permis d'obtenir des informations 95 % plus rapidement pour la maintenance prédictive et l'optimisation.  La migration a également permis une réduction de plus de 60 % des coûts de calcul, des requêtes plus de 20 fois plus rapides et des économies de plus de 30 % sur le coût total de possession (TCO).</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">Cas d'utilisation client de vente de pièces automobiles.</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*Défis* : Au sein de cette société mondiale de vente de pièces automobiles, les groupes de planification et d'analyse financière de la direction et de l'entreprise n'étaient pas en mesure d'obtenir une vue consolidée des rapports de vente et étaient obligés de lire les rapports de mesures de vente de chaque secteur d'activité et de tenter de les consolider.  Cela a conduit les clients à prendre des décisions avec des données datant d’au moins un jour.  Les délais d’obtention de nouvelles informations analytiques prennent généralement plus de quatre semaines.  Le dépannage des pipelines de données nécessiterait encore plus de temps, ajoutant trois jours ou plus au délai déjà long.  Le processus lent de développement des rapports ainsi que les performances des rapports ont obligé la communauté des analystes à attendre continuellement que les données soient traitées ou chargées, plutôt que de leur permettre de trouver de nouvelles perspectives commerciales et de stimuler de nouveaux comportements commerciaux.  Ces environnements perturbés étaient composés de nombreuses bases de données différentes pour différents secteurs d’activité, ce qui a donné lieu à de nombreux silos de données.  L’environnement lent et fragmenté a compliqué la gouvernance des données, car les analystes disposaient de trop de moyens pour élaborer leur propre version de la vérité par rapport à une source unique de vérité.  L’approche a coûté plus de 1,9 million de dollars en frais de plateforme de données et de personnel.  La maintenance de la plateforme existante et le traitement des demandes de données nécessitaient sept ingénieurs techniques de terrain (ETP) par an.  Avec l'augmentation des demandes de données, l'équipe de renseignement sur les données n'a pas pu adapter l'environnement existant pour répondre aux besoins futurs.</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*Solution* : Stockez et gérez de manière rentable de grandes tables Iceberg dans NetApp Object Store.  Créez des domaines de données à l'aide de la couche sémantique de Dremio, permettant aux utilisateurs professionnels de créer, rechercher et partager facilement des produits de données.</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*Avantages pour le client* : • Architecture de données existante améliorée et optimisée et temps d'obtention d'informations réduit de quatre semaines à quelques heures seulement • Temps de dépannage réduit de trois jours à quelques heures seulement • Coûts de gestion et de plateforme de données réduits de plus de 380 000 $ • (2) ETP d'efforts de renseignement sur les données économisés par an</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">Nous avons effectué les tests tpc-ds avec cinq nœuds pour les charges de travail SQL avec le stockage d'objets NetApp tel que dans ONTAP et StorageGrid.</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">Présentation de la vérification des solutions</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">Dans cette section, nous avons exécuté des requêtes de test SQL à partir de plusieurs sources pour vérifier la fonctionnalité, tester et vérifier le débordement vers le stockage NetApp .</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">Requête SQL sur le stockage d'objets</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">Définissez la mémoire à 250 Go par serveur dans dremio.env</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">Vérifiez l'emplacement de débordement (${DREMIO_HOME}"/dremiocache) dans le fichier dremio.conf et les détails de stockage.</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Dirigez l'emplacement de débordement de Dremio vers le stockage NetApp NFS</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">Sélectionnez le contexte.  Dans notre test, nous avons exécuté le test sur les fichiers parquet générés par TPCDS résidant dans ONTAP S3.  Tableau de bord Dremio -&gt; Exécuteur SQL -&gt; Contexte -&gt; NetAppONTAPS3 -&gt; Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">définir le contexte sur le dossier parquet ontaps3</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">Exécutez la requête TPC-DS67 à partir du tableau de bord Dremio</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">Exécutez la requête 67 qui est l'une des 99 requêtes dans TPC-DS</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">Vérifiez que le travail est en cours d’exécution sur tous les exécuteurs.  Tableau de bord Dremio -&gt; tâches -&gt; &lt;jobid&gt; -&gt; profil brut -&gt; sélectionnez EXTERNAL_SORT -&gt; Nom d'hôte</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">liste des nœuds dans la requête Q67</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">Lorsque la requête SQL est en cours d'exécution, vous pouvez vérifier le dossier divisé pour la mise en cache des données dans le contrôleur de stockage NetApp .</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">déborder les détails lorsque la requête 67 se termine</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">La requête SQL complétée avec débordement<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">Résumé du travail de la requête terminée 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">Résumé de l'achèvement du travail.<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">détails des données spécifiées à partir du résultat de la requête</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">Vérifiez la taille des données renversées<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">La même procédure s'applique au stockage d'objets NAS et StorageGRID .</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Cette section fournit un résumé des cas d’utilisation et des solutions fournies par NetApp pour répondre aux diverses exigences de protection des données Hadoop.</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Cette section fournit un résumé des cas d’utilisation et des solutions fournies par NetApp pour répondre aux diverses exigences de protection des données Hadoop.  En utilisant la structure de données optimisée par NetApp, les clients peuvent :</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">Bénéficiez de la flexibilité nécessaire pour choisir les solutions de protection des données adaptées en tirant parti des riches capacités de gestion des données de NetApp et de l'intégration avec les flux de travail natifs Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Réduisez le temps de sauvegarde de leur cluster Hadoop de près de 70 %.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Éliminez tout effet sur les performances résultant des sauvegardes de cluster Hadoop.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Offrez une protection des données multicloud et un accès aux données de différents fournisseurs de cloud simultanément à une source unique de données d'analyse.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Créez des copies de cluster Hadoop rapides et peu encombrantes à l'aide de la technologie FlexClone .</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Pour en savoir plus sur les informations décrites dans ce document, consultez les documents et/ou sites Web suivants :</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Solutions d'analyse de Big Data NetApp</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Charge de travail Apache Spark avec stockage NetApp</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Solutions de stockage NetApp pour Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop sur Data Fabric activé par NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Remerciements</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, représentant commercial, ventes du district ANZ Victoria, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, responsable du développement commercial, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, directeur MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, ingénieur système, ANZ Victoria District SE, NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">Historique des versions</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Date</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Historique des versions du document</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Version 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Janvier 2018</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Version initiale</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Version 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Octobre 2021</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Mise à jour avec le cas d'utilisation n° 5 : Accélérer la charge de travail analytique</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Version 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">Novembre 2023</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">Détails NIPAM supprimés</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">La structure de données optimisée par NetApp simplifie et intègre la gestion des données dans les environnements cloud et sur site pour accélérer la transformation numérique.  La structure de données optimisée par NetApp fournit des services et des applications de gestion de données cohérents et intégrés (blocs de construction) pour la visibilité et les informations sur les données, l'accès et le contrôle des données, ainsi que la protection et la sécurité des données.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data Fabric optimisé par NetApp pour l'architecture Big Data</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">La structure de données optimisée par NetApp simplifie et intègre la gestion des données dans les environnements cloud et sur site pour accélérer la transformation numérique.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">La structure de données optimisée par NetApp fournit des services et des applications de gestion de données cohérents et intégrés (blocs de construction) pour la visibilité et les informations sur les données, l'accès et le contrôle des données, ainsi que la protection et la sécurité des données, comme illustré dans la figure ci-dessous.</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Cas d'utilisation client éprouvés de Data Fabric</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">La structure de données optimisée par NetApp fournit les neuf cas d'utilisation éprouvés suivants aux clients :</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Accélérer les charges de travail d'analyse</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Accélérer la transformation DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Construire une infrastructure d'hébergement cloud</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Intégrer les services de données cloud</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Protéger et sécuriser les données</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Optimiser les données non structurées</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Gagnez en efficacité dans votre centre de données</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Fournir des informations et un contrôle sur les données</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Simplifier et automatiser</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Ce document couvre deux des neuf cas d’utilisation (ainsi que leurs solutions) :</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Accès direct NetApp NFS</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS permet aux clients d'exécuter des tâches d'analyse de Big Data sur leurs données NFSv3 ou NFSv4 existantes ou nouvelles sans déplacer ni copier les données.  Il empêche les copies multiples de données et élimine le besoin de synchroniser les données avec une source.  Par exemple, dans le secteur financier, le déplacement de données d’un endroit à un autre doit répondre à des obligations légales, ce qui n’est pas une tâche facile.  Dans ce scénario, l’accès direct NetApp NFS analyse les données financières à partir de leur emplacement d’origine.  Un autre avantage clé est que l’utilisation de l’accès direct NetApp NFS simplifie la protection des données Hadoop en utilisant des commandes Hadoop natives et permet des flux de travail de protection des données exploitant le riche portefeuille de gestion des données de NetApp.</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">L'accès direct NetApp NFS offre deux types d'options de déploiement pour les clusters Hadoop/Spark :</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Par défaut, les clusters Hadoop/Spark utilisent Hadoop Distributed File System (HDFS) pour le stockage des données et le système de fichiers par défaut.  L'accès direct NetApp NFS peut remplacer le HDFS par défaut par le stockage NFS comme système de fichiers par défaut, permettant des opérations d'analyse directes sur les données NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">Dans une autre option de déploiement, l'accès direct NetApp NFS prend en charge la configuration de NFS comme stockage supplémentaire avec HDFS dans un seul cluster Hadoop/Spark.  Dans ce cas, le client peut partager des données via des exportations NFS et y accéder à partir du même cluster avec les données HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Les principaux avantages de l’utilisation de l’accès direct NetApp NFS incluent :</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analyse les données à partir de leur emplacement actuel, ce qui évite la tâche fastidieuse et coûteuse en performances consistant à déplacer les données d'analyse vers une infrastructure Hadoop telle que HDFS.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Réduit le nombre de répliques de trois à une.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Permet aux utilisateurs de découpler le calcul et le stockage pour les faire évoluer indépendamment.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Fournit une protection des données d'entreprise en exploitant les riches capacités de gestion des données d' ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Est certifié avec la plateforme de données Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Permet des déploiements d’analyse de données hybrides.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Réduit le temps de sauvegarde en exploitant la capacité multithread dynamique.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Éléments de base du Big Data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">La structure de données optimisée par NetApp intègre des services et des applications de gestion des données (blocs de construction) pour l'accès, le contrôle, la protection et la sécurité des données, comme illustré dans la figure ci-dessous.</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Les éléments constitutifs de la figure ci-dessus comprennent :</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* Accès direct NetApp NFS.*  Fournit aux derniers clusters Hadoop et Spark un accès direct aux volumes NetApp NFS sans exigences de logiciel ou de pilote supplémentaires.</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP et Google Cloud NetApp Volumes.*  Stockage connecté défini par logiciel basé sur ONTAP exécuté dans Amazon Web Services (AWS) ou Azure NetApp Files (ANF) dans les services cloud Microsoft Azure.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* Technologie NetApp SnapMirror *.  Fournit des capacités de protection des données entre les instances locales et ONTAP Cloud ou NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Fournisseurs de services cloud.*  Ces fournisseurs incluent AWS, Microsoft Azure, Google Cloud et IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.*  Services d'analyse basés sur le cloud tels qu'Amazon Elastic MapReduce (EMR) et Databricks dans AWS ainsi que Microsoft Azure HDInsight et Azure Databricks.</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp est un outil natif utilisé pour la copie intercluster et intracluster de grande taille.  Le processus de base Hadoop DistCp est un flux de travail de sauvegarde typique utilisant des outils natifs Hadoop tels que MapReduce pour copier les données Hadoop d'une source HDFS vers une cible correspondante.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Protection des données Hadoop et NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp est un outil natif utilisé pour la copie intercluster et intracluster de grande taille.  Le processus de base Hadoop DistCp illustré dans la figure ci-dessous est un flux de travail de sauvegarde typique utilisant des outils natifs Hadoop tels que MapReduce pour copier les données Hadoop d'une source HDFS vers une cible correspondante.</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">L'accès direct NetApp NFS permet aux clients de définir NFS comme destination cible pour l'outil Hadoop DistCp afin de copier les données de la source HDFS dans un partage NFS via MapReduce.  L'accès direct NetApp NFS agit comme un pilote NFS pour l'outil DistCp.</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Ce document décrit les solutions de données cloud hybrides utilisant les systèmes de stockage NetApp AFF et FAS , NetApp Cloud Volumes ONTAP, le stockage connecté NetApp et la technologie NetApp FlexClone pour Spark et Hadoop.  Ces architectures de solutions permettent aux clients de choisir une solution de protection des données adaptée à leur environnement.  NetApp a conçu ces solutions en fonction de l’interaction avec les clients et de leurs cas d’utilisation commerciale.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam et Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Ce document décrit les solutions de données cloud hybrides utilisant les systèmes de stockage NetApp AFF et FAS , NetApp Cloud Volumes ONTAP, le stockage connecté NetApp et la technologie NetApp FlexClone pour Spark et Hadoop.  Ces architectures de solutions permettent aux clients de choisir une solution de protection des données adaptée à leur environnement.  NetApp a conçu ces solutions en fonction de l’interaction avec les clients et de leurs cas d’utilisation commerciale.  Ce document fournit les informations détaillées suivantes :</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Pourquoi nous avons besoin d’une protection des données pour les environnements Spark et Hadoop et les défis des clients.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">La structure de données optimisée par la vision NetApp et ses éléments constitutifs et services.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Comment ces éléments de base peuvent être utilisés pour concevoir des flux de travail de protection des données flexibles.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Les avantages et les inconvénients de plusieurs architectures basées sur des cas d’utilisation client réels.  Chaque cas d'utilisation fournit les composants suivants :</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Scénarios clients</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">Exigences et défis</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Solutions</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Résumé des solutions</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Pourquoi la protection des données Hadoop ?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Dans un environnement Hadoop et Spark, les préoccupations suivantes doivent être prises en compte :</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Défaillances logicielles ou humaines.*  Une erreur humaine dans les mises à jour logicielles lors de l’exécution d’opérations de données Hadoop peut entraîner un comportement défectueux susceptible de provoquer des résultats inattendus du travail.  Dans un tel cas, nous devons protéger les données pour éviter des échecs ou des résultats déraisonnables.  Par exemple, à la suite d'une mise à jour logicielle mal exécutée d'une application d'analyse des feux de circulation, une nouvelle fonctionnalité ne parvient pas à analyser correctement les données des feux de circulation sous forme de texte brut.  Le logiciel analyse toujours le JSON et d'autres formats de fichiers non textuels, ce qui fait que le système d'analyse du contrôle du trafic en temps réel produit des résultats de prédiction qui manquent de points de données.  Cette situation peut entraîner des sorties défectueuses qui peuvent conduire à des accidents aux feux de circulation.  La protection des données peut résoudre ce problème en offrant la possibilité de revenir rapidement à la version précédente de l'application.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Taille et échelle.*  La taille des données d’analyse augmente de jour en jour en raison du nombre et du volume toujours croissants de sources de données.  Les médias sociaux, les applications mobiles, l'analyse de données et les plateformes de cloud computing sont les principales sources de données sur le marché actuel du Big Data, qui connaît une croissance très rapide. Par conséquent, les données doivent être protégées pour garantir des opérations de données précises.</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Protection des données native de Hadoop.*  Hadoop dispose d'une commande native pour protéger les données, mais cette commande ne fournit pas de cohérence des données lors de la sauvegarde.  Il prend uniquement en charge la sauvegarde au niveau du répertoire.  Les instantanés créés par Hadoop sont en lecture seule et ne peuvent pas être utilisés pour réutiliser directement les données de sauvegarde.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Les défis de la protection des données pour les clients Hadoop et Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Un défi commun pour les clients Hadoop et Spark est de réduire le temps de sauvegarde et d’augmenter la fiabilité de la sauvegarde sans affecter négativement les performances du cluster de production pendant la protection des données.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Les clients doivent également minimiser les temps d’arrêt liés à l’objectif de point de récupération (RPO) et à l’objectif de temps de récupération (RTO) et contrôler leurs sites de reprise après sinistre sur site et dans le cloud pour une continuité d’activité optimale.  Ce contrôle provient généralement de l’utilisation d’outils de gestion au niveau de l’entreprise.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Les environnements Hadoop et Spark sont complexes car non seulement le volume de données est énorme et en croissance, mais le rythme auquel ces données arrivent augmente également.  Ce scénario rend difficile la création rapide d’environnements DevTest et QA efficaces et à jour à partir des données sources.  NetApp reconnaît ces défis et propose les solutions présentées dans ce document.</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">Dans ce scénario, la plate-forme d'analyse d'une grande banque de services financiers et d'investissement a été modernisée à l'aide de la solution de stockage NetApp NFS pour obtenir une amélioration significative de l'analyse des risques d'investissement et des produits dérivés pour son unité commerciale de gestion d'actifs et quantitative.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">Cas d'utilisation 5 : Accélérer les charges de travail analytiques</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Scénario</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">Dans l'environnement existant du client, l'infrastructure Hadoop utilisée pour la plate-forme d'analyse exploitait le stockage interne des serveurs Hadoop.  En raison de la nature propriétaire de l'environnement JBOD, de nombreux clients internes de l'organisation n'ont pas pu profiter de leur modèle quantitatif Monte Carlo, une simulation qui repose sur des échantillons récurrents de données en temps réel.  La capacité sous-optimale à comprendre les effets de l’incertitude sur les mouvements du marché était défavorable à l’unité commerciale de gestion quantitative des actifs.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">L'unité commerciale quantitative de la banque souhaitait une méthode de prévision efficace pour obtenir des prévisions précises et opportunes.  Pour ce faire, l’équipe a reconnu la nécessité de moderniser l’infrastructure, de réduire le temps d’attente des E/S existantes et d’améliorer les performances des applications analytiques telles que Hadoop et Spark pour simuler efficacement les modèles d’investissement, mesurer les gains potentiels et analyser les risques.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Solution</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">Le client disposait de JBOD pour sa solution Spark existante.  NetApp ONTAP, NetApp StorageGRID et MinIO Gateway vers NFS ont ensuite été exploités pour réduire le temps d'attente des E/S pour le groupe financier quantitatif de la banque qui exécute des simulations et des analyses sur des modèles d'investissement qui évaluent les gains et les risques potentiels.  Cette image montre la solution Spark avec le stockage NetApp .</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Comme le montre la figure ci-dessus, les systèmes AFF A800, A700 et StorageGRID ont été déployés pour accéder aux fichiers Parquet via les protocoles NFS et S3 dans un cluster Hadoop à six nœuds avec Spark et les services de métadonnées YARN et Hive pour les opérations d'analyse de données.</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">Une solution de stockage à connexion directe (DAS) dans l'ancien environnement du client présentait l'inconvénient de permettre une mise à l'échelle indépendante du calcul et du stockage.  Grâce à la solution NetApp ONTAP pour Spark, l'unité commerciale d'analyse financière de la banque a pu découpler le stockage du calcul et apporter de manière transparente des ressources d'infrastructure plus efficacement selon les besoins.</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">En utilisant ONTAP avec NFS, les processeurs du serveur de calcul ont été presque entièrement utilisés pour les tâches Spark SQL et le temps d'attente des E/S a été réduit de près de 70 %, offrant ainsi une meilleure puissance de calcul et une amélioration des performances des charges de travail Spark.  Par la suite, l’augmentation de l’utilisation du processeur a également permis au client d’exploiter les GPU, tels que GPUDirect, pour une modernisation supplémentaire de la plate-forme.  De plus, StorageGRID fournit une option de stockage à faible coût pour les charges de travail Spark et MinIO Gateway fournit un accès sécurisé aux données NFS via le protocole S3.  Pour les données dans le cloud, NetApp recommande Cloud Volumes ONTAP, Azure NetApp Files et Google Cloud NetApp Volumes.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Ce cas d’utilisation est basé sur un client de diffusion qui a besoin de sauvegarder des données d’analyse basées sur le cloud dans son centre de données sur site.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">Cas d'utilisation 2 : Sauvegarde et reprise après sinistre du cloud vers les locaux</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Ce cas d’utilisation est basé sur un client de diffusion qui a besoin de sauvegarder des données d’analyse basées sur le cloud dans son centre de données sur site, comme illustré dans la figure ci-dessous.</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">Dans ce scénario, les données du capteur IoT sont ingérées dans le cloud et analysées à l’aide d’un cluster Apache Spark open source au sein d’AWS.  L’exigence est de sauvegarder les données traitées du cloud vers les locaux.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Les principales exigences et défis pour ce cas d'utilisation incluent :</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">L'activation de la protection des données ne devrait pas avoir d'effet sur les performances du cluster Spark/Hadoop de production dans le cloud.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Les données des capteurs cloud doivent être déplacées et protégées sur site de manière efficace et sécurisée.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilité pour transférer des données du cloud vers les locaux dans différentes conditions, telles que la demande, l'instantané et pendant les périodes de faible charge du cluster.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">Le client utilise AWS Elastic Block Store (EBS) pour son stockage HDFS de cluster Spark afin de recevoir et d'ingérer des données provenant de capteurs distants via Kafka.  Par conséquent, le stockage HDFS agit comme source pour les données de sauvegarde.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Pour répondre à ces exigences, NetApp ONTAP Cloud est déployé dans AWS et un partage NFS est créé pour servir de cible de sauvegarde pour le cluster Spark/Hadoop.</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">Une fois le partage NFS créé, copiez les données du stockage EBS HDFS dans le partage NFS ONTAP .  Une fois les données stockées dans NFS dans ONTAP Cloud, la technologie SnapMirror peut être utilisée pour mettre en miroir les données du cloud vers le stockage sur site, selon les besoins, de manière sécurisée et efficace.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Cette image montre la solution de sauvegarde et de reprise après sinistre du cloud vers la solution sur site.</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">Dans ce scénario, le client dispose d’un grand référentiel Hadoop sur site et souhaite le sauvegarder à des fins de reprise après sinistre.  Cependant, la solution de sauvegarde actuelle du client est coûteuse et souffre d'une longue fenêtre de sauvegarde de plus de 24 heures.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">Cas d'utilisation 1 : Sauvegarde des données Hadoop</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Rétrocompatibilité du logiciel :</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">La solution de sauvegarde alternative proposée doit être compatible avec les versions logicielles actuelles utilisées dans le cluster Hadoop de production.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Pour respecter les SLA engagés, la solution alternative proposée devrait atteindre des RPO et RTO très bas.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">La sauvegarde créée par la solution de sauvegarde NetApp peut être utilisée dans le cluster Hadoop créé localement dans le centre de données ainsi que dans le cluster Hadoop exécuté dans l'emplacement de reprise après sinistre sur le site distant.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">La solution proposée doit être rentable.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">La solution proposée doit réduire l’effet sur les performances des tâches d’analyse en cours d’exécution et en production pendant les périodes de sauvegarde.</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">Solution de sauvegarde existante du clientx</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">La figure ci-dessous montre la solution de sauvegarde native Hadoop d’origine.</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Les données de production sont protégées sur bande via le cluster de sauvegarde intermédiaire :</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">Les données HDFS1 sont copiées vers HDFS2 en exécutant le<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">Le cluster de sauvegarde agit comme une passerelle NFS et les données sont copiées manuellement sur bande via Linux<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> commande via la bibliothèque de bandes.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Les avantages de la solution de sauvegarde native Hadoop d'origine incluent :</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">La solution est basée sur des commandes natives Hadoop, ce qui évite à l'utilisateur d'avoir à apprendre de nouvelles procédures.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">La solution s’appuie sur une architecture et un matériel standard du secteur.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Les inconvénients de la solution de sauvegarde native Hadoop d'origine incluent :</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">La longue fenêtre de sauvegarde dépasse 24 heures, ce qui rend les données de production vulnérables.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Dégradation significative des performances du cluster pendant les périodes de sauvegarde.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">La copie sur bande est un processus manuel.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">La solution de sauvegarde est coûteuse en termes de matériel requis et d’heures humaines nécessaires aux processus manuels.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Solutions de sauvegarde</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">Sur la base de ces défis et exigences, et en tenant compte du système de sauvegarde existant, trois solutions de sauvegarde possibles ont été suggérées.  Les sous-sections suivantes décrivent chacune de ces trois solutions de sauvegarde différentes, appelées solution A à solution C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Solution A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">Dans la solution A, le cluster Hadoop de sauvegarde envoie les sauvegardes secondaires aux systèmes de stockage NetApp NFS, éliminant ainsi le besoin de bande, comme illustré dans la figure ci-dessous.</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Les tâches détaillées pour la solution A comprennent :</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">Le cluster Hadoop de production contient les données d'analyse du client dans le HDFS qui nécessitent une protection.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">Le cluster Hadoop de sauvegarde avec HDFS agit comme un emplacement intermédiaire pour les données.  Un simple ensemble de disques (JBOD) fournit le stockage pour HDFS dans les clusters Hadoop de production et de sauvegarde.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Protégez les données de production Hadoop du cluster de production HDFS vers le cluster de sauvegarde HDFS en exécutant le<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Le snapshot Hadoop est utilisé pour protéger les données de la production vers le cluster Hadoop de sauvegarde.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">Le contrôleur de stockage NetApp ONTAP fournit un volume exporté NFS, qui est provisionné sur le cluster Hadoop de sauvegarde.</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">En exécutant le<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> commande exploitant MapReduce et plusieurs mappeurs, les données d'analyse sont protégées du cluster Hadoop de sauvegarde vers NFS.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Une fois les données stockées dans NFS sur le système de stockage NetApp , les technologies NetApp Snapshot, SnapRestore et FlexClone sont utilisées pour sauvegarder, restaurer et dupliquer les données Hadoop selon les besoins.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Les données Hadoop peuvent être protégées dans le cloud ainsi que dans les emplacements de reprise après sinistre à l'aide de la technologie SnapMirror .</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">Les avantages de la solution A incluent :</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Les données de production Hadoop sont protégées du cluster de sauvegarde.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">Les données HDFS sont protégées via NFS, ce qui permet une protection dans le cloud et les emplacements de reprise après sinistre.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Améliore les performances en déchargeant les opérations de sauvegarde sur le cluster de sauvegarde.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Élimine les opérations manuelles sur bande</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Permet des fonctions de gestion d'entreprise via les outils NetApp .</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Nécessite des modifications minimales à l’environnement existant.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">C'est une solution rentable.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">L’inconvénient de cette solution est qu’elle nécessite un cluster de sauvegarde et des mappeurs supplémentaires pour améliorer les performances.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">Le client a récemment déployé la solution A en raison de sa simplicité, de son coût et de ses performances globales.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">Dans cette solution, les disques SAN d' ONTAP peuvent être utilisés à la place de JBOD.  Cette option décharge la charge de stockage du cluster de sauvegarde sur ONTAP; cependant, l’inconvénient est que des commutateurs de structure SAN sont nécessaires.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Solution B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">La solution B ajoute un volume NFS au cluster Hadoop de production, ce qui élimine le besoin du cluster Hadoop de sauvegarde, comme illustré dans la figure ci-dessous.</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Les tâches détaillées pour la solution B incluent :</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">Le contrôleur de stockage NetApp ONTAP provisionne l'exportation NFS vers le cluster Hadoop de production.</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Le natif de Hadoop<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> la commande protège les données Hadoop du cluster de production HDFS vers NFS.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Une fois les données stockées dans NFS sur le système de stockage NetApp , les technologies Snapshot, SnapRestore et FlexClone sont utilisées pour sauvegarder, restaurer et dupliquer les données Hadoop selon les besoins.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">Les avantages de la solution B incluent :</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">Le cluster de production est légèrement modifié pour la solution de sauvegarde, ce qui simplifie la mise en œuvre et réduit les coûts d'infrastructure supplémentaires.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Un cluster de sauvegarde n'est pas requis pour l'opération de sauvegarde.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">Les données de production HDFS sont protégées lors de la conversion en données NFS.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">La solution permet des fonctions de gestion d’entreprise via les outils NetApp .</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">L’inconvénient de cette solution est qu’elle est implémentée dans le cluster de production, ce qui peut ajouter des tâches d’administrateur supplémentaires dans le cluster de production.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Solution C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">Dans la solution C, les volumes SAN NetApp sont directement provisionnés sur le cluster de production Hadoop pour le stockage HDFS, comme illustré dans la figure ci-dessous.</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">Les étapes détaillées de la solution C incluent :</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">Le stockage SAN NetApp ONTAP est provisionné sur le cluster Hadoop de production pour le stockage de données HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Les technologies NetApp Snapshot et SnapMirror sont utilisées pour sauvegarder les données HDFS du cluster Hadoop de production.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">Il n’y a aucun effet sur les performances de production du cluster Hadoop/Spark pendant le processus de sauvegarde de copie d’instantané, car la sauvegarde se situe au niveau de la couche de stockage.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">La technologie Snapshot fournit des sauvegardes qui s'effectuent en quelques secondes, quelle que soit la taille des données.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">Les avantages de la solution C incluent :</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">Une sauvegarde peu encombrante peut être créée à l'aide de la technologie Snapshot.</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">Dans ce cas d'utilisation, l'exigence du client est de créer rapidement et efficacement de nouveaux clusters Hadoop/Spark basés sur un cluster Hadoop existant contenant une grande quantité de données d'analyse à des fins de DevTest et de reporting dans le même centre de données ainsi que dans des emplacements distants.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">Cas d'utilisation 3 : Activation de DevTest sur des données Hadoop existantes</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">Dans ce scénario, plusieurs clusters Spark/Hadoop sont construits à partir d'une grande implémentation de lac de données Hadoop sur site ainsi que sur des sites de reprise après sinistre.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Créez plusieurs clusters Hadoop pour DevTest, QA ou tout autre objectif nécessitant l'accès aux mêmes données de production.  Le défi ici est de cloner un très grand cluster Hadoop plusieurs fois instantanément et de manière très efficace en termes d’espace.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Synchronisez les données Hadoop avec les équipes DevTest et de reporting pour une efficacité opérationnelle.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribuez les données Hadoop en utilisant les mêmes informations d’identification entre la production et les nouveaux clusters.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Utilisez des stratégies planifiées pour créer efficacement des clusters QA sans affecter le cluster de production.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">La technologie FlexClone est utilisée pour répondre aux exigences qui viennent d'être décrites.  La technologie FlexClone est la copie en lecture/écriture d'une copie Snapshot.  Il lit les données à partir des données de copie Snapshot parent et consomme uniquement de l'espace supplémentaire pour les blocs nouveaux/modifiés.  C'est rapide et peu encombrant.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Tout d’abord, une copie instantanée du cluster existant a été créée à l’aide d’un groupe de cohérence NetApp .</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">Copies instantanées dans NetApp System Manager ou dans l'invite d'administration du stockage.  Les copies Snapshot du groupe de cohérence sont des copies Snapshot du groupe cohérentes avec l'application, et le volume FlexClone est créé sur la base des copies Snapshot du groupe de cohérence.  Il convient de mentionner qu'un volume FlexClone hérite de la politique d'exportation NFS du volume parent.  Une fois la copie Snapshot créée, un nouveau cluster Hadoop doit être installé à des fins de DevTest et de création de rapports, comme illustré dans la figure ci-dessous.  Le volume NFS cloné du nouveau cluster Hadoop accède aux données NFS.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Cette image montre le cluster Hadoop pour DevTest.</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Ce cas d'utilisation est pertinent pour un partenaire de services cloud chargé de fournir une connectivité multicloud pour les données d'analyse de Big Data des clients.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">Cas d'utilisation 4 : Protection des données et connectivité multicloud</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">Dans ce scénario, les données IoT reçues dans AWS à partir de différentes sources sont stockées dans un emplacement central dans NPS.  Le stockage NPS est connecté aux clusters Spark/Hadoop situés dans AWS et Azure, permettant aux applications d'analyse de Big Data de s'exécuter dans plusieurs clouds accédant aux mêmes données.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Les clients souhaitent exécuter des tâches d’analyse sur les mêmes données à l’aide de plusieurs clouds.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Les données doivent être reçues de différentes sources telles que sur site et dans le cloud via différents capteurs et hubs.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">La solution doit être efficace et rentable.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">Le principal défi consiste à créer une solution rentable et efficace qui fournit des services d’analyse hybrides entre les sites locaux et entre différents clouds.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Cette image illustre la solution de protection des données et de connectivité multicloud.</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">Comme le montre la figure ci-dessus, les données des capteurs sont diffusées et ingérées dans le cluster AWS Spark via Kafka.  Les données sont stockées dans un partage NFS résidant dans NPS, qui est situé en dehors du fournisseur de cloud dans un centre de données Equinix.  Étant donné que NetApp NPS est connecté à Amazon AWS et Microsoft Azure via des connexions Direct Connect et Express Route, respectivement, les clients peuvent accéder aux données NFS à partir des clusters d'analyse Amazon et AWS.  Cette approche permet de résoudre le problème de l’analyse du cloud sur plusieurs hyperscalers.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Par conséquent, étant donné que le stockage sur site et NPS exécute le logiciel ONTAP , SnapMirror peut refléter les données NPS dans le cluster sur site, fournissant ainsi des analyses de cloud hybride sur site et sur plusieurs clouds.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Pour des performances optimales, NetApp recommande généralement d'utiliser plusieurs interfaces réseau et des connexions directes/routes express pour accéder aux données à partir d'instances cloud.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Cette section fournit une description de haut niveau des cas d’utilisation de la protection des données, qui constituent l’objet de cet article.  Les sections restantes fournissent plus de détails pour chaque cas d'utilisation, tels que le problème client (scénario), les exigences et les défis, ainsi que les solutions.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Aperçu des cas d'utilisation de la protection des données Hadoop</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">Pour ce cas d'utilisation, le volume NetApp NFS a aidé une grande institution financière à réduire la longue fenêtre de sauvegarde de plus de 24 heures à un peu moins de quelques heures.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">En utilisant la structure de données optimisée par NetApp comme éléments de base, une grande société de radiodiffusion a pu répondre à son exigence de sauvegarde des données cloud dans son centre de données sur site en fonction des différents modes de transfert de données, tels que la demande, l'instantané ou la charge du cluster Hadoop/Spark.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Les solutions NetApp ont aidé un distributeur de musique en ligne à créer rapidement plusieurs clusters Hadoop peu encombrants dans différentes branches pour créer des rapports et exécuter des tâches DevTest quotidiennes à l'aide de politiques planifiées.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Un grand fournisseur de services a utilisé la structure de données optimisée par NetApp pour fournir des analyses multicloud à ses clients à partir de différentes instances cloud.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">L'une des plus grandes banques de services financiers et d'investissement a utilisé la solution de stockage en réseau NetApp pour réduire le temps d'attente des E/S et accélérer sa plateforme d'analyse financière quantitative.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">Cette section présente les enseignements tirés de cette certification.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Lignes directrices sur les meilleures pratiques</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Sur la base de notre validation, le stockage d’objets S3 est le meilleur moyen pour Confluent de conserver les données.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Nous pouvons utiliser un SAN à haut débit (en particulier FC) pour conserver les données chaudes du courtier ou le disque local, car, dans la configuration de stockage hiérarchisé Confluent, la taille des données conservées dans le répertoire de données des courtiers est basée sur la taille du segment et le temps de rétention lorsque les données sont déplacées vers le stockage d'objets.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Les magasins d'objets offrent de meilleures performances lorsque segment.bytes est plus élevé ; nous avons testé 512 Mo.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Dans Kafka, la longueur de la clé ou de la valeur (en octets) pour chaque enregistrement produit dans le sujet est contrôlée par le<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> paramètre.  Pour StorageGRID, les performances d'ingestion et de récupération d'objets S3 ont été augmentées à des valeurs plus élevées.  Par exemple, 512 octets ont fourni une récupération de 5,8 Gbit/s, 1 024 octets ont fourni une récupération S3 de 7,5 Gbit/s et 2 048 octets ont fourni près de 10 Gbit/s.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">La figure suivante présente l'objet S3 ingéré et récupéré en fonction de<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> .</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Réglage Kafka.*  Pour améliorer les performances du stockage hiérarchisé, vous pouvez augmenter TierFetcherNumThreads et TierArchiverNumThreads.  En règle générale, vous souhaitez augmenter TierFetcherNumThreads pour qu'il corresponde au nombre de cœurs de processeur physiques et augmenter TierArchiverNumThreads à la moitié du nombre de cœurs de processeur.  Par exemple, dans les propriétés du serveur, si vous disposez d’une machine avec huit cœurs physiques, définissez confluent.tier.fetcher.num.threads = 8 et confluent.tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervalle de temps pour les suppressions de sujets.*  Lorsqu'une rubrique est supprimée, la suppression des fichiers de segment de journal dans le stockage d'objets ne commence pas immédiatement.  Il existe plutôt un intervalle de temps avec une valeur par défaut de 3 heures avant que la suppression de ces fichiers n'ait lieu.  Vous pouvez modifier la configuration, confluent.tier.topic.delete.check.interval.ms, pour modifier la valeur de cet intervalle.  Si vous supprimez une rubrique ou un cluster, vous pouvez également supprimer manuellement les objets dans le compartiment correspondant.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACL sur les sujets internes du stockage hiérarchisé.*  Une bonne pratique recommandée pour les déploiements sur site consiste à activer un autorisateur ACL sur les rubriques internes utilisées pour le stockage hiérarchisé.  Définissez des règles ACL pour limiter l’accès à ces données à l’utilisateur du courtier uniquement.  Cela sécurise les sujets internes et empêche l'accès non autorisé aux données et métadonnées de stockage hiérarchisées.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Remplacer l'utilisateur<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> avec le courtier principal réel dans votre déploiement.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Par exemple, la commande<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> définit les ACL sur le sujet interne pour le stockage hiérarchisé.  Actuellement, il n’existe qu’un seul sujet interne lié au stockage hiérarchisé.  L'exemple crée une ACL qui fournit l'autorisation principale Kafka pour toutes les opérations sur la rubrique interne.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Nous avons effectué la certification avec Confluent Platform avec Kafka pour le stockage hiérarchisé dans NetApp StorageGRID.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Vérification confluente</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Nous avons effectué une vérification avec Confluent Platform 6.2 Tiered Storage dans NetApp StorageGRID.  Les équipes NetApp et Confluent ont travaillé ensemble sur cette vérification et ont exécuté les cas de test requis pour la vérification.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configuration de la plateforme Confluent</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Nous avons utilisé la configuration suivante pour la vérification.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Pour la vérification, nous avons utilisé trois gardiens de zoo, cinq courtiers, cinq serveurs d'exécution de scripts de test, des serveurs d'outils nommés avec 256 Go de RAM et 16 processeurs.  Pour le stockage NetApp , nous avons utilisé StorageGRID avec un équilibreur de charge SG1000 avec quatre SGF6024.  Le stockage et les courtiers étaient connectés via des connexions 100 GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">La figure suivante montre la topologie du réseau de configuration utilisée pour la vérification Confluent.</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Les serveurs d’outils agissent comme des clients d’application qui envoient des requêtes aux nœuds Confluent.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configuration de stockage hiérarchisé Confluent</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">La configuration du stockage hiérarchisé nécessite les paramètres suivants dans Kafka :</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Pour la vérification, nous avons utilisé StorageGRID avec le protocole HTTP, mais HTTPS fonctionne également.  La clé d'accès et la clé secrète sont stockées dans le nom de fichier fourni dans le<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Stockage d'objets NetApp - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Nous avons configuré une configuration à site unique dans StorageGRID pour vérification.</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Tests de vérification</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Nous avons réalisé les cinq cas de test suivants pour la vérification.  Ces tests sont exécutés sur le framework Trogdor.  Les deux premiers étaient des tests de fonctionnalité et les trois autres étaient des tests de performance.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Test d'exactitude du magasin d'objets</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Ce test détermine si toutes les opérations de base (par exemple, obtenir/mettre/supprimer) sur l'API du magasin d'objets fonctionnent bien en fonction des besoins du stockage hiérarchisé.  Il s’agit d’un test de base que chaque service de magasin d’objets doit s’attendre à réussir avant les tests suivants.  Il s’agit d’un test assertif qui réussit ou échoue.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Test d'exactitude des fonctionnalités de hiérarchisation</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Ce test détermine si la fonctionnalité de stockage hiérarchisé de bout en bout fonctionne bien avec un test assertif qui réussit ou échoue.  Le test crée une rubrique de test qui, par défaut, est configurée avec la hiérarchisation activée et une taille de hotset fortement réduite.  Il produit un flux d'événements vers la rubrique de test nouvellement créée, il attend que les courtiers archivent les segments dans le magasin d'objets, puis il consomme le flux d'événements et valide que le flux consommé correspond au flux produit.  Le nombre de messages produits dans le flux d'événements est configurable, ce qui permet à l'utilisateur de générer une charge de travail suffisamment importante en fonction des besoins des tests.  La taille réduite du hotset garantit que les récupérations du consommateur en dehors du segment actif sont servies uniquement à partir du magasin d'objets ; cela permet de tester l'exactitude du magasin d'objets pour les lectures.  Nous avons effectué ce test avec et sans injection de fautes dans le magasin d’objets.  Nous avons simulé une défaillance de nœud en arrêtant le service du gestionnaire de services dans l’un des nœuds de StorageGRID et en validant que la fonctionnalité de bout en bout fonctionne avec le stockage d’objets.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Benchmark de récupération de niveaux</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Ce test a validé les performances de lecture du stockage d'objets hiérarchisé et a vérifié la plage de requêtes de lecture d'extraction sous une charge importante à partir des segments générés par le benchmark.  Dans cette référence, Confluent a développé des clients personnalisés pour répondre aux demandes de récupération de niveau.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Benchmark de la charge de travail de production et de consommation</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Ce test a généré indirectement une charge de travail d'écriture sur le magasin d'objets via l'archivage des segments.  La charge de travail de lecture (segments lus) a été générée à partir du stockage d'objets lorsque les groupes de consommateurs ont récupéré les segments.  Cette charge de travail a été générée par le script de test.  Ce test a vérifié les performances de lecture et d'écriture sur le stockage d'objets dans des threads parallèles.  Nous avons testé avec et sans injection de pannes de magasin d'objets comme nous l'avons fait pour le test d'exactitude de la fonctionnalité de hiérarchisation.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Benchmark de la charge de travail de rétention</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Ce test a vérifié les performances de suppression d'un magasin d'objets sous une charge de travail de rétention de sujets importante.  La charge de travail de rétention a été générée à l’aide d’un script de test qui produit de nombreux messages en parallèle avec une rubrique de test.  Le sujet de test consistait à configurer un paramètre de rétention agressif basé sur la taille et le temps, ce qui entraînait la purge continue du flux d'événements du magasin d'objets.  Les segments ont ensuite été archivés.  Cela a conduit à un grand nombre de suppressions dans le stockage d'objets par le courtier et à la collecte des performances des opérations de suppression du magasin d'objets.</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">Qu'est-ce qu'Apache Kafka ?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">Qu'est-ce qu'un renommage idiot ?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP est conçu pour les applications de streaming.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentation produit NetApp</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">Qu'est-ce que NFS ?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">Qu'est-ce que la réaffectation de partition Kafka ?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">Qu'est-ce que le benchmark OpenMessaging ?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">Comment migrer un courtier Kafka ?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Comment surveiller le courtier Kafka avec Prometheus ?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Plateforme gérée pour Apache Kafka</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Prise en charge d'Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Services de conseil pour Apache Kafka</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">La solution NetApp au problème de renommage stupide fournit une forme de stockage simple, peu coûteuse et gérée de manière centralisée pour les charges de travail qui étaient auparavant incompatibles avec NFS.</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">Ce nouveau paradigme permet aux clients de créer des clusters Kafka plus faciles à gérer, plus faciles à migrer et à mettre en miroir à des fins de reprise après sinistre et de protection des données.  Nous avons également constaté que NFS offre des avantages supplémentaires tels qu'une utilisation réduite du processeur et un temps de récupération plus rapide, une efficacité de stockage considérablement améliorée et de meilleures performances grâce à NetApp ONTAP.</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">Ce document décrit les sujets suivants : le problème de renommage idiot et la validation de la solution, la réduction de l'utilisation du processeur pour réduire le temps d'attente des E/S, le temps de récupération plus rapide du courtier Kafka et les performances dans le cloud et sur site.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947 : Charge de travail Apache Kafka avec stockage NetApp NFS – Validation fonctionnelle et performances</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam et Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka est un système de messagerie de publication-abonnement distribué avec une file d'attente robuste qui peut accepter de grandes quantités de données de message.  Avec Kafka, les applications peuvent écrire et lire des données sur des sujets de manière très rapide.  En raison de sa tolérance aux pannes et de son évolutivité, Kafka est souvent utilisé dans l’espace Big Data comme un moyen fiable d’ingérer et de déplacer de nombreux flux de données très rapidement.  Les cas d'utilisation incluent le traitement des flux, le suivi de l'activité du site Web, la collecte et la surveillance des mesures, l'agrégation des journaux, les analyses en temps réel, etc.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">ici</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">Bien que les opérations Kafka normales sur NFS fonctionnent bien, le problème de renommage stupide fait planter l'application lors du redimensionnement ou du repartitionnement d'un cluster Kafka exécuté sur NFS.  Il s’agit d’un problème important car un cluster Kafka doit être redimensionné ou repartitionné à des fins d’équilibrage de charge ou de maintenance.  Vous pouvez trouver des détails supplémentaires<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block> .</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">Ce document décrit les sujets suivants :</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">Le problème du changement de nom idiot et la validation de la solution</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">Réduire l'utilisation du processeur pour réduire le temps d'attente des E/S</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Temps de récupération plus rapide du courtier Kafka</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">Performances dans le cloud et sur site</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Pourquoi utiliser le stockage NFS pour les charges de travail Kafka ?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">Les charges de travail Kafka dans les applications de production peuvent diffuser d’énormes quantités de données entre les applications.  Ces données sont conservées et stockées dans les nœuds du courtier Kafka dans le cluster Kafka.  Kafka est également connu pour sa disponibilité et son parallélisme, qu'il obtient en divisant les sujets en partitions, puis en répliquant ces partitions dans tout le cluster.  Cela signifie finalement que l’énorme quantité de données qui circule dans un cluster Kafka est généralement multipliée en taille.  NFS permet de rééquilibrer les données en fonction des changements du nombre de courtiers très rapidement et facilement.  Pour les environnements de grande taille, le rééquilibrage des données sur DAS lorsque le nombre de courtiers change prend beaucoup de temps et, dans la plupart des environnements Kafka, le nombre de courtiers change fréquemment.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">Les autres avantages comprennent les suivants :</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*Maturité.*  NFS est un protocole mature, ce qui signifie que la plupart des aspects de sa mise en œuvre, de sa sécurisation et de son utilisation sont bien compris.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*Ouvrir.*  NFS est un protocole ouvert et son développement continu est documenté dans les spécifications Internet en tant que protocole réseau libre et ouvert.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*Rentable.*  NFS est une solution économique de partage de fichiers en réseau, facile à configurer car elle utilise l'infrastructure réseau existante.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*Gestion centralisée.*  La gestion centralisée de NFS réduit le besoin de logiciels et d’espace disque supplémentaires sur les systèmes utilisateur individuels.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*Distribué.*  NFS peut être utilisé comme système de fichiers distribué, réduisant ainsi le besoin de périphériques de stockage amovibles.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Pourquoi NetApp pour les charges de travail Kafka ?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">L'implémentation NetApp NFS est considérée comme une référence absolue pour le protocole et est utilisée dans d'innombrables environnements NAS d'entreprise. Outre la crédibilité de NetApp, il offre également les avantages suivants :</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">Fiabilité et efficacité</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">Évolutivité et performance</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">Haute disponibilité (partenaire HA dans un cluster NetApp ONTAP )</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">Protection des données</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*Reprise après sinistre (NetApp SnapMirror).*  Votre site tombe en panne ou vous souhaitez démarrer sur un autre site et reprendre là où vous vous êtes arrêté.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">Facilité de gestion de votre système de stockage (administration et gestion via NetApp OnCommand).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*Équilibrage de charge.*  Le cluster vous permet d'accéder à différents volumes à partir de LIF de données hébergés sur différents nœuds.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*Opérations non perturbatrices.*  Les LIF ou les déplacements de volumes sont transparents pour les clients NFS.</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">Sur site, nous avons utilisé le contrôleur de stockage NetApp AFF A900 avec ONTAP 9.12.1RC1 pour valider les performances et la mise à l'échelle d'un cluster Kafka.  Nous avons utilisé le même banc d’essai que dans nos précédentes meilleures pratiques de stockage hiérarchisé avec ONTAP et AFF.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">Aperçu des performances et validation avec AFF A900 sur site</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">Sur site, nous avons utilisé le contrôleur de stockage NetApp AFF A900 avec ONTAP 9.12.1RC1 pour valider les performances et la mise à l'échelle d'un cluster Kafka.  Nous avons utilisé le même banc d’essai que dans nos précédentes meilleures pratiques de stockage hiérarchisé avec ONTAP et AFF.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">Nous avons utilisé Confluent Kafka 6.2.0 pour évaluer l' AFF A900.  Le cluster comprend huit nœuds de courtier et trois nœuds de gardien de zoo.  Pour les tests de performances, nous avons utilisé cinq nœuds de travail OMB.</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configuration de stockage</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">Nous avons utilisé des instances NetApp FlexGroups pour fournir un espace de noms unique pour les répertoires de journaux, simplifiant ainsi la récupération et la configuration.  Nous avons utilisé NFSv4.1 et pNFS pour fournir un accès direct aux données des segments de journaux.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">Réglage du client</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">Chaque client a monté l’instance FlexGroup avec la commande suivante.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">De plus, nous avons augmenté le<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> à partir de la valeur par défaut<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> à<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block> .  Cela correspond à la limite d'emplacement de session par défaut dans ONTAP.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Réglage du courtier Kafka</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">Afin de maximiser le débit du système testé, nous avons considérablement augmenté les paramètres par défaut pour certains pools de threads clés.  Nous vous recommandons de suivre les meilleures pratiques de Confluent Kafka pour la plupart des configurations.  Ce réglage a été utilisé pour maximiser la concurrence des E/S en attente vers le stockage.  Ces paramètres peuvent être ajustés pour correspondre aux ressources de calcul et aux attributs de stockage de votre courtier.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">Méthodologie de test du générateur de charge de travail</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">Nous avons utilisé les mêmes configurations OMB que pour les tests cloud pour le pilote de débit et la configuration de rubrique.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">Une instance FlexGroup a été provisionnée à l’aide d’Ansible sur un cluster AFF .</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">pNFS a été activé sur le SVM ONTAP .</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">La charge de travail a été déclenchée avec le pilote de débit utilisant la même configuration de charge de travail que pour Cloud Volumes ONTAP.  Voir la section "<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " ci-dessous.  La charge de travail utilisait un facteur de réplication de 3, ce qui signifie que trois copies de segments de journaux étaient conservées dans NFS.</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">Enfin, nous avons réalisé des mesures à l’aide d’un backlog pour évaluer la capacité des consommateurs à rattraper les derniers messages.  L'OMB construit un backlog en mettant les consommateurs en pause au début d'une mesure.  Cela produit trois phases distinctes : la création du backlog (trafic réservé aux producteurs), l'épuisement du backlog (une phase très axée sur les consommateurs dans laquelle les consommateurs rattrapent les événements manqués dans un sujet) et l'état stable. Voir la section "<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> " pour plus d'informations.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">Performances à l'état stable</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">Nous avons évalué l' AFF A900 à l'aide de l'OpenMessaging Benchmark pour fournir une comparaison similaire à celle de Cloud Volumes ONTAP dans AWS et DAS dans AWS.  Toutes les valeurs de performance représentent le débit du cluster Kafka au niveau du producteur et du consommateur.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Les performances en régime permanent avec Confluent Kafka et l' AFF A900 ont atteint un débit moyen de plus de 3,4 Gbit/s pour les producteurs et les consommateurs.  Cela représente plus de 3,4 millions de messages sur l’ensemble du cluster Kafka.  En visualisant le débit soutenu en octets par seconde pour BrokerTopicMetrics, nous constatons les excellentes performances en régime permanent et le trafic pris en charge par l' AFF A900.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">Ce graphique montre le débit du réseau de courtiers.</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">Cela correspond bien à la vue des messages délivrés par sujet.  Le graphique suivant fournit une répartition par sujet.  Dans la configuration testée, nous avons vu près de 900 000 messages par sujet sur quatre sujets.</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">Performances extrêmes et exploration des limites de stockage</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">Pour AFF, nous avons également testé avec OMB en utilisant la fonctionnalité backlog.  La fonctionnalité de backlog suspend les abonnements des consommateurs pendant qu'un backlog d'événements est constitué dans le cluster Kafka.  Au cours de cette phase, seul le trafic du producteur se produit, ce qui génère des événements qui sont validés dans les journaux.  Cela émule le plus étroitement les flux de travail de traitement par lots ou d'analyse hors ligne ; dans ces flux de travail, les abonnements des consommateurs sont démarrés et doivent lire les données historiques qui ont déjà été expulsées du cache du courtier.</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">Pour comprendre les limites de stockage sur le débit du consommateur dans cette configuration, nous avons mesuré la phase réservée au producteur pour comprendre la quantité de trafic d'écriture que l'A900 pouvait absorber.  Voir la section suivante "<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> " pour comprendre comment exploiter ces données.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">Au cours de la partie réservée aux producteurs de cette mesure, nous avons constaté un débit de pointe élevé qui a repoussé les limites des performances de l'A900 (lorsque les autres ressources du courtier n'étaient pas saturées et ne desservaient pas le trafic des producteurs et des consommateurs).</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">Nous avons augmenté la taille du message à 16 Ko pour cette mesure afin de limiter les frais généraux par message et de maximiser le débit de stockage vers les points de montage NFS.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Le cluster Confluent Kafka a atteint un débit de production maximal de 4,03 Gbit/s.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">Une fois que l'OMB a terminé de remplir le backlog des événements, le trafic consommateur a été redémarré.  Lors des mesures avec drainage du backlog, nous avons observé un débit consommateur maximal de plus de 20 Gbit/s sur tous les sujets.  Le débit combiné du volume NFS stockant les données du journal OMB approchait environ 30 Gbit/s.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">Guide de dimensionnement</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">guide des tailles</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services propose une<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> pour le dimensionnement et la mise à l'échelle des clusters Kafka.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">Ce dimensionnement fournit une formule utile pour déterminer les besoins en débit de stockage de votre cluster Kafka :</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">Pour un débit agrégé produit dans le cluster de tcluster avec un facteur de réplication de r, le débit reçu par le stockage du courtier est le suivant :</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">Cela peut être encore simplifié :</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">L’utilisation de cette formule vous permet de sélectionner la plate-forme ONTAP appropriée à vos besoins en matière de niveau chaud Kafka.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">Le tableau suivant explique le débit de production prévu pour l'A900 avec différents facteurs de réplication :</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">Facteur de réplication</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">Débit du producteur (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3 (mesuré)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3,4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5,1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10,2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">Un cluster Kafka avec la couche de stockage montée sur NetApp NFS a été évalué pour les performances dans le cloud AWS.  Les exemples d’analyse comparative sont décrits dans les sections suivantes.</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">Présentation et validation des performances dans AWS FSx ONTAP</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">Un cluster Kafka avec la couche de stockage montée sur NetApp NFS a été évalué pour les performances dans AWS FSx ONTAP.  Les exemples d’analyse comparative sont décrits dans les sections suivantes.</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">Apache Kafka dans AWS FSx ONTAP</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">Network File System (NFS) est un système de fichiers réseau largement utilisé pour stocker de grandes quantités de données.  Dans la plupart des organisations, les données sont de plus en plus générées par des applications de streaming comme Apache Kafka.  Ces charges de travail nécessitent une évolutivité, une faible latence et une architecture d’ingestion de données robuste avec des capacités de stockage modernes.  Pour permettre des analyses en temps réel et fournir des informations exploitables, une infrastructure bien conçue et hautement performante est nécessaire.</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka, de par sa conception, fonctionne avec un système de fichiers compatible POSIX et s'appuie sur le système de fichiers pour gérer les opérations de fichiers, mais lors du stockage de données sur un système de fichiers NFSv3, le client NFS du courtier Kafka peut interpréter les opérations de fichiers différemment d'un système de fichiers local comme XFS ou Ext4.  Un exemple courant est le renommage idiot de NFS qui a provoqué l'échec des courtiers Kafka lors de l'extension des clusters et de la réallocation des partitions.  Pour relever ce défi, NetApp a mis à jour le client NFS Linux open source avec des modifications désormais généralement disponibles dans RHEL8.7, RHEL9.1 et prises en charge à partir de la version actuelle de FSx ONTAP , ONTAP 9.12.1.</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP fournit un système de fichiers NFS entièrement géré, évolutif et hautement performant dans le cloud.  Les données Kafka sur FSx ONTAP peuvent évoluer pour gérer de grandes quantités de données et garantir la tolérance aux pannes.  NFS fournit une gestion centralisée du stockage et une protection des données pour les ensembles de données critiques et sensibles.</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">Ces améliorations permettent aux clients AWS de profiter de FSx ONTAP lors de l’exécution de charges de travail Kafka sur les services de calcul AWS.  Ces avantages sont : * Réduction de l’utilisation du processeur pour réduire le temps d’attente des E/S * Temps de récupération du courtier Kafka plus rapide.  * Fiabilité et efficacité.  * Évolutivité et performance.  * Disponibilité en zone multi-disponibilité.  * Protection des données.</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">Kafka dans AWS FSx ONTAP</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">Un cluster Kafka avec AWS FSx ONTAP a été évalué pour ses performances dans le cloud AWS.  Cette analyse comparative est décrite dans les sections suivantes.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">Configuration architecturale</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">Le tableau suivant présente la configuration environnementale d’un cluster Kafka utilisant AWS FSx ONTAP.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Composant de la plateforme</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configuration de l'environnement</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">Kafka 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 x gardiens de zoo – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 serveurs courtiers – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x producteur/consommateur -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Système d'exploitation sur tous les nœuds</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">Multi-AZ avec un débit de 4 Go/s et 160 000 IOPS</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">Configuration de NetApp FSx ONTAP</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">Pour nos tests initiaux, nous avons créé un système de fichiers FSx ONTAP avec 2 To de capacité et 40 000 IOP pour un débit de 2 Go/s.</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">Dans notre exemple, nous déployons FSx ONTAP via l'AWS CLI.  Vous devrez personnaliser davantage la commande dans votre environnement selon vos besoins.  FSx ONTAP peut également être déployé et géré via la console AWS pour une expérience de déploiement plus simple et plus rationalisée avec moins de saisie de ligne de commande.</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">Dans FSx ONTAP, le nombre maximal d'IOPS réalisables pour un système de fichiers à débit de 2 Go/s dans notre région de test (US-East-1) est de 80 000 IOPS.  Le nombre total d'I/O maximal pour un système de fichiers FSx ONTAP est de 160 000 I/O, ce qui nécessite un déploiement de débit de 4 Go/s pour y parvenir, ce que nous démontrerons plus tard dans ce document.</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">Pour plus d'informations sur les spécifications de performances de FSx ONTAP , n'hésitez pas à consulter la documentation AWS FSx ONTAP ici :<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> .</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">La syntaxe détaillée de la ligne de commande pour FSx « create-file-system » peut être trouvée ici :<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">Par exemple, vous pouvez spécifier une clé KMS spécifique par opposition à la clé principale AWS FSx par défaut qui est utilisée lorsqu'aucune clé KMS n'est spécifiée.</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">Lors de la création du système de fichiers FSx ONTAP , attendez que le statut « LifeCycle » passe à « DISPONIBLE » dans votre retour JSON après avoir décrit votre système de fichiers comme suit :</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">Validez les informations d'identification en vous connectant à FSx ONTAP SSH avec l'utilisateur fsxadmin : Fsxadmin est le compte administrateur par défaut pour les systèmes de fichiers FSx ONTAP lors de la création.  Le mot de passe pour fsxadmin est le mot de passe qui a été configuré lors de la première création du système de fichiers, soit dans la console AWS, soit avec l'AWS CLI, comme nous l'avons fait à l'étape 1.</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">Une fois vos informations d'identification validées, créez la machine virtuelle de stockage sur le système de fichiers FSx ONTAP</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">Une machine virtuelle de stockage (SVM) est un serveur de fichiers isolé avec ses propres informations d'identification administratives et points de terminaison pour administrer et accéder aux données dans les volumes FSx ONTAP et fournit une multilocation FSx ONTAP .</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">Une fois que vous avez configuré votre machine virtuelle de stockage principale, connectez-vous au système de fichiers FSx ONTAP nouvellement créé et créez des volumes dans la machine virtuelle de stockage à l'aide de l'exemple de commande ci-dessous et de la même manière, nous créons 6 volumes pour cette validation.  Sur la base de notre validation, conservez le constituant par défaut (8) ou moins de constituants qui offriront de meilleures performances à Kafka.</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">Nous aurons besoin de capacités supplémentaires dans nos volumes pour nos tests.  Étendez la taille du volume à 2 To et montez-le sur le chemin de jonction.</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">Dans FSx ONTAP, les volumes peuvent être provisionnés de manière dynamique.  Dans notre exemple, la capacité totale du volume étendu dépasse la capacité totale du système de fichiers. Nous devrons donc étendre la capacité totale du système de fichiers afin de débloquer une capacité de volume provisionnée supplémentaire que nous démontrerons dans notre prochaine étape.</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">Ensuite, pour des performances et une capacité supplémentaires, nous étendons la capacité de débit de FSx ONTAP de 2 Go/s à 4 Go/s et les IOPS à 160 000, et la capacité à 5 To.</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">La syntaxe détaillée de la ligne de commande pour FSx « update-file-system » peut être trouvée ici :<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">Les volumes FSx ONTAP sont montés avec nconnect et les options par défaut dans les courtiers Kafka</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">L'image suivante montre notre architecture finale de notre cluster Kafka basé sur FSx ONTAP :</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">Cette image montre l’architecture d’un cluster Kafka basé sur FSx ONTAP.</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">Calculer.  Nous avons utilisé un cluster Kafka à trois nœuds avec un ensemble zookeeper à trois nœuds exécuté sur des serveurs dédiés.  Chaque courtier disposait de six points de montage NFS sur six volumes sur l'instance FSx ONTAP .</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">Surveillance.  Nous avons utilisé deux nœuds pour une combinaison Prometheus-Grafana.  Pour générer des charges de travail, nous avons utilisé un cluster à trois nœuds distinct qui pouvait produire et consommer sur ce cluster Kafka.</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">Stockage.  Nous avons utilisé un FSx ONTAP avec six volumes de 2 To montés.  Le volume a ensuite été exporté vers le courtier Kafka avec un montage NFS. Les volumes FSx ONTAP sont montés avec 16 sessions nconnect et des options par défaut dans les courtiers Kafka.</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">Configurations d'analyse comparative OpenMessage.</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">Nous avons utilisé la même configuration que celle utilisée pour les volumes NetApp Cloud ONTAP et leurs détails sont ici - lien : kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">Méthodologie des tests</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">Un cluster Kafka a été provisionné conformément à la spécification décrite ci-dessus à l'aide de Terraform et d'ansible.  Terraform est utilisé pour créer l'infrastructure à l'aide d'instances AWS pour le cluster Kafka et Ansible construit le cluster Kafka sur celles-ci.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">Une charge de travail OMB a été déclenchée avec la configuration de charge de travail décrite ci-dessus et le pilote Sync.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">Une autre charge de travail a été déclenchée avec le pilote de débit avec la même configuration de charge de travail.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observation</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">Deux types de pilotes différents ont été utilisés pour générer des charges de travail afin d'évaluer les performances d'une instance Kafka exécutée sur NFS.  La différence entre les pilotes est la propriété de vidage du journal.</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Pour un facteur de réplication Kafka 1 et le FSx ONTAP:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Débit total généré de manière cohérente par le pilote Sync : ~ 3 218 Mo/s et performances maximales à ~ 3 652 Mo/s.</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">Débit total généré de manière cohérente par le pilote de débit : ~ 3 679 Mo/s et performances maximales à ~ 3 908 Mo/s.</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">Pour Kafka avec facteur de réplication 3 et FSx ONTAP :</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Débit total généré de manière cohérente par le pilote Sync : ~ 1 252 Mo/s et performances maximales à ~ 1 382 Mo/s.</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">Débit total généré de manière cohérente par le pilote de débit : environ 1 218 Mo/s et performances maximales d'environ 1 328 Mo/s.</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">Dans le facteur de réplication Kafka 3, l'opération de lecture et d'écriture s'est produite trois fois sur le FSx ONTAP. Dans le facteur de réplication Kafka 1, l'opération de lecture et d'écriture s'est produite une fois sur le FSx ONTAP. Ainsi, dans les deux validations, nous avons pu atteindre le débit maximal de 4 Go/s.</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">Le pilote de synchronisation peut générer un débit constant lorsque les journaux sont vidés instantanément sur le disque, tandis que le pilote de débit génère des rafales de débit lorsque les journaux sont validés sur le disque en masse.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">Ces numéros de débit sont générés pour la configuration AWS donnée.  Pour des exigences de performances plus élevées, les types d'instances peuvent être mis à l'échelle et optimisés davantage pour de meilleurs chiffres de débit.  Le débit total ou le taux total est la combinaison du taux du producteur et du taux du consommateur.</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">Cette image montre les performances de Kafka avec RF1 et RF3</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">Le graphique ci-dessous montre les performances de FSx ONTAP à 2 Go/s et de 4 Go/s pour le facteur de réplication Kafka 3.  Le facteur de réplication 3 effectue l'opération de lecture et d'écriture trois fois sur le stockage FSx ONTAP .  Le débit total du pilote de débit est de 881 Mo/s, ce qui permet de lire et d'écrire l'opération Kafka à environ 2,64 Go/s sur le système de fichiers FSx ONTAP à 2 Go/s et le débit total du pilote de débit est de 1 328 Mo/s, ce qui permet de lire et d'écrire l'opération Kafka à environ 3,98 Go/s.  Les performances de Kafka sont linéaires et évolutives en fonction du débit FSx ONTAP .</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">Cette image montre les performances de mise à l'échelle de 2 Go/s et 4 Go/s.</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">Le graphique ci-dessous montre les performances entre l'instance EC2 et FSx ONTAP (facteur de réplication Kafka : 3)</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">Cette image montre la comparaison des performances d'EC2 et de FSx ONTAP dans RF3.</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">Aperçu des performances et validation dans AWS</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">Kafka dans le cloud AWS avec NetApp Cloud Volumes ONTAP (paire haute disponibilité et nœud unique)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">Un cluster Kafka avec NetApp Cloud Volumes ONTAP (paire HA) a été évalué pour ses performances dans le cloud AWS.  Cette analyse comparative est décrite dans les sections suivantes.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">Le tableau suivant montre la configuration environnementale d’un cluster Kafka utilisant NAS.</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">Instance NetApp Cloud Volumes ONTAP</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">Instance de paire HA – m5dn.12xLarge x 2node Instance de nœud unique - m5dn.12xLarge x 1 nœud</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">Configuration du volume de cluster NetApp ONTAP</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Pour la paire Cloud Volumes ONTAP HA, nous avons créé deux agrégats avec trois volumes sur chaque agrégat sur chaque contrôleur de stockage.  Pour le nœud unique Cloud Volumes ONTAP , nous créons six volumes dans un agrégat.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">Cette image illustre les propriétés d'aggr3 et d'aggr22.</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">Cette image illustre les propriétés d'aggr2.</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">Pour obtenir de meilleures performances réseau, nous avons activé la mise en réseau à haut débit pour la paire HA et le nœud unique.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">Cette image montre comment activer la mise en réseau à haut débit.</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">Nous avons remarqué que la NVRAM ONTAP avait plus d'IOPS, nous avons donc modifié les IOPS à 2350 pour le volume racine Cloud Volumes ONTAP .  Le disque du volume racine dans Cloud Volumes ONTAP avait une taille de 47 Go.  La commande ONTAP suivante concerne la paire HA et la même étape s’applique au nœud unique.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">Cette image montre comment modifier les propriétés du volume.</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">La figure suivante illustre l’architecture d’un cluster Kafka basé sur NAS.</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*Calculer.*  Nous avons utilisé un cluster Kafka à trois nœuds avec un ensemble zookeeper à trois nœuds exécuté sur des serveurs dédiés.  Chaque courtier disposait de deux points de montage NFS sur un seul volume sur l'instance Cloud Volumes ONTAP via un LIF dédié.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*Surveillance.*  Nous avons utilisé deux nœuds pour une combinaison Prometheus-Grafana.  Pour générer des charges de travail, nous avons utilisé un cluster à trois nœuds distinct qui pouvait produire et consommer sur ce cluster Kafka.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*Stockage.*  Nous avons utilisé une instance ONTAP de volumes Cloud à paire HA avec un volume AWS-EBS GP3 de 6 To monté sur l'instance.  Le volume a ensuite été exporté vers le courtier Kafka avec un montage NFS.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">Cette figure illustre l’architecture d’un cluster Kafka basé sur NAS.</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">Configurations d'analyse comparative d'OpenMessage</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">Pour de meilleures performances NFS, nous avons besoin de plus de connexions réseau entre le serveur NFS et le client NFS, qui peuvent être créées à l'aide de nconnect.  Montez les volumes NFS sur les nœuds du courtier avec l'option nconnect en exécutant la commande suivante :</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Vérifiez les connexions réseau dans Cloud Volumes ONTAP.  La commande ONTAP suivante est utilisée à partir du nœud Cloud Volumes ONTAP unique.  La même étape s’applique à la paire Cloud Volumes ONTAP HA.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">Nous utilisons le Kafka suivant<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> dans tous les courtiers Kafka pour la paire Cloud Volumes ONTAP HA.  Le<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la propriété est différente pour chaque courtier, et les propriétés restantes sont communes aux courtiers.  Pour broker1, le<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la valeur est la suivante :</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">Pour broker2, le<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la valeur de la propriété est la suivante :</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">Pour broker3, le<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la valeur de la propriété est la suivante :</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">Pour le nœud unique Cloud Volumes ONTAP , Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> est le même que pour la paire Cloud Volumes ONTAP HA, à l'exception du<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> propriété.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">Pour broker1, le<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la valeur est la suivante :</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">Pour broker2, le<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> la valeur est la suivante :</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">La charge de travail dans l'OMB est configurée avec les propriétés suivantes :<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> .</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">Le<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> peut varier pour chaque cas d'utilisation.  Dans notre test de performance, nous avons utilisé 3K.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Nous avons utilisé deux pilotes différents, Sync ou Throughput, d'OMB pour générer la charge de travail sur le cluster Kafka.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">Le fichier yaml utilisé pour les propriétés du pilote de synchronisation est le suivant<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> :</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">Le fichier yaml utilisé pour les propriétés du pilote de débit est le suivant<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> :</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Un cluster Kafka a été provisionné conformément à la spécification décrite ci-dessus à l'aide de Terraform et Ansible.  Terraform est utilisé pour créer l'infrastructure à l'aide d'instances AWS pour le cluster Kafka et Ansible construit le cluster Kafka sur celles-ci.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Pour une paire Cloud Volumes ONTAP HA :</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Débit total généré de manière cohérente par le pilote Sync : environ 1 236 Mo/s.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Débit total généré pour le pilote de débit : pic ~ 1 412 Mo/s.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">Pour un seul nœud Cloud Volumes ONTAP :</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Débit total généré de manière cohérente par le pilote Sync : ~ 1 962 Mo/s.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Débit total généré par le pilote de débit : pic ~ 1 660 Mo/s</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">Quatre graphiques différents sont présentés ici.  Pilote de débit de paire CVO-HA.  Pilote de synchronisation de paire CVO-HA.  Pilote de débit à nœud unique CVO.  Pilote de synchronisation à nœud unique CVO.</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">Assurez-vous de vérifier le débit de stockage lorsque vous effectuez une analyse comparative du débit ou du pilote de synchronisation.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">Ce graphique montre les performances en termes de latence, d'IOPS et de débit.</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">Cette section décrit le problème de renommage stupide et les modifications requises pour que le serveur NFS et le client NFS résolvent le problème.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">Solution NetApp pour le problème de renommage stupide des charges de travail NFS vers Kafka</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka est construit avec l'hypothèse que le système de fichiers sous-jacent est compatible POSIX : par exemple, XFS ou Ext4.  Le rééquilibrage des ressources Kafka supprime les fichiers pendant que l'application les utilise encore.  Un système de fichiers compatible POSIX permet de procéder à la dissociation.  Cependant, il ne supprime le fichier qu'une fois que toutes les références au fichier ont disparu.  Si le système de fichiers sous-jacent est connecté au réseau, le client NFS intercepte les appels de dissociation et gère le flux de travail.  Étant donné qu'il existe des ouvertures en attente sur le fichier en cours de dissociation, le client NFS envoie une demande de changement de nom au serveur NFS et, lors de la dernière fermeture du fichier dissocié, émet une opération de suppression sur le fichier renommé.  Ce comportement est communément appelé renommage idiot NFS et il est orchestré par le client NFS.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">Tout courtier Kafka utilisant le stockage d’un serveur NFSv3 rencontre des problèmes en raison de ce comportement.  Cependant, le protocole NFSv4.x dispose de fonctionnalités permettant de résoudre ce problème en permettant au serveur d'assumer la responsabilité des fichiers ouverts et non liés.  Les serveurs NFS prenant en charge cette fonctionnalité facultative communiquent la capacité de propriété au client NFS au moment de l'ouverture du fichier.  Le client NFS cesse alors la gestion de la dissociation lorsqu'il y a des ouvertures en attente et permet au serveur de gérer le flux.  Bien que la spécification NFSv4 fournisse des directives pour la mise en œuvre, jusqu'à présent, il n'existait aucune implémentation de serveur NFS connue prenant en charge cette fonctionnalité facultative.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">Les modifications suivantes sont nécessaires pour que le serveur NFS et le client NFS résolvent le problème de renommage stupide :</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*Modifications apportées au client NFS (Linux).*  Au moment de l'ouverture du fichier, le serveur NFS répond avec un indicateur, indiquant la capacité à gérer la dissociation des fichiers ouverts.  Les modifications côté client NFS permettent au serveur NFS de gérer la dissociation en présence de l'indicateur.  NetApp a mis à jour le client NFS Linux open source avec ces modifications.  Le client NFS mis à jour est désormais généralement disponible dans RHEL8.7 et RHEL9.1.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*Modifications apportées au serveur NFS.*  Le serveur NFS garde une trace des ouvertures.  La dissociation d'un fichier ouvert existant est désormais gérée par le serveur pour correspondre à la sémantique POSIX.  Lorsque la dernière ouverture est fermée, le serveur NFS lance alors la suppression effective du fichier et évite ainsi le processus de renommage stupide.  Le serveur ONTAP NFS a implémenté cette capacité dans sa dernière version, ONTAP 9.12.1.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">Grâce aux modifications ci-dessus apportées au client et au serveur NFS, Kafka peut profiter en toute sécurité de tous les avantages du stockage NFS connecté au réseau.</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">Pour la validation fonctionnelle, nous avons montré qu'un cluster Kafka avec un montage NFSv3 pour le stockage ne parvient pas à effectuer des opérations Kafka comme la redistribution de partition, alors qu'un autre cluster monté sur NFSv4 avec le correctif peut effectuer les mêmes opérations sans aucune interruption.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">Validation fonctionnelle - Correction d'un changement de nom idiot</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">Configuration de validation</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">L'installation est exécutée sur AWS.  Le tableau suivant présente les différents composants de la plateforme et la configuration environnementale utilisés pour la validation.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Plateforme Confluent version 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 x gardiens de zoo – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 serveurs courtiers – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x centre de contrôle – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x Producteur/consommateur</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL 8.7 ou version ultérieure</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">Instance à nœud unique – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">La figure suivante montre la configuration architecturale de cette solution.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">Cette image montre la topologie AWS contenant un VPC contenant trois sous-réseaux privés avec un essaim de producteurs, le cluster Kafka et l'instance CVO respectivement.</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">Flux architectural</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*Calculer.*  Nous avons utilisé un cluster Kafka à quatre nœuds avec un ensemble zookeeper à trois nœuds exécuté sur des serveurs dédiés.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*Surveillance.*  Nous avons utilisé deux nœuds pour une combinaison Prometheus-Grafana.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*Charge de travail.*  Pour générer des charges de travail, nous avons utilisé un cluster à trois nœuds distinct qui peut produire et consommer à partir de ce cluster Kafka.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*Stockage.*  Nous avons utilisé une instance ONTAP de volumes NetApp Cloud à nœud unique avec deux volumes AWS-EBS GP2 de 500 Go attachés à l'instance.  Ces volumes ont ensuite été exposés au cluster Kafka en tant que volume NFSv4.1 unique via un LIF.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">Les propriétés par défaut de Kafka ont été choisies pour tous les serveurs.  La même chose a été faite pour l’essaim de gardiens de zoo.</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">Mise à jour<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> au volume Kafka, comme suit :</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">Deux clusters Kafka similaires ont été créés avec la différence suivante :</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*Groupe 1.*  Le serveur backend NFS v4.1 exécutant la version ONTAP 9.12.1 prête pour la production était hébergé par une instance NetApp CVO.  RHEL 8.7/RHEL 9.1 ont été installés sur les courtiers.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*Groupe 2.*  Le serveur NFS principal était un serveur Linux NFSv3 générique créé manuellement.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">Un sujet de démonstration a été créé sur les deux clusters Kafka.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">Groupe 1 :</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">Cette capture d’écran montre le sujet de démonstration créé sur le cluster 1.</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">Groupe 2 :</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">Cette capture d’écran montre le sujet de démonstration créé sur le cluster 2.</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">Les données ont été chargées dans ces rubriques nouvellement créées pour les deux clusters.  Cela a été fait en utilisant la boîte à outils producer-perf-test fournie dans le package Kafka par défaut :</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Un contrôle de santé a été effectué pour broker-1 pour chacun des clusters à l'aide de telnet :</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">telnet<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">telnet<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">Un contrôle de santé réussi pour les courtiers sur les deux clusters est présenté dans la capture d'écran suivante :</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">Cette capture d'écran montre la lecture d'un contrôle de santé réussi sur les deux courtiers.</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">Pour déclencher la condition d’échec qui provoque le blocage des clusters Kafka utilisant des volumes de stockage NFSv3, nous avons lancé le processus de réaffectation de partition sur les deux clusters.  La réaffectation des partitions a été effectuée à l'aide de<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> .  Le processus détaillé est le suivant :</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Pour réaffecter les partitions d'un sujet dans un cluster Kafka, nous avons généré la configuration de réaffectation proposée JSON (cela a été effectué pour les deux clusters).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">Le JSON de réaffectation généré a ensuite été enregistré dans<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> .</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">Le processus de réaffectation de partition réel a été déclenché par la commande suivante :</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">Quelques minutes après la fin de la réaffectation, un autre contrôle de santé sur les courtiers a montré que le cluster utilisant des volumes de stockage NFSv3 avait rencontré un problème de renommage stupide et s'était écrasé, tandis que le cluster 1 utilisant des volumes de stockage NetApp ONTAP NFSv4.1 avec le correctif a continué ses opérations sans aucune interruption.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">Cette capture d'écran montre la sortie d'un courtier en panne.</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 est actif.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 est mort.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Après avoir vérifié les répertoires de journaux Kafka, il était clair que le cluster 1 utilisant les volumes de stockage NetApp ONTAP NFSv4.1 avec le correctif avait une attribution de partition propre, tandis que le cluster 2 utilisant le stockage NFSv3 générique ne l'avait pas en raison de problèmes de renommage stupides, ce qui a conduit au crash.  L'image suivante montre le rééquilibrage des partitions du cluster 2, qui a entraîné un problème de renommage stupide sur le stockage NFSv3.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">Cette capture d'écran montre la sortie du journal pour le crash du cluster 2.</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">L'image suivante montre un rééquilibrage de partition propre du cluster 1 à l'aide du stockage NetApp NFSv4.1.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">Cette capture d'écran montre la sortie du journal pour une affectation de partition propre réussie pour le cluster 1 alors que</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Maintenant qu’il existe une solution au problème de renommage stupide dans le stockage NFS avec Kafka, vous pouvez créer des déploiements robustes qui exploitent le stockage NetApp ONTAP pour votre charge de travail Kafka.  Non seulement cela réduit considérablement les frais opérationnels, mais cela apporte également les avantages suivants à vos clusters Kafka.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Pourquoi NetApp NFS pour les charges de travail Kafka ?</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Maintenant qu’il existe une solution au problème de renommage stupide dans le stockage NFS avec Kafka, vous pouvez créer des déploiements robustes qui exploitent le stockage NetApp ONTAP pour votre charge de travail Kafka.  Non seulement cela réduit considérablement les frais opérationnels, mais cela apporte également les avantages suivants à vos clusters Kafka :</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Utilisation réduite du processeur sur les courtiers Kafka.*  L'utilisation d'un stockage NetApp ONTAP désagrégé sépare les opérations d'E/S de disque du courtier et réduit ainsi son empreinte CPU.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*Temps de récupération du courtier plus rapide.*  Étant donné que le stockage NetApp ONTAP désagrégé est partagé entre les nœuds de courtier Kafka, une nouvelle instance de calcul peut remplacer un courtier défectueux à tout moment en une fraction du temps par rapport aux déploiements Kafka conventionnels sans reconstruire les données.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*Efficacité de stockage.* Étant donné que la couche de stockage de l'application est désormais provisionnée via NetApp ONTAP, les clients peuvent bénéficier de tous les avantages de l'efficacité du stockage offerts par ONTAP, tels que la compression des données en ligne, la déduplication et le compactage.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">Ces avantages ont été testés et validés dans des cas de test que nous discutons en détail dans cette section.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Utilisation réduite du processeur sur le courtier Kafka</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">Nous avons découvert que l'utilisation globale du processeur est inférieure à celle de son homologue DAS lorsque nous avons exécuté des charges de travail similaires sur deux clusters Kafka distincts qui étaient identiques dans leurs spécifications techniques mais différaient dans leurs technologies de stockage.  Non seulement l’utilisation globale du processeur est plus faible lorsque le cluster Kafka utilise le stockage ONTAP , mais l’augmentation de l’utilisation du processeur a démontré un gradient plus doux que dans un cluster Kafka basé sur DAS.</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">Le tableau suivant montre la configuration environnementale utilisée pour démontrer l’utilisation réduite du processeur.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Outil d'analyse comparative Kafka 3.2.3 : OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x Producteur/Consommateur -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 ou version ultérieure</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">Instance à nœud unique – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">Outil d'analyse comparative</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">OpenMessaging</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">L'outil d'analyse comparative utilisé dans ce cas de test est le<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> cadre.  OpenMessaging est indépendant des fournisseurs et de la langue ; il fournit des directives sectorielles pour la finance, le commerce électronique, l'IoT et le big data ; et il aide à développer des applications de messagerie et de streaming sur des systèmes et des plates-formes hétérogènes.  La figure suivante illustre l’interaction des clients OpenMessaging avec un cluster Kafka.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">Cette image illustre l’interaction des clients OpenMessaging avec un cluster Kafka.</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*Calculer.*  Nous avons utilisé un cluster Kafka à trois nœuds avec un ensemble zookeeper à trois nœuds exécuté sur des serveurs dédiés.  Chaque courtier disposait de deux points de montage NFSv4.1 sur un seul volume sur l'instance NetApp CVO via un LIF dédié.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*Surveillance.*  Nous avons utilisé deux nœuds pour une combinaison Prometheus-Grafana.  Pour générer des charges de travail, nous disposons d'un cluster distinct à trois nœuds qui peut produire et consommer à partir de ce cluster Kafka.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*Stockage.*  Nous avons utilisé une instance ONTAP de volumes NetApp Cloud à nœud unique avec six volumes AWS-EBS GP2 de 250 Go montés sur l'instance.  Ces volumes ont ensuite été exposés au cluster Kafka sous forme de six volumes NFSv4.1 via des LIF dédiés.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*Configuration.*  Les deux éléments configurables dans ce cas de test étaient les courtiers Kafka et les charges de travail OpenMessaging.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*Configuration du courtier.*  Les spécifications suivantes ont été sélectionnées pour les courtiers Kafka.  Nous avons utilisé un facteur de réplication de 3 pour toutes les mesures, comme indiqué ci-dessous.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">Cette image illustre les spécifications sélectionnées pour les courtiers Kafka.</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*Configuration de la charge de travail du benchmark OpenMessaging (OMB).*  Les spécifications suivantes ont été fournies.  Nous avons spécifié un taux de producteur cible, mis en évidence ci-dessous.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">Cette image illustre les spécifications sélectionnées pour la configuration de la charge de travail de référence OpenMessaging.</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">Deux clusters similaires ont été créés, chacun disposant de son propre ensemble d'essaims de clusters d'analyse comparative.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*Groupe 1.*  Cluster Kafka basé sur NFS.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*Groupe 2.*  Cluster Kafka basé sur DAS.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">À l’aide d’une commande OpenMessaging, des charges de travail similaires ont été déclenchées sur chaque cluster.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">La configuration du taux de production a été augmentée en quatre itérations et l'utilisation du processeur a été enregistrée avec Grafana.  Le taux de production a été fixé aux niveaux suivants :</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10 000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40 000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80 000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100 000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">L’utilisation du stockage NetApp NFS avec Kafka présente deux avantages principaux :</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*Vous pouvez réduire l’utilisation du processeur de près d’un tiers.*  L'utilisation globale du processeur sous des charges de travail similaires était inférieure pour NFS par rapport aux SSD DAS ; les économies varient de 5 % pour des taux de production inférieurs à 32 % pour des taux de production plus élevés.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*Une réduction de trois fois de la dérive d'utilisation du processeur à des taux de production plus élevés.*  Comme prévu, il y a eu une tendance à la hausse de l’utilisation du processeur à mesure que les taux de production ont augmenté.  Cependant, l'utilisation du processeur sur les courtiers Kafka utilisant DAS est passée de 31 % pour le taux de production inférieur à 70 % pour le taux de production supérieur, soit une augmentation de 39 %.  Cependant, avec un backend de stockage NFS, l'utilisation du processeur est passée de 26 % à 38 %, soit une augmentation de 12 %.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">Ce graphique illustre le comportement d’un cluster basé sur DAS.</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">Ce graphique illustre le comportement d’un cluster basé sur NFS.</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">De plus, à 100 000 messages, DAS affiche une utilisation du processeur supérieure à celle d'un cluster NFS.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">Ce graphique illustre le comportement d’un cluster basé sur DAS à 100 000 messages.</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">Ce graphique illustre le comportement d’un cluster basé sur NFS à 100 000 messages.</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">Récupération plus rapide des courtiers</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Nous avons découvert que les courtiers Kafka récupèrent plus rapidement lorsqu’ils utilisent un stockage NetApp NFS partagé.  Lorsqu'un courtier tombe en panne dans un cluster Kafka, ce courtier peut être remplacé par un courtier sain avec le même ID de courtier.  Après avoir effectué ce cas de test, nous avons constaté que, dans le cas d'un cluster Kafka basé sur DAS, le cluster reconstruit les données sur un courtier sain nouvellement ajouté, ce qui prend du temps.  Dans le cas d'un cluster Kafka basé sur NetApp NFS, le courtier de remplacement continue de lire les données du répertoire de journaux précédent et récupère beaucoup plus rapidement.</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x producteur/consommateur -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x nœud Kafka de sauvegarde – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 ou version ultérieure</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*Calculer.*  Un cluster Kafka à trois nœuds avec un ensemble zookeeper à trois nœuds exécuté sur des serveurs dédiés.  Chaque courtier dispose de deux points de montage NFS sur un seul volume sur l'instance NetApp CVO via un LIF dédié.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*Surveillance.*  Deux nœuds pour une combinaison Prometheus-Grafana.  Pour générer des charges de travail, nous utilisons un cluster à trois nœuds distinct qui peut produire et consommer sur ce cluster Kafka.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*Stockage.*  Une instance ONTAP de volumes NetApp Cloud à nœud unique avec six volumes AWS-EBS GP2 de 250 Go montés sur l'instance.  Ces volumes sont ensuite exposés au cluster Kafka sous forme de six volumes NFS via des LIF dédiés.</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*Configuration du courtier.*  Le seul élément configurable dans ce cas de test sont les courtiers Kafka.  Les spécifications suivantes ont été sélectionnées pour les courtiers Kafka.  Le<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> est défini sur une valeur élevée car cela détermine la vitesse à laquelle un nœud particulier est retiré de la liste ISR.  Lorsque vous basculez entre des nœuds défectueux et sains, vous ne souhaitez pas que cet ID de courtier soit exclu de la liste ISR.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">Cette image montre les spécifications choisies pour les courtiers Kafka.</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">Deux clusters similaires ont été créés :</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">Un cluster confluent basé sur EC2.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">Un cluster confluent basé sur NetApp NFS.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">Un nœud Kafka de secours a été créé avec une configuration identique aux nœuds du cluster Kafka d'origine.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">Sur chacun des clusters, un exemple de sujet a été créé et environ 110 Go de données ont été renseignés sur chacun des courtiers.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*Cluster basé sur EC2.*  Un répertoire de données de courtier Kafka est mappé sur<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (Dans la figure suivante, Broker-1 du cluster1 [terminal gauche]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* Cluster basé sur NetApp NFS.*  Un répertoire de données de courtier Kafka est monté sur un point NFS<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (Dans la figure suivante, Broker-1 du cluster2 [terminal de droite]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">Cette image montre deux écrans de terminal.</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">Dans chacun des clusters, Broker-1 a été arrêté pour déclencher un processus de récupération de courtier ayant échoué.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">Une fois le courtier terminé, l'adresse IP du courtier a été attribuée comme adresse IP secondaire au courtier de secours.  Cela était nécessaire car un courtier dans un cluster Kafka est identifié par les éléments suivants :</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*Adresse IP.*  Attribué en réaffectant l'IP du courtier défaillant au courtier de secours.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*Identifiant du courtier.*  Ceci a été configuré dans le courtier de secours<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> .</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">Lors de l'attribution de l'IP, le service Kafka a été démarré sur le courtier de secours.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">Après un certain temps, les journaux du serveur ont été extraits pour vérifier le temps nécessaire à la création des données sur le nœud de remplacement du cluster.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">La récupération du courtier Kafka a été presque neuf fois plus rapide.  Le temps nécessaire pour récupérer un nœud de courtier défaillant s'est avéré nettement plus rapide lors de l'utilisation du stockage partagé NetApp NFS par rapport à l'utilisation de SSD DAS dans un cluster Kafka.  Pour 1 To de données de sujet, le temps de récupération pour un cluster basé sur DAS était de 48 minutes, contre moins de 5 minutes pour un cluster Kafka basé sur NetApp-NFS.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">Nous avons observé que le cluster basé sur EC2 a mis 10 minutes pour reconstruire les 110 Go de données sur le nouveau nœud de courtier, tandis que le cluster basé sur NFS a terminé la récupération en 3 minutes.  Nous avons également observé dans les journaux que les décalages des consommateurs pour les partitions pour EC2 étaient de 0, tandis que, sur le cluster NFS, les décalages des consommateurs étaient récupérés à partir du courtier précédent.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">Cluster basé sur DAS</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">Le nœud de sauvegarde a démarré à 08:55:53,730.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">Cette image montre la sortie du journal pour un cluster basé sur DAS.</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">Le processus de reconstruction des données s'est terminé à 09:05:24,860.  Le traitement de 110 Go de données a nécessité environ 10 minutes.</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">Cluster basé sur NFS</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">Le nœud de sauvegarde a été démarré à 09:39:17,213.  L'entrée du journal de départ est mise en évidence ci-dessous.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">Cette image montre la sortie du journal pour un cluster basé sur NFS.</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">Le processus de reconstruction des données s'est terminé à 09:42:29,115.  Le traitement de 110 Go de données a nécessité environ 3 minutes.</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">Le test a été répété pour les courtiers contenant environ 1 To de données, ce qui a pris environ 48 minutes pour le DAS et 3 minutes pour le NFS.  Les résultats sont représentés dans le graphique suivant.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">Ce graphique montre le temps nécessaire à la récupération du courtier en fonction de la quantité de données chargées sur le courtier pour un cluster basé sur DAS ou un cluster basé sur NFS.</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">Efficacité du stockage</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Étant donné que la couche de stockage du cluster Kafka a été provisionnée via NetApp ONTAP, nous avons obtenu toutes les capacités d’efficacité de stockage d’ ONTAP.  Cela a été testé en générant une quantité importante de données sur un cluster Kafka avec un stockage NFS provisionné sur Cloud Volumes ONTAP.  Nous avons pu constater une réduction significative de l’espace grâce aux capacités ONTAP .</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">Instance à nœud unique – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*Calculer.*  Nous avons utilisé un cluster Kafka à trois nœuds avec un ensemble zookeeper à trois nœuds exécuté sur des serveurs dédiés.  Chaque courtier disposait de deux points de montage NFS sur un seul volume sur l'instance NetApp CVO via un LIF dédié.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*Stockage.*  Nous avons utilisé une instance NetApp Cloud Volumes ONTAP à nœud unique avec six volumes AWS-EBS GP2 de 250 Go montés sur l'instance.  Ces volumes ont ensuite été exposés au cluster Kafka sous forme de six volumes NFS via des LIF dédiés.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*Configuration.*  Les éléments configurables dans ce cas de test étaient les courtiers Kafka.</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">La compression a été désactivée du côté du producteur, permettant ainsi aux producteurs de générer un débit élevé.  L'efficacité du stockage était plutôt gérée par la couche de calcul.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">Un cluster Kafka a été provisionné avec les spécifications mentionnées ci-dessus.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">Sur le cluster, environ 350 Go de données ont été produites à l’aide de l’outil OpenMessaging Benchmarking.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">Une fois la charge de travail terminée, les statistiques d'efficacité du stockage ont été collectées à l'aide ONTAP System Manager et de l'interface de ligne de commande.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">Pour les données générées à l’aide de l’outil OMB, nous avons constaté des économies d’espace d’environ 33 % avec un ratio d’efficacité de stockage de 1,70:1.  Comme le montrent les figures suivantes, l’espace logique utilisé par les données produites était de 420,3 Go et l’espace physique utilisé pour contenir les données était de 281,7 Go.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">Cette image illustre les économies d’espace dans VMDISK.</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">Capture d'écran</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Ce document décrit les tests de performances de la plateforme Confluent sur NetApp ONTAP à l'aide d'un kit d'analyse comparative de stockage à plusieurs niveaux.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941 : Confluent avec les contrôleurs de stockage NetApp ONTAP</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Pour rendre la plateforme Confluent plus évolutive et élastique, elle doit être capable de faire évoluer et d’équilibrer les charges de travail très rapidement.  Le stockage hiérarchisé permet de gérer le stockage d’énormes volumes de données dans Confluent en réduisant cette charge opérationnelle.</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">L’idée fondamentale est de séparer le stockage des données du traitement des données, ce qui facilite grandement la mise à l’échelle indépendante de chacun.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Doté d'innovations de pointe, le logiciel de gestion de données NetApp ONTAP offre à Confluent de nombreux avantages partout où se trouvent les données.</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Nous avons effectué les tests de stockage à plusieurs niveaux avec trois à quatre nœuds pour les charges de travail de production et de consommation avec la configuration NetApp StorageGRID .</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Tests de performance avec évolutivité</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Nous avons effectué les tests de stockage hiérarchisé avec trois à quatre nœuds pour les charges de travail des producteurs et des consommateurs avec la configuration NetApp StorageGRID .  Selon nos tests, le temps d’exécution et les résultats de performance étaient directement proportionnels au nombre de nœuds StorageGRID .  La configuration de StorageGRID nécessitait un minimum de trois nœuds.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">Le temps nécessaire pour terminer l’opération de production et de consommation a diminué linéairement lorsque le nombre de nœuds de stockage a augmenté.</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">Les performances de l’opération de récupération s3 ont augmenté linéairement en fonction du nombre de nœuds StorageGRID .  StorageGRID prend en charge jusqu'à 200 nœuds StorgeGRID.</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Ce test est basé sur la fonctionnalité de clusters auto-équilibrés, qui automatise le rééquilibrage en fonction des changements de topologie du cluster ou d'une charge inégale.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Clusters auto-équilibrés confluents</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Si vous avez déjà géré un cluster Kafka, vous connaissez probablement les défis liés à la réaffectation manuelle de partitions à différents courtiers pour garantir que la charge de travail est équilibrée sur l'ensemble du cluster.  Pour les organisations disposant de déploiements Kafka importants, la réorganisation de grandes quantités de données peut être intimidante, fastidieuse et risquée, en particulier si des applications critiques sont construites sur le cluster.  Cependant, même pour les plus petits cas d’utilisation de Kafka, le processus prend du temps et est sujet à des erreurs humaines.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">Dans notre laboratoire, nous avons testé la fonctionnalité de clusters auto-équilibrés de Confluent, qui automatise le rééquilibrage en fonction des changements de topologie du cluster ou d'une charge inégale.  Le test de rééquilibrage Confluent permet de mesurer le temps nécessaire pour ajouter un nouveau courtier lorsque la défaillance du nœud ou le nœud de mise à l'échelle nécessite un rééquilibrage des données entre les courtiers.  Dans les configurations Kafka classiques, la quantité de données à rééquilibrer augmente à mesure que le cluster se développe, mais, dans le stockage hiérarchisé, le rééquilibrage est limité à une petite quantité de données.  D'après notre validation, le rééquilibrage du stockage hiérarchisé prend quelques secondes ou minutes dans une architecture Kafka classique et augmente de manière linéaire à mesure que le cluster se développe.</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">Dans les clusters à équilibrage automatique, les rééquilibrages de partition sont entièrement automatisés pour optimiser le débit de Kafka, accélérer la mise à l'échelle du courtier et réduire la charge opérationnelle liée à l'exécution d'un grand cluster.  À l'état stable, les clusters auto-équilibrés surveillent l'asymétrie des données entre les courtiers et réaffectent en permanence les partitions pour optimiser les performances du cluster.  Lors de la mise à l'échelle de la plate-forme vers le haut ou vers le bas, les clusters auto-équilibrés reconnaissent automatiquement la présence de nouveaux courtiers ou la suppression d'anciens courtiers et déclenchent une réaffectation de partition ultérieure.  Cela vous permet d'ajouter et de désactiver facilement des courtiers, rendant vos clusters Kafka fondamentalement plus élastiques.  Ces avantages sont offerts sans aucune intervention manuelle, sans calculs complexes ni risque d’erreur humaine que les réaffectations de partitions impliquent généralement.  Par conséquent, les rééquilibrages de données sont effectués en beaucoup moins de temps et vous êtes libre de vous concentrer sur des projets de diffusion d'événements à plus forte valeur ajoutée plutôt que de devoir superviser en permanence vos clusters.</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">Dans cette configuration, nous vous montrons comment lire et écrire des rubriques dans le stockage d'objets à partir de Kafka directement à l'aide du connecteur de récepteur Kafka s3.  Pour ce test, nous avons utilisé un cluster Confluent autonome, mais cette configuration est applicable à un cluster distribué.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Connecteur Confluent s3</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Le connecteur Amazon S3 Sink exporte les données des rubriques Apache Kafka vers des objets S3 aux formats Avro, JSON ou Bytes.  Le connecteur de récepteur Amazon S3 interroge périodiquement les données de Kafka et les télécharge à son tour vers S3.  Un partitionneur est utilisé pour diviser les données de chaque partition Kafka en morceaux.  Chaque bloc de données est représenté sous la forme d’un objet S3.  Le nom de la clé code le sujet, la partition Kafka et le décalage de début de ce bloc de données.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Téléchargez Confluent Kafka depuis le site Web de Confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Décompressez le package dans un dossier sur votre serveur.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exporter deux variables.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Pour une configuration Confluent Kafka autonome, le cluster crée un dossier racine temporaire dans<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> Il crée également Zookeeper, Kafka, un registre de schémas, connect, un serveur ksql et des dossiers de centre de contrôle et copie leurs fichiers de configuration respectifs à partir de<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> .  Voir l’exemple suivant :</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Configurer Zookeeper.  Vous n’avez rien à modifier si vous utilisez les paramètres par défaut.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">Dans la configuration ci-dessus, nous avons mis à jour le<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> propriété.  Par défaut, vous avez besoin de trois gardiens de zoo pour la sélection du chef Kafka.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Nous avons créé un fichier myid dans<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> avec un identifiant unique :</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Nous avons utilisé le dernier numéro d'adresses IP pour le fichier myid.  Nous avons utilisé des valeurs par défaut pour les configurations Kafka, connect, control-center, Kafka, Kafka-rest, ksql-server et schema-registry.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Démarrez les services Kafka.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Il existe un dossier journal pour chaque configuration, ce qui permet de résoudre les problèmes.  Dans certains cas, les services prennent plus de temps à démarrer.  Assurez-vous que tous les services sont opérationnels.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Installer Kafka Connect en utilisant<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> .</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">Vous pouvez également installer une version spécifique en utilisant<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> .</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Par défaut,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> est installé dans<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block> .</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Mettre à jour le chemin du plug-in avec le nouveau<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> .</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Arrêtez les services Confluent et redémarrez-les.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configurez l'ID d'accès et la clé secrète dans le<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> déposer.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Vérifiez que le bucket est accessible.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configurez le fichier de propriétés s3-sink pour la configuration s3 et bucket.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importez quelques enregistrements dans le bucket s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Chargez le connecteur s3-sink.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Vérifiez l'état du s3-sink.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Vérifiez le journal pour vous assurer que s3-sink est prêt à accepter des sujets.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Consultez les sujets dans Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Vérifiez les objets dans le bucket s3.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Pour vérifier le contenu, copiez chaque fichier de S3 vers votre système de fichiers local en exécutant la commande suivante :</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Archives Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Pour imprimer les enregistrements, utilisez avro-tools-1.11.0.1.jar (disponible dans le<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ).</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Cette page décrit les meilleures pratiques pour améliorer les performances de cette solution.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Lignes directrices sur les meilleures pratiques en matière de performance</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Pour ONTAP, lorsque cela est possible, utilisez une taille GET &gt;=1 Mo.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Croissant<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> et<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> dans<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> sur les nœuds de courtier, vous permet de pousser l'activité de hiérarchisation accrue vers le niveau S3.  Ces résultats sont avec<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> et<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> réglé sur 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">Les compartiments S3 doivent cibler huit constituants par agrégat de membres.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Les liaisons Ethernet générant du trafic S3 doivent utiliser un MTU de 9 k lorsque cela est possible, à la fois sur le stockage et sur le client.</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Ce test de vérification a atteint 31,74 Gbit/s de débit de hiérarchisation sur Confluent avec un contrôleur de stockage NetApp ONTAP .</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Ce test de vérification a atteint 31,74 Gbit/s de débit de hiérarchisation sur Confluent avec le contrôleur de stockage NetApp ONTAP .</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Qu'est-ce que Confluent ?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">Meilleures pratiques S3 dans ONTAP</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gestion du stockage d'objets S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Cette page décrit la validation des performances de Confluent dans les paramètres de cette solution.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validation des performances de Confluent</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Nous avons effectué la vérification avec Confluent Platform pour le stockage hiérarchisé sur NetApp ONTAP.  Les équipes NetApp et Confluent ont travaillé ensemble sur cette vérification et ont exécuté les cas de test nécessaires à cet effet.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configuration confluente</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Pour la configuration, nous avons utilisé trois gardiens de zoo, cinq courtiers et cinq serveurs de test avec 256 Go de RAM et 16 processeurs.  Pour le stockage NetApp , nous avons utilisé ONTAP avec une paire AFF A900 HA.  Le stockage et les courtiers étaient connectés via des connexions 100 GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">La figure suivante montre la topologie du réseau de configuration utilisée pour la vérification du stockage à plusieurs niveaux.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Ce graphique montre la topologie du réseau de configuration utilisée pour la vérification du stockage à plusieurs niveaux.</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Les serveurs d’outils agissent comme des clients d’application qui envoient ou reçoivent des événements vers ou depuis des nœuds Confluent.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Nous avons utilisé les paramètres de test suivants :</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Pour la vérification, nous avons utilisé ONTAP avec le protocole HTTP, mais HTTPS a également fonctionné.  La clé d'accès et la clé secrète sont stockées dans le nom de fichier fourni dans le<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Contrôleur de stockage NetApp – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Nous avons configuré une seule configuration de paire HA dans ONTAP pour vérification.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Ce graphique illustre comment l’environnement a été configuré en tant que paire HA unique pour la vérification.</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Résultats de la vérification</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Nous avons réalisé les cinq cas de test suivants pour la vérification.  Les deux premiers étaient des tests de fonctionnalité et les trois autres étaient des tests de performance.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Ce test effectue des opérations de base telles que get, put et delete sur le magasin d'objets utilisé pour le stockage hiérarchisé à l'aide d'appels API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Ce test vérifie la fonctionnalité de bout en bout du stockage d'objets.  Il crée une rubrique, produit un flux d'événements vers la rubrique nouvellement créée, attend que les courtiers archivent les segments dans le stockage d'objets, consomme le flux d'événements et valide les correspondances du flux consommé avec le flux produit.  Nous avons effectué ce test avec et sans injection de fautes dans le magasin d’objets.  Nous avons simulé une défaillance de nœud en arrêtant le service du gestionnaire de services dans l’un des nœuds d’ ONTAP et en validant que la fonctionnalité de bout en bout fonctionne avec le stockage d’objets.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Générateur de charge de travail de production-consommation</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Ce test génère indirectement une charge de travail d'écriture sur le magasin d'objets via l'archivage des segments.  La charge de travail de lecture (segments lus) a été générée à partir du stockage d'objets lorsque les groupes de consommateurs ont récupéré les segments.  Cette charge de travail a été générée par un script TOCC.  Ce test a vérifié les performances de lecture et d'écriture sur le stockage d'objets dans des threads parallèles.  Nous avons testé avec et sans injection de pannes de magasin d'objets comme nous l'avons fait pour le test d'exactitude de la fonctionnalité de hiérarchisation.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Générateur de charge de travail de rétention</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Ce test a vérifié les performances de suppression d'un stockage d'objets sous une charge de travail de rétention de sujets importante.  La charge de travail de rétention a été générée à l'aide d'un script TOCC qui produit de nombreux messages en parallèle avec une rubrique de test.  Le sujet de test consistait à configurer un paramètre de rétention agressif basé sur la taille et le temps, ce qui entraînait la purge continue du flux d'événements du magasin d'objets.  Les segments ont ensuite été archivés.  Cela a conduit à de nombreuses suppressions dans le stockage d'objets par le courtier et à la collecte des performances des opérations de suppression du magasin d'objets.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Confluent</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Pour plus de détails sur la vérification, consultez le<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> site web.</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Nous avons effectué des tests de stockage à plusieurs niveaux avec cinq ou huit nœuds de courtier pendant une charge de travail de production-consommation avec le contrôleur de stockage NetApp à une paire AFF A900 HA.  Selon nos tests, le temps d'exécution et les résultats de performance ont évolué avec le nombre de nœuds de courtier jusqu'à ce que l'utilisation des ressources AFF A900 atteigne cent pour cent.  La configuration du contrôleur de stockage ONTAP nécessitait au moins une paire HA.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Tests de performance avec générateur de charge de travail de production-consommation</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">Les performances de l’opération de récupération S3 ont augmenté linéairement en fonction du nombre de nœuds de courtier Confluent.  Le contrôleur de stockage ONTAP prend en charge jusqu'à 12 paires HA dans un seul déploiement.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">Le graphique suivant montre le trafic de hiérarchisation S3 combiné avec cinq ou huit nœuds de courtier.  Nous avons maximisé les performances de la paire HA unique de AFF A900 .</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Ce graphique de données montre le trafic de hiérarchisation S3 combiné avec cinq ou huit nœuds de courtier.</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">Le graphique suivant montre le débit de Kafka à environ 31,74 Gbit/s.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Ce graphique de données montre le débit de Kafka à environ 31,74 Gbit/s.</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Nous avons également observé un débit similaire dans le contrôleur de stockage ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> rapport.</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Cette section couvre le matériel et les logiciels utilisés pour la vérification des performances dans le déploiement de Confluent Platform avec NetApp ONTAP pour le stockage hiérarchisé.  Le tableau suivant couvre l’architecture de la solution et les composants de base.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Les contrôleurs de stockage Confluent et NetApp AFF A900 optimisés par ONTAP sont des systèmes distribués conçus pour les flux de données.  Les deux sont évolutifs horizontalement, tolérants aux pannes et offrent d’excellentes performances sous charge.  Ils se complètent dans le streaming de données distribuées et le traitement de flux avec des coûts de stockage inférieurs grâce à des technologies de réduction des données qui minimisent l'empreinte des données.  Le contrôleur de stockage AFF A900 offre d'excellentes performances, tout en permettant le découplage des ressources de calcul et de stockage de données.  Cela simplifie l’administration du système et permet de faire évoluer les ressources de manière indépendante.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Image illustrant l'aperçu de la solution.</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Plateforme Confluent version 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 x gardiens de zoo</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 x serveurs de courtage</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 x serveurs d'outils</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x centre de contrôle</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP pour les buckets chauds</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 paire AFF A900 haute disponibilité (HA)</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 processeurs ; 16 cœurs physiques au total</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 Go de mémoire physique</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Port double 100 GbE</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Cette page décrit la technologie utilisée dans cette solution.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Aperçu de la technologie</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Contrôleur de stockage NetApp ONTAP</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP est un système d’exploitation de stockage hautes performances de niveau entreprise.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 introduit la prise en charge des API Amazon Simple Storage Service (S3).  ONTAP prend en charge un sous-ensemble d'actions d'API S3 d'Amazon Web Services (AWS) et permet aux données d'être représentées sous forme d'objets dans les systèmes basés sur ONTAP sur les fournisseurs de cloud (AWS, Azure et GCP) et sur site.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">Le logiciel NetApp StorageGRID est la solution phare de NetApp pour le stockage d'objets.  ONTAP complète StorageGRID en fournissant un point d'ingestion et de prétraitement en périphérie, en étendant la structure de données optimisée par NetApp pour les données d'objets et en augmentant la valeur du portefeuille de produits NetApp .</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">L'accès à un compartiment S3 est fourni via des applications utilisateur et client autorisées.  Le diagramme suivant montre l’application accédant à un bucket S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Ce graphique montre l’application accédant à un bucket S3.</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Principaux cas d'utilisation</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">L’objectif principal de la prise en charge des API S3 est de fournir un accès aux objets sur ONTAP.  L'architecture de stockage unifiée ONTAP prend désormais en charge les fichiers (NFS et SMB), les blocs (FC et iSCSI) et les objets (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Applications S3 natives</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Un nombre croissant d’applications sont capables d’exploiter la prise en charge ONTAP pour l’accès aux objets à l’aide de S3.  Bien que bien adapté aux charges de travail d'archivage à haute capacité, le besoin de hautes performances dans les applications S3 natives augmente rapidement et comprend :</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analytique</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Intelligence artificielle</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Ingestion de la périphérie au cœur</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Les clients peuvent désormais utiliser des outils de gestion familiers tels ONTAP System Manager pour provisionner rapidement un stockage d'objets hautes performances pour le développement et les opérations dans ONTAP, en profitant de l'efficacité et de la sécurité du stockage ONTAP .</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Points de terminaison FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">À partir d' ONTAP 9.8, FabricPool prend en charge la hiérarchisation des buckets dans ONTAP, permettant ainsi la hiérarchisation ONTAP vers ONTAP .  Il s’agit d’une excellente option pour les clients qui souhaitent réutiliser l’infrastructure FAS existante comme point de terminaison de magasin d’objets.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool prend en charge la hiérarchisation vers ONTAP de deux manières :</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Hiérarchisation des clusters locaux.*  Les données inactives sont hiérarchisées vers un compartiment situé sur le cluster local à l'aide de LIF de cluster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Hiérarchisation de clusters distants.*  Les données inactives sont hiérarchisées vers un compartiment situé sur un cluster distant d'une manière similaire à un niveau cloud FabricPool traditionnel à l'aide de LIF IC sur le client FabricPool et de LIF de données sur le magasin d'objets ONTAP .</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 est approprié si vous souhaitez des fonctionnalités S3 sur des clusters existants sans matériel ni gestion supplémentaires.  Pour les déploiements supérieurs à 300 To, le logiciel NetApp StorageGRID reste la solution phare de NetApp pour le stockage d'objets.  Une licence FabricPool n’est pas requise lors de l’utilisation ONTAP ou de StorageGRID comme niveau cloud.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP pour le stockage hiérarchisé Confluent</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Chaque centre de données doit garantir le fonctionnement des applications critiques pour l’entreprise et la disponibilité et la sécurité des données importantes.  Le nouveau système NetApp AFF A900 est alimenté par le logiciel ONTAP Enterprise Edition et une conception haute résilience.  Notre nouveau système de stockage NVMe ultra-rapide élimine les perturbations des opérations critiques, minimise le réglage des performances et protège vos données contre les attaques de ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Du déploiement initial à la mise à l'échelle de votre cluster Confluent, votre environnement exige une adaptation rapide aux changements qui ne perturbent pas vos applications critiques.  La gestion des données d'entreprise, la qualité de service (QoS) et les performances ONTAP vous permettent de planifier et de vous adapter à votre environnement.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">L'utilisation conjointe de NetApp ONTAP et de Confluent Tiered Storage simplifie la gestion des clusters Apache Kafka en exploitant ONTAP comme cible de stockage évolutive et permet une mise à l'échelle indépendante des ressources de calcul et de stockage pour Confluent.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Un serveur ONTAP S3 est construit sur les capacités de stockage évolutives matures d' ONTAP.  La mise à l’échelle de votre cluster ONTAP peut être effectuée de manière transparente en étendant vos buckets S3 pour utiliser les nœuds nouvellement ajoutés au cluster ONTAP .</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gestion simple avec ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager est une interface graphique basée sur un navigateur qui vous permet de configurer, de gérer et de surveiller votre contrôleur de stockage ONTAP sur des emplacements répartis dans le monde entier dans une seule fenêtre.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Ce graphique montre l’espace de travail d’ ONTAP System Manager.</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">Vous pouvez configurer et gérer ONTAP S3 avec System Manager et l'interface de ligne de commande ONTAP .  Lorsque vous activez S3 et créez des buckets à l’aide de System Manager, ONTAP fournit des valeurs par défaut de bonnes pratiques pour une configuration simplifiée.  Si vous configurez le serveur S3 et les buckets à partir de l'interface de ligne de commande, vous pouvez toujours les gérer avec System Manager si vous le souhaitez ou vice-versa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Lorsque vous créez un compartiment S3 à l'aide de System Manager, ONTAP configure un niveau de service de performances par défaut qui est le plus élevé disponible sur votre système.  Par exemple, sur un système AFF , le paramètre par défaut serait Extrême.  Les niveaux de service de performance sont des groupes de politiques QoS adaptatifs prédéfinis.  Au lieu de l’un des niveaux de service par défaut, vous pouvez spécifier un groupe de politiques QoS personnalisé ou aucun groupe de politiques.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Les groupes de politiques QoS adaptatives prédéfinis incluent les éléments suivants :</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extrême.*  Utilisé pour les applications qui nécessitent la latence la plus faible et les performances les plus élevées.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Performance.*  Utilisé pour les applications avec des besoins de performances et de latence modestes.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valeur.*  Utilisé pour les applications pour lesquelles le débit et la capacité sont plus importants que la latence.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Coutume.*  Spécifiez une politique QoS personnalisée ou aucune politique QoS.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Si vous sélectionnez *Utiliser pour la hiérarchisation*, aucun niveau de service de performances n'est sélectionné et le système tente de sélectionner des supports à faible coût avec des performances optimales pour les données hiérarchisées.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP essaie de provisionner ce bucket sur les niveaux locaux qui disposent des disques les plus appropriés, satisfaisant le niveau de service choisi.  Toutefois, si vous devez spécifier les disques à inclure dans le bucket, envisagez de configurer le stockage d'objets S3 à partir de l'interface de ligne de commande en spécifiant les niveaux locaux (agrégat).  Si vous configurez le serveur S3 à partir de l'interface de ligne de commande, vous pouvez toujours le gérer avec le Gestionnaire système si vous le souhaitez.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Si vous souhaitez pouvoir spécifier quels agrégats sont utilisés pour les buckets, vous ne pouvez le faire qu'à l'aide de l'interface de ligne de commande.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform est une plateforme de streaming de données à grande échelle qui vous permet d'accéder, de stocker et de gérer facilement les données sous forme de flux continus en temps réel.  Conçu par les créateurs originaux d'Apache Kafka, Confluent étend les avantages de Kafka avec des fonctionnalités de niveau entreprise tout en supprimant le fardeau de la gestion ou de la surveillance de Kafka.  Aujourd’hui, plus de 80 % des entreprises du Fortune 100 utilisent la technologie de streaming de données, et la plupart utilisent Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Pourquoi Confluent ?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">En intégrant des données historiques et en temps réel dans une source unique et centrale de vérité, Confluent facilite la création d'une toute nouvelle catégorie d'applications modernes axées sur les événements, l'obtention d'un pipeline de données universel et le déblocage de nouveaux cas d'utilisation puissants avec une évolutivité, des performances et une fiabilité complètes.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">À quoi sert Confluent ?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform vous permet de vous concentrer sur la manière de tirer profit de vos données plutôt que de vous soucier des mécanismes sous-jacents, tels que la manière dont les données sont transportées ou intégrées entre des systèmes disparates.  Plus précisément, Confluent Platform simplifie la connexion des sources de données à Kafka, la création d'applications de streaming, ainsi que la sécurisation, la surveillance et la gestion de votre infrastructure Kafka.  Aujourd'hui, Confluent Platform est utilisé pour un large éventail de cas d'utilisation dans de nombreux secteurs, des services financiers, de la vente au détail omnicanal et des voitures autonomes à la détection de fraude, aux microservices et à l'IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">La figure suivante montre les composants de Confluent Platform.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Ce graphique montre les composants de la plateforme Confluent.</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Présentation de la technologie de diffusion d'événements Confluent</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Au cœur de la plateforme Confluent se trouve<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block> , la plateforme de streaming distribuée open source la plus populaire.  Les principales fonctionnalités de Kafka sont les suivantes :</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Publiez et abonnez-vous à des flux d'enregistrements.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Stockez des flux d’enregistrements de manière tolérante aux pannes.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Traiter les flux d'enregistrements.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Prêt à l'emploi, Confluent Platform inclut également Schema Registry, REST Proxy, un total de plus de 100 connecteurs Kafka prédéfinis et ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Présentation des fonctionnalités d'entreprise de la plateforme Confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Centre de contrôle Confluent.*  Un système basé sur l'interface utilisateur pour la gestion et la surveillance de Kafka.  Il vous permet de gérer facilement Kafka Connect et de créer, modifier et gérer des connexions à d'autres systèmes.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent pour Kubernetes.*  Confluent pour Kubernetes est un opérateur Kubernetes.  Les opérateurs Kubernetes étendent les capacités d’orchestration de Kubernetes en fournissant les fonctionnalités et les exigences uniques pour une application de plate-forme spécifique.  Pour Confluent Platform, cela inclut la simplification considérable du processus de déploiement de Kafka sur Kubernetes et l'automatisation des tâches typiques du cycle de vie de l'infrastructure.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Connecteurs Kafka Connect.*  Les connecteurs utilisent l'API Kafka Connect pour connecter Kafka à d'autres systèmes tels que des bases de données, des magasins de clés-valeurs, des index de recherche et des systèmes de fichiers.  Confluent Hub propose des connecteurs téléchargeables pour les sources et récepteurs de données les plus populaires, y compris des versions entièrement testées et prises en charge de ces connecteurs avec Confluent Platform.  Plus de détails peuvent être trouvés<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Clusters auto-équilibrés.*  Fournit un équilibrage de charge automatisé, une détection des pannes et une auto-réparation.  Il fournit également un support pour l'ajout ou la désactivation de courtiers selon les besoins, sans réglage manuel.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Liaison de cluster confluent.*  Connecte directement les clusters entre eux et reflète les sujets d'un cluster à un autre via un pont de liaison.  La liaison de cluster simplifie la configuration des déploiements multi-centres de données, multi-clusters et cloud hybride.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Équilibreur de données automatique Confluent.*  Surveille votre cluster pour le nombre de courtiers, la taille des partitions, le nombre de partitions et le nombre de leaders au sein du cluster.  Il vous permet de déplacer les données pour créer une charge de travail uniforme sur votre cluster, tout en limitant le trafic de rééquilibrage pour minimiser l'effet sur les charges de travail de production lors du rééquilibrage.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Réplicateur confluent.*  Il est plus facile que jamais de maintenir plusieurs clusters Kafka dans plusieurs centres de données.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Stockage à plusieurs niveaux.*  Fournit des options pour stocker de grands volumes de données Kafka à l'aide de votre fournisseur de cloud préféré, réduisant ainsi la charge et les coûts opérationnels.  Avec le stockage hiérarchisé, vous pouvez conserver les données sur un stockage d'objets rentable et faire évoluer les courtiers uniquement lorsque vous avez besoin de davantage de ressources de calcul.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Client JMS confluent.*  Confluent Platform inclut un client compatible JMS pour Kafka.  Ce client Kafka implémente l'API standard JMS 1.1, en utilisant les courtiers Kafka comme backend.  Ceci est utile si vous avez des applications héritées utilisant JMS et que vous souhaitez remplacer le courtier de messages JMS existant par Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Proxy MQTT confluent.*  Fournit un moyen de publier des données directement sur Kafka à partir d'appareils et de passerelles MQTT sans avoir besoin d'un courtier MQTT au milieu.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Plugins de sécurité Confluent.*  Les plugins de sécurité Confluent sont utilisés pour ajouter des fonctionnalités de sécurité à divers outils et produits de la plateforme Confluent.  Actuellement, il existe un plugin disponible pour le proxy REST Confluent qui permet d'authentifier les requêtes entrantes et de propager le principal authentifié aux requêtes vers Kafka.  Cela permet aux clients proxy Confluent REST d'utiliser les fonctionnalités de sécurité multilocataire du courtier Kafka.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID est une plate-forme de stockage d'objets hautes performances et rentable.  En utilisant le stockage hiérarchisé, la plupart des données sur Confluent Kafka, qui sont stockées dans le stockage local ou le stockage SAN du courtier, sont déchargées vers le magasin d'objets distant.  Cette configuration entraîne des améliorations opérationnelles significatives en réduisant le temps et le coût nécessaires pour rééquilibrer, étendre ou réduire les clusters ou remplacer un courtier défaillant.  Le stockage d'objets joue un rôle important dans la gestion des données qui résident sur le niveau du magasin d'objets, c'est pourquoi il est important de choisir le bon stockage d'objets.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID offre une gestion intelligente des données mondiales basée sur des politiques à l'aide d'une architecture de grille distribuée basée sur des nœuds.  Il simplifie la gestion de pétaoctets de données non structurées et de milliards d'objets grâce à son espace de noms d'objets global omniprésent combiné à des fonctionnalités de gestion de données sophistiquées.  L'accès aux objets par appel unique s'étend sur plusieurs sites et simplifie les architectures à haute disponibilité tout en garantissant un accès continu aux objets, quelles que soient les pannes du site ou de l'infrastructure.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">La multilocation permet à plusieurs applications de données cloud et d'entreprise non structurées d'être gérées en toute sécurité au sein de la même grille, augmentant ainsi le retour sur investissement et les cas d'utilisation de NetApp StorageGRID.  Vous pouvez créer plusieurs niveaux de service avec des politiques de cycle de vie d'objet basées sur les métadonnées, optimisant la durabilité, la protection, les performances et la localité dans plusieurs zones géographiques.  Les utilisateurs peuvent ajuster les politiques de gestion des données et surveiller et appliquer des limites de trafic pour se réaligner sur le paysage des données de manière non perturbatrice à mesure que leurs besoins évoluent dans des environnements informatiques en constante évolution.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gestion simple avec Grid Manager</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager est une interface graphique basée sur un navigateur qui vous permet de configurer, de gérer et de surveiller votre système StorageGRID sur des emplacements distribués à l'échelle mondiale dans une seule fenêtre.</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Vous pouvez effectuer les tâches suivantes avec l'interface StorageGRID Grid Manager :</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Gérez des référentiels d'objets distribués à l'échelle mondiale et à l'échelle du pétaoctet, tels que des images, des vidéos et des enregistrements.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Surveillez les nœuds et les services de la grille pour garantir la disponibilité des objets.</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">Gérez le placement des données d'objet au fil du temps à l'aide de règles de gestion du cycle de vie des informations (ILM).  Ces règles régissent ce qui arrive aux données d'un objet après son ingestion, comment elles sont protégées contre la perte, où les données de l'objet sont stockées et pendant combien de temps.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Surveiller les transactions, les performances et les opérations au sein du système.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Politiques de gestion du cycle de vie de l'information</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID dispose de politiques de gestion des données flexibles qui incluent la conservation de copies de réplique de vos objets et l'utilisation de schémas EC (codage d'effacement) tels que 2+1 et 4+2 (entre autres) pour stocker vos objets, en fonction des exigences spécifiques en matière de performances et de protection des données.  À mesure que les charges de travail et les exigences évoluent au fil du temps, il est courant que les politiques ILM doivent également évoluer au fil du temps.  La modification des politiques ILM est une fonctionnalité essentielle, permettant aux clients de StorageGRID de s'adapter rapidement et facilement à leur environnement en constante évolution.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Performances</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 ou SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID augmente les performances en ajoutant davantage de nœuds de stockage, qui peuvent être des machines virtuelles, du matériel nu ou des appareils spécialement conçus comme le<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> .  Lors de nos tests, nous avons dépassé les exigences de performances clés d'Apache Kafka avec une grille à trois nœuds de taille minimale utilisant l'appliance SGF6024.  À mesure que les clients font évoluer leur cluster Kafka avec des courtiers supplémentaires, ils peuvent ajouter davantage de nœuds de stockage pour augmenter les performances et la capacité.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Configuration de l'équilibreur de charge et du point de terminaison</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Les nœuds d'administration de StorageGRID fournissent l'interface utilisateur de Grid Manager et le point de terminaison de l'API REST pour afficher, configurer et gérer votre système StorageGRID , ainsi que des journaux d'audit pour suivre l'activité du système.  Pour fournir un point de terminaison S3 hautement disponible pour le stockage hiérarchisé Confluent Kafka, nous avons implémenté l'équilibreur de charge StorageGRID , qui s'exécute en tant que service sur les nœuds d'administration et les nœuds de passerelle.  De plus, l'équilibreur de charge gère également le trafic local et communique avec le GSLB (Global Server Load Balancing) pour faciliter la reprise après sinistre.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Pour améliorer davantage la configuration des points de terminaison, StorageGRID fournit des stratégies de classification du trafic intégrées au nœud d'administration, vous permet de surveiller le trafic de votre charge de travail et applique diverses limites de qualité de service (QoS) à vos charges de travail.  Les stratégies de classification du trafic sont appliquées aux points de terminaison sur le service StorageGRID Load Balancer pour les nœuds de passerelle et les nœuds d'administration.  Ces politiques peuvent aider à réguler et à surveiller le trafic.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Classification du trafic dans StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID dispose d'une fonctionnalité QoS intégrée.  Les politiques de classification du trafic peuvent aider à surveiller différents types de trafic S3 provenant d’une application cliente.  Vous pouvez ensuite créer et appliquer des politiques pour limiter ce trafic en fonction de la bande passante entrante/sortante, du nombre de requêtes simultanées en lecture/écriture ou du taux de requêtes en lecture/écriture.</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka est une implémentation framework d'un bus logiciel utilisant le traitement de flux écrit en Java et Scala.  Son objectif est de fournir une plate-forme unifiée, à haut débit et à faible latence pour gérer les flux de données en temps réel.  Kafka peut se connecter à un système externe pour l'exportation et l'importation de données via Kafka Connect et fournit des flux Kafka, une bibliothèque de traitement de flux Java.  Kafka utilise un protocole binaire basé sur TCP, optimisé pour l'efficacité et s'appuyant sur une abstraction « d'ensemble de messages » qui regroupe naturellement les messages pour réduire la surcharge de l'aller-retour réseau.  Cela permet des opérations de disque séquentielles plus importantes, des paquets réseau plus volumineux et des blocs de mémoire contigus, permettant ainsi à Kafka de transformer un flux rafaleux d'écritures de messages aléatoires en écritures linéaires.  La figure suivante illustre le flux de données de base d’Apache Kafka.</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka stocke les messages clé-valeur provenant d'un nombre arbitraire de processus appelés producteurs.  Les données peuvent être partitionnées en différentes partitions au sein de différents sujets.  Au sein d'une partition, les messages sont strictement ordonnés par leurs décalages (la position d'un message au sein d'une partition) et indexés et stockés avec un horodatage.  D’autres processus appelés consommateurs peuvent lire les messages des partitions.  Pour le traitement des flux, Kafka propose l'API Streams qui permet d'écrire des applications Java qui consomment des données de Kafka et réécrivent les résultats dans Kafka.  Apache Kafka fonctionne également avec des systèmes de traitement de flux externes tels qu'Apache Apex, Apache Flink, Apache Spark, Apache Storm et Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka s'exécute sur un cluster d'un ou plusieurs serveurs (appelés courtiers), et les partitions de tous les sujets sont réparties sur les nœuds du cluster.  De plus, les partitions sont répliquées sur plusieurs courtiers.  Cette architecture permet à Kafka de diffuser des flux massifs de messages de manière tolérante aux pannes et lui a permis de remplacer certains des systèmes de messagerie conventionnels tels que Java Message Service (JMS), Advanced Message Queuing Protocol (AMQP), etc.  Depuis la version 0.11.0.0, Kafka propose des écritures transactionnelles, qui fournissent un traitement de flux une seule fois à l'aide de l'API Streams.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka prend en charge deux types de sujets : réguliers et compactés.  Les sujets réguliers peuvent être configurés avec un temps de rétention ou une limite d'espace.  S'il existe des enregistrements plus anciens que la durée de conservation spécifiée ou si l'espace limité est dépassé pour une partition, Kafka est autorisé à supprimer les anciennes données pour libérer de l'espace de stockage.  Par défaut, les sujets sont configurés avec une durée de conservation de 7 jours, mais il est également possible de stocker des données indéfiniment.  Pour les sujets compactés, les enregistrements n'expirent pas en fonction des limites de temps ou d'espace.  Au lieu de cela, Kafka traite les messages ultérieurs comme des mises à jour d'un message plus ancien avec la même clé et garantit de ne jamais supprimer le dernier message par clé.  Les utilisateurs peuvent supprimer entièrement les messages en écrivant un message dit « tombstone » avec la valeur nulle pour une clé spécifique.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Il existe cinq API principales dans Kafka :</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*API du producteur.*  Permet à une application de publier des flux d'enregistrements.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*API consommateur.*  Permet à une application de s'abonner à des sujets et de traiter des flux d'enregistrements.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*API du connecteur.*  Exécute les API de production et de consommation réutilisables qui peuvent lier les sujets aux applications existantes.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*API de flux.*  Cette API convertit les flux d'entrée en sortie et produit le résultat.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*API d'administration.*  Utilisé pour gérer les sujets Kafka, les courtiers et autres objets Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Les API consommateur et producteur s'appuient sur le protocole de messagerie Kafka et offrent une implémentation de référence pour les clients consommateurs et producteurs Kafka en Java.  Le protocole de messagerie sous-jacent est un protocole binaire que les développeurs peuvent utiliser pour écrire leurs propres clients consommateurs ou producteurs dans n'importe quel langage de programmation.  Cela déverrouille Kafka de l'écosystème Java Virtual Machine (JVM).  Une liste des clients non Java disponibles est conservée dans le wiki Apache Kafka.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Cas d'utilisation d'Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka est le plus populaire pour la messagerie, le suivi de l'activité du site Web, les métriques, l'agrégation de journaux, le traitement de flux, l'approvisionnement d'événements et la journalisation des validations.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka a amélioré le débit, le partitionnement intégré, la réplication et la tolérance aux pannes, ce qui en fait une bonne solution pour les applications de traitement de messages à grande échelle.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka peut reconstruire les activités d'un utilisateur (pages vues, recherches) dans un pipeline de suivi sous la forme d'un ensemble de flux de publication-abonnement en temps réel.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka est souvent utilisé pour les données de surveillance opérationnelle.  Il s’agit d’agréger des statistiques provenant d’applications distribuées pour produire des flux centralisés de données opérationnelles.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">De nombreuses personnes utilisent Kafka comme solution de remplacement pour une solution d’agrégation de journaux.  L'agrégation de journaux collecte généralement les fichiers journaux physiques des serveurs et les place dans un emplacement central (par exemple, un serveur de fichiers ou HDFS) pour traitement.  Kafka résume les détails des fichiers et fournit une abstraction plus propre des données de journal ou d'événement sous forme de flux de messages.  Cela permet un traitement à faible latence et une prise en charge plus facile de plusieurs sources de données et d'une consommation de données distribuée.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">De nombreux utilisateurs de Kafka traitent les données dans des pipelines de traitement composés de plusieurs étapes, dans lesquels les données d'entrée brutes sont consommées à partir des rubriques Kafka, puis agrégées, enrichies ou transformées d'une autre manière en de nouvelles rubriques pour une consommation ultérieure ou un traitement de suivi.  Par exemple, un pipeline de traitement pour recommander des articles d'actualité peut explorer le contenu des articles à partir de flux RSS et le publier dans une rubrique « articles ».  Un traitement ultérieur pourrait normaliser ou dédupliquer ce contenu et publier le contenu de l'article nettoyé dans une nouvelle rubrique, et une étape de traitement finale pourrait tenter de recommander ce contenu aux utilisateurs.  Ces pipelines de traitement créent des graphiques de flux de données en temps réel en fonction des sujets individuels.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">L'approvisionnement d'événements est un style de conception d'application pour lequel les changements d'état sont enregistrés sous la forme d'une séquence d'enregistrements ordonnée dans le temps.  La prise en charge par Kafka de données de journaux stockées très volumineuses en fait un excellent backend pour une application construite dans ce style.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka peut servir de sorte de journal de validation externe pour un système distribué.  Le journal permet de répliquer les données entre les nœuds et agit comme un mécanisme de resynchronisation pour les nœuds défaillants afin de restaurer leurs données.  La fonctionnalité de compactage des journaux dans Kafka permet de prendre en charge ce cas d'utilisation.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform est une plateforme prête pour l'entreprise qui complète Kafka avec des fonctionnalités avancées conçues pour aider à accélérer le développement et la connectivité des applications, permettre les transformations grâce au traitement des flux, simplifier les opérations d'entreprise à grande échelle et répondre aux exigences architecturales strictes.  Conçu par les créateurs originaux d'Apache Kafka, Confluent étend les avantages de Kafka avec des fonctionnalités de niveau entreprise tout en supprimant le fardeau de la gestion ou de la surveillance de Kafka.  Aujourd’hui, plus de 80 % des entreprises du Fortune 100 utilisent la technologie de streaming de données, et la plupart d’entre elles utilisent Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform vous permet de vous concentrer sur la manière de tirer profit de vos données plutôt que de vous soucier des mécanismes sous-jacents, tels que la manière dont les données sont transportées ou intégrées entre des systèmes disparates.  Plus précisément, Confluent Platform simplifie la connexion des sources de données à Kafka, la création d'applications de streaming, ainsi que la sécurisation, la surveillance et la gestion de votre infrastructure Kafka.  Aujourd'hui, Confluent Platform est utilisé pour un large éventail de cas d'utilisation dans de nombreux secteurs, des services financiers, de la vente au détail omnicanal et des voitures autonomes, à la détection de fraude, aux microservices et à l'IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">La figure suivante montre les composants de la plateforme Confluent Kafka.</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Présentation de la technologie de streaming d'événements de Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Au cœur de la plateforme Confluent se trouve<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block> , la plateforme de streaming distribuée open source la plus populaire.  Les principales fonctionnalités de Kafka sont les suivantes :</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Aperçu des fonctionnalités d'entreprise de la plateforme Confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Centre de contrôle Confluent.*  Un système basé sur une interface graphique pour la gestion et la surveillance de Kafka.  Il vous permet de gérer facilement Kafka Connect et de créer, modifier et gérer des connexions à d'autres systèmes.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Connecteurs confluents vers Kafka.*  Les connecteurs utilisent l'API Kafka Connect pour connecter Kafka à d'autres systèmes tels que des bases de données, des magasins de valeurs clés, des index de recherche et des systèmes de fichiers.  Confluent Hub propose des connecteurs téléchargeables pour les sources et récepteurs de données les plus populaires, y compris des versions entièrement testées et prises en charge de ces connecteurs avec Confluent Platform.  Plus de détails peuvent être trouvés<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Clusters auto-équilibrés.*  Fournit un équilibrage de charge automatisé, une détection des pannes et une auto-réparation.  Il fournit un support pour l'ajout ou la désactivation de courtiers selon les besoins, sans réglage manuel.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Équilibreur automatique de données Confluent.*  Surveille votre cluster pour le nombre de courtiers, la taille des partitions, le nombre de partitions et le nombre de leaders au sein du cluster.  Il vous permet de déplacer les données pour créer une charge de travail uniforme sur votre cluster, tout en limitant le trafic de rééquilibrage pour minimiser l'effet sur les charges de travail de production lors du rééquilibrage.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY : charge de travail Apache Spark avec solution de stockage NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY décrit la validation des performances et des fonctionnalités d'Apache Spark SQL sur les systèmes de stockage NetApp NFS AFF .  Il passe en revue la configuration, l'architecture et les tests de performances en fonction de divers scénarios, ainsi que des recommandations pour l'utilisation de Spark avec le logiciel de gestion de données NetApp ONTAP .  Il couvre également les résultats des tests basés sur un seul ensemble de disques (JBOD) par rapport au contrôleur de stockage NetApp AFF A800 .</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Analyse de données moderne - Différentes solutions pour différentes stratégies d'analyse</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">Ce livre blanc décrit les stratégies de solutions d’analyse de données modernes de NetApp .  Il comprend des détails sur les résultats commerciaux, les défis des clients, les tendances technologiques, l'architecture héritée de la concurrence, les flux de travail modernes, les cas d'utilisation, les industries, le cloud, les partenaires technologiques, les déménageurs de données, NetApp Active IQ Digital Advisor (également connu sous le nom de Digital Advisor), NetApp DataOps Toolkit, Hadoop vers Spark, le stockage défini par logiciel avec NetApp Trident Protect, les conteneurs, la gestion des données d'entreprise, l'archivage et la hiérarchisation pour atteindre les objectifs de l'IA et de l'analyse et comment NetApp et les clients modernisent ensemble leur architecture de données.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">Les références suivantes ont été utilisées dans ce TR :</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Architecture et composants d'Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Cas d'utilisation d'Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Réseau profond et croisé pour les prévisions de clics publicitaires</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">ETL en continu</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Solutions NetApp E-Series pour Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">Solutions d'analyse de données modernes NetApp</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">Solutions d'analyse de données</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">Copie et synchronisation BlueXP</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Boîte à outils DataOps</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Cette page décrit plus en détail les principaux cas d’utilisation et architectures de l’IA, du ML et du DL.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principaux cas d'utilisation et architectures de l'IA, du ML et du DL</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Les principaux cas d’utilisation et méthodologies de l’IA, du ML et du DL peuvent être divisés dans les sections suivantes :</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Pipelines Spark NLP et inférence distribuée TensorFlow</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">La liste suivante contient les bibliothèques NLP open source les plus populaires qui ont été adoptées par la communauté des sciences des données à différents niveaux de développement :</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Boîte à outils en langage naturel (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> . La boîte à outils complète pour toutes les techniques PNL.  Il est maintenu depuis le début des années 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> . Une API Python d'outils NLP facile à utiliser construite sur NLTK et Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core PNL</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> . Services et packages NLP en Java développés par le Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> . Topic Modelling for Humans a commencé comme une collection de scripts Python pour le projet de bibliothèque numérique de mathématiques tchèque.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> . Workflows NLP industriels de bout en bout avec Python et Cython avec accélération GPU pour les transformateurs.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Texte rapide</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> . Une bibliothèque NLP gratuite, légère et open source pour l'apprentissage des intégrations de mots et la classification des phrases créée par le laboratoire de recherche en IA (FAIR) de Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP est une solution unique et unifiée pour toutes les tâches et exigences NLP qui permet de disposer de logiciels NLP évolutifs, hautes performances et haute précision pour des cas d'utilisation de production réels.  Il s’appuie sur l’apprentissage par transfert et met en œuvre les algorithmes et modèles de pointe les plus récents dans la recherche et dans tous les secteurs.  En raison du manque de support complet par Spark pour les bibliothèques ci-dessus, Spark NLP a été construit sur<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> pour tirer parti du moteur de traitement de données distribué en mémoire à usage général de Spark en tant que bibliothèque NLP de niveau entreprise pour les flux de travail de production critiques.  Ses annotateurs utilisent des algorithmes basés sur des règles, l’apprentissage automatique et TensorFlow pour alimenter les implémentations d’apprentissage en profondeur.  Cela couvre les tâches courantes de PNL, y compris, mais sans s'y limiter, la tokenisation, la lemmatisation, la dérivation, l'étiquetage des parties du discours, la reconnaissance d'entités nommées, la vérification orthographique et l'analyse des sentiments.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Les représentations d'encodeurs bidirectionnels à partir de transformateurs (BERT) sont une technique d'apprentissage automatique basée sur des transformateurs pour le PNL.  Il a popularisé le concept de pré-entraînement et de réglage fin.  L'architecture du transformateur dans BERT est issue de la traduction automatique, qui modélise mieux les dépendances à long terme que les modèles de langage basés sur le réseau neuronal récurrent (RNN).  Il a également introduit la tâche de modélisation du langage masqué (MLM), où 15 % aléatoires de tous les jetons sont masqués et le modèle les prédit, permettant une véritable bidirectionnalité.</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Banque de phrases financières</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Expliquer le document DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">L’analyse du sentiment financier est difficile en raison du langage spécialisé et du manque de données étiquetées dans ce domaine.  FinBERT, un modèle de langage basé sur BERT pré-entraîné, a été adapté au domaine<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> , un corpus financier, et affiné avec des données étiquetées (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) pour la classification du sentiment financier.  Les chercheurs ont extrait 4 500 phrases d’articles de presse contenant des termes financiers.  Ensuite, 16 experts et étudiants en master ayant une formation en finance ont étiqueté les phrases comme positives, neutres et négatives.  Nous avons créé un flux de travail Spark de bout en bout pour analyser le sentiment des 10 premières sociétés du NASDAQ dans leurs transcriptions d'appels sur les résultats de 2016 à 2020, en utilisant FinBERT et deux autres pipelines pré-entraînés.<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) de Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Le moteur d'apprentissage profond sous-jacent de Spark NLP est TensorFlow, une plate-forme open source de bout en bout pour l'apprentissage automatique qui permet une création de modèles facile, une production ML robuste n'importe où et une expérimentation puissante pour la recherche.  Par conséquent, lors de l'exécution de nos pipelines dans Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> En mode, nous exécutions essentiellement TensorFlow distribué avec parallélisation des données et des modèles sur un maître et plusieurs nœuds de travail, ainsi qu'un stockage en réseau monté sur le cluster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Formation distribuée Horovod</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">Solution NetApp E-Series pour Hadoop</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">La validation Hadoop principale pour les performances liées à MapReduce est effectuée avec TeraGen, TeraSort, TeraValidate et DFSIO (lecture et écriture).  Les résultats de validation de TeraGen et TeraSort sont présentés dans<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> et dans la section « Storage Tiering » pour AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod sur Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">Sur la base des demandes des clients, nous considérons la formation distribuée avec Spark comme l’un des cas d’utilisation les plus importants.  Dans ce document, nous avons utilisé le<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> pour valider les performances de Spark avec les solutions NetApp sur site, cloud natives et cloud hybrides à l'aide des contrôleurs de stockage NetApp All Flash FAS (AFF), Azure NetApp Files et StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Le package Horovod sur Spark fournit un wrapper pratique autour de Horovod qui simplifie l'exécution de charges de travail de formation distribuées dans les clusters Spark, permettant une boucle de conception de modèle étroite dans laquelle le traitement des données, la formation du modèle et l'évaluation du modèle sont tous effectués dans Spark où résident les données de formation et d'inférence.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Ventes en magasin Kaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Il existe deux API pour exécuter Horovod sur Spark : une API Estimator de haut niveau et une API Run de niveau inférieur.  Bien que les deux utilisent le même mécanisme sous-jacent pour lancer Horovod sur les exécuteurs Spark, l'API Estimator fait abstraction du traitement des données, de la boucle de formation du modèle, du point de contrôle du modèle, de la collecte de métriques et de la formation distribuée.  Nous avons utilisé Horovod Spark Estimators, TensorFlow et Keras pour une préparation de données de bout en bout et un flux de travail de formation distribué basé sur le<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> concours.</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">Le scénario<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> peut être trouvé dans la section<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> Il contient trois parties :</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">La première partie effectue diverses étapes de prétraitement des données sur un ensemble initial de fichiers CSV fournis par Kaggle et collectés par la communauté.  Les données d'entrée sont séparées dans un ensemble d'apprentissage avec un<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> sous-ensemble et un ensemble de données de test.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">La deuxième partie définit un modèle Keras Deep Neural Network (DNN) avec une fonction d'activation sigmoïde logarithmique et un optimiseur Adam, et effectue une formation distribuée du modèle à l'aide d'Horovod sur Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">La troisième partie effectue une prédiction sur l'ensemble de données de test en utilisant le meilleur modèle qui minimise l'erreur absolue moyenne globale de l'ensemble de validation.  Il crée ensuite un fichier CSV de sortie.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">Apprentissage automatique</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">Voir la section<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block> pour divers résultats de comparaison d'exécution.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Apprentissage profond multi-travailleurs utilisant Keras pour la prédiction du CTR</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">Avec les avancées récentes des plateformes et applications ML, une grande attention est désormais portée à l’apprentissage à grande échelle.  Le taux de clics (CTR) est défini comme le nombre moyen de clics pour cent impressions d'annonces en ligne (exprimé en pourcentage).  Il est largement adopté comme indicateur clé dans divers secteurs d’activité et cas d’utilisation, notamment le marketing numérique, la vente au détail, le commerce électronique et les fournisseurs de services.  Pour plus de détails sur les applications du CTR et les résultats de performance de formation distribuée, consultez le<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block> section.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Ensemble de données Criteo Terabyte Click Logs</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">Dans ce rapport technique, nous avons utilisé une variante de la<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (voir TR-4904) pour l'apprentissage en profondeur distribué multi-travailleurs utilisant Keras pour créer un flux de travail Spark avec des modèles Deep and Cross Network (DCN), en comparant ses performances en termes de fonction d'erreur de perte de journal avec un modèle de régression logistique Spark ML de base.  DCN capture efficacement les interactions de caractéristiques efficaces de degrés limités, apprend les interactions hautement non linéaires, ne nécessite aucune ingénierie de caractéristiques manuelle ni recherche exhaustive et présente un faible coût de calcul.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Les données des systèmes de recommandation à l'échelle du Web sont pour la plupart discrètes et catégoriques, ce qui conduit à un espace de fonctionnalités vaste et clairsemé qui rend difficile l'exploration des fonctionnalités.  Cela a limité la plupart des systèmes à grande échelle à des modèles linéaires tels que la régression logistique.  Cependant, identifier fréquemment des caractéristiques prédictives et explorer simultanément des caractéristiques croisées invisibles ou rares est la clé pour faire de bonnes prédictions.  Les modèles linéaires sont simples, interprétables et faciles à mettre à l’échelle, mais leur pouvoir d’expression est limité.</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">Les caractéristiques croisées, en revanche, se sont avérées significatives pour améliorer l'expressivité des modèles.  Malheureusement, il faut souvent procéder à une ingénierie manuelle des fonctionnalités ou à une recherche exhaustive pour identifier ces fonctionnalités.  Il est souvent difficile de généraliser aux interactions entre fonctionnalités invisibles.  L'utilisation d'un réseau neuronal croisé comme DCN évite l'ingénierie des fonctionnalités spécifiques à la tâche en appliquant explicitement le croisement des fonctionnalités de manière automatique.  Le réseau croisé est constitué de plusieurs couches, où le degré d'interaction le plus élevé est déterminé de manière prouvable par la profondeur de la couche.  Chaque couche produit des interactions d’ordre supérieur basées sur celles existantes et conserve les interactions des couches précédentes.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Un réseau neuronal profond (DNN) promet de capturer des interactions très complexes entre les fonctionnalités.  Cependant, comparé au DCN, il nécessite près d'un ordre de grandeur de paramètres supplémentaires, est incapable de former explicitement des fonctionnalités croisées et peut ne pas réussir à apprendre efficacement certains types d'interactions de fonctionnalités.  Le réseau croisé est efficace en termes de mémoire et facile à mettre en œuvre.  L'entraînement conjoint des composants croisés et DNN capture efficacement les interactions des fonctionnalités prédictives et offre des performances de pointe sur l'ensemble de données Criteo CTR.</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">Un modèle DCN commence par une couche d'intégration et d'empilement, suivie d'un réseau croisé et d'un réseau profond en parallèle.  Celles-ci sont à leur tour suivies d'une couche de combinaison finale qui combine les sorties des deux réseaux.  Vos données d’entrée peuvent être un vecteur avec des caractéristiques clairsemées et denses.  Dans Spark, les bibliothèques contiennent le type<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> .  Il est donc important pour les utilisateurs de faire la distinction entre les deux et d’être attentifs lorsqu’ils appellent leurs fonctions et méthodes respectives.  Dans les systèmes de recommandation à l'échelle du Web tels que la prédiction du CTR, les entrées sont principalement des caractéristiques catégorielles, par exemple<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block> .  Ces caractéristiques sont souvent codées sous forme de vecteurs one-hot, par exemple,<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> .  Encodage à chaud (OHE) avec<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> est utile lorsqu'il s'agit de traiter des ensembles de données du monde réel avec des vocabulaires en constante évolution et en croissance.  Nous avons modifié des exemples dans<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> pour traiter de grands vocabulaires, en créant des vecteurs d'intégration dans la couche d'intégration et d'empilement de notre DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Ensemble de données Criteo Display Ads</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">Le<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> prédit le taux de clics des publicités.  Il comporte 13 caractéristiques entières et 26 caractéristiques catégorielles dans lesquelles chaque catégorie a une cardinalité élevée.  Pour cet ensemble de données, une amélioration de 0,001 de la perte logarithmique est pratiquement significative en raison de la grande taille d’entrée.  Une petite amélioration de la précision des prédictions pour une large base d’utilisateurs peut potentiellement conduire à une augmentation importante des revenus d’une entreprise.  L'ensemble de données contient 11 Go de journaux d'utilisateurs sur une période de 7 jours, ce qui équivaut à environ 41 millions d'enregistrements.  Nous avons utilisé Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> pour diviser aléatoirement les données pour la formation (80 %), la validation croisée (10 %) et les 10 % restants pour les tests.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN a été implémenté sur TensorFlow avec Keras.  La mise en œuvre du processus de formation du modèle avec DCN comporte quatre composants principaux :</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Traitement et intégration des données.*  Les fonctionnalités à valeur réelle sont normalisées en appliquant une transformation logarithmique.  Pour les fonctionnalités catégorielles, nous intégrons les fonctionnalités dans des vecteurs denses de dimension 6×(cardinalité de catégorie)1/4.  La concaténation de tous les plongements donne un vecteur de dimension 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Optimisation.*  Nous avons appliqué l’optimisation stochastique par mini-lots avec l’optimiseur Adam.  La taille du lot a été définie sur 512.  La normalisation par lots a été appliquée au réseau profond et la norme de clip de gradient a été fixée à 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Régularisation.*  Nous avons utilisé l'arrêt précoce, car la régularisation ou l'abandon de L2 ne s'est pas avéré efficace.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hyperparamètres.*  Nous rapportons les résultats basés sur une recherche de grille sur le nombre de couches cachées, la taille de la couche cachée, le taux d'apprentissage initial et le nombre de couches croisées.  Le nombre de couches cachées variait de 2 à 5, avec des tailles de couches cachées allant de 32 à 1024.  Pour le DCN, le nombre de couches croisées était de 1 à 6.  Le taux d’apprentissage initial a été réglé de 0,0001 à 0,001 avec des incréments de 0,0001.  Toutes les expériences ont appliqué un arrêt précoce à l'étape d'entraînement 150 000, au-delà de laquelle un surapprentissage a commencé à se produire.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">En plus du DCN, nous avons également testé d'autres modèles d'apprentissage profond populaires pour la prédiction du CTR, notamment<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> ,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> , et<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block> .</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Architectures utilisées pour la validation</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Pour cette validation, nous avons utilisé quatre nœuds de travail et un nœud maître avec une paire AFF-A800 HA.  Tous les membres du cluster étaient connectés via des commutateurs réseau 10 GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Pour cette validation de solution NetApp Spark, nous avons utilisé trois contrôleurs de stockage différents : le E5760, le E5724 et le AFF-A800.  Les contrôleurs de stockage de la série E étaient connectés à cinq nœuds de données avec des connexions SAS 12 Gbit/s.  Le contrôleur de stockage AFF HA-pair fournit des volumes NFS exportés via des connexions 10 GbE aux nœuds de travail Hadoop.  Les membres du cluster Hadoop étaient connectés via des connexions 10 GbE dans les solutions Hadoop E-Series, AFF et StorageGRID .</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Architectures utilisées pour la validation.</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Un centre de données d’entreprise moderne est un cloud hybride qui connecte plusieurs environnements d’infrastructure distribués via un plan de gestion des données continu avec un modèle d’exploitation cohérent, sur site et/ou dans plusieurs clouds publics.  Pour tirer le meilleur parti d'un cloud hybride, vous devez être en mesure de déplacer de manière transparente des données entre vos environnements sur site et multicloud sans avoir besoin de conversions de données ou de refactorisation d'applications.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Solution de cloud hybride</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Les clients ont indiqué qu'ils commençaient leur parcours vers le cloud hybride soit en déplaçant le stockage secondaire vers le cloud pour des cas d'utilisation tels que la protection des données, soit en déplaçant des charges de travail moins critiques pour l'entreprise, telles que le développement d'applications et DevOps vers le cloud.  Ils passent ensuite à des charges de travail plus critiques.  L'hébergement Web et de contenu, le développement DevOps et d'applications, les bases de données, les analyses et les applications conteneurisées font partie des charges de travail de cloud hybride les plus populaires.  La complexité, le coût et les risques des projets d’IA d’entreprise ont historiquement entravé l’adoption de l’IA du stade expérimental à la production.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Avec une solution de cloud hybride NetApp , les clients bénéficient d'outils intégrés de sécurité, de gouvernance des données et de conformité avec un panneau de contrôle unique pour la gestion des données et des flux de travail dans des environnements distribués, tout en optimisant le coût total de possession en fonction de leur consommation.  La figure suivante est un exemple de solution d'un partenaire de service cloud chargé de fournir une connectivité multicloud pour les données d'analyse de Big Data des clients.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Exemple de solution d'un partenaire de service cloud.</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">Dans ce scénario, les données IoT reçues dans AWS à partir de différentes sources sont stockées dans un emplacement central dans NetApp Private Storage (NPS).  Le stockage NPS est connecté aux clusters Spark ou Hadoop situés dans AWS et Azure, permettant aux applications d'analyse de Big Data de s'exécuter dans plusieurs clouds et d'accéder aux mêmes données.  Les principales exigences et défis pour ce cas d'utilisation sont les suivants :</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Les données doivent être reçues de différentes sources telles que des environnements sur site et dans le cloud via différents capteurs et hubs.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">La solution doit être efficace et rentable.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">Le principal défi est de créer une solution rentable et efficace qui fournit des services d’analyse hybrides entre différents environnements sur site et cloud.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Notre solution de protection des données et de connectivité multicloud résout le problème des applications d'analyse cloud sur plusieurs hyperscalers.  Comme le montre la figure ci-dessus, les données des capteurs sont diffusées et ingérées dans le cluster AWS Spark via Kafka.  Les données sont stockées dans un partage NFS résidant dans NPS, qui est situé en dehors du fournisseur de cloud dans un centre de données Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Étant donné que NetApp NPS est connecté à Amazon AWS et Microsoft Azure via des connexions Direct Connect et Express Route respectivement, les clients peuvent exploiter le module d'analyse sur place pour accéder aux données des clusters d'analyse Amazon et AWS.  Par conséquent, étant donné que le stockage sur site et le stockage NPS exécutent tous deux le logiciel ONTAP ,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> peut refléter les données NPS dans le cluster sur site, fournissant des analyses de cloud hybride sur site et sur plusieurs clouds.</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">Pour des performances optimales, NetApp recommande généralement d’utiliser plusieurs interfaces réseau et une connexion directe ou des routes express pour accéder aux données à partir d’instances cloud.  Nous avons d'autres solutions de transfert de données, notamment<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> et<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> pour aider les clients à créer des clusters Spark hybrides cloud compatibles avec les applications, sécurisés et rentables.</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Les trois scripts Python suivants correspondent aux trois principaux cas d’utilisation testés.  Le premier est<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block> .</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">Le deuxième script est<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">Le troisième script est<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> .</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp dispose de trois portefeuilles de stockage : FAS/ AFF, E-Series et Cloud Volumes ONTAP.  Nous avons validé AFF et la série E avec le système de stockage ONTAP pour les solutions Hadoop avec Apache Spark.  La structure de données optimisée par NetApp intègre des services et des applications de gestion des données (blocs de construction) pour l'accès, le contrôle, la protection et la sécurité des données.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Présentation des solutions NetApp Spark</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp dispose de trois portefeuilles de stockage : FAS/ AFF, E-Series et Cloud Volumes ONTAP.  Nous avons validé AFF et la série E avec le système de stockage ONTAP pour les solutions Hadoop avec Apache Spark.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">La structure de données fournit des services et des applications de gestion de données.</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* Accès direct NetApp NFS.*  Fournit aux derniers clusters Hadoop et Spark un accès direct aux volumes NetApp NFS sans exigences de logiciel ou de pilote supplémentaires.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* Technologie NetApp SnapMirror .*  Fournit des capacités de protection des données entre les instances locales et ONTAP Cloud ou NPS.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">La figure suivante illustre la solution Spark avec le stockage NetApp .</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Solution Spark avec stockage NetApp .</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">La solution ONTAP Spark utilise le protocole d'accès direct NetApp NFS pour les analyses sur place et les flux de travail IA, ML et DL utilisant l'accès aux données de production existantes.  Les données de production disponibles pour les nœuds Hadoop sont exportées pour effectuer des tâches d'analyse et d'IA, de ML et de DL sur place.  Vous pouvez accéder aux données à traiter dans les nœuds Hadoop avec ou sans accès direct NetApp NFS.  Dans Spark avec le standalone ou<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> gestionnaire de cluster, vous pouvez configurer un volume NFS en utilisant<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> .  Nous avons validé trois cas d’utilisation avec différents ensembles de données.  Les détails de ces validations sont présentés dans la section « Résultats des tests ».  (xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">La figure suivante illustre le positionnement du stockage NetApp Apache Spark/Hadoop.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Positionnement du stockage NetApp Apache Spark/Hadoop.</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Nous avons identifié les caractéristiques uniques de la solution E-Series Spark, de la solution AFF/ FAS ONTAP Spark et de la solution StorageGRID Spark, et avons effectué une validation et des tests détaillés.  Sur la base de nos observations, NetApp recommande la solution E-Series pour les installations greenfield et les nouveaux déploiements évolutifs, ainsi que la solution AFF/ FAS pour les charges de travail d'analyse sur place, d'IA, de ML et de DL utilisant les données NFS existantes, et StorageGRID pour l'IA, le ML et le DL et les analyses de données modernes lorsque le stockage d'objets est requis.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Solutions NetApp recommandées pour Spark.</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Un lac de données est un référentiel de stockage pour de grands ensembles de données sous forme native qui peuvent être utilisés pour les tâches d'analyse, d'IA, de ML et de DL.  Nous avons créé un référentiel de lac de données pour les solutions E-Series, AFF/ FAS et StorageGRID SG6060 Spark.  Le système E-Series fournit un accès HDFS au cluster Hadoop Spark, tandis que les données de production existantes sont accessibles via le protocole d'accès direct NFS au cluster Hadoop.  Pour les ensembles de données résidant dans le stockage d'objets, NetApp StorageGRID fournit un accès sécurisé S3 et S3a.</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Cette page décrit l'architecture Splunk, y compris les définitions clés, les déploiements distribués Splunk, Splunk SmartStore, le flux de données, les exigences matérielles et logicielles, les exigences mono et multisites, etc.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Architecture Splunk</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">Cette section décrit l'architecture Splunk, y compris les définitions clés, les déploiements distribués Splunk, Splunk SmartStore, le flux de données, les exigences matérielles et logicielles, les exigences mono et multisites, etc.</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Définitions clés</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">Les deux tableaux suivants répertorient les composants Splunk et NetApp utilisés dans le déploiement Splunk distribué.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Ce tableau répertorie les composants matériels Splunk pour la configuration distribuée de Splunk Enterprise.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Composant Splunk</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Tâche</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexeur</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Référentiel pour les données Splunk Enterprise</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Transitaire universel</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsable de l'ingestion des données et de leur transmission aux indexeurs</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Tête de recherche</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">L'interface utilisateur utilisée pour rechercher des données dans les indexeurs</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Maître de cluster</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Gère l'installation Splunk des indexeurs et des têtes de recherche</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Console de surveillance</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Outil de surveillance centralisé utilisé sur l'ensemble du déploiement</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Licence master</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">Le maître des licences gère les licences Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Serveur de déploiement</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Met à jour les configurations et distribue les applications au composant de traitement</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Composant de stockage</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Stockage entièrement flash utilisé pour gérer les données de niveau chaud.  Également connu sous le nom de stockage local.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Stockage d'objets S3 utilisé pour gérer les données de niveau chaud.  Utilisé par SmartStore pour déplacer des données entre les niveaux chaud et tiède.  Également connu sous le nom de stockage à distance.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Ce tableau répertorie les composants de l’architecture de stockage Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Composant responsable</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">Magasin intelligent</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Fournit aux indexeurs la possibilité de hiérarchiser les données du stockage local vers le stockage d'objets.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Chaud</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">Le point d'atterrissage où les transitaires universels placent les données nouvellement écrites.  Le stockage est accessible en écriture et les données sont consultables.  Ce niveau de données est généralement composé de SSD ou de disques durs rapides.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Gestionnaire de cache</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Gère le cache local des données indexées, récupère les données chaudes du stockage distant lorsqu'une recherche se produit et supprime les données les moins fréquemment utilisées du cache.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Chaud</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Les données sont transférées logiquement vers le bucket, renommées d'abord vers le niveau chaud à partir du niveau chaud.  Les données de ce niveau sont protégées et, comme le niveau chaud, peuvent être composées de SSD ou de disques durs de plus grande capacité.  Les sauvegardes incrémentielles et complètes sont prises en charge à l'aide de solutions de protection des données courantes.</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Déploiements distribués Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Pour prendre en charge des environnements plus vastes dans lesquels les données proviennent de nombreuses machines, vous devez traiter de grands volumes de données.  Si de nombreux utilisateurs doivent rechercher les données, vous pouvez faire évoluer le déploiement en distribuant les instances Splunk Enterprise sur plusieurs machines.  C'est ce qu'on appelle un déploiement distribué.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">Dans un déploiement distribué typique, chaque instance Splunk Enterprise exécute une tâche spécialisée et réside sur l’un des trois niveaux de traitement correspondant aux principales fonctions de traitement.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">Le tableau suivant répertorie les niveaux de traitement de Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Étage</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Composant</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Description</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Saisie de données</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Transitaire</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Un transitaire consomme des données, puis les transmet à un groupe d’indexeurs.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indexage</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Un indexeur indexe les données entrantes qu'il reçoit généralement d'un groupe de transitaires.  L'indexeur transforme les données en événements et stocke les événements dans un index.  L'indexeur recherche également les données indexées en réponse aux demandes de recherche d'une tête de recherche.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gestion de la recherche</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Une tête de recherche sert de ressource centrale pour la recherche.  Les têtes de recherche d'un cluster sont interchangeables et ont accès aux mêmes recherches, tableaux de bord, objets de connaissances, etc., à partir de n'importe quel membre du cluster de têtes de recherche.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">Le tableau suivant répertorie les composants importants utilisés dans un environnement Splunk Enterprise distribué.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilité</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Maître du cluster d'index</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordonne les activités et les mises à jour d'un cluster d'indexeurs</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestion des indices</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">cluster d'index</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Groupe d'indexeurs Splunk Enterprise configurés pour répliquer des données entre eux</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Déploiement de la tête de recherche</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Gère le déploiement et les mises à jour du cluster maître</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gestion de la tête de recherche</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Cluster de têtes de recherche</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Groupe de têtes de recherche qui sert de ressource centrale pour la recherche</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Équilibreurs de charge</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Utilisé par les composants en cluster pour gérer la demande croissante des têtes de recherche, des indexeurs et de la cible S3 afin de répartir la charge sur les composants en cluster.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Gestion de la charge pour les composants en cluster</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Découvrez les avantages suivants des déploiements distribués Splunk Enterprise :</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Accéder à des sources de données diverses ou dispersées</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Fournir des fonctionnalités pour gérer les besoins en données des entreprises de toute taille et de toute complexité</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Obtenez une haute disponibilité et assurez la reprise après sinistre grâce à la réplication des données et au déploiement multisite</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore est une fonctionnalité d'indexation qui permet aux magasins d'objets distants tels qu'Amazon S3 de stocker des données indexées.  À mesure que le volume de données d’un déploiement augmente, la demande de stockage dépasse généralement la demande de ressources de calcul.  SmartStore vous permet de gérer de manière rentable le stockage de votre indexeur et vos ressources de calcul en mettant à l'échelle ces ressources séparément.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore introduit un niveau de stockage à distance et un gestionnaire de cache.  Ces fonctionnalités permettent aux données de résider soit localement sur des indexeurs, soit sur le niveau de stockage distant.  Le gestionnaire de cache gère le déplacement des données entre l'indexeur et le niveau de stockage distant, qui est configuré sur l'indexeur.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Avec SmartStore, vous pouvez réduire au minimum l'empreinte de stockage de l'indexeur et choisir des ressources de calcul optimisées pour les E/S.  La plupart des données résident sur le stockage distant.  L'indexeur conserve un cache local contenant une quantité minimale de données : buckets chauds, copies de buckets chauds participant à des recherches actives ou récentes et métadonnées de bucket.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Flux de données Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Lorsque les données provenant de diverses sources atteignent les indexeurs, les données sont indexées et enregistrées localement dans un bucket chaud.  L'indexeur réplique également les données du compartiment chaud vers les indexeurs cibles.  Jusqu’à présent, le flux de données est identique au flux de données des index non SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Lorsque le seau chaud devient chaud, le flux de données diverge.  L'indexeur source copie le bucket chaud dans le magasin d'objets distant (niveau de stockage distant) tout en laissant la copie existante dans son cache, car les recherches ont tendance à s'exécuter sur des données récemment indexées.  Cependant, les indexeurs cibles suppriment leurs copies car le magasin distant offre une haute disponibilité sans conserver plusieurs copies locales.  La copie principale du bucket réside désormais dans le magasin distant.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">L'image suivante montre le flux de données Splunk SmartStore.</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">Le gestionnaire de cache sur l'indexeur est au cœur du flux de données SmartStore.  Il récupère des copies des buckets du magasin distant si nécessaire pour gérer les demandes de recherche.  Il supprime également les copies plus anciennes ou moins recherchées des buckets du cache, car la probabilité qu'ils participent aux recherches diminue avec le temps.</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">Le travail du gestionnaire de cache est d'optimiser l'utilisation du cache disponible tout en garantissant que les recherches ont un accès immédiat aux compartiments dont elles ont besoin.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">Le tableau ci-dessous répertorie les composants logiciels nécessaires à la mise en œuvre de la solution.  Les composants logiciels utilisés dans toute implémentation de la solution peuvent varier en fonction des exigences du client.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Famille de produits</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nom du produit</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Version du produit</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Système opérateur</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Stockage d'objets StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11,6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">n / A</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8,1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Entreprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise avec SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Exigences mono et multisites</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">Dans un environnement Splunk Enterprise (déploiements moyens et grands) où les données proviennent de nombreuses machines et où de nombreux utilisateurs doivent rechercher les données, vous pouvez faire évoluer votre déploiement en distribuant des instances Splunk Enterprise sur un ou plusieurs sites.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">Le tableau suivant répertorie les composants utilisés dans un environnement Splunk Enterprise distribué.</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">Groupe d'indexeurs Splunk Enterprise configurés pour répliquer les données des autres</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Équilibreurs de charge</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gestion de la charge pour les composants en cluster</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Cette figure illustre un exemple de déploiement distribué sur un seul site.</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Cette figure illustre un exemple de déploiement distribué multisite.</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">Les tableaux suivants répertorient le nombre minimum de composants matériels requis pour implémenter la solution.  Les composants matériels utilisés dans les implémentations spécifiques de la solution peuvent varier en fonction des exigences du client.</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Que vous ayez déployé Splunk SmartStore et StorageGRID sur un seul site ou sur plusieurs sites, tous les systèmes sont gérés à partir de StorageGRID GRID Manager dans une seule fenêtre.  Consultez la section « Gestion simple avec Grid Manager » pour plus de détails.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Ce tableau répertorie le matériel utilisé pour un seul site.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disque</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacité utilisable</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Remarque</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nœud d'administration et équilibreur de charge</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48, 8 To (disque dur NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Stockage à distance</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Ce tableau répertorie le matériel utilisé pour une configuration multisite (par site).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nœud d'administration et équilibreur de charge</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Équilibreur de charge NetApp StorageGRID : SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">Le stockage d’objets nécessite l’utilisation d’un équilibreur de charge pour présenter l’espace de noms de stockage cloud.  StorageGRID prend en charge les équilibreurs de charge tiers des principaux fournisseurs tels que F5 et Citrix, mais de nombreux clients choisissent l'équilibreur StorageGRID de niveau entreprise pour sa simplicité, sa résilience et ses hautes performances.  L'équilibreur de charge StorageGRID est disponible sous forme de machine virtuelle, de conteneur ou d'appliance spécialement conçue.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">Le StorageGRID SG1000 facilite l'utilisation de groupes de haute disponibilité (HA) et l'équilibrage de charge intelligent pour les connexions de chemin de données S3.  Aucun autre système de stockage d’objets sur site ne fournit un équilibreur de charge personnalisé.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">L'appareil SG1000 offre les fonctionnalités suivantes :</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Un équilibreur de charge et, éventuellement, des fonctions de nœud d'administration pour un système StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">Le programme d'installation de l'appliance StorageGRID pour simplifier le déploiement et la configuration des nœuds</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configuration simplifiée des points de terminaison S3 et SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Bande passante dédiée (par rapport au partage d'un équilibreur de charge tiers avec d'autres applications)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Jusqu'à 4 x 100 Gbit/s de bande passante Ethernet agrégée</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">L'image suivante montre l'appareil SG1000 Gateway Services.</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">L'appliance StorageGRID SG6060 comprend un contrôleur de calcul (SG6060) et une étagère de contrôleur de stockage (E-Series E2860) contenant deux contrôleurs de stockage et 60 disques.  Cet appareil offre les fonctionnalités suivantes :</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Évoluez jusqu'à 400 Po dans un seul espace de noms.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Jusqu'à 4x 25 Gbit/s de bande passante Ethernet agrégée.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Inclut le programme d'installation de l'appliance StorageGRID pour simplifier le déploiement et la configuration des nœuds.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Chaque appareil SG6060 peut disposer d'une ou deux étagères d'extension supplémentaires pour un total de 180 disques.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Deux contrôleurs E-Series E2800 (configuration duplex) pour fournir une prise en charge du basculement du contrôleur de stockage.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Étagère à cinq tiroirs pouvant contenir soixante disques de 3,5 pouces (deux disques SSD et 58 disques NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">L'image suivante montre l'appareil SG6060.</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Conception de Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">Le tableau suivant répertorie la configuration Splunk pour un seul site.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Noyaux</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">Système d'exploitation</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 cœurs</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 Go de RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gère les données des utilisateurs</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">L'interface utilisateur recherche des données dans les indexeurs</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Gère les mises à jour des clusters de têtes de recherche</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Gère l'installation et les indexeurs de Splunk</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Console de surveillance et maître de licence</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Effectue une surveillance centralisée de l'ensemble du déploiement Splunk et gère les licences Splunk</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">Les tableaux suivants décrivent la configuration Splunk pour les configurations multisites.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Ce tableau répertorie la configuration Splunk pour une configuration multisite (site A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsable de l'ingestion des données et de leur transmission aux indexeurs.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Effectue une surveillance centralisée de l'ensemble du déploiement Splunk et gère les licences Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Ce tableau répertorie la configuration Splunk pour une configuration multisite (site B).</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise est la solution SIEM leader du marché qui génère des résultats pour les équipes de sécurité, d'informatique et de DevOps.</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise est la solution SIEM leader du marché qui génère des résultats pour les équipes de sécurité, d'informatique et de DevOps.  L’utilisation de Splunk a considérablement augmenté dans les organisations de nos clients.  Il est donc nécessaire d’ajouter davantage de sources de données tout en conservant les données pendant une période plus longue, sollicitant ainsi l’infrastructure Splunk.</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">La combinaison de Splunk SmartStore et de NetApp StorageGRID est conçue pour fournir une architecture évolutive permettant aux organisations d'obtenir des performances d'ingestion améliorées avec le stockage d'objets SmartStore et StorageGRID et une évolutivité accrue pour un environnement Splunk dans plusieurs régions géographiques.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">Ressources de documentation NetApp StorageGRID</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Documentation de Splunk Enterprise</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise À propos de SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Manuel de déploiement distribué Splunk Enterprise</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise Gestion des indexeurs et des clusters d'indexeurs</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Ce rapport technique décrit les avantages que NetApp apporte à une solution Splunk SmartStore tout en démontrant un cadre pour la conception et le dimensionnement de Splunk SmartStore dans votre environnement.  Le résultat est une solution simple, évolutive et résiliente qui offre un TCO convaincant.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869 : NetApp StorageGRID avec Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise est la solution de gestion des informations et des événements de sécurité (SIEM) leader du marché qui génère des résultats pour les équipes de sécurité, d'informatique et de DevOps.</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Aperçu</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">Les volumes de données continuent de croître à un rythme exponentiel, créant d’énormes opportunités pour les entreprises qui peuvent exploiter cette vaste ressource.  Splunk Enterprise continue de gagner en adoption dans une plus grande variété de cas d’utilisation.  À mesure que les cas d’utilisation augmentent, la quantité de données que Splunk Enterprise ingère et traite augmente également.  L'architecture traditionnelle de Splunk Enterprise est une conception évolutive distribuée offrant un excellent accès aux données et une excellente disponibilité.  Cependant, les entreprises utilisant cette architecture sont confrontées à des coûts croissants liés à la mise à l’échelle pour répondre au volume de données en croissance rapide.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore avec NetApp StorageGRID résout ce défi en proposant un nouveau modèle de déploiement dans lequel le calcul et le stockage sont découplés.  Cette solution offre également une évolutivité et une élasticité inégalées pour les environnements Splunk Enterprise en permettant aux clients de s'adapter à un ou plusieurs sites, tout en réduisant les coûts en permettant au calcul et au stockage de s'adapter indépendamment et en ajoutant une hiérarchisation intelligente au stockage d'objets S3 basé sur le cloud et rentable.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">La solution optimise la quantité de données dans le stockage local tout en maintenant les performances de recherche, permettant ainsi de faire évoluer le calcul et le stockage à la demande.  SmartStore évalue automatiquement les modèles d'accès aux données pour déterminer quelles données doivent être accessibles pour des analyses en temps réel et quelles données doivent résider dans un stockage d'objets S3 à moindre coût.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Ce rapport technique décrit les avantages que NetApp apporte à une solution Splunk SmartStore tout en démontrant un cadre pour la conception et le dimensionnement de Splunk SmartStore dans votre environnement.  Le résultat est une solution simple, évolutive et résiliente qui offre un TCO convaincant.  StorageGRID fournit un stockage d'objets basé sur le protocole S3/API évolutif et rentable, également connu sous le nom de stockage à distance, permettant aux organisations de faire évoluer leur solution Splunk à moindre coût tout en augmentant la résilience.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore fait référence au stockage d'objets sous forme de magasins distants ou de niveaux de stockage distants.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">À propos de NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID est une solution de stockage d'objets définie par logiciel pour les grandes archives, les référentiels multimédias et les magasins de données Web.  Avec StorageGRID, NetApp s'appuie sur deux décennies d'expérience dans la fourniture de solutions d'innovation et de gestion des données de pointe tout en aidant les organisations à gérer et à maximiser la valeur de leurs informations sur site et dans des déploiements de cloud public, privé ou hybride.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID fournit un stockage sécurisé et durable pour les données non structurées à grande échelle.  Les politiques de gestion du cycle de vie intégrées et basées sur les métadonnées optimisent l'emplacement de vos données tout au long de leur vie.  Le contenu est placé au bon endroit, au bon moment et sur le bon niveau de stockage pour réduire les coûts.  L'espace de noms unique permet d'accéder aux données via un seul appel, quel que soit l'emplacement géographique du stockage StorageGRID .  Les clients peuvent déployer et gérer plusieurs instances StorageGRID entre les centres de données et dans l’infrastructure cloud.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Un système StorageGRID est composé de nœuds hétérogènes, redondants et distribués à l'échelle mondiale qui peuvent être intégrés aux applications clientes existantes et de nouvelle génération.</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape a récemment désigné NetApp comme leader dans le dernier rapport, IDC MarketScape : Worldwide Object-Based Storage 2019 Vendor Assessment.  Avec près de 20 ans de déploiements de production dans les secteurs les plus exigeants, StorageGRID est un leader reconnu dans le domaine des données non structurées.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Avec StorageGRID, vous pouvez réaliser les objectifs suivants :</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Déployez plusieurs instances StorageGRID pour accéder aux données depuis n’importe quel emplacement entre les centres de données et le cloud via un espace de noms unique qui s’adapte facilement à des centaines de pétaoctets.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Offrez la flexibilité nécessaire pour déployer et gérer de manière centralisée les infrastructures.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Offrez une durabilité inégalée avec quinze neuf de durabilité tirant parti du codage d'effacement en couches (EC).</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Activez davantage de fonctionnalités multicloud hybrides avec des intégrations validées dans Amazon S3 Glacier et Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Respectez les obligations réglementaires et facilitez la conformité grâce à une conservation des données inviolable, sans API propriétaires ni dépendance vis-à-vis des fournisseurs.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Page d'accueil de NetApp StorageGRID</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Pour plus d'informations sur la manière dont StorageGRID peut vous aider à résoudre vos problèmes de gestion de données non structurées les plus complexes, consultez le<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> .</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">À propos de Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise est une plateforme permettant de transformer les données en actions.  Les données générées par diverses sources telles que les fichiers journaux, les sites Web, les appareils, les capteurs et les applications sont envoyées et analysées par les indexeurs Splunk, vous permettant de tirer des informations riches des données.  Il peut identifier les violations de données, mettre en évidence les tendances des clients et des produits, trouver des opportunités d'optimisation de l'infrastructure ou créer des informations exploitables dans une grande variété de cas d'utilisation.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">À propos de Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore étend les avantages de l'architecture Splunk tout en simplifiant sa capacité à évoluer de manière rentable.  Le découplage des ressources de calcul et de stockage donne lieu à des nœuds d'indexation optimisés pour les E/S avec des besoins de stockage considérablement réduits car ils ne stockent qu'un sous-ensemble de données sous forme de cache.  Vous n’avez pas besoin d’ajouter de ressources de calcul ou de stockage supplémentaires lorsqu’une seule de ces ressources est nécessaire, ce qui vous permet de réaliser des économies de coûts importantes.  Vous pouvez utiliser un stockage d'objets basé sur S3 rentable et facilement évolutif, ce qui simplifie davantage l'environnement, réduit les coûts et vous permet de conserver un ensemble de données plus volumineux.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore offre une valeur significative aux organisations, notamment les suivantes :</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Réduire les coûts de stockage en déplaçant les données chaudes vers un stockage d'objets S3 optimisé en termes de coûts</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Mise à l'échelle transparente en découplant le stockage et le calcul</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Simplifier la continuité des activités en exploitant un stockage cloud natif résilient</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">Cette page décrit les performances de Splunk SmartStore sur un contrôleur NetApp StorageGRID .</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Performances du SmartStore sur un seul site</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">Cette section décrit les performances de Splunk SmartStore sur un contrôleur NetApp StorageGRID .  Splunk SmartStore déplace les données chaudes vers un stockage distant, qui dans ce cas est le stockage d'objets StorageGRID dans la validation des performances.</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Nous avons utilisé EF600 pour le stockage à chaud/cache et StorageGRID 6060 pour le stockage à distance.  Nous avons utilisé l’architecture suivante pour la validation des performances.  Nous avons utilisé deux têtes de recherche, quatre transitaires lourds pour transmettre les données aux indexeurs, sept générateurs d'événements Splunk (Eventgens) pour générer les données en temps réel et 18 indexeurs pour stocker les données.</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">Configuration</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Ce tableau répertorie le matériel utilisé pour la validation des performances de SmartStorage.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Porteur lourd</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 cœurs</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">L'interface utilisateur recherche des données dans les indexeurs</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Validation des performances du magasin à distance SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">Dans cette validation des performances, nous avons configuré le cache SmartStore dans le stockage local sur tous les indexeurs pour 10 jours de données.  Nous avons permis à<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (taille du bucket de 750 Mo) dans le gestionnaire de cluster Splunk et a poussé les modifications vers tous les indexeurs.  Pour mesurer les performances de téléchargement, nous avons ingéré 10 To par jour pendant 10 jours et avons transféré tous les buckets chauds vers des buckets chauds en même temps et capturé le débit maximal et moyen par instance et à l'échelle du déploiement à partir du tableau de bord de la console de surveillance SmartStore.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Cette image montre les données ingérées en une journée.</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Nous avons exécuté la commande suivante à partir du cluster master (le nom de l'index est<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block> ).  Nous avons ensuite capturé le débit de téléchargement maximal et moyen par instance et à l'échelle du déploiement via les tableaux de bord de la console de surveillance SmartStore.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">Le maître du cluster dispose d'une authentification sans mot de passe pour tous les indexeurs (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Pour mesurer les performances de téléchargement, nous avons expulsé toutes les données du cache en exécutant la CLI d'expulsion deux fois à l'aide de la commande suivante.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Nous avons exécuté la commande suivante à partir du cluster master et exécuté la recherche à partir de la tête de recherche sur 10 jours de données du magasin distant de StorageGRID.  Nous avons ensuite capturé le débit de téléchargement maximal et moyen par instance et à l'échelle du déploiement via les tableaux de bord de la console de surveillance SmartStore.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Les configurations de l'indexeur ont été poussées depuis le maître du cluster SmartStore.  Le maître du cluster avait la configuration suivante pour l'indexeur.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Nous avons exécuté la requête de recherche suivante sur la tête de recherche pour collecter la matrice de performances.</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Nous avons collecté les informations de performance du cluster master.  La performance maximale était de 61,34 Gbit/s.</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">La performance moyenne était d’environ 29 Gbit/s.</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Performances de StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">Les performances de SmartStore sont basées sur la recherche de modèles et de chaînes spécifiques à partir de grandes quantités de données.  Dans cette validation, les événements sont générés à l'aide de<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> sur un index Splunk spécifique (eventgen-test) via la tête de recherche, et la requête va à StorageGRID pour la plupart des requêtes.  L'image suivante montre les succès et les échecs des données de requête.  Les données de hits proviennent du disque local et les données d'échecs proviennent du contrôleur StorageGRID .</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">La couleur verte montre les données de hits et la couleur orange montre les données d'échecs.</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Lorsque la requête s'exécute pour la recherche sur StorageGRID, le temps de récupération S3 à partir de StorageGRID est indiqué dans l'image suivante.</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Utilisation du matériel StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">L'instance StorageGRID dispose d'un équilibreur de charge et de trois contrôleurs StorageGRID .  L'utilisation du processeur pour les trois contrôleurs est comprise entre 75 % et 100 %.</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore avec contrôleur de stockage NetApp - avantages pour le client</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Découplage du calcul et du stockage.*  Splunk SmartStore dissocie le calcul et le stockage, ce qui vous aide à les faire évoluer indépendamment.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Données à la demande.*  SmartStore rapproche les données du calcul à la demande et offre une élasticité de calcul et de stockage ainsi qu'une rentabilité pour obtenir une conservation des données plus longue à grande échelle.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*Conforme à l'API AWS S3.*  SmartStore utilise l'API AWS S3 pour communiquer avec le stockage de restauration, qui est un magasin d'objets compatible AWS S3 et S3 API tel que StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Réduit les besoins et les coûts de stockage.*  SmartStore réduit les besoins de stockage des données anciennes (chaudes/froides).  Une seule copie des données est nécessaire, car le stockage NetApp assure la protection des données et prend en charge les pannes et la haute disponibilité.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Panne matérielle.*  Une défaillance de nœud dans un déploiement SmartStore ne rend pas les données inaccessibles et permet une récupération de l'indexeur beaucoup plus rapide en cas de défaillance matérielle ou de déséquilibre des données.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Cache sensible aux applications et aux données.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Ajoutez-supprimez des indexeurs et configurez-désinstallez des clusters à la demande.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">Le niveau de stockage n’est plus lié au matériel.</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">La solution permet d'ajouter des ressources de calcul, de stockage à chaud ou S3 pour répondre à la demande croissante en termes de nombre d'utilisateurs ou de taux d'ingestion sur des déploiements mono et multi-sites.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">Avantages de cette solution</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Performance.*  La combinaison de Splunk SmartStore et de NetApp StorageGRID permet une migration rapide des données entre les buckets chauds et les buckets tièdes à l'aide du stockage d'objets.  StorageGRID dynamise le processus de migration en offrant des performances rapides pour les charges de travail d'objets volumineux.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Prêt pour le multisite.*  L'architecture distribuée StorageGRID permet à Splunk SmartStore d'étendre les déploiements sur des sites uniques et multiples via un espace de noms global unique où les données sont accessibles depuis n'importe quel site, quel que soit l'endroit où se trouvent les données.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Évolutivité améliorée.*  Faites évoluer les ressources de stockage indépendamment des ressources de calcul pour répondre aux besoins et aux demandes en constante évolution de votre environnement Splunk, offrant ainsi un coût total de possession amélioré.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacité.*  Répondez aux volumes en croissance rapide dans le déploiement de Splunk avec StorageGRID en faisant évoluer un seul espace de noms à plus de 560 Po.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilité des données.*  Optimisez la disponibilité des données, les performances, la géodistribution, la conservation, la protection et les coûts de stockage grâce à des politiques basées sur les métadonnées qui peuvent s'ajuster de manière dynamique à mesure que la valeur commerciale de vos données évolue.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">directives fournies par Splunk</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">Augmentez les performances avec le cache SmartStore, qui est un composant de l'indexeur qui gère le transfert des copies de bucket entre le stockage local (à chaud) et distant (à chaud).  Le dimensionnement de Splunk pour cette solution est basé sur le<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> .  La solution permet d'ajouter des ressources de calcul, de stockage à chaud ou S3 pour répondre à la demande croissante en termes de nombre d'utilisateurs ou de taux d'ingestion sur des déploiements mono et multi-sites.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Cette page décrit les composants utilisés pour compléter cette solution, notamment NetApp StorageGRID, Splunk Enterprise et Splunk SmartStore.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">Présentation de la solution</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID est une plate-forme de stockage d'objets hautes performances et rentable.  Il offre une gestion intelligente des données mondiales basée sur des politiques utilisant une architecture de grille distribuée basée sur des nœuds.  Il simplifie la gestion de pétaoctets de données non structurées et de milliards d'objets grâce à son espace de noms d'objets global omniprésent combiné à des fonctionnalités de gestion de données sophistiquées.  L'accès aux objets par appel unique s'étend sur plusieurs sites et simplifie les architectures à haute disponibilité tout en garantissant un accès continu aux objets, quelles que soient les pannes du site ou de l'infrastructure.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">La multilocation permet à plusieurs applications de données non structurées cloud et d'entreprise d'être gérées en toute sécurité au sein de la même grille, augmentant ainsi le retour sur investissement et les cas d'utilisation de StorageGRID.  Plusieurs niveaux de service peuvent être créés avec des politiques de cycle de vie d'objets basées sur les métadonnées, optimisant la durabilité, la protection, les performances et la localité dans plusieurs zones géographiques.  Les utilisateurs peuvent ajuster les politiques et réaligner le paysage des données de manière non perturbatrice à mesure que leurs besoins évoluent.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore exploite StorageGRID comme niveau de stockage à distance et permet aux clients de déployer plusieurs sites géographiquement répartis pour une disponibilité et une durabilité robustes, présentées sous la forme d'un espace de noms d'objet unique.  Cela permet à Splunk SmartStore de tirer parti des hautes performances, de la capacité dense et de la capacité de StorageGRID à évoluer vers des centaines de nœuds sur plusieurs sites physiques à l'aide d'une seule URL pour interagir avec les objets.  Cette URL unique permet également d'étendre le stockage, de mettre à niveau et de réparer sans interruption, même au-delà d'un seul site.  Le moteur de politique de gestion des données unique de StorageGRID offre des niveaux optimisés de performances et de durabilité ainsi que le respect des exigences de localisation des données.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, leader dans la collecte et l'analyse de données générées par des machines, contribue à simplifier et à moderniser l'informatique grâce à ses capacités d'analyse opérationnelle.  Il s'étend également aux cas d'utilisation de l'analyse commerciale, de la sécurité et de l'IoT.  Le stockage est un élément essentiel pour un déploiement réussi du logiciel Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Les données générées par machine constituent le type de big data qui connaît la croissance la plus rapide.  Le format est imprévisible et provient de nombreuses sources différentes, souvent à des tarifs élevés et en grands volumes.  Ces caractéristiques de charge de travail sont souvent appelées échappement numérique.  Splunk SmartStore permet de donner un sens à ces données et fournit une hiérarchisation intelligente des données pour un placement optimisé des données chaudes et tièdes sur le niveau de stockage le plus rentable.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore est une fonctionnalité d'indexation qui utilise le stockage d'objets (également appelé stockage distant ou niveaux de stockage distants) tel que StorageGRID pour stocker des données chaudes à l'aide du protocole S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">À mesure que le volume de données d’un déploiement augmente, la demande de stockage dépasse généralement la demande de ressources informatiques.  SmartStore vous permet de gérer de manière rentable le stockage de votre indexeur et vos ressources de calcul en mettant à l'échelle le calcul et le stockage séparément.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore introduit un niveau de stockage à distance, utilisant le protocole S3, et un gestionnaire de cache.  Ces fonctionnalités permettent aux données de résider localement sur des indexeurs ou sur un stockage distant.  Le gestionnaire de cache, qui réside sur l'indexeur, gère le déplacement des données entre l'indexeur et le niveau de stockage distant.  Les données sont stockées dans des buckets (chauds et tièdes) avec les métadonnées des buckets.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Avec SmartStore, vous pouvez réduire l'empreinte de stockage de l'indexeur au minimum et choisir des ressources de calcul optimisées pour les E/S, car la plupart des données résident sur le niveau de stockage distant.  L'indexeur maintient un cache local, représentant la quantité minimale de données nécessaire pour renvoyer les résultats demandés et prédits.  Le cache local contient des buckets chauds, des copies de buckets chauds participant à des recherches actives ou récentes et des métadonnées de bucket.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore avec StorageGRID permet aux clients de faire évoluer progressivement l'environnement avec un stockage à distance hautes performances et rentable tout en offrant un degré élevé d'élasticité à la solution globale.  Cela permet aux clients d'ajouter n'importe quel composant (stockage à chaud et/ou stockage S3 chaud) dans n'importe quelle quantité à tout moment, qu'ils aient besoin de plus d'indexeurs, de modifier la conservation des données ou d'augmenter le taux d'ingestion sans aucune interruption.</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID dispose d'une grande variété de fonctionnalités que les utilisateurs peuvent exploiter et personnaliser pour leur environnement en constante évolution.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Fonctionnalités flexibles de StorageGRID pour Splunk SmartStore</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID dispose d'une grande variété de fonctionnalités que les utilisateurs peuvent exploiter et personnaliser pour leur environnement en constante évolution.  Du déploiement à la mise à l'échelle de votre Splunk SmartStore, votre environnement exige une adoption rapide des changements et ne doit pas perturber Splunk.  Les politiques de gestion des données flexibles (ILM) et les classificateurs de trafic (QoS) de StorageGRID vous permettent de planifier et de vous adapter à votre environnement.</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager est l'interface graphique basée sur un navigateur qui vous permet de configurer, de gérer et de surveiller votre système StorageGRID sur des emplacements distribués à l'échelle mondiale dans un seul volet de verre, comme illustré dans l'image suivante.</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Effectuez les tâches suivantes avec l’interface Grid Manager :</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Application NetApp StorageGRID pour Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">L'application NetApp StorageGRID pour Splunk est une application spécifique à Splunk Enterprise.  Cette application fonctionne en conjonction avec le module complémentaire NetApp StorageGRID pour Splunk.  Il offre une visibilité sur l'état de StorageGRID , les informations d'utilisation du compte, les détails de l'audit de sécurité, l'utilisation et la surveillance des ressources, etc.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">L'image suivante montre l'application StorageGRID pour Splunk.</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Politiques ILM</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID dispose de politiques de gestion des données flexibles qui incluent la conservation de plusieurs copies de vos objets et l'utilisation de schémas EC (codage d'effacement) tels que 2+1 et 4+2 (et bien d'autres) pour stocker vos objets en fonction des exigences spécifiques de performances et de protection des données.  À mesure que les charges de travail et les exigences évoluent au fil du temps, il est courant que les politiques ILM doivent également évoluer au fil du temps.  La modification des politiques ILM est une fonctionnalité essentielle, permettant aux clients de StorageGRID de s'adapter rapidement et facilement à leur environnement en constante évolution.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID adapte les performances en ajoutant davantage de nœuds, qui peuvent être des machines virtuelles, des appareils bare metal ou des appliances spécialement conçues comme les SG5712, SG5760, SG6060 ou SGF6024.  Lors de nos tests, nous avons dépassé les exigences de performances clés de SmartStore avec une grille à trois nœuds de taille minimale en utilisant l'appliance SG6060.  À mesure que les clients font évoluer leur infrastructure Splunk avec des indexeurs supplémentaires, ils peuvent ajouter davantage de nœuds de stockage pour augmenter les performances et la capacité.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Configuration de l'équilibreur de charge et du point de terminaison</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Les nœuds d'administration de StorageGRID fournissent l'interface utilisateur de Grid Manager et le point de terminaison de l'API REST pour afficher, configurer et gérer votre système StorageGRID , ainsi que des journaux d'audit pour suivre l'activité du système.  Pour fournir un point de terminaison S3 hautement disponible pour le stockage à distance Splunk SmartStore, nous avons implémenté l'équilibreur de charge StorageGRID , qui s'exécute en tant que service sur les nœuds d'administration et les nœuds de passerelle.  De plus, l'équilibreur de charge gère également le trafic local et communique avec le GSLB (Global Server Load Balancing) pour faciliter la reprise après sinistre.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Pour améliorer davantage la configuration des points de terminaison, StorageGRID fournit des stratégies de classification du trafic intégrées au nœud d'administration, vous permet de surveiller le trafic de votre charge de travail et d'appliquer diverses limites de qualité de service (QoS) à vos charges de travail.  Les stratégies de classification du trafic sont appliquées aux points de terminaison sur le service StorageGRID Load Balancer pour les nœuds de passerelle et les nœuds d'administration.  Ces politiques peuvent aider à limiter et à surveiller le trafic.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">À mesure que les clients réalisent la puissance et la facilité d’utilisation de l’analyse de données Splunk, ils souhaitent naturellement indexer une quantité toujours croissante de données.  À mesure que la quantité de données augmente, l’infrastructure de calcul et de stockage nécessaire pour les gérer augmente également.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Hiérarchisation intelligente et économies de coûts</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">À mesure que les clients réalisent la puissance et la facilité d’utilisation de l’analyse de données Splunk, ils souhaitent naturellement indexer une quantité toujours croissante de données.  À mesure que la quantité de données augmente, l’infrastructure de calcul et de stockage nécessaire pour les gérer augmente également.  Étant donné que les données plus anciennes sont référencées moins fréquemment, engager la même quantité de ressources de calcul et consommer un stockage primaire coûteux devient de plus en plus inefficace.  Pour fonctionner à grande échelle, les clients bénéficient du déplacement des données chaudes vers un niveau plus rentable, libérant ainsi du calcul et du stockage principal pour les données chaudes.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore avec StorageGRID offre aux organisations une solution évolutive, performante et rentable.  Étant donné que SmartStore est sensible aux données, il évalue automatiquement les modèles d'accès aux données pour déterminer quelles données doivent être accessibles pour l'analyse en temps réel (données chaudes) et quelles données doivent résider dans un stockage à long terme à moindre coût (données chaudes).  SmartStore utilise l'API AWS S3 standard de l'industrie de manière dynamique et intelligente, en plaçant les données dans le stockage S3 fourni par StorageGRID.  L'architecture évolutive flexible de StorageGRID permet au niveau de données chaudes de croître de manière rentable selon les besoins.  L'architecture basée sur les nœuds de StorageGRID garantit que les exigences de performances et de coûts sont satisfaites de manière optimale.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">L'image suivante illustre la hiérarchisation de Splunk et StorageGRID .</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">La combinaison leader du secteur de Splunk SmartStore avec NetApp StorageGRID offre les avantages d'une architecture découplée via une solution complète.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623 : NetApp E-Series E5700 et Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 décrit l'architecture intégrée de la conception NetApp E-Series et Splunk.  Optimisée pour l'équilibre du stockage des nœuds, la fiabilité, les performances, la capacité de stockage et la densité, cette conception utilise le modèle de nœud d'index clusterisé Splunk, avec une évolutivité plus élevée et un coût total de possession plus faible.  Le découplage du stockage du calcul offre la possibilité de mettre à l'échelle chacun séparément, ce qui permet d'économiser le coût de surprovisionnement de l'un ou de l'autre.  De plus, ce document résume les résultats des tests de performances obtenus à partir d'un outil de simulation d'événements de journal de machine Splunk.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">Fonctionnalités d'IA NetApp qui permettent une gestion et un déplacement transparents des données dans le pipeline d'IA pour la formation, le recyclage, le réglage fin, l'inférence et la surveillance des modèles d'IA génératifs.</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">IA générative et valeur NetApp</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">La demande d’intelligence artificielle générative (IA) entraîne des bouleversements dans tous les secteurs, améliorant la créativité des entreprises et l’innovation des produits.</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">De nombreuses organisations utilisent l’IA générative pour créer de nouvelles fonctionnalités de produits, améliorer la productivité de l’ingénierie et prototyper des applications basées sur l’IA qui offrent de meilleurs résultats et expériences client.  L'IA générative telle que les transformateurs pré-entraînés génératifs (GPT) utilise des réseaux neuronaux pour créer de nouveaux contenus, aussi divers que du texte, de l'audio et de la vidéo.  Compte tenu de l’échelle extrême et des ensembles de données massifs impliqués dans les grands modèles linguistiques (LLM), il est essentiel de concevoir une infrastructure d’IA robuste qui tire parti des fonctionnalités de stockage de données convaincantes des options de déploiement sur site, hybrides et multicloud et réduit les risques associés à la mobilité des données, à la protection des données et à la gouvernance avant que les entreprises puissent concevoir des solutions d’IA.  Cet article décrit ces considérations et les fonctionnalités NetApp AI correspondantes qui permettent une gestion transparente des données et un déplacement des données à travers le pipeline de données IA pour la formation, le recyclage, le réglage fin et l'inférence des modèles d'IA génératifs.</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">Résumé exécutif</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">Plus récemment, après le lancement de ChatGPT, un spin-off de GPT-3 en novembre 2022, de nouveaux outils d'IA utilisés pour générer du texte, du code, des images ou même des protéines thérapeutiques en réponse aux invites des utilisateurs ont acquis une renommée significative.  Cela indique que les utilisateurs peuvent faire une demande en utilisant le langage naturel et que l'IA interprétera et générera du texte, tel que des articles d'actualité ou des descriptions de produits qui reflètent la demande de l'utilisateur ou produiront du code, de la musique, de la parole, des effets visuels et des ressources 3D à l'aide d'algorithmes formés sur des données déjà existantes.  En conséquence, des expressions telles que « diffusion stable », « hallucinations », « ingénierie rapide » et « alignement des valeurs » apparaissent rapidement dans la conception des systèmes d’IA.  Ces modèles d'apprentissage automatique (ML) auto-supervisés ou semi-supervisés deviennent largement disponibles en tant que modèles de base pré-entraînés (FM) via des fournisseurs de services cloud et d'autres fournisseurs d'IA, qui sont adoptés par divers établissements commerciaux dans tous les secteurs pour une large gamme de tâches de traitement du langage naturel (NLP) en aval.  Comme l’affirment des cabinets d’analyse de recherche comme McKinsey : « L’impact de l’IA générative sur la productivité pourrait ajouter des milliers de milliards de dollars de valeur à l’économie mondiale. »  Alors que les entreprises réinventent l’IA en tant que partenaires de réflexion des humains et que les FM élargissent simultanément ce que les entreprises et les institutions peuvent faire avec l’IA générative, les opportunités de gérer des volumes massifs de données continueront de croître.  Ce document présente des informations introductives sur l’IA générative et les concepts de conception relatifs aux fonctionnalités NetApp qui apportent de la valeur aux clients NetApp , à la fois sur site et dans des environnements hybrides ou multicloud.</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">Qu'est-ce que l'IA générative ?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">L’IA générative change la façon dont nous créons du contenu, générons de nouveaux concepts de conception et explorons de nouvelles compositions.  Il illustre les cadres de réseaux neuronaux tels que le réseau antagoniste génératif (GAN), les autoencodeurs variationnels (VAE) et les transformateurs pré-entraînés génératifs (GPT), qui peuvent générer du nouveau contenu comme du texte, du code, des images, de l'audio, de la vidéo et des données synthétiques.  Les modèles basés sur des transformateurs tels que Chat-GPT d'OpenAI, Bard de Google, BLOOM de Hugging Face et LLaMA de Meta sont devenus la technologie fondamentale qui sous-tend de nombreuses avancées dans les grands modèles linguistiques.  De même, Dall-E d'OpenAI, CM3leon de Meta et Imagen de Google sont des exemples de modèles de diffusion de texte en image qui offrent aux clients un degré de photoréalisme sans précédent pour créer de nouvelles images complexes à partir de zéro ou modifier des images existantes pour générer des images contextuelles de haute qualité en utilisant l'augmentation de l'ensemble de données et la synthèse de texte en image reliant la sémantique textuelle et visuelle.  Les artistes numériques commencent à appliquer une combinaison de technologies de rendu comme NeRF (Neural Radiance Field) avec l'IA générative pour convertir des images 2D statiques en scènes 3D immersives.  En général, les LLM sont largement caractérisés par quatre paramètres : (1) la taille du modèle (généralement en milliards de paramètres) ; (2) la taille de l'ensemble de données de formation ; (3) le coût de la formation et (4) les performances du modèle après la formation.  Les LLM se répartissent également principalement en trois architectures de transformateurs.  (i) Modèles à encodeur uniquement.  Par exemple BERT (Google, 2018) ; (ii) Modèles encodeur-décodeur, par exemple BART (Meta, 2020) et (iii) Modèles décodeur uniquement.  Par exemple LLaMA (Meta, 2023), PaLM-E (Google, 2023).  En fonction des besoins de l'entreprise, quelle que soit l'architecture choisie par l'entreprise, le nombre de paramètres de modèle (N) et le nombre de jetons (D) dans l'ensemble de données de formation déterminent généralement le coût de base de la formation (pré-formation) ou du réglage fin d'un LLM.</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">Cas d'utilisation en entreprise et tâches NLP en aval</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">Les entreprises de tous les secteurs découvrent de plus en plus le potentiel de l’IA pour extraire et produire de nouvelles formes de valeur à partir de données existantes pour les opérations commerciales, les ventes, le marketing et les services juridiques.  Selon les informations de marché d'IDC (International Data Corporation) sur les cas d'utilisation et les investissements mondiaux en matière d'IA générative, la gestion des connaissances dans le développement de logiciels et la conception de produits sera la plus impactée, suivie de la création de scénarios pour le marketing et de la génération de code pour les développeurs.  Dans le domaine de la santé, les organismes de recherche clinique innovent en médecine.  Les modèles pré-entraînés comme ProteinBERT intègrent des annotations Gene Ontology (GO) pour concevoir rapidement des structures protéiques pour les médicaments médicaux, ce qui représente une étape importante dans la découverte de médicaments, la bioinformatique et la biologie moléculaire.  Des entreprises de biotechnologie ont lancé des essais sur l'homme pour la médecine générative découverte par l'IA, qui vise à traiter des maladies comme la fibrose pulmonaire (FPI), une maladie pulmonaire qui provoque des cicatrices irréversibles du tissu pulmonaire.</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">Figure 1 : Cas d'utilisation de l'IA générative</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">L’augmentation de l’adoption de l’automatisation, induite par l’IA générative, modifie également l’offre et la demande d’activités professionnelles pour de nombreuses professions.  Selon McKinsey, le marché du travail américain (diagramme ci-dessous) a connu une transition rapide, qui ne peut que se poursuivre si l’on prend en compte l’impact de l’IA.</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">Source : McKinsey &amp; Company</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">Figure 2 : Source : McKinsey &amp;amp; Company</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">Rôle du stockage dans l'IA générative</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 Mo</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">Les LLM s’appuient en grande partie sur l’apprentissage profond, les GPU et le calcul.  Cependant, lorsque la mémoire tampon du GPU est pleine, les données doivent être écrites rapidement sur le stockage.  Alors que certains modèles d’IA sont suffisamment petits pour s’exécuter en mémoire, les LLM nécessitent des IOPS élevées et un stockage à haut débit pour fournir un accès rapide à de grands ensembles de données, en particulier s’il s’agit de milliards de jetons ou de millions d’images.  Pour une exigence de mémoire GPU typique d'un LLM, la mémoire nécessaire pour entraîner un modèle avec 1 milliard de paramètres pourrait aller jusqu'à 80 Go avec une précision totale de 32 bits.  Dans ce cas, le LLaMA 2 de Meta, une famille de LLM dont l'échelle varie de 7 à 70 milliards de paramètres, peut nécessiter 70x80, environ 5600 Go ou 5,6 To de RAM GPU.  De plus, la quantité de mémoire dont vous avez besoin est directement proportionnelle au nombre maximal de jetons que vous souhaitez générer.  Par exemple, si vous souhaitez générer des sorties allant jusqu'à 512 jetons (environ 380 mots), vous avez besoin<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> .  Cela peut sembler sans importance, mais si vous souhaitez exécuter des lots plus importants, cela commence à s’accumuler.  Par conséquent, il est très coûteux pour les organisations de former ou d’affiner les LLM en mémoire, faisant ainsi du stockage une pierre angulaire de l’IA générative.</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">Trois approches principales pour les LLM</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">Harvard Business Review</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">Pour la plupart des entreprises, sur la base des tendances actuelles, l’approche de déploiement des LLM peut être condensée en 3 scénarios de base.  Comme décrit dans un récent<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block> article : (1) Former (pré-former) un LLM à partir de zéro – coûteux et nécessite des compétences expertes en IA/ML ; (2) Ajuster un modèle de base avec des données d'entreprise – complexe, mais faisable ; (3) Utiliser la génération augmentée par récupération (RAG) pour interroger les référentiels de documents, les API et les bases de données vectorielles qui contiennent des données d'entreprise.  Chacune d’entre elles nécessite des compromis entre l’effort, la vitesse d’itération, la rentabilité et la précision du modèle dans leurs implémentations, utilisées pour résoudre différents types de problèmes (diagramme ci-dessous).</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">Figure 3 : Types de problèmes</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">Modèles de fondation</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">Un modèle de fondation (FM), également connu sous le nom de modèle de base, est un grand modèle d'IA (LLM) formé sur de grandes quantités de données non étiquetées, utilisant l'auto-supervision à grande échelle, généralement adapté à une large gamme de tâches NLP en aval.  Étant donné que les données de formation ne sont pas étiquetées par des humains, le modèle émerge plutôt que d’être explicitement codé.  Cela signifie que le modèle peut générer ses propres histoires ou son propre récit sans être explicitement programmé pour le faire.  Une caractéristique importante de la FM est donc l’homogénéisation, ce qui signifie que la même méthode est utilisée dans de nombreux domaines.  Cependant, grâce aux techniques de personnalisation et de réglage fin, les FM intégrés aux produits apparaissant de nos jours sont non seulement efficaces pour générer du texte, du texte en images et du texte en code, mais également pour expliquer des tâches spécifiques à un domaine ou déboguer du code.  Par exemple, des FM comme Codex d'OpenAI ou Code Llama de Meta peuvent générer du code dans plusieurs langages de programmation en fonction des descriptions en langage naturel d'une tâche de programmation.  Ces modèles maîtrisent plus d’une douzaine de langages de programmation, notamment Python, C#, JavaScript, Perl, Ruby et SQL.  Ils comprennent l'intention de l'utilisateur et génèrent un code spécifique qui accomplit la tâche souhaitée, utile pour le développement de logiciels, l'optimisation du code et l'automatisation des tâches de programmation.</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">Réglage fin, spécificité du domaine et recyclage</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Le lama de Meta 2</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">Source : Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">Ingénierie rapide et inférence</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">L'ingénierie rapide fait référence aux méthodes efficaces permettant de communiquer avec les LLM pour effectuer les tâches souhaitées sans mettre à jour les poids du modèle.  Aussi important que soit l’entraînement et le réglage fin des modèles d’IA pour les applications PNL, l’inférence est tout aussi importante, lorsque les modèles entraînés répondent aux invites de l’utilisateur.  Les exigences système pour l'inférence sont généralement beaucoup plus axées sur les performances de lecture du système de stockage d'IA qui alimente les données des LLM vers les GPU, car il doit être capable d'appliquer des milliards de paramètres de modèle stockés pour produire la meilleure réponse.</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps, surveillance des modèles et magasins de vecteurs</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">Tout comme les opérations d'apprentissage automatique traditionnelles (MLOps), les opérations de modèles de langage volumineux (LLMOps) nécessitent également la collaboration de scientifiques des données et d'ingénieurs DevOps avec des outils et des meilleures pratiques pour la gestion des LLM dans les environnements de production.  Cependant, le flux de travail et la pile technologique des LLM peuvent varier de certaines manières.  Par exemple, les pipelines LLM créés à l'aide de frameworks tels que LangChain enchaînent plusieurs appels d'API LLM vers des points de terminaison d'intégration externes tels que des magasins vectoriels ou des bases de données vectorielles.  L'utilisation d'un point de terminaison d'intégration et d'un magasin vectoriel pour les connecteurs en aval (comme pour une base de données vectorielle) représente une évolution significative dans la manière dont les données sont stockées et consultées.  Contrairement aux modèles ML traditionnels qui sont développés à partir de zéro, les LLM s'appuient souvent sur l'apprentissage par transfert, car ces modèles commencent avec des FM qui sont affinés avec de nouvelles données pour améliorer les performances dans un domaine plus spécifique.  Il est donc crucial que les LLMOps fournissent des capacités de gestion des risques et de surveillance de la dégradation des modèles.</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">Risques et éthique à l'ère de l'IA générative</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">« ChatGPT – C'est astucieux mais ça continue à dire des bêtises. » – MIT Tech Review.  Le principe du « garbage in » et du « garbage out » a toujours été un défi en informatique.  La seule différence avec l’IA générative est qu’elle excelle à rendre les déchets hautement crédibles, ce qui conduit à des résultats inexacts.  Les LLM ont tendance à inventer des faits pour s'adapter au récit qu'ils construisent.  Par conséquent, les entreprises qui voient l’IA générative comme une excellente opportunité de réduire leurs coûts avec des équivalents IA doivent détecter efficacement les deep fakes, réduire les biais et diminuer les risques pour maintenir les systèmes honnêtes et éthiques.  Un pipeline de données fluide doté d'une infrastructure d'IA robuste qui prend en charge la mobilité des données, la qualité des données, la gouvernance des données et la protection des données via un cryptage de bout en bout et des garde-fous d'IA est essentiel à la conception de modèles d'IA génératifs responsables et explicables.</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">Scénario client et NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">Figure 3 : Flux de travail d'apprentissage automatique/modèle de langage volumineux</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*Sommes-nous en train de nous entraîner ou de peaufiner ?*  La question de savoir s'il faut (a) former un modèle LLM à partir de zéro, affiner un FM pré-entraîné ou utiliser RAG pour récupérer des données à partir de référentiels de documents en dehors d'un modèle de base et augmenter les invites, et (b) soit en exploitant des LLM open source (par exemple, Llama 2) ou des FM propriétaires (par exemple, ChatGPT, Bard, AWS Bedrock) est une décision stratégique pour les organisations.  Chaque approche présente un compromis entre rentabilité, gravité des données, opérations, précision du modèle et gestion des LLM.</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">En tant qu'entreprise, NetApp intègre l'IA en interne dans sa culture de travail et dans son approche de la conception et de l'ingénierie des produits.  Par exemple, la protection autonome contre les ransomwares de NetApp est construite à l’aide de l’IA et de l’apprentissage automatique.  Il permet une détection précoce des anomalies du système de fichiers pour aider à identifier les menaces avant qu'elles n'affectent les opérations.  Deuxièmement, NetApp utilise l’IA prédictive pour ses opérations commerciales telles que les prévisions de ventes et d’inventaire et les chatbots pour aider les clients dans les services d’assistance produit du centre d’appels, les spécifications techniques, la garantie, les manuels de service, etc.  Troisièmement, NetApp apporte de la valeur client au pipeline de données d'IA et au flux de travail ML/LLM via des produits et des solutions au service des clients qui créent des solutions d'IA prédictives telles que la prévision de la demande, l'imagerie médicale, l'analyse des sentiments et des solutions d'IA génératives comme les GAN pour la détection d'anomalies d'images industrielles dans le secteur manufacturier et la détection de la lutte contre le blanchiment d'argent et de la fraude dans les services bancaires et financiers avec des produits et des fonctionnalités NetApp tels que NetApp ONTAP AI, NetApp SnapMirror et NetApp FlexCache.</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">Capacités NetApp</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">Le mouvement et la gestion des données dans les applications d'IA générative telles que le chatbot, la génération de code, la génération d'images ou l'expression de modèles de génome peuvent s'étendre à l'écosystème périphérique, au centre de données privé et à l'écosystème multicloud hybride.  Par exemple, un robot IA en temps réel aidant un passager à surclasser son billet d'avion en classe affaires à partir d'une application utilisateur final exposée via des API de modèles pré-entraînés tels que ChatGPT ne peut pas accomplir cette tâche par lui-même puisque les informations sur le passager ne sont pas accessibles au public sur Internet.  L'API nécessite l'accès aux informations personnelles du passager et aux informations sur le billet de la compagnie aérienne qui peuvent exister dans un écosystème hybride ou multicloud.  Un scénario similaire pourrait s'appliquer aux scientifiques partageant une molécule de médicament et des données de patients via une application d'utilisateur final qui utilise des LLM pour réaliser des essais cliniques dans le cadre de la découverte de médicaments impliquant un à plusieurs établissements de recherche biomédicale.  Les données sensibles transmises aux FM ou aux LLM peuvent inclure des informations personnelles identifiables, des informations financières, des informations sur la santé, des données biométriques, des données de localisation, des données de communication, des données de comportement en ligne et des informations juridiques.  Dans un tel cas de rendu en temps réel, d'exécution rapide et d'inférence de périphérie, il y a un mouvement de données de l'application de l'utilisateur final vers les points de terminaison de stockage via des modèles LLM open source ou propriétaires vers un centre de données sur site ou des plateformes de cloud public.  Dans tous ces scénarios, la mobilité et la protection des données sont cruciales pour les opérations d’IA impliquant des LLM qui s’appuient sur de grands ensembles de données de formation et sur le mouvement de ces données.</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">Figure 4 : IA générative - Pipeline de données LLM</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">Figure 4 : Pipeline de données génératif AI-LLM</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">Le portefeuille d'infrastructures de stockage, de données et de services cloud de NetApp est alimenté par un logiciel de gestion de données intelligent.</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*Préparation des données* : Le premier pilier de la pile technologique LLM est en grande partie inchangé par rapport à l'ancienne pile ML traditionnelle.  Le prétraitement des données dans le pipeline d’IA est nécessaire pour normaliser et nettoyer les données avant la formation ou le réglage fin.  Cette étape inclut des connecteurs pour ingérer des données où qu'elles résident sous la forme d'un niveau Amazon S3 ou dans des systèmes de stockage sur site tels qu'un magasin de fichiers ou un magasin d'objets comme NetApp StorageGRID.</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* est la technologie fondamentale qui sous-tend les solutions de stockage critiques de NetApp dans le centre de données et le cloud.  ONTAP inclut diverses fonctionnalités et capacités de gestion et de protection des données, notamment une protection automatique contre les ransomwares contre les cyberattaques, des fonctionnalités de transport de données intégrées et des capacités d'efficacité de stockage pour une gamme d'architectures sur site, hybrides, multiclouds dans des situations de stockage NAS, SAN, objet et défini par logiciel (SDS) des déploiements LLM.</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI* pour la formation de modèles d'apprentissage en profondeur.  NetApp ONTAP prend en charge le stockage direct GPU NVIDIA avec l'utilisation de NFS sur RDMA pour les clients NetApp avec cluster de stockage ONTAP et nœuds de calcul NVIDIA DGX.  Il offre des performances rentables pour lire et traiter les ensembles de données sources du stockage vers la mémoire à plusieurs reprises afin de favoriser l'intelligence, permettant aux organisations de bénéficier d'un accès à la formation, au réglage fin et à la mise à l'échelle des LLM.</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* est une fonctionnalité de mise en cache à distance qui simplifie la distribution de fichiers et met en cache uniquement les données lues activement.  Cela peut être utile pour la formation, le recyclage et le réglage fin du LLM, apportant de la valeur aux clients ayant des exigences commerciales telles que le rendu en temps réel et l'inférence LLM.</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* est une fonctionnalité ONTAP qui réplique les snapshots de volume entre deux systèmes ONTAP .  Cette fonctionnalité transfère de manière optimale les données en périphérie vers votre centre de données sur site ou vers le cloud.  SnapMirror peut être utilisé pour déplacer des données de manière sécurisée et efficace entre les clouds sur site et les clouds hyperscaler, lorsque les clients souhaitent développer une IA générative dans des clouds avec RAG contenant des données d'entreprise.  Il transfère efficacement uniquement les modifications, économisant ainsi la bande passante et accélérant la réplication, apportant ainsi des fonctionnalités essentielles de mobilité des données lors des opérations de formation, de recyclage et de réglage fin des FM ou des LLM.</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* apporte une capacité de disque immuable sur les systèmes de stockage basés sur ONTAP pour le contrôle de version des ensembles de données.  L'architecture microcore est conçue pour protéger les données client avec le moteur FPolicy Zero Trust.  NetApp garantit la disponibilité des données client en résistant aux attaques par déni de service (DoS) lorsqu'un attaquant interagit avec un LLM d'une manière particulièrement gourmande en ressources.</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* permet d'identifier, de cartographier et de classer les informations personnelles présentes dans les ensembles de données d'entreprise, d'appliquer des politiques, de répondre aux exigences de confidentialité sur site ou dans le cloud, d'améliorer la posture de sécurité et de se conformer aux réglementations.</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* Classification NetApp BlueXP*, optimisée par Cloud Data Sense.  Les clients peuvent automatiquement analyser, catégoriser et agir sur les données de l'ensemble du parc de données, détecter les risques de sécurité, optimiser le stockage et accélérer les déploiements cloud.  Il combine des services de stockage et de données via son plan de contrôle unifié. Les clients peuvent utiliser des instances GPU pour le calcul et des environnements multicloud hybrides pour la hiérarchisation du stockage à froid et pour les archives et les sauvegardes.</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* Dualité fichier-objet NetApp *.  NetApp ONTAP permet un accès à double protocole pour NFS et S3.  Avec cette solution, les clients peuvent accéder aux données NFS des blocs-notes Amazon AWS SageMaker via des buckets S3 de NetApp Cloud Volumes ONTAP.  Cela offre une flexibilité aux clients qui ont besoin d'un accès facile à des sources de données hétérogènes avec la possibilité de partager des données à partir de NFS et de S3.  Par exemple, le réglage fin des FM comme les modèles de génération de texte Llama 2 de Meta sur SageMaker avec accès aux buckets d'objets fichiers.</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">Le service * NetApp Cloud Sync* offre un moyen simple et sécurisé de migrer des données vers n'importe quelle cible, dans le cloud ou sur site.  Cloud Sync transfère et synchronise de manière transparente les données entre le stockage sur site ou dans le cloud, le NAS et les magasins d'objets.</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* est un logiciel client qui permet des migrations de données rapides et fiables de n'importe quel système vers NetApp et de NetApp vers NetApp .  XCP offre également la possibilité de déplacer efficacement des données en masse à partir des systèmes de fichiers Hadoop HDFS vers ONTAP NFS, S3 ou StorageGRID et les analyses de fichiers XCP offrent une visibilité sur le système de fichiers.</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* est une bibliothèque Python qui permet aux scientifiques des données, aux DevOps et aux ingénieurs de données d'effectuer facilement diverses tâches de gestion des données, telles que le provisionnement, le clonage ou la capture instantanée quasi instantanée d'un volume de données ou d'un espace de travail JupyterLab, soutenus par un stockage NetApp évolutif hautes performances.</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*Sécurité des produits NetApp*.  Les LLM peuvent révéler par inadvertance des données confidentielles dans leurs réponses, ce qui constitue une préoccupation pour les RSSI qui étudient les vulnérabilités associées aux applications d'IA exploitant les LLM.  Comme le souligne l'OWASP (Open Worldwide Application Security Project), les problèmes de sécurité tels que l'empoisonnement des données, la fuite de données, le déni de service et les injections rapides dans les LLM peuvent avoir un impact sur les entreprises en raison de l'exposition des données à des accès non autorisés au service des attaquants.  Les exigences de stockage des données doivent inclure des contrôles d’intégrité et des instantanés immuables pour les données structurées, semi-structurées et non structurées.  Les instantanés NetApp et SnapLock sont utilisés pour le contrôle de version des ensembles de données.  Il apporte un contrôle d'accès strict basé sur les rôles (RBAC), ainsi que des protocoles sécurisés et un cryptage standard du secteur pour sécuriser les données au repos et en transit.  Cloud Insights et Cloud Data Sense offrent ensemble des fonctionnalités pour vous aider à identifier de manière médico-légale la source de la menace et à hiérarchiser les données à restaurer.</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* ONTAP AI avec DGX BasePOD *</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">L'architecture de référence NetApp ONTAP AI avec NVIDIA DGX BasePOD est une architecture évolutive pour les charges de travail d'apprentissage automatique (ML) et d'intelligence artificielle (IA).  Pour la phase de formation critique des LLM, les données sont généralement copiées du stockage de données vers le cluster de formation à intervalles réguliers.  Les serveurs utilisés dans cette phase utilisent des GPU pour paralléliser les calculs, créant ainsi un énorme appétit pour les données.  Répondre aux besoins bruts en bande passante d'E/S est essentiel pour maintenir une utilisation élevée du GPU.</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI avec NVIDIA AI Enterprise*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise est une suite de logiciels d'IA et d'analyse de données cloud native de bout en bout, optimisée, certifiée et prise en charge par NVIDIA pour s'exécuter sur VMware vSphere avec les systèmes certifiés NVIDIA.  Ce logiciel facilite le déploiement, la gestion et la mise à l’échelle simples et rapides des charges de travail d’IA dans l’environnement cloud hybride moderne.  NVIDIA AI Enterprise, optimisé par NetApp et VMware, offre une gestion des charges de travail et des données d'IA de niveau entreprise dans un package simplifié et familier.</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*Plateformes Cloud 1P*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">Les offres de stockage cloud entièrement gérées sont disponibles nativement sur Microsoft Azure sous le nom d' Azure NetApp Files (ANF), sur AWS sous le nom d' Amazon FSx for NetApp ONTAP (FSx ONTAP) et sur Google sous le nom de Google Cloud NetApp Volumes (GNCV).  1P est un système de fichiers géré et hautes performances qui permet aux clients d'exécuter des charges de travail d'IA hautement disponibles avec une sécurité des données améliorée dans les clouds publics, pour affiner les LLM/FM avec des plates-formes ML natives du cloud comme AWS SageMaker, Azure-OpenAI Services et Vertex AI de Google.</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">Suite de solutions partenaires NetApp</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">En plus de ses principaux produits, technologies et capacités de données, NetApp collabore également étroitement avec un solide réseau de partenaires d'IA pour apporter une valeur ajoutée aux clients.</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* Les garde-fous NVIDIA * dans les systèmes d’IA servent de garanties pour garantir l’utilisation éthique et responsable des technologies d’IA.  Les développeurs d’IA peuvent choisir de définir le comportement des applications basées sur LLM sur des sujets spécifiques et les empêcher de s’engager dans des discussions sur des sujets indésirables.  Guardrails, une boîte à outils open source, offre la possibilité de connecter un LLM à d'autres services, de manière transparente et sécurisée, pour créer des systèmes conversationnels LLM fiables, sûrs et sécurisés.</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* fournit des outils polyvalents de niveau entreprise pour créer et produire une IA générative - rapide, sûre et économique, où que vous soyez dans votre parcours d'IA.  Avec la plateforme Enterprise MLOps de Domino, les scientifiques des données peuvent utiliser leurs outils préférés et toutes leurs données, former et déployer facilement des modèles n'importe où et gérer les risques et les coûts de manière efficace, le tout à partir d'un seul centre de contrôle.</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy pour Edge AI*.  NetApp et Modzy se sont associés pour fournir une IA à grande échelle à tout type de données, y compris les images, l'audio, le texte et les tableaux.  Modzy est une plateforme MLOps pour le déploiement, l'intégration et l'exécution de modèles d'IA, qui offre aux scientifiques des données les capacités de surveillance des modèles, de détection des dérives et d'explicabilité, avec une solution intégrée pour une inférence LLM transparente.</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* et NetApp se sont associés pour démontrer les capacités uniques de la solution NetApp ONTAP AI avec la plate-forme de gestion de cluster Run:AI pour simplifier l'orchestration des charges de travail d'IA.  Il divise et joint automatiquement les ressources GPU, conçues pour faire évoluer vos pipelines de traitement de données vers des centaines de machines avec des cadres d'intégration intégrés pour Spark, Ray, Dask et Rapids.</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">L’IA générative ne peut produire des résultats efficaces que lorsque le modèle est formé sur des volumes importants de données de qualité.  Bien que les LLM aient franchi des étapes remarquables, il est essentiel de reconnaître leurs limites, les défis de conception et les risques associés à la mobilité et à la qualité des données.  Les LLM s’appuient sur des ensembles de données de formation volumineux et disparates provenant de sources de données hétérogènes.  Les résultats inexacts ou biaisés générés par les modèles peuvent mettre en danger les entreprises et les consommateurs.  Ces risques peuvent correspondre à des contraintes pour les LLM émergeant potentiellement des défis de gestion des données associés à la qualité des données, à la sécurité des données et à la mobilité des données.  NetApp aide les organisations à faire face aux complexités créées par la croissance rapide des données, la mobilité des données, la gestion multicloud et l’adoption de l’IA.  Une infrastructure d’IA à grande échelle et une gestion efficace des données sont essentielles pour définir le succès des applications d’IA telles que l’IA générative.  Il est essentiel que les clients couvrent tous les scénarios de déploiement sans compromettre la capacité d’expansion selon les besoins des entreprises tout en maintenant la rentabilité, la gouvernance des données et les pratiques éthiques d’IA sous contrôle.  NetApp travaille constamment pour aider ses clients à simplifier et à accélérer leurs déploiements d’IA.</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN : NetApp AIPod avec Lenovo pour NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen, Abhinav Singh, Roney Daniel, NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">Cette architecture de référence associe des serveurs Lenovo ThinkSystem OVX certifiés NVIDIA, alimentés par des GPU NVIDIA L40S, à la mise en réseau NVIDIA Spectrum pour fournir une solution d'infrastructure optimale pour optimiser et déployer des LLM (modèles à grand langage).  L’objectif de ce document est de fournir des conseils relatifs au stockage d’une configuration OVX.  Cette plateforme est adaptée à diverses charges de travail d'IA générative, notamment RAG (Retrieval Augmented Generation), le réglage fin et la formation de modèles légers.</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN : Guide de conception NetApp AIPod avec Lenovo pour NVIDIA OVX</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod avec systèmes NVIDIA DGX - Architecture</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">Architecture de la solution NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX H100</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">Cette section se concentre sur l’architecture du NetApp AIPod avec les systèmes NVIDIA DGX.</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">NetApp AIPod avec systèmes DGX</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">Cette architecture de référence exploite des structures distinctes pour l'interconnexion des clusters de calcul et l'accès au stockage, avec une connectivité InfiniBand (IB) de 400 Gb/s entre les nœuds de calcul.  Le dessin ci-dessous montre la topologie globale de la solution NetApp AIPod avec les systèmes DGX H100.</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_Topologie de la solution NetApp AIpod_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Conception de réseau</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">Dans cette configuration, la structure du cluster de calcul utilise une paire de commutateurs IB QM9700 400 Gb/s, qui sont connectés ensemble pour une haute disponibilité.  Chaque système DGX H100 est connecté aux commutateurs à l'aide de huit connexions, avec des ports pairs connectés à un commutateur et des ports impairs connectés à l'autre commutateur.</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">Pour l'accès au système de stockage, la gestion en bande et l'accès client, une paire de commutateurs Ethernet SN4600 est utilisée.  Les commutateurs sont connectés avec des liaisons inter-commutateurs et configurés avec plusieurs VLAN pour isoler les différents types de trafic.  Le routage L3 de base est activé entre des VLAN spécifiques pour permettre plusieurs chemins entre les interfaces client et de stockage sur le même commutateur ainsi qu'entre les commutateurs pour une haute disponibilité.  Pour les déploiements plus importants, le réseau Ethernet peut être étendu à une configuration feuille-épine en ajoutant des paires de commutateurs supplémentaires pour les commutateurs de colonne vertébrale et des feuilles supplémentaires selon les besoins.</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">détails du déploiement</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">En plus de l'interconnexion informatique et des réseaux Ethernet haut débit, tous les périphériques physiques sont également connectés à un ou plusieurs commutateurs Ethernet SN2201 pour la gestion hors bande.  Veuillez consulter le<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> page pour plus d'informations sur la configuration du réseau.</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">Présentation de l'accès au stockage pour les systèmes DGX H100</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">Chaque système DGX H100 est équipé de deux adaptateurs ConnectX-7 à double port pour le trafic de gestion et de stockage, et pour cette solution, les deux ports de chaque carte sont connectés au même commutateur.  Un port de chaque carte est ensuite configuré dans une liaison LACP MLAG avec un port connecté à chaque commutateur, et les VLAN pour la gestion en bande, l'accès client et l'accès au stockage au niveau utilisateur sont hébergés sur cette liaison.</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">L'autre port de chaque carte est utilisé pour la connectivité aux systèmes de stockage AFF A90 et peut être utilisé dans plusieurs configurations en fonction des exigences de charge de travail.  Pour les configurations utilisant NFS sur RDMA pour prendre en charge NVIDIA Magnum IO GPUDirect Storage, les ports sont utilisés individuellement avec des adresses IP dans des VLAN distincts.  Pour les déploiements qui ne nécessitent pas RDMA, les interfaces de stockage peuvent également être configurées avec la liaison LACP pour offrir une haute disponibilité et une bande passante supplémentaire.  Avec ou sans RDMA, les clients peuvent monter le système de stockage à l'aide de NFS v4.1 pNFS et de la jonction de session pour permettre l'accès parallèle à tous les nœuds de stockage du cluster.  Veuillez consulter le<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> page pour plus d'informations sur la configuration du client.</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">Documentation NVIDIA BasePOD</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">Pour plus de détails sur la connectivité du système DGX H100, veuillez vous référer au<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">Conception du système de stockage</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">Chaque système de stockage AFF A90 est connecté à l'aide de six ports 200 GbE de chaque contrôleur.  Quatre ports de chaque contrôleur sont utilisés pour l'accès aux données de charge de travail à partir des systèmes DGX, et deux ports de chaque contrôleur sont configurés en tant que groupe d'interfaces LACP pour prendre en charge l'accès à partir des serveurs du plan de gestion pour les artefacts de gestion de cluster et les répertoires personnels des utilisateurs.  Tous les accès aux données du système de stockage sont fournis via NFS, avec une machine virtuelle de stockage (SVM) dédiée à l'accès à la charge de travail de l'IA et une SVM distincte dédiée aux utilisations de gestion des clusters.</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">Le SVM de gestion ne nécessite qu'un seul LIF, qui est hébergé sur les groupes d'interfaces à 2 ports configurés sur chaque contrôleur.  D'autres volumes FlexGroup sont provisionnés sur la SVM de gestion pour héberger des artefacts de gestion de cluster tels que des images de nœuds de cluster, des données historiques de surveillance du système et des répertoires personnels des utilisateurs finaux.  Le dessin ci-dessous montre la configuration logique du système de stockage.</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_Configuration logique du cluster de stockage NetApp A90_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">Serveurs de plan de gestion</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">Cette architecture de référence comprend également cinq serveurs basés sur CPU pour les utilisations du plan de gestion.  Deux de ces systèmes sont utilisés comme nœuds principaux pour NVIDIA Base Command Manager pour le déploiement et la gestion des clusters.  Les trois autres systèmes sont utilisés pour fournir des services de cluster supplémentaires tels que des nœuds maîtres Kubernetes ou des nœuds de connexion pour les déploiements utilisant Slurm pour la planification des tâches.  Les déploiements utilisant Kubernetes peuvent exploiter le pilote NetApp Trident CSI pour fournir des services de provisionnement et de données automatisés avec un stockage persistant pour les charges de travail de gestion et d'IA sur le système de stockage AFF A900 .</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">Chaque serveur est physiquement connecté aux commutateurs IB et aux commutateurs Ethernet pour permettre le déploiement et la gestion du cluster, et configuré avec des montages NFS sur le système de stockage via le SVM de gestion pour le stockage des artefacts de gestion du cluster comme décrit précédemment.</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod avec systèmes NVIDIA DGX : où trouver des informations supplémentaires ?</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX - Conclusion et informations complémentaires</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">Cette section inclut des références pour des informations supplémentaires sur les systèmes NetApp AIPod avec NVIDIA DGX.</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">L'architecture DGX BasePOD est une plate-forme d'apprentissage en profondeur de nouvelle génération qui nécessite des capacités de stockage et de gestion des données tout aussi avancées.  En combinant DGX BasePOD avec les systèmes NetApp AFF , l'architecture des systèmes NetApp AIPod avec DGX peut être mise en œuvre à presque toutes les échelles.  Associé à l'intégration cloud supérieure et aux capacités définies par logiciel de NetApp ONTAP, AFF permet une gamme complète de pipelines de données qui couvrent la périphérie, le cœur et le cloud pour des projets DL réussis.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">Informations supplémentaires</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">Pour en savoir plus sur les informations décrites dans ce document, veuillez vous référer aux documents et/ou sites Web suivants :</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Logiciel de gestion de données NetApp ONTAP — Bibliothèque d'informations ONTAP</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">Systèmes de stockage NetApp AFF A90</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">Informations sur NetApp ONTAP RDMA-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">Blog sur le stockage NetApp GPUDirect-</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">Systèmes NVIDIA DGX H100</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">Réseau NVIDIA</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">Stockage NVIDIA Magnum IO - GPUDirect</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">Commande de base NVIDIA</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">Gestionnaire de commandes de base NVIDIA</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI Enterprise</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">Ce document est le travail des équipes NetApp Solutions et ONTAP Engineering : David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar et Raghuram Sudhaakar.  Les auteurs souhaitent également remercier NVIDIA et l’équipe d’ingénierie NVIDIA DGX BasePOD pour leur soutien continu.</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod avec systèmes NVIDIA DGX - Déploiement</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX - Détails du déploiement</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">Cette section décrit les détails de déploiement utilisés lors de la validation de cette solution.  Les adresses IP utilisées sont des exemples et doivent être modifiées en fonction de l'environnement de déploiement.  Pour plus d'informations sur les commandes spécifiques utilisées dans la mise en œuvre de cette configuration, veuillez vous référer à la documentation produit appropriée.</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">Le diagramme ci-dessous présente des informations détaillées sur le réseau et la connectivité pour 1 système DGX H100 et 1 paire HA de contrôleurs AFF A90 .  Les instructions de déploiement dans les sections suivantes sont basées sur les détails de ce diagramme.</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">_Configuration du réseau NetApp AIpod_</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">Le tableau suivant présente des exemples d'affectations de câblage pour un maximum de 16 systèmes DGX et 2 paires AFF A90 HA.</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">Commutateur et port</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">Appareil</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">Port de l'appareil</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">ports 1 à 16 du commutateur 1</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 à -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0, emplacement 1 port 1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">ports 17-32 du commutateur 1</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1, emplacement 1 port 2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">ports 33-36 du commutateur 1</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 à -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">port e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">ports 37-40 du commutateur 1</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">port e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">ports 41-44 du commutateur 1</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">port e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">ports 57-64 du commutateur 1</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL vers switch2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">ports 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">commutateur 2 ports 1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0, emplacement 2 port 1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">commutateur 2 ports 17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1, emplacement 2 port 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">commutateur 2 ports 33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">port e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">commutateur 2 ports 37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">port e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">commutateur 2 ports 41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">port e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">commutateur 2 ports 57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL vers switch1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">Le tableau suivant présente les versions logicielles des différents composants utilisés dans cette validation.</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Version du logiciel</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">Commutateurs NVIDIA SN4600</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">Système NVIDIA DGX</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">Système d'exploitation DGX v6.2.1 (Ubuntu 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24,01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">Configuration du réseau de stockage</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">Documentation de NVIDIA Cumulus Linux</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">Cette section décrit les détails clés de la configuration du réseau de stockage Ethernet.  Pour plus d'informations sur la configuration du réseau informatique InfiniBand, veuillez consulter le<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .  Pour plus de détails sur la configuration du commutateur, veuillez vous référer au<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> .</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">Les étapes de base utilisées pour configurer les commutateurs SN4600 sont décrites ci-dessous.  Ce processus suppose que le câblage et la configuration de base du commutateur (adresse IP de gestion, licence, etc.) sont terminés.</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">Configurer la liaison ISL entre les commutateurs pour activer l'agrégation multi-liens (MLAG) et le trafic de basculement</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">Cette validation a utilisé 8 liens pour fournir une bande passante plus que suffisante pour la configuration de stockage testée</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">Pour des instructions spécifiques sur l'activation de MLAG, veuillez vous référer à la documentation de Cumulus Linux.</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">Configurer LACP MLAG pour chaque paire de ports client et de ports de stockage sur les deux commutateurs</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">port swp17 sur chaque commutateur pour DGX-H100-01 (enp170s0f1np1 et enp41s0f1np1), port swp18 pour DGX-H100-02, etc. (bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">port swp41 sur chaque commutateur pour AFF-A90-01 (e2a et e2b), port swp42 pour AFF-A90-02, etc. (bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv set interface bondX membre de liaison swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv set interface bondx bond mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">Ajoutez tous les ports et liaisons MLAG au domaine de pont par défaut</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv set int swp1-16,33-40 domaine de pont br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv set int bond1-20 domaine de pont br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">Activer RoCE sur chaque commutateur</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv set roce mode sans perte</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">Configurer les VLAN : 2 pour les ports clients, 2 pour les ports de stockage, 1 pour la gestion, 1 pour le commutateur L3 vers le commutateur</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">interrupteur 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 pour le routage du commutateur L3 vers le commutateur en cas de défaillance de la carte réseau client</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">VLAN 101 pour le port de stockage 1 sur chaque système DGX (enp170s0f0np0, slot1 port 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">VLAN 102 pour les ports e6a et e11a sur chaque contrôleur de stockage AFF A90</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 pour la gestion à l'aide des interfaces MLAG de chaque système DGX et contrôleur de stockage</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">interrupteur 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">VLAN 201 pour le port de stockage 2 sur chaque système DGX (enp41s0f0np0, slot2 port 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">VLAN 202 pour les ports e6b et e11b sur chaque contrôleur de stockage AFF A90</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">Attribuez des ports physiques à chaque VLAN selon le cas, par exemple des ports clients dans les VLAN clients et des ports de stockage dans les VLAN de stockage</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; domaine de pont br_default accès &lt;id vlan&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">Les ports MLAG doivent rester des ports de jonction pour activer plusieurs VLAN sur les interfaces liées selon les besoins.</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">Configurer les interfaces virtuelles de commutateur (SVI) sur chaque VLAN pour agir comme une passerelle et activer le routage L3</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv set int vlan3 adresse IP 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv set int vlan101 adresse IP 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv set int vlan102 adresse IP 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv set int vlan3 adresse IP 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv set int vlan201 adresse IP 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv set int vlan202 adresse IP 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">Créer des itinéraires statiques</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">Les routes statiques sont automatiquement créées pour les sous-réseaux sur le même commutateur</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">Des routes statiques supplémentaires sont nécessaires pour le routage de commutateur à commutateur en cas de défaillance d'une liaison client</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv set vrf routeur par défaut statique 100.127.128.0/17 via 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv set vrf routeur par défaut statique 100.127.0.0/17 via 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">Configuration du système de stockage</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">Documentation ONTAP</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">Cette section décrit les détails clés de la configuration du système de stockage A90 pour cette solution.  Pour plus de détails sur la configuration des systèmes ONTAP , veuillez vous référer au<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> .  Le schéma ci-dessous montre la configuration logique du système de stockage.</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">Les étapes de base utilisées pour configurer le système de stockage sont décrites ci-dessous.  Ce processus suppose que l’installation du cluster de stockage de base a été effectuée.</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">Configurez 1 agrégat sur chaque contrôleur avec toutes les partitions disponibles moins 1 de rechange</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;nœud&gt; -aggregate &lt;nœud&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">Configurer ifgrps sur chaque contrôleur</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">port net ifgrp create -node &lt;nœud&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">port réseau ifgrp add-port -node &lt;nœud&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;nœud&gt;:e2a,&lt;nœud&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">Configurer le port VLAN de gestion sur ifgrp sur chaque contrôleur</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">création d'un port réseau vlan -node aff-a90-01 -port a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">création d'un port réseau vlan -node aff-a90-02 -port a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">création d'un port réseau vlan -node aff-a90-03 -port a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">création d'un port réseau vlan -node aff-a90-04 -port a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">Créer des domaines de diffusion</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">domaine de diffusion créer -domaine de diffusion vlan21 -mtu 9000 -ports aff-a90-01:e6a,aff-a90-01:e11a,aff-a90-02:e6a,aff-a90-02:e11a,aff-a90-03:e6a,aff-a90-03:e11a,aff-a90-04:e6a,aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">domaine de diffusion créer -domaine de diffusion vlan22 -mtu 9000 -ports aaff-a90-01:e6b,aff-a90-01:e11b,aff-a90-02:e6b,aff-a90-02:e11b,aff-a90-03:e6b,aff-a90-03:e11b,aff-a90-04:e6b,aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">domaine de diffusion créer -domaine de diffusion vlan31 -mtu 9000 -ports aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">Créer une SVM de gestion *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">Configurer la gestion SVM</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">créer un LIF</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">créer des volumes FlexGroup</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">vol create -vserver basepod-mgmt -volume home -size 10T -auto-provision-as flexgroup -junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">vol create -vserver basepod-mgmt -volume cm -size 10T -auto-provision-as flexgroup -junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">créer une politique d'exportation</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">créer une règle de stratégie d'exportation -vserver basepod-mgmt -policy default -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">Créer des données SVM *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">Configurer les données SVM</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">configurer SVM pour la prise en charge RDMA</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs modifier -vserver basepod-data -rdma activé</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">créer des LIF</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -home-node aff-a90-02 -home-port e11a -address 100.127.102.108 -netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -home-node aff-a90-02 -home-port e11b -address 100.127.202.108 -netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">Configurer les LIF pour l'accès RDMA</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">Pour les déploiements avec ONTAP 9.15.1, la configuration RoCE QoS pour les informations physiques nécessite des commandes au niveau du système d'exploitation qui ne sont pas disponibles dans l'interface de ligne de commande ONTAP .  Veuillez contacter le support NetApp pour obtenir de l'aide sur la configuration des ports pour la prise en charge RoCE.  NFS sur RDMA fonctionne sans problème</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">À partir d' ONTAP 9.16.1, les interfaces physiques seront automatiquement configurées avec les paramètres appropriés pour la prise en charge RoCE de bout en bout.</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int modifier -vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">Configurer les paramètres NFS sur le SVM de données</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs modifier -vserver basepod-data -v4.1 activé -v4.1-pnfs activé -v4.1-trunking activé -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">Créer des volumes FlexGroup</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">vol create -vserver basepod-data -volume data -size 100T -auto-provision-as flexgroup -junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">Créer une politique d'exportation</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">créer une règle de politique d'exportation -vserver basepod-data -policy default -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">créer une règle de politique d'exportation -vserver basepod-data -policy default -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">créer des itinéraires</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">route ajouter -vserver basepod_data -destination 100.127.0.0/17 -gateway 100.127.102.1 métrique 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">route ajouter -vserver basepod_data -destination 100.127.0.0/17 -gateway 100.127.202.1 métrique 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">route ajouter -vserver basepod_data -destination 100.127.128.0/17 -gateway 100.127.202.1 métrique 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">route add -vserver basepod_data -destination 100.127.128.0/17 -gateway 100.127.102.1 metric 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">Configuration DGX H100 pour l'accès au stockage RoCE</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">Documentation BCM</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">Cette section décrit les détails clés de la configuration des systèmes DGX H100.  Bon nombre de ces éléments de configuration peuvent être inclus dans l’image du système d’exploitation déployée sur les systèmes DGX ou implémentés par Base Command Manager au démarrage.  Ils sont répertoriés ici à titre de référence. Pour plus d'informations sur la configuration des nœuds et des images logicielles dans BCM, veuillez consulter le<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> .</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">Installer des packages supplémentaires</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Installer les packages Python</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">paramiko</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">Reconfigurer dpkg après l'installation du package</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">Installer MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">Définir les valeurs mst pour le réglage des performances</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; set ADVANCED_PCI_SETTINGS=1 NOMBRE_DE_VFS=0 LECTURE_MAX_ACC_OUT=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">Réinitialiser les adaptateurs après avoir modifié les paramètres</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y réinitialiser</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">Définir MaxReadReq sur les périphériques PCI</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">Définir la taille du tampon annulaire RX et TX</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">Définir PFC et DSCP à l'aide de mlnx_qos</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">Définir les conditions de service pour le trafic RoCE sur les ports réseau</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">echo 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">Configurez chaque carte réseau de stockage avec une adresse IP sur le sous-réseau approprié</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 pour la carte réseau de stockage 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 pour le stockage NIC 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">Configurer les ports réseau en bande pour la liaison LACP (enp170s0f1np1,enp41s0f1np1)</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">configurer des routes statiques pour les chemins principaux et secondaires vers chaque sous-réseau de stockage</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">route add –net 100.127.0.0/17 gw 100.127.101.1 métrique 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">route add –net 100.127.0.0/17 gw 100.127.201.1 métrique 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">route add –net 100.127.128.0/17 gw 100.127.201.1 métrique 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">route ajouter –net 100.127.128.0/17 gw 100.127.101.1 métrique 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">Monter / volume d'accueil</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">mount -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">Monter /volume de données</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">Les options de montage suivantes ont été utilisées lors du montage du volume de données :</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # active pNFS pour l'accès parallèle à plusieurs nœuds de stockage</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # définit le protocole de transfert sur RDMA au lieu du protocole TCP par défaut</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # active la jonction de session NFS pour agréger la bande passante du port de stockage</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # améliore les performances d'écriture des écritures en mémoire tampon</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # définit la taille de transfert d'E/S à 256 Ko</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NetApp AIPod avec systèmes NVIDIA DGX - Composants matériels</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX - Composants matériels</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">Cette section se concentre sur les composants matériels du NetApp AIPod avec les systèmes NVIDIA DGX.</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">Systèmes de stockage NetApp AFF</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">Les systèmes de stockage de pointe NetApp AFF permettent aux services informatiques de répondre aux exigences de stockage de l'entreprise avec des performances de pointe, une flexibilité supérieure, une intégration cloud et une gestion des données de premier ordre.  Conçus spécifiquement pour le flash, les systèmes AFF aident à accélérer, gérer et protéger les données critiques de l'entreprise.</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">Systèmes de stockage AFF A90</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">Le logiciel de gestion de données NetApp AFF A90 optimisé par NetApp ONTAP offre une protection des données intégrée, des fonctionnalités anti-ransomware en option, ainsi que les hautes performances et la résilience requises pour prendre en charge les charges de travail commerciales les plus critiques.  Il élimine les perturbations des opérations critiques, minimise le réglage des performances et protège vos données contre les attaques de ransomware.  Il offre : • Des performances de pointe • Une sécurité des données sans compromis • Des mises à niveau simplifiées et non perturbatrices</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_Système de stockage NetApp AFF A90</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">Performances de pointe dans l'industrie</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">L' AFF A90 gère facilement les charges de travail de nouvelle génération telles que l'apprentissage en profondeur, l'IA et l'analyse à grande vitesse, ainsi que les bases de données d'entreprise traditionnelles telles qu'Oracle, SAP HANA, Microsoft SQL Server et les applications virtualisées.  Il permet aux applications stratégiques de fonctionner à une vitesse maximale avec jusqu'à 2,4 M IOPS par paire HA et une latence aussi faible que 100 µs, et augmente les performances jusqu'à 50 % par rapport aux modèles NetApp précédents.  Avec NFS sur RDMA, pNFS et Session Trunking, les clients peuvent atteindre le niveau élevé de performances réseau requis pour les applications de nouvelle génération en utilisant l'infrastructure réseau du centre de données existante.  Les clients peuvent également évoluer et se développer grâce à la prise en charge multiprotocole unifiée pour le stockage SAN, NAS et d'objets et offrir une flexibilité maximale avec un logiciel de gestion de données ONTAP unifié et unique, pour les données sur site ou dans le cloud.  De plus, la santé du système peut être optimisée grâce à des analyses prédictives basées sur l’IA fournies par Active IQ et Cloud Insights.</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">Sécurité des données sans compromis</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">Les systèmes AFF A90 contiennent une suite complète de logiciels de protection des données intégrés et cohérents avec les applications NetApp .  Il fournit une protection des données intégrée et des solutions anti-ransomware de pointe pour la préemption et la récupération après attaque.  Les fichiers malveillants peuvent être bloqués et ne plus être écrits sur le disque, et les anomalies de stockage sont facilement surveillées pour obtenir des informations.</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">Mises à niveau simplifiées et non perturbatrices</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">L' AFF A90 est disponible en tant que mise à niveau intégrée au châssis sans interruption pour les clients A800 existants.  NetApp simplifie l'actualisation et l'élimination des interruptions des opérations critiques grâce à nos capacités avancées de fiabilité, de disponibilité, de facilité d'entretien et de gestion (RASM).  De plus, NetApp augmente encore l'efficacité opérationnelle et simplifie les activités quotidiennes des équipes informatiques, car le logiciel ONTAP applique automatiquement les mises à jour du micrologiciel pour tous les composants du système.</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">Pour les déploiements les plus importants, les systèmes AFF A1K offrent les options de performances et de capacité les plus élevées, tandis que d'autres systèmes de stockage NetApp , tels que l' AFF A70 et AFF C800, offrent des options pour les déploiements plus petits à des coûts inférieurs.</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD est une solution intégrée composée de composants matériels et logiciels NVIDIA , de solutions MLOps et de stockage tiers.  En tirant parti des meilleures pratiques de conception de systèmes évolutifs avec les produits NVIDIA et les solutions partenaires validées, les clients peuvent mettre en œuvre une plate-forme efficace et gérable pour le développement de l'IA.  La figure 1 met en évidence les différents composants de NVIDIA DGX BasePOD.</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_Solution NVIDIA DGX BasePOD_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">Systèmes NVIDIA DGX H100</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">Le système NVIDIA DGX H100 est une centrale d'IA accélérée par les performances révolutionnaires du GPU NVIDIA H100 Tensor Core.</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_Système NVIDIA DGX H100_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">Les principales spécifications du système DGX H100 sont : • Huit GPU NVIDIA H100.  • 80 Go de mémoire GPU par GPU, pour un total de 640 Go.  • Quatre puces NVIDIA NVSwitch.  • Processeurs Intel Xeon Platinum 8480 à deux cœurs 56 cœurs avec prise en charge PCIe 5.0.  • 2 To de mémoire système DDR5.  • Quatre ports OSFP desservant huit adaptateurs NVIDIA ConnectX-7 (InfiniBand/Ethernet) à port unique et deux adaptateurs NVIDIA ConnectX-7 (InfiniBand/Ethernet) à double port.  • Deux disques M.2 NVMe de 1,92 To pour le système d'exploitation DGX, huit disques U.2 NVMe de 3,84 To pour le stockage/cache.  • Puissance maximale de 10,2 kW.  Les ports arrière du plateau CPU DGX H100 sont illustrés ci-dessous.  Quatre des ports OSFP desservent huit adaptateurs ConnectX-7 pour la structure de calcul InfiniBand.  Chaque paire d'adaptateurs ConnectX-7 à double port fournit des voies parallèles vers les structures de stockage et de gestion.  Le port hors bande est utilisé pour l'accès BMC .</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_Panneau arrière NVIDIA DGX H100_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">Commutateur NVIDIA Quantum-2 QM9700</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_Commutateur InfiniBand NVIDIA Quantum-2 QM9700_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">Les commutateurs NVIDIA Quantum-2 QM9700 avec connectivité InfiniBand 400 Gb/s alimentent la structure de calcul dans les configurations NVIDIA Quantum-2 InfiniBand BasePOD.  Les adaptateurs à port unique ConnectX-7 sont utilisés pour la structure de calcul InfiniBand.  Chaque système NVIDIA DGX dispose de deux connexions à chaque commutateur QM9700, offrant plusieurs chemins à bande passante élevée et à faible latence entre les systèmes.</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">Commutateur NVIDIA Spectrum-3 SN4600</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_Commutateur NVIDIA Spectrum-3 SN4600_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">Les commutateurs NVIDIA Spectrum-3 SN4600 offrent 128 ports au total (64 par commutateur) pour fournir une connectivité redondante pour la gestion en bande du DGX BasePOD.  Le commutateur NVIDIA SN4600 peut fournir des vitesses comprises entre 1 GbE et 200 GbE.  Pour les appareils de stockage connectés via Ethernet, les commutateurs NVIDIA SN4600 sont également utilisés.  Les ports des adaptateurs ConnectX-7 à double port NVIDIA DGX sont utilisés à la fois pour la gestion en bande et la connectivité de stockage.</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">Commutateur NVIDIA Spectrum SN2201</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_Commutateur NVIDIA Spectrum SN2201_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">Les commutateurs NVIDIA Spectrum SN2201 offrent 48 ports pour fournir une connectivité pour la gestion hors bande.  La gestion hors bande fournit une connectivité de gestion consolidée pour tous les composants de DGX BasePOD.</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">Adaptateur NVIDIA ConnectX-7</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_Adaptateur NVIDIA ConnectX-7_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">L'adaptateur NVIDIA ConnectX-7 peut fournir un débit de 25/50/100/200/400 G.  Les systèmes NVIDIA DGX utilisent les adaptateurs ConnectX-7 à port unique et double pour offrir une flexibilité dans les déploiements DGX BasePOD avec InfiniBand 400 Gb/s et Ethernet.</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">NetApp AIPod avec NVIDIA DGX Systems est une architecture de référence prête pour l'entreprise basée sur NVIDIA BasePOD pour l'apprentissage en profondeur et l'intelligence artificielle utilisant les systèmes de stockage NetApp ONTAP AFF et les systèmes réseau et DGX NVIDIA .</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX - Introduction</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,Erreur : Image graphique manquante</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">Ingénierie des solutions NetApp</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">Les systèmes NetApp AIPod avec NVIDIA DGX et les systèmes de stockage connectés au cloud NetApp simplifient les déploiements d'infrastructure pour les charges de travail d'apprentissage automatique (ML) et d'intelligence artificielle (IA) en éliminant la complexité de conception et les conjectures.  S'appuyant sur la conception NVIDIA DGX BasePOD pour offrir des performances de calcul exceptionnelles pour les charges de travail de nouvelle génération, AIPod avec les systèmes NVIDIA DGX ajoute des systèmes de stockage NetApp AFF qui permettent aux clients de commencer petit et de se développer sans interruption tout en gérant intelligemment les données de la périphérie au cœur jusqu'au cloud et vice-versa.  NetApp AIPod fait partie du portefeuille plus large de solutions d'IA NetApp , illustré dans la figure ci-dessous.</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_Portefeuille de solutions NetApp IA_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">Ce document décrit les composants clés de l'architecture de référence AIPod , les informations de connectivité et de configuration du système, les résultats des tests de validation et les conseils de dimensionnement de la solution.  Ce document est destiné aux ingénieurs de solutions NetApp et partenaires ainsi qu'aux décideurs stratégiques des clients intéressés par le déploiement d'une infrastructure hautes performances pour les charges de travail ML/DL et d'analyse.</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod avec NVIDIA DGX Systems - Composants logiciels</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX - Composants logiciels</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">Cette section se concentre sur les composants logiciels du NetApp AIPod avec les systèmes NVIDIA DGX.</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">Logiciel NVIDIA</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command alimente chaque DGX BasePOD, permettant aux organisations de tirer parti du meilleur de l'innovation logicielle NVIDIA .  Les entreprises peuvent exploiter tout le potentiel de leur investissement grâce à une plateforme éprouvée qui comprend une orchestration et une gestion de cluster de niveau entreprise, des bibliothèques qui accélèrent l'infrastructure de calcul, de stockage et de réseau, ainsi qu'un système d'exploitation (OS) optimisé pour les charges de travail d'IA.</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_Solution NVIDIA BaseCommand_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU Cloud (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC fournit des logiciels pour répondre aux besoins des scientifiques de données, des développeurs et des chercheurs ayant différents niveaux d'expertise en IA.  Les logiciels hébergés sur NGC sont soumis à des analyses par rapport à un ensemble agrégé de vulnérabilités et d'expositions courantes (CVE), de cryptographie et de clés privées.  Il est testé et conçu pour s'adapter à plusieurs GPU et, dans de nombreux cas, à plusieurs nœuds, garantissant ainsi aux utilisateurs de maximiser leur investissement dans les systèmes DGX.</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_NVIDIA GPU Cloud_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise est la plate-forme logicielle de bout en bout qui met l'IA générative à la portée de chaque entreprise, offrant le temps d'exécution le plus rapide et le plus efficace pour les modèles de base d'IA générative optimisés pour s'exécuter sur la plate-forme NVIDIA DGX.  Avec une sécurité, une stabilité et une facilité de gestion de niveau production, il rationalise le développement de solutions d'IA génératives.  NVIDIA AI Enterprise est inclus avec DGX BasePOD pour permettre aux développeurs d'entreprise d'accéder à des modèles pré-entraînés, des frameworks optimisés, des microservices, des bibliothèques accélérées et un support d'entreprise.</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">Logiciel NetApp</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser leur infrastructure et de passer à un centre de données prêt pour le cloud.  En s'appuyant sur des capacités de gestion de données de pointe, ONTAP permet la gestion et la protection des données avec un seul ensemble d'outils, quel que soit l'endroit où résident ces données.  Vous pouvez également déplacer librement les données là où elles sont nécessaires : vers la périphérie, le cœur ou le cloud.  ONTAP 9 inclut de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données critiques et permettent des capacités d'infrastructure de nouvelle génération dans les architectures de cloud hybride.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Accélérer et protéger les données</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP offre des niveaux supérieurs de performance et de protection des données et étend ces capacités des manières suivantes :</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">Performances et latence réduite.  ONTAP offre le débit le plus élevé possible avec la latence la plus faible possible, y compris la prise en charge de NVIDIA GPUDirect Storage (GDS) à l'aide de NFS sur RDMA, de NFS parallèle (pNFS) et de la jonction de session NFS.</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">Protection des données.  ONTAP fournit des capacités de protection des données intégrées et la garantie anti-ransomware la plus solide du secteur avec une gestion commune sur toutes les plateformes.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">Chiffrement de volume NetApp (NVE).  ONTAP offre un cryptage natif au niveau du volume avec prise en charge de la gestion des clés intégrée et externe.</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">Stockage multi-locataire et authentification multifactorielle.  ONTAP permet le partage des ressources d'infrastructure avec les plus hauts niveaux de sécurité.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Simplifier la gestion des données</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">La gestion des données est essentielle pour les opérations informatiques de l’entreprise et les scientifiques des données afin que les ressources appropriées soient utilisées pour les applications d’IA et la formation des ensembles de données d’IA/ML.  Les informations supplémentaires suivantes sur les technologies NetApp ne sont pas couvertes par cette validation, mais peuvent être pertinentes en fonction de votre déploiement.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">Le logiciel de gestion des données ONTAP comprend les fonctionnalités suivantes pour rationaliser et simplifier les opérations et réduire votre coût total d'exploitation :</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">Les instantanés et les clones permettent la collaboration, l'expérimentation parallèle et une gouvernance des données améliorée pour les flux de travail ML/DL.</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror permet un déplacement transparent des données dans les environnements cloud hybrides et multisites, fournissant les données où et quand elles sont nécessaires.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compactage des données en ligne et déduplication étendue.  La compaction des données réduit l’espace gaspillé à l’intérieur des blocs de stockage et la déduplication augmente considérablement la capacité effective.  Cela s’applique aux données stockées localement et aux données hiérarchisées vers le cloud.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Qualité de service minimale, maximale et adaptative (AQoS).  Les contrôles granulaires de qualité de service (QoS) aident à maintenir les niveaux de performances des applications critiques dans les environnements hautement partagés.</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">Les groupes NetApp FlexGroups permettent la distribution des données sur tous les nœuds du cluster de stockage, offrant une capacité massive et des performances supérieures pour les ensembles de données extrêmement volumineux.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598 : Bonnes pratiques FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">FabricPool NetApp .  Fournit une hiérarchisation automatique des données froides vers des options de stockage cloud publiques et privées, notamment Amazon Web Services (AWS), Azure et la solution de stockage NetApp StorageGRID .  Pour plus d'informations sur FabricPool, voir<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> .</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">FlexCache NetApp .  Fournit des fonctionnalités de mise en cache de volume à distance qui simplifient la distribution de fichiers, réduisent la latence WAN et diminuent les coûts de bande passante WAN.  FlexCache permet le développement de produits distribués sur plusieurs sites, ainsi qu'un accès accéléré aux ensembles de données d'entreprise à partir d'emplacements distants.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Une infrastructure à l'épreuve du temps</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP permet de répondre aux besoins commerciaux exigeants et en constante évolution grâce aux fonctionnalités suivantes :</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">Mise à l'échelle transparente et opérations non perturbatrices.  ONTAP prend en charge l'ajout en ligne de capacité aux contrôleurs existants et aux clusters évolutifs.  Les clients peuvent passer aux dernières technologies, telles que NVMe et FC 32 Go, sans migrations de données ni pannes coûteuses.</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">Connexion au Cloud.  ONTAP est le logiciel de gestion de stockage le plus connecté au cloud, avec des options de stockage défini par logiciel (ONTAP Select) et des instances cloud natives (Google Cloud NetApp Volumes) dans tous les clouds publics.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Intégration avec les applications émergentes.  ONTAP propose des services de données de niveau entreprise pour les plates-formes et applications de nouvelle génération, telles que les véhicules autonomes, les villes intelligentes et l'industrie 4.0, en utilisant la même infrastructure qui prend en charge les applications d'entreprise existantes.</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit est un outil basé sur Python qui simplifie la gestion des espaces de travail de développement/formation et des serveurs d'inférence soutenus par un stockage NetApp hautes performances et évolutif.  La boîte à outils DataOps peut fonctionner comme un utilitaire autonome et est encore plus efficace dans les environnements Kubernetes exploitant NetApp Trident pour automatiser les opérations de stockage.  Les principales fonctionnalités comprennent :</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Provisionnez rapidement de nouveaux espaces de travail JupyterLab haute capacité soutenus par un stockage NetApp hautes performances et évolutif.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Provisionnez rapidement de nouvelles instances de NVIDIA Triton Inference Server soutenues par un stockage NetApp de classe entreprise.</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">Clonage quasi instantané d'espaces de travail JupyterLab de grande capacité afin de permettre l'expérimentation ou l'itération rapide.</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">Instantanés quasi instantanés des espaces de travail JupyterLab haute capacité pour la sauvegarde et/ou la traçabilité/l'établissement de référence.</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">Provisionnement, clonage et instantanés quasi instantanés de volumes de données haute capacité et hautes performances.</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Anthos. Trident fonctionne avec l'ensemble du portefeuille de stockage NetApp , y compris NetApp ONTAP, et prend également en charge les connexions NFS, NVMe/TCP et iSCSI. Trident accélère le flux de travail DevOps en permettant aux utilisateurs finaux de provisionner et de gérer le stockage à partir de leurs systèmes de stockage NetApp sans nécessiter l'intervention d'un administrateur de stockage.</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod avec systèmes NVIDIA DGX : validation de la solution et conseils de dimensionnement</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NetApp AIPod NVA-1173 avec systèmes NVIDIA DGX - Validation de la solution et conseils de dimensionnement</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">Cette section se concentre sur la validation de la solution et les conseils de dimensionnement pour les systèmes NetApp AIPod avec NVIDIA DGX.</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">Validation de la solution</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">La configuration de stockage de cette solution a été validée à l’aide d’une série de charges de travail synthétiques utilisant l’outil open source FIO.  Ces tests incluent des modèles d'E/S de lecture et d'écriture destinés à simuler la charge de travail de stockage générée par les systèmes DGX exécutant des tâches de formation en apprentissage approfondi.  La configuration de stockage a été validée à l'aide d'un cluster de serveurs CPU à 2 sockets exécutant simultanément les charges de travail FIO pour simuler un cluster de systèmes DGX.  Chaque client a été configuré avec la même configuration réseau décrite précédemment, avec l’ajout des détails suivants.</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">Les options de montage suivantes ont été utilisées pour cette validation :</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">vers=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">active pNFS pour un accès parallèle à plusieurs nœuds de stockage</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">proto=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">définit le protocole de transfert sur RDMA au lieu du protocole TCP par défaut</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">port=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">spécifier le port correct pour le service RDMA NFS</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">max_connect=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">permet la jonction de session NFS pour agréger la bande passante du port de stockage</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">écrire=impatient</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">améliore les performances d'écriture des écritures en mémoire tampon</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144,wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">définit la taille de transfert d'E/S à 256 Ko</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">De plus, les clients ont été configurés avec une valeur NFS max_session_slots de 1024.  Comme la solution a été testée à l’aide de NFS sur RDMA, les ports des réseaux de stockage ont été configurés avec une liaison active/passive.  Les paramètres de liaison suivants ont été utilisés pour cette validation :</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">mode=sauvegarde active</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">définit la liaison en mode actif/passif</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primaire=&lt;nom de l'interface&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">les interfaces principales pour tous les clients ont été réparties sur les commutateurs</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">intervalle-moniteur-mii=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">spécifie un intervalle de surveillance de 100 ms</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">fail-over-mac-policy=active</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">spécifie que l'adresse MAC du lien actif est le MAC de la liaison.  Ceci est nécessaire au bon fonctionnement du RDMA sur l'interface liée.</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">Le système de stockage a été configuré comme décrit avec deux paires HA A900 (4 contrôleurs) avec deux étagères de disques NS224 de 24 disques NVMe de 1,9 To attachés à chaque paire HA.  Comme indiqué dans la section Architecture, la capacité de stockage de tous les contrôleurs a été combinée à l’aide d’un volume FlexGroup et les données de tous les clients ont été distribuées sur tous les contrôleurs du cluster.</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">Guide de dimensionnement du système de stockage</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp a obtenu avec succès la certification DGX BasePOD et les deux paires A90 HA testées peuvent facilement prendre en charge un cluster de seize systèmes DGX H100.  Pour les déploiements plus importants avec des exigences de performances de stockage plus élevées, des systèmes AFF supplémentaires peuvent être ajoutés au cluster NetApp ONTAP jusqu'à 12 paires HA (24 nœuds) dans un seul cluster.  En utilisant la technologie FlexGroup décrite dans cette solution, un cluster à 24 nœuds peut fournir plus de 79 Po et jusqu'à 552 Gbit/s de débit dans un seul espace de noms.  D'autres systèmes de stockage NetApp tels que les AFF A400, A250 et C800 offrent des performances inférieures et/ou des options de capacité supérieure pour des déploiements plus petits à des coûts inférieurs.  Étant donné ONTAP 9 prend en charge les clusters à modèles mixtes, les clients peuvent commencer avec une empreinte initiale plus petite et ajouter des systèmes de stockage plus nombreux ou plus grands au cluster à mesure que les exigences de capacité et de performances augmentent.  Le tableau ci-dessous montre une estimation approximative du nombre de GPU A100 et H100 pris en charge sur chaque modèle AFF .</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_Guide de dimensionnement du système de stockage NetApp_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">BeeGFS sur NetApp avec stockage série E</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">BeeGFS sur NetApp avec stockage E-Series est une solution intégrée et éprouvée avec une infrastructure HPC simple, fiable, évolutive et rentable qui suit le rythme de vos charges de travail les plus extrêmes.</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY : Guide de déploiement des systèmes Quantum StorNext avec NetApp E-Series</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Ce document fournit des détails sur la manière de déployer une solution de système de fichiers parallèle StorNext avec les systèmes de stockage NetApp E-Series.  Cette solution couvre la baie entièrement flash NetApp EF280, la baie entièrement flash NVMe NetApp EF300, la baie entièrement flash NVMe NetApp EF600 et le système hybride NetApp E5760.  Il offre une caractérisation des performances basée sur l'analyse comparative Frametest, un outil largement utilisé pour les tests dans l'industrie des médias et du divertissement.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN : Guide de conception des systèmes Quantum StorNext avec NetApp E-Series</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Ce document fournit des détails sur la manière de concevoir une solution de système de fichiers parallèle StorNext avec les systèmes de stockage NetApp E-Series.  Cette solution couvre la baie entièrement flash NetApp EF280, la baie entièrement flash NVMe NetApp EF300, la baie entièrement flash NVMe EF600 et le système hybride NetApp E5760.  Il offre une caractérisation des performances basée sur l'analyse comparative Frametest, un outil largement utilisé pour les tests dans l'industrie des médias et du divertissement.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859 : Déploiement d'IBM Spectrum Scale avec le stockage NetApp E-Series – Installation et validation</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 décrit le processus de déploiement d'une solution complète de système de fichiers parallèle basée sur la pile logicielle Spectrum Scale d'IBM.  TR-4859 est conçu pour fournir des détails sur la façon d'installer Spectrum Scale, de valider l'infrastructure et de gérer la configuration.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">Cette architecture vérifiée NetApp décrit la conception du NVIDIA DGX SuperPOD avec les blocs de construction NetApp BeeGFS.  Cette solution est une plateforme de centre de données full-stack validée sur un cluster d'acceptation dédié chez NVIDIA.</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD avec NetApp - Guide de conception</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">Cette architecture vérifiée NetApp décrit la conception du NVIDIA DGX SuperPOD avec les blocs de construction NetApp BeeGFS.  Cette solution est une plateforme de centre de données full-stack validée sur un cluster d'acceptation dédié chez NVIDIA.</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200 200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">Amine Bennani, Christian Whiteside, David Arnette et Sathish Thyagarajan, NetApp</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">Résumé exécutif</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">Dans le paysage technologique actuel en évolution rapide, l’IA révolutionne les expériences des consommateurs et stimule l’innovation dans tous les secteurs.  Cependant, cela présente également des défis importants pour les services informatiques, qui sont sous pression pour déployer des solutions de calcul haute performance (HPC) capables de gérer les demandes intenses des charges de travail de l'IA.  Alors que les organisations se précipitent pour exploiter la puissance de l’IA, l’urgence d’une solution facile à déployer, à faire évoluer et à gérer augmente.</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD est une plate-forme d'infrastructure de centre de données IA fournie sous forme de solution clé en main pour l'informatique afin de prendre en charge les charges de travail IA les plus complexes auxquelles sont confrontées les entreprises d'aujourd'hui.  Au cœur de tout modèle d’apprentissage profond (DL) précis se trouvent de grands volumes de données, nécessitant une solution de stockage à haut débit capable de servir et de réutiliser efficacement ces données.  La solution NetApp BeeGFS, composée de baies de stockage NetApp EF600 avec le système de fichiers parallèle BeeGFS, permet au NVIDIA DGX SuperPOD de libérer toutes ses capacités.  La solution NetApp BeeGFS a été validée par NVIDIA pour s'intégrer et évoluer avec l'architecture SuperPOD.  Le résultat est un déploiement et une gestion simplifiés du centre de données IA tout en offrant une évolutivité pratiquement illimitée en termes de performances et de capacité.</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">La solution NetApp BeeGFS, optimisée par les systèmes de stockage NVMe NetApp EF600 hautes performances et le système de fichiers parallèles évolutif BeeGFS, offre une base de stockage robuste et efficace pour les charges de travail d'IA exigeantes.  Son architecture de disque partagé garantit une haute disponibilité, en maintenant des performances et une accessibilité constantes, même face aux défis du système.  Cette solution fournit une architecture évolutive et flexible qui peut être personnalisée pour répondre à diverses exigences de stockage.  Les clients peuvent facilement étendre leurs performances et leur capacité de stockage en intégrant des blocs de construction de stockage supplémentaires pour gérer même les charges de travail les plus exigeantes.</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD exploite les systèmes DGX H100 et H200 avec un stockage partagé externe validé :</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">Chaque unité évolutive (SU) DGX SuperPOD se compose de 32 systèmes DGX et est capable de 640 pétaFLOPS de performances d'IA avec une précision FP8.  NetApp recommande de dimensionner la solution de stockage NetApp BeeGFS avec au moins 2 blocs de construction pour une seule configuration DGX SuperPOD.</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_Une vue d'ensemble de la solution_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">Figure montrant un aperçu de haut niveau de la solution NetApp BeeGFS avec un NVIDIA DGX SuperPOD.</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">Les blocs de construction NetApp BeeGFS se composent de deux baies NetApp EF600 et de deux serveurs x86 :</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">Avec les baies 100 % flash NetApp EF600 à la base de NVIDIA DGX SuperPOD, les clients bénéficient d'une base de stockage fiable soutenue par six 9 de disponibilité.</block>
  <block id="23830778b135794055062035d895d122" category="list-text">La couche du système de fichiers entre les systèmes NetApp EF600 et NVIDIA DGX est le système de fichiers parallèle BeeGFS.  BeeGFS a été créé par le Centre Fraunhofer pour le calcul haute performance en Allemagne pour résoudre les problèmes des systèmes de fichiers parallèles hérités.  Le résultat est un système de fichiers avec une architecture d’espace utilisateur moderne qui est désormais développé et fourni par ThinkParQ et utilisé par de nombreux environnements de supercalcul.</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">Le support NetApp pour BeeGFS aligne l'excellente organisation de support de NetApp sur les exigences des clients en matière de performances et de disponibilité.  Les clients ont accès à des ressources d'assistance supérieures, à un accès anticipé aux versions de BeeGFS et à l'accès à certaines fonctionnalités d'entreprise de BeeGFS telles que l'application des quotas et la haute disponibilité (HA).</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">La combinaison des SU NVIDIA SuperPOD et des blocs de construction NetApp BeeGFS fournit une solution d'IA agile dans laquelle le calcul ou le stockage évolue facilement et de manière transparente.</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_Bloc de construction NetApp BeeGFS_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">Figure montrant un seul bloc de construction NetApp BeeGFS.</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">Résumé du cas d'utilisation</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Cette solution s'applique aux cas d'utilisation suivants :</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">Intelligence artificielle (IA) comprenant l'apprentissage automatique (ML), l'apprentissage profond (DL), le traitement du langage naturel (NLP), la compréhension du langage naturel (NLU) et l'IA générative (GenAI).</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">Formation en IA à moyenne et grande échelle</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">Vision par ordinateur, parole, audio et modèles de langage</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC incluant les applications accélérées par l'interface de passage de messages (MPI) et d'autres techniques de calcul distribué</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">Charges de travail des applications caractérisées par les éléments suivants :</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">Lecture ou écriture dans des fichiers de plus de 1 Go</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">Lecture ou écriture dans le même fichier par plusieurs clients (10, 100 et 1000)</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">Ensembles de données multitéraoctets ou multipétaoctets</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">Environnements nécessitant un espace de stockage unique optimisable pour un mélange de fichiers volumineux et petits</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">Cette section couvre les exigences technologiques pour la solution NVIDIA DGX SuperPOD avec NetApp .</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">Architecture de référence NVIDIA DGX H100 SuperPOD</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN : Conception de NVA BeeGFS sur NetApp</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">Le tableau 1 ci-dessous répertorie les composants matériels nécessaires à la mise en œuvre de la solution pour un seul SU.  Le dimensionnement de la solution commence avec 32 systèmes NVIDIA DGX H100 et deux ou trois blocs de construction NetApp BeeGFS.  Un seul bloc de construction NetApp BeeGFS se compose de deux baies NetApp EF600 et de deux serveurs x86.  Les clients peuvent ajouter des blocs de construction supplémentaires à mesure que la taille du déploiement augmente.  Pour plus d'informations, consultez le<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block> et<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block> .</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 ou H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">Commutateurs NVIDIA Quantum QM9700</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 feuilles, 4 épines</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">Blocs de construction NetApp BeeGFS</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">Le tableau 2 ci-dessous répertorie les composants logiciels nécessaires à la mise en œuvre de la solution.  Les composants logiciels utilisés dans une implémentation particulière de la solution peuvent varier en fonction des exigences du client.</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">Pile logicielle NVIDIA DGX</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">Système de fichiers parallèle ThinkParQ BeeGFS</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">Vérification de la solution</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: architecture de référence NetApp EF600 et BeeGFS</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NVIDIA DGX SuperPOD avec NetApp a été validé sur un cluster d'acceptation dédié chez NVIDIA en utilisant les blocs de construction NetApp BeeGFS.  Les critères d'acceptation étaient basés sur une série de tests d'application, de performances et de stress effectués par NVIDIA. Pour plus d'informations, consultez le<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> .</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp et NVIDIA ont une longue histoire de collaboration pour proposer un portefeuille de solutions d'IA sur le marché.  NVIDIA DGX SuperPOD avec la baie entièrement flash NetApp EF600 est une solution éprouvée et validée que les clients peuvent déployer en toute confiance.  Cette architecture clé en main entièrement intégrée élimine les risques liés au déploiement et met tout le monde sur la voie de la victoire dans la course au leadership de l'IA.</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">Architecture de référence NVIDIA DGX SuperPOD</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">Guide de référence de conception du centre de données NVIDIA DGX SuperPOD</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 et BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">L’automatisation basée sur l’IA et l’informatique de pointe constituent une approche de pointe pour aider les entreprises à réaliser leur transformation numérique et à maximiser l’efficacité et la sécurité opérationnelles.  Avec l’informatique de pointe, les données sont traitées beaucoup plus rapidement car elles n’ont pas besoin de voyager vers et depuis un centre de données.  Par conséquent, le coût associé à l’envoi et au retour de données vers les centres de données ou le cloud est réduit.</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">L’automatisation basée sur l’IA et l’informatique de pointe constituent une approche de pointe pour aider les entreprises à réaliser leur transformation numérique et à maximiser l’efficacité et la sécurité opérationnelles.  Avec l’informatique de pointe, les données sont traitées beaucoup plus rapidement car elles n’ont pas besoin de voyager vers et depuis un centre de données.  Par conséquent, le coût associé à l’envoi et au retour de données vers les centres de données ou le cloud est réduit.  Une latence plus faible et une vitesse accrue peuvent être bénéfiques lorsque les entreprises doivent prendre des décisions en temps quasi réel à l’aide de modèles d’inférence d’IA déployés en périphérie.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">Les systèmes de stockage NetApp offrent des performances identiques ou supérieures à celles du stockage SSD local et offrent les avantages suivants aux scientifiques des données, aux ingénieurs de données, aux développeurs d'IA/ML et aux décideurs commerciaux ou informatiques :</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Partage de données sans effort entre les systèmes d’IA, les analyses et d’autres systèmes commerciaux critiques.  Ce partage de données réduit les frais généraux de l’infrastructure, améliore les performances et rationalise la gestion des données dans l’ensemble de l’entreprise.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Calcul et stockage évolutifs indépendamment pour minimiser les coûts et améliorer l'utilisation des ressources.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Flux de travail de développement et de déploiement rationalisés à l'aide de copies et de clones Snapshot intégrés pour des espaces de travail utilisateur instantanés et peu encombrants, un contrôle de version intégré et un déploiement automatisé.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Protection des données de niveau entreprise pour la reprise après sinistre et la continuité des activités.  La solution NetApp et Lenovo présentée dans ce document est une architecture flexible et évolutive, idéale pour les déploiements d’inférence d’IA de niveau entreprise à la périphérie.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Remerciements</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">JJ  Falkanger, directeur principal, solutions HPC et IA, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, ingénieur marketing technique, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, responsable technique des solutions d'IA de la série E, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, ingénieur assurance qualité, NetApp</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Pour en savoir plus sur les informations décrites dans ce document, reportez-vous aux documents et/ou sites Web suivants :</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Page produit des baies NetApp AFF série A</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Logiciel de gestion de données NetApp ONTAP — Bibliothèque d'informations ONTAP 9</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727 : Présentation de la série NetApp EF</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Fiche technique du logiciel SANtricity NetApp E-Series</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">Stockage persistant NetApp pour conteneurs — NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Test de référence TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Serveur Edge Lenovo ThinkSystem SE350</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Baie de stockage flash unifiée Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SE350 et les détails de provisionnement du stockage.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Configuration de test</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">La figure suivante montre la configuration de test.  Nous avons utilisé le système de stockage NetApp AFF C190 et deux serveurs Lenovo ThinkSystem SE350 (chacun avec un accélérateur NVIDIA T4).  Ces composants sont connectés via un commutateur réseau 10GbE.  Le stockage réseau contient des ensembles de données de validation/test et des modèles pré-entraînés.  Les serveurs offrent une capacité de calcul et le stockage est accessible via le protocole NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SE350 et les détails de provisionnement du stockage.  Le tableau suivant répertorie les composants de base de l’architecture de la solution.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Serveurs Lenovo ThinkSystem</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 serveurs SE350 chacun avec une carte GPU NVIDIA T4</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Chaque serveur contient un processeur Intel Xeon D-2123IT avec quatre cœurs physiques fonctionnant à 2,20 GHz et 128 Go de RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Système de stockage NetApp AFF d'entrée de gamme (paire HA)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Logiciel NetApp ONTAP 9</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24x SSD de 960 Go</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">Protocole NFS</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Un groupe d'interfaces par contrôleur, avec quatre adresses IP logiques pour les points de montage</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">Le tableau suivant répertorie la configuration de stockage : AFF C190 avec 2RU, 24 emplacements de lecteur.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Contrôleur</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Agrégat</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volume FlexGroup</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Taille des agrégats</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Volumesize</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Point de montage du système d'exploitation</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 To</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">Le dossier /netappLenovo_AI_fg contient les ensembles de données utilisés pour la validation du modèle.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">La figure ci-dessous montre la configuration de test.  Nous avons utilisé le système de stockage NetApp EF280 et deux serveurs Lenovo ThinkSystem SE350 (chacun avec un accélérateur NVIDIA T4).  Ces composants sont connectés via un commutateur réseau 10GbE.  Le stockage réseau contient des ensembles de données de validation/test et des modèles pré-entraînés.  Les serveurs offrent une capacité de calcul et le stockage est accessible via le protocole NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">Le tableau suivant répertorie la configuration de stockage pour EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Groupe de volumes</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volume</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">Taille DDP</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Méthode de connexion</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volume 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 To</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 vers iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volume 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 vers iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Ce document décrit une architecture de calcul et de stockage pour déployer l'inférence d'intelligence artificielle (IA) basée sur le GPU sur les contrôleurs de stockage NetApp et les serveurs Lenovo ThinkSystem dans un environnement de périphérie qui répond aux scénarios d'application émergents.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886 : Inférence IA en périphérie – NetApp avec Lenovo ThinkSystem – Conception de solutions</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">Résumé</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Plusieurs scénarios d’application émergents, tels que les systèmes avancés d’assistance à la conduite (ADAS), l’industrie 4.0, les villes intelligentes et l’Internet des objets (IoT), nécessitent le traitement de flux de données continus avec une latence proche de zéro.  Ce document décrit une architecture de calcul et de stockage pour déployer l'inférence d'intelligence artificielle (IA) basée sur le GPU sur les contrôleurs de stockage NetApp et les serveurs Lenovo ThinkSystem dans un environnement de périphérie qui répond à ces exigences.  Ce document fournit également des données de performances pour le benchmark d'inférence MLPerf standard de l'industrie, évaluant diverses tâches d'inférence sur des serveurs Edge équipés de GPU NVIDIA T4.  Nous étudions les performances des scénarios d'inférence hors ligne, à flux unique et à flux multiples et montrons que l'architecture avec un système de stockage en réseau partagé rentable est très performante et fournit un point central pour la gestion des données et des modèles pour plusieurs serveurs périphériques.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Les entreprises génèrent de plus en plus de volumes massifs de données à la périphérie du réseau.  Pour tirer le meilleur parti des capteurs intelligents et des données IoT, les organisations recherchent une solution de streaming d’événements en temps réel qui permet l’informatique de pointe.  Les tâches exigeantes en termes de calcul sont donc de plus en plus effectuées en périphérie, en dehors des centres de données.  L’inférence de l’IA est l’un des moteurs de cette tendance.  Les serveurs Edge fournissent une puissance de calcul suffisante pour ces charges de travail, en particulier lors de l'utilisation d'accélérateurs, mais le stockage limité est souvent un problème, en particulier dans les environnements multiserveurs.  Dans ce document, nous montrons comment vous pouvez déployer un système de stockage partagé dans l’environnement Edge et comment il profite aux charges de travail d’inférence IA sans imposer de pénalité de performances.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Ce document décrit une architecture de référence pour l’inférence de l’IA à la périphérie.  Il combine plusieurs serveurs Edge Lenovo ThinkSystem avec un système de stockage NetApp pour créer une solution facile à déployer et à gérer.  Il est destiné à être un guide de base pour les déploiements pratiques dans diverses situations, telles que l'usine avec plusieurs caméras et capteurs industriels, les systèmes de point de vente (POS) dans les transactions de détail ou les systèmes de conduite entièrement autonome (FSD) qui identifient les anomalies visuelles dans les véhicules autonomes.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Ce document couvre les tests et la validation d'une configuration de calcul et de stockage composée d'un serveur Lenovo ThinkSystem SE350 Edge et d'un système de stockage NetApp AFF et EF-Series d'entrée de gamme.  Les architectures de référence offrent une solution efficace et rentable pour les déploiements d'IA tout en fournissant des services de données complets, une protection des données intégrée, une évolutivité transparente et un stockage de données connecté au cloud avec les logiciels de gestion de données NetApp ONTAP et NetApp SANtricity .</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Ce document est destiné aux publics suivants :</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Les chefs d’entreprise et les architectes d’entreprise qui souhaitent produire l’IA à la périphérie.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Scientifiques des données, ingénieurs des données, chercheurs en IA/apprentissage automatique (ML) et développeurs de systèmes d’IA.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Architectes d'entreprise qui conçoivent des solutions pour le développement de modèles et d'applications d'IA/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Les scientifiques des données et les ingénieurs en IA recherchent des moyens efficaces de déployer des modèles d'apprentissage profond (DL) et de ML.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Gestionnaires de périphériques Edge et administrateurs de serveurs Edge responsables du déploiement et de la gestion des modèles d'inférence Edge.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Architecture de la solution</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Cette solution de serveur Lenovo ThinkSystem et de stockage NetApp ONTAP ou NetApp SANtricity est conçue pour gérer l'inférence IA sur de grands ensembles de données en utilisant la puissance de traitement des GPU aux côtés des CPU traditionnels.  Cette validation démontre des performances élevées et une gestion optimale des données avec une architecture qui utilise un ou plusieurs serveurs Edge Lenovo SR350 interconnectés avec un seul système de stockage NetApp AFF , comme illustré dans les deux figures suivantes.</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">L’aperçu de l’architecture logique dans la figure suivante montre les rôles des éléments de calcul et de stockage dans cette architecture.  Plus précisément, il montre ce qui suit :</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Appareils de calcul Edge effectuant des inférences sur les données qu'ils reçoivent des caméras, des capteurs, etc.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Un élément de stockage partagé qui sert à plusieurs fins :</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Fournit un emplacement central pour les modèles d’inférence et d’autres données nécessaires pour effectuer l’inférence.  Les serveurs de calcul accèdent directement au stockage et utilisent des modèles d'inférence sur le réseau sans avoir besoin de les copier localement.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Les modèles mis à jour sont poussés ici.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Les archives saisissent les données que les serveurs Edge reçoivent pour une analyse ultérieure.  Par exemple, si les périphériques périphériques sont connectés à des caméras, l’élément de stockage conserve les vidéos capturées par les caméras.</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">rouge</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">bleu</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Système informatique Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Système de stockage NetApp AFF</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Appareils de périphérie effectuant des inférences sur les entrées provenant de caméras, de capteurs, etc.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Stockage partagé contenant des modèles d'inférence et des données provenant d'appareils périphériques pour une analyse ultérieure.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Cette solution NetApp et Lenovo offre les principaux avantages suivants :</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">Calcul accéléré par GPU à la périphérie.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Déploiement de plusieurs serveurs Edge sauvegardés et gérés à partir d'un stockage partagé.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Protection robuste des données pour atteindre les objectifs de points de récupération (RPO) et de temps de récupération (RTO) faibles sans perte de données.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gestion optimisée des données avec des copies et des clones NetApp Snapshot pour rationaliser les flux de travail de développement.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Comment utiliser cette architecture</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Ce document valide la conception et les performances de l'architecture proposée.  Cependant, nous n'avons pas testé certains éléments au niveau logiciel, tels que la gestion des conteneurs, des charges de travail ou des modèles et la synchronisation des données avec le cloud ou le centre de données sur site, car ils sont spécifiques à un scénario de déploiement.  Ici, plusieurs choix existent.</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">Plan de contrôle de l'IA NetApp</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">Au niveau de la gestion des conteneurs, la gestion des conteneurs Kubernetes est un bon choix et est bien prise en charge soit dans une version entièrement en amont (Canonical), soit dans une version modifiée adaptée aux déploiements d'entreprise (Red Hat).  Le<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block> qui utilise NetApp Trident et le nouveau<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> fournit une traçabilité intégrée, des fonctions de gestion des données, des interfaces et des outils permettant aux scientifiques et aux ingénieurs de données de s'intégrer au stockage NetApp .  Kubeflow, la boîte à outils ML pour Kubernetes, fournit des fonctionnalités d'IA supplémentaires ainsi qu'une prise en charge du contrôle de version des modèles et de KFServing sur plusieurs plates-formes telles que TensorFlow Serving ou NVIDIA Triton Inference Server.  Une autre option est la plate-forme NVIDIA EGX, qui fournit une gestion de la charge de travail ainsi qu'un accès à un catalogue de conteneurs d'inférence d'IA compatibles GPU.  Cependant, ces options peuvent nécessiter des efforts et une expertise considérables pour les mettre en production et peuvent nécessiter l’assistance d’un fournisseur de logiciels indépendant (ISV) ou d’un consultant tiers.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">Domaines de solutions</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">Le principal avantage de l’inférence de l’IA et de l’informatique de pointe est la capacité des appareils à calculer, traiter et analyser des données avec un niveau de qualité élevé sans latence.  Il existe beaucoup trop d'exemples de cas d'utilisation de l'informatique de pointe pour les décrire dans ce document, mais en voici quelques-uns parmi les plus importants :</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automobiles : Véhicules autonomes</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">L'illustration classique de l'informatique de pointe se trouve dans les systèmes avancés d'assistance à la conduite (ADAS) dans les véhicules autonomes (VA).  L’IA des voitures sans conducteur doit traiter rapidement de nombreuses données provenant de caméras et de capteurs pour être un conducteur sûr et performant.  Prendre trop de temps pour interpréter la différence entre un objet et un humain peut signifier la vie ou la mort. Il est donc crucial de pouvoir traiter ces données au plus près du véhicule.  Dans ce cas, un ou plusieurs serveurs de calcul Edge gèrent les entrées des caméras, du RADAR, du LiDAR et d'autres capteurs, tandis que le stockage partagé contient les modèles d'inférence et stocke les données d'entrée des capteurs.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Santé : Suivi des patients</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">L’un des plus grands impacts de l’IA et de l’informatique de pointe est sa capacité à améliorer la surveillance continue des patients atteints de maladies chroniques, tant dans les soins à domicile que dans les unités de soins intensifs (USI).  Les données provenant des appareils de pointe qui surveillent les niveaux d'insuline, la respiration, l'activité neurologique, le rythme cardiaque et les fonctions gastro-intestinales nécessitent une analyse instantanée des données sur lesquelles il faut agir immédiatement car le temps est limité pour agir afin de sauver la vie de quelqu'un.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Commerce de détail : paiement sans caissier</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">L'informatique de pointe peut alimenter l'IA et le ML pour aider les détaillants à réduire le temps de paiement et à augmenter le trafic piétonnier.  Les systèmes sans caissier prennent en charge divers composants, tels que les suivants :</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Authentification et accès.  Connecter l'acheteur physique à un compte validé et lui permettre d'accéder à l'espace de vente.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Suivi des stocks.  Utilisation de capteurs, d’étiquettes RFID et de systèmes de vision par ordinateur pour aider à confirmer la sélection ou la désélection d’articles par les acheteurs.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Ici, chacun des serveurs périphériques gère chaque comptoir de caisse et le système de stockage partagé sert de point de synchronisation central.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Services financiers : sécurité humaine aux guichets et prévention de la fraude</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Les organisations bancaires utilisent l’IA et l’informatique de pointe pour innover et créer des expériences bancaires personnalisées.  Les bornes interactives utilisant l'analyse de données en temps réel et l'inférence de l'IA permettent désormais aux distributeurs automatiques de billets non seulement d'aider les clients à retirer de l'argent, mais également de surveiller de manière proactive les bornes grâce aux images capturées par les caméras pour identifier les risques pour la sécurité humaine ou les comportements frauduleux.  Dans ce scénario, les serveurs de calcul Edge et les systèmes de stockage partagés sont connectés à des bornes interactives et à des caméras pour aider les banques à collecter et à traiter des données avec des modèles d'inférence d'IA.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Fabrication : Industrie 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">La quatrième révolution industrielle (Industrie 4.0) a commencé, avec l’émergence de nouvelles tendances telles que l’usine intelligente et l’impression 3D.  Pour préparer un avenir axé sur les données, la communication machine à machine (M2M) à grande échelle et l'IoT sont intégrés pour une automatisation accrue sans intervention humaine.  La fabrication est déjà hautement automatisée et l’ajout de fonctionnalités d’IA est une continuation naturelle de la tendance à long terme.  L’IA permet d’automatiser des opérations qui peuvent être automatisées à l’aide de la vision par ordinateur et d’autres capacités d’IA.  Vous pouvez automatiser le contrôle qualité ou les tâches qui reposent sur la vision humaine ou la prise de décision pour effectuer des analyses plus rapides des matériaux sur les chaînes de montage dans les usines afin d'aider les usines de fabrication à respecter les normes ISO requises en matière de sécurité et de gestion de la qualité.  Ici, chaque serveur de calcul Edge est connecté à un ensemble de capteurs surveillant le processus de fabrication et les modèles d'inférence mis à jour sont poussés vers le stockage partagé, selon les besoins.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Télécommunications : détection de rouille, inspection des tours et optimisation du réseau</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">L’industrie des télécommunications utilise des techniques de vision par ordinateur et d’IA pour traiter des images qui détectent automatiquement la rouille et identifient les tours cellulaires qui contiennent de la corrosion et nécessitent donc une inspection plus approfondie.  L’utilisation d’images de drones et de modèles d’IA pour identifier des régions distinctes d’une tour afin d’analyser la rouille, les fissures de surface et la corrosion a augmenté ces dernières années.  La demande continue de croître pour les technologies d’IA qui permettent d’inspecter efficacement les infrastructures de télécommunication et les tours de téléphonie mobile, d’évaluer régulièrement leur dégradation et de les réparer rapidement si nécessaire.</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">En outre, un autre cas d’utilisation émergent dans les télécommunications est l’utilisation d’algorithmes d’IA et de ML pour prédire les modèles de trafic de données, détecter les appareils compatibles 5G et automatiser et augmenter la gestion de l’énergie à entrées et sorties multiples (MIMO).  Le matériel MIMO est utilisé dans les tours radio pour augmenter la capacité du réseau ; cependant, cela entraîne des coûts énergétiques supplémentaires.  Les modèles ML pour le « mode veille MIMO » déployés sur les sites cellulaires peuvent prédire l'utilisation efficace des radios et aider à réduire les coûts de consommation d'énergie pour les opérateurs de réseaux mobiles (MNO).  Les solutions d'inférence d'IA et d'informatique de pointe aident les opérateurs de réseaux mobiles à réduire la quantité de données transmises dans les deux sens vers les centres de données, à réduire leur coût total de possession, à optimiser les opérations réseau et à améliorer les performances globales pour les utilisateurs finaux.</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Ce document suit le code MLPerf Inference v0.7, le code et les règles MLPerf Inference v1.1.  Nous avons exécuté des tests de référence conçus pour l’inférence à la périphérie, comme défini dans les tableaux présentés dans cette section.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Plan de test</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">code</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">règles</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Ce document suit MLPerf Inference v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> , Inférence MLPerf v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> , et<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block> .  Nous avons exécuté des tests MLPerf conçus pour l’inférence à la périphérie, comme défini dans le tableau suivant.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Zone</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">Modèle</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Ensemble de données</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Taille QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualité</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Contrainte de latence multiflux</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Vision</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Classification des images</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99% du FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Détection d'objets (grand)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Détection d'objet (petit)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD-MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentation d'images médicales</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">UNET 3D</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99% et 99,9% du FP32</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Discours</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Conversion de la parole en texte</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Langue</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Traitement du langage</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">Le tableau suivant présente les scénarios de référence Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Scénarios</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Classification des images</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Flux unique, hors ligne, multiflux</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Flux unique, hors ligne</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">Conversion de la parole en texte</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Nous avons effectué ces tests de référence en utilisant l'architecture de stockage en réseau développée dans cette validation et comparé les résultats à ceux des exécutions locales sur les serveurs périphériques précédemment soumis à MLPerf.  La comparaison vise à déterminer l’impact du stockage partagé sur les performances d’inférence.</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Cette section décrit les procédures de test utilisées pour valider cette solution.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procédure de test</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Configuration du système d'exploitation et de l'inférence de l'IA</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Pour AFF C190, nous avons utilisé Ubuntu 18.04 avec les pilotes NVIDIA et Docker avec prise en charge des GPU NVIDIA et utilisé MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> disponible dans le cadre de la soumission de Lenovo à MLPerf Inference v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Pour EF280, nous avons utilisé Ubuntu 20.04 avec les pilotes NVIDIA et Docker avec prise en charge des GPU NVIDIA et MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> disponible dans le cadre de la soumission de Lenovo à MLPerf Inference v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Pour configurer l’inférence de l’IA, suivez ces étapes :</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Téléchargez les ensembles de données nécessitant une inscription, l'ensemble de validation ImageNet 2012, l'ensemble de données Criteo Terabyte et l'ensemble de formation BraTS 2019, puis décompressez les fichiers.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Créez un répertoire de travail d'au moins 1 To et définissez une variable d'environnement<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> se référant au répertoire.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Vous devez partager ce répertoire sur le stockage partagé pour le cas d'utilisation du stockage réseau, ou sur le disque local lors des tests avec des données locales.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Exécutez la marque<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> commande, qui construit et lance le conteneur Docker pour les tâches d'inférence requises.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Les commandes suivantes sont toutes exécutées à partir du conteneur Docker en cours d'exécution :</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Téléchargez des modèles d'IA pré-entraînés pour les tâches d'inférence MLPerf :<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Téléchargez des ensembles de données supplémentaires téléchargeables gratuitement :<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Prétraiter les données : faire<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Courir:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> .</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Créez des moteurs d'inférence optimisés pour le GPU dans les serveurs de calcul :<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Pour exécuter des charges de travail d’inférence, exécutez la commande suivante (une seule commande) :</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">Les inférences de l'IA s'exécutent</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Trois types d'exécutions ont été exécutées :</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inférence IA sur serveur unique utilisant le stockage local</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inférence IA sur serveur unique utilisant le stockage réseau</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inférence IA multi-serveurs utilisant le stockage réseau</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Une multitude de tests ont été effectués pour évaluer les performances de l’architecture proposée.  Il existe six charges de travail différentes (classification d'images, détection d'objets [petits], détection d'objets [grands], imagerie médicale, conversion de la parole en texte et traitement du langage naturel [NLP]), que vous pouvez exécuter dans trois scénarios différents : hors ligne, flux unique et multiflux.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Résultats des tests</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">Une multitude de tests ont été effectués pour évaluer les performances de l’architecture proposée.</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">Il existe six charges de travail différentes (classification d'images, détection d'objets [petits], détection d'objets [grands], imagerie médicale, conversion de la parole en texte et traitement du langage naturel [NLP]), que vous pouvez exécuter dans trois scénarios différents : hors ligne, flux unique et flux multiple.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">Le dernier scénario est implémenté uniquement pour la classification d’images et la détection d’objets.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Cela donne 15 charges de travail possibles, qui ont toutes été testées dans trois configurations différentes :</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Serveur unique/stockage local</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Stockage sur serveur unique/réseau</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Stockage multi-serveurs/réseau</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Les résultats sont décrits dans les sections suivantes.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inférence IA dans un scénario hors ligne pour AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">Dans ce scénario, toutes les données étaient disponibles sur le serveur et le temps nécessaire au traitement de tous les échantillons a été mesuré.  Nous rapportons les bandes passantes en échantillons par seconde comme résultats des tests.  Lorsque plusieurs serveurs de calcul sont utilisés, nous signalons la bande passante totale additionnée sur tous les serveurs.  Les résultats pour les trois cas d’utilisation sont présentés dans la figure ci-dessous.  Dans le cas de deux serveurs, nous rapportons la bande passante combinée des deux serveurs.</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Les résultats montrent que le stockage réseau n’affecte pas négativement les performances : le changement est minime et pour certaines tâches, aucun n’est constaté.  Lors de l'ajout du deuxième serveur, la bande passante totale double exactement ou, au pire, le changement est inférieur à 1 %.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">Inférence de l'IA dans un scénario à flux unique pour AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Ce benchmark mesure la latence.  Pour le cas de plusieurs serveurs de calcul, nous rapportons la latence moyenne.  Les résultats de la série de tâches sont donnés dans la figure ci-dessous.  Pour le cas à deux serveurs, nous rapportons la latence moyenne des deux serveurs.</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Les résultats montrent une fois de plus que le stockage réseau est suffisant pour gérer les tâches.  La différence entre le stockage local et le stockage réseau dans le cas d'un serveur unique est minime, voire nulle.  De même, lorsque deux serveurs utilisent le même stockage, la latence sur les deux serveurs reste la même ou change très légèrement.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inférence IA dans un scénario multiflux pour AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">Dans ce cas, le résultat est le nombre de flux que le système peut gérer tout en satisfaisant la contrainte QoS.  Ainsi, le résultat est toujours un entier.  Pour plusieurs serveurs, nous rapportons le nombre total de flux additionnés sur tous les serveurs.  Toutes les charges de travail ne prennent pas en charge ce scénario, mais nous avons exécuté celles qui le permettent. Les résultats de nos tests sont résumés dans la figure ci-dessous.  Dans le cas de deux serveurs, nous signalons le nombre combiné de flux provenant des deux serveurs.</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Les résultats montrent des performances parfaites de la configuration : le stockage local et réseau donne les mêmes résultats et l'ajout du deuxième serveur double le nombre de flux que la configuration proposée peut gérer.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Résultats des tests pour EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Une multitude de tests ont été effectués pour évaluer les performances de l’architecture proposée.  Il existe six charges de travail différentes (classification d'images, détection d'objets [petits], détection d'objets [grands], imagerie médicale, conversion de la parole en texte et traitement du langage naturel [NLP]), qui ont été exécutées dans deux scénarios différents : hors ligne et flux unique.  Les résultats sont décrits dans les sections suivantes.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inférence de l'IA dans un scénario hors ligne pour EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">Dans ce scénario, toutes les données étaient disponibles sur le serveur et le temps nécessaire au traitement de tous les échantillons a été mesuré.  Nous rapportons les bandes passantes en échantillons par seconde comme résultats des tests.  Pour les exécutions à nœud unique, nous rapportons la moyenne des deux serveurs, tandis que pour les exécutions à deux serveurs, nous rapportons la bande passante totale additionnée sur tous les serveurs.  Les résultats des cas d’utilisation sont présentés dans la figure ci-dessous.</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Inférence de l'IA dans un scénario à flux unique pour EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Ce benchmark mesure la latence.  Dans tous les cas, nous signalons la latence moyenne sur tous les serveurs impliqués dans les exécutions.  Les résultats de la série de tâches sont donnés.</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Les résultats montrent à nouveau que le stockage réseau est suffisant pour gérer les tâches.  La différence entre le stockage local et le stockage réseau dans le cas d'un serveur unique est minime, voire nulle.  De même, lorsque deux serveurs utilisent le même stockage, la latence sur les deux serveurs reste la même ou change très légèrement.</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Vous pouvez ajuster la configuration utilisée pour la validation afin de l'adapter à d'autres cas d'utilisation.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Options de dimensionnement de l'architecture</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">serveur de calcul</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Nous avons utilisé un processeur Intel Xeon D-2123IT, qui est le niveau de processeur le plus bas pris en charge dans SE350, avec quatre cœurs physiques et un TDP de 60 W.  Bien que le serveur ne prenne pas en charge le remplacement des processeurs, il peut être commandé avec un processeur plus puissant.  Le processeur le plus pris en charge est l'Intel Xeon D-2183IT avec 16 cœurs, 100 W fonctionnant à 2,20 GHz.  Cela augmente considérablement la capacité de calcul du processeur.  Bien que le processeur ne soit pas un goulot d’étranglement pour l’exécution des charges de travail d’inférence elles-mêmes, il aide au traitement des données et à d’autres tâches liées à l’inférence.  À l’heure actuelle, NVIDIA T4 est le seul GPU disponible pour les cas d’utilisation de pointe ; par conséquent, il n’existe actuellement aucune possibilité de mettre à niveau ou de rétrograder le GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Stockage partagé</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Pour les tests et la validation, le système NetApp AFF C190 , qui dispose d'une capacité de stockage maximale de 50,5 To, d'un débit de 4,4 Gbit/s pour les lectures séquentielles et de 230 000 IOPS pour les petites lectures aléatoires, a été utilisé dans le cadre de ce document et s'est avéré bien adapté aux charges de travail d'inférence de périphérie.</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">Toutefois, si vous avez besoin d'une plus grande capacité de stockage ou de vitesses de réseau plus rapides, vous devez utiliser les systèmes de stockage NetApp AFF A220 ou NetApp AFF A250 .  De plus, le système NetApp EF280, doté d'une capacité maximale de 1,5 Po et d'une bande passante de 10 Gbit/s, a également été utilisé pour la validation de cette solution.  Si vous préférez une plus grande capacité de stockage avec une bande passante plus élevée,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> peut être utilisé.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Cette section décrit les fondements technologiques de cette solution d’IA.</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">Systèmes NetApp AFF</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Les systèmes de stockage NetApp AFF de pointe permettent des déploiements d'inférence d'IA à la périphérie pour répondre aux exigences de stockage de l'entreprise avec des performances de pointe, une flexibilité supérieure, une intégration cloud et une gestion des données de premier ordre.  Conçus spécifiquement pour le flash, les systèmes NetApp AFF aident à accélérer, gérer et protéger les données critiques pour l'entreprise.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">Les systèmes de stockage NetApp AFF d'entrée de gamme sont basés sur le matériel FAS2750 et les supports flash SSD</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Deux contrôleurs en configuration HA</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">Les systèmes de stockage d'entrée de gamme NetApp AFF C190 prennent en charge les fonctionnalités suivantes :</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Un nombre maximal de disques SSD de 24x 960 Go</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Deux configurations possibles :</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10 GbE) : 4 ports 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unifié (16 Gb FC ou 10 GbE) : 4 ports d'adaptateur cible unifié 2 (UTA2)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Une capacité effective maximale de 50,5 To</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Pour les charges de travail NAS, un seul système AFF C190 d'entrée de gamme prend en charge un débit de 4,4 Gbit/s pour les lectures séquentielles et de 230 000 IOPS pour les petites lectures aléatoires à des latences de 1 ms ou moins.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp propose également d’autres systèmes de stockage d’entrée de gamme qui offrent des performances et une évolutivité supérieures pour les déploiements à plus grande échelle.  Pour les charges de travail NAS, un seul système AFF A220 d'entrée de gamme prend en charge :</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Débit de 6,2 Gbit/s pour les lectures séquentielles</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375 000 IOPS pour de petites lectures aléatoires avec des latences de 1 ms ou moins</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Nombre maximal de disques SSD : 144 x 960 Go, 3,8 To ou 7,6 To</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 peut évoluer jusqu'à une capacité effective supérieure à 1 Po</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">La capacité effective maximale est de 35 Po avec une évolutivité maximale de 2 à 24 nœuds (12 paires HA)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Offre une augmentation des performances ≥ 45 % par rapport à AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440 000 IOPS en lectures aléatoires à 1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Construit sur la dernière version de NetApp ONTAP : ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Exploite deux ports Ethernet 25 Gb pour l'interconnexion HA et cluster</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Systèmes EF NetApp série E</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">La série EF est une famille de baies de stockage SAN 100 % flash d'entrée et de milieu de gamme qui peuvent accélérer l'accès à vos données et vous aider à en tirer profit plus rapidement grâce au logiciel NetApp SANtricity .  Ces systèmes offrent à la fois un stockage flash SAS et NVMe et vous offrent des IOPS abordables à extrêmes, des temps de réponse inférieurs à 100 microsecondes et une bande passante allant jusqu'à 44 Gbit/s, ce qui les rend idéaux pour les charges de travail mixtes et les applications exigeantes telles que l'inférence IA et le calcul haute performance (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">La figure suivante montre le système de stockage NetApp EF280.</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Prise en charge FC 32 Go/16 Go, iSCSI 25 Go/10 Go et SAS 12 Go</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">La capacité effective maximale est de 96 disques totalisant 1,5 Po</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Débit de 10 Gbit/s (lectures séquentielles)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300 000 IOP (lectures aléatoires)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">Le NetApp EF280 est la baie entièrement flash (AFA) la moins chère du portefeuille NetApp</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 disques SSD NVMe pour une capacité totale de 367 To</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Options d'extension totalisant 240 disques durs NL-SAS, 96 SSD SAS ou une combinaison</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100 Go NVMe/IB, NVMe/RoCE, iSER/IB et SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">NVME/FC 32 Go, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">iSCSI 25 Go</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 Gbit/s (lectures séquentielles)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670 000 IOP (lectures aléatoires)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Fiche technique des NetApp 100 % flash NetApp EF-Series EF600, F300, EF570 et EF280</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Pour plus d'informations, consultez le<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> .</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser leur infrastructure et de passer à un centre de données prêt pour le cloud.  En s'appuyant sur des capacités de gestion de données de pointe, ONTAP permet la gestion et la protection des données avec un seul ensemble d'outils, quel que soit l'endroit où résident ces données.  Vous pouvez également déplacer librement les données là où elles sont nécessaires : vers la périphérie, le cœur ou le cloud.  ONTAP 9.8.1 inclut de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données critiques et permettent des capacités d'infrastructure de nouvelle génération dans les architectures de cloud hybride.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">La gestion des données est essentielle aux opérations informatiques de l’entreprise afin que les ressources appropriées soient utilisées pour les applications et les ensembles de données.  ONTAP inclut les fonctionnalités suivantes pour rationaliser et simplifier les opérations et réduire le coût total d'exploitation :</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Compactage des données en ligne et déduplication étendue.*  La compaction des données réduit l’espace gaspillé à l’intérieur des blocs de stockage et la déduplication augmente considérablement la capacité effective.  Cela s’applique aux données stockées localement et aux données hiérarchisées vers le cloud.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Qualité de service minimale, maximale et adaptative (AQoS).*  Les contrôles granulaires de qualité de service (QoS) aident à maintenir les niveaux de performances des applications critiques dans les environnements hautement partagés.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool.*  Cette fonctionnalité fournit une hiérarchisation automatique des données froides vers des options de stockage cloud publiques et privées, notamment Amazon Web Services (AWS), Azure et la solution de stockage NetApp StorageGRID .  Pour plus d'informations sur FabricPool, voir<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> .</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 offre des niveaux supérieurs de performances et de protection des données et étend ces capacités des manières suivantes :</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Performances et latence réduite.*  ONTAP offre le débit le plus élevé possible avec la latence la plus faible possible.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Protection des données.*  ONTAP fournit des fonctionnalités de protection des données intégrées avec une gestion commune sur toutes les plates-formes.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* Chiffrement de volume NetApp (NVE).*  ONTAP offre un cryptage natif au niveau du volume avec prise en charge de la gestion des clés intégrée et externe.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Authentification multi-locataire et multifacteur.*  ONTAP permet le partage des ressources d'infrastructure avec les plus hauts niveaux de sécurité.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 permet de répondre aux besoins commerciaux exigeants et en constante évolution grâce aux fonctionnalités suivantes :</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Mise à l'échelle transparente et opérations non perturbatrices.*  ONTAP prend en charge l'ajout non perturbateur de capacité aux contrôleurs existants et aux clusters évolutifs.  Les clients peuvent passer aux dernières technologies, telles que NVMe et FC 32 Go, sans migrations de données ni pannes coûteuses.</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*Connexion au Cloud.*  ONTAP est le logiciel de gestion de stockage le plus connecté au cloud, avec des options de stockage défini par logiciel (ONTAP Select) et des instances cloud natives (Google Cloud NetApp Volumes) dans tous les clouds publics.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Intégration avec les applications émergentes.*  ONTAP propose des services de données de niveau entreprise pour les plates-formes et applications de nouvelle génération, telles que les véhicules autonomes, les villes intelligentes et l'industrie 4.0, en utilisant la même infrastructure qui prend en charge les applications d'entreprise existantes.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Fiche technique du logiciel SANtricity NetApp E-Series</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity est conçu pour offrir des performances, une fiabilité et une simplicité de pointe aux baies hybrides Flash de la série E et aux baies entièrement Flash de la série EF.  Bénéficiez de performances et d'une utilisation maximales de vos baies hybrides Flash de la série E et de vos baies entièrement Flash de la série EF pour les applications à charge de travail élevée, notamment l'analyse de données, la vidéosurveillance, la sauvegarde et la récupération.  Avec SANtricity, les ajustements de configuration, la maintenance, l'extension de capacité et d'autres tâches peuvent être effectués pendant que le stockage reste en ligne.  SANtricity offre également une protection supérieure des données, une surveillance proactive et une sécurité certifiée, le tout accessible via l'interface System Manager intégrée et facile à utiliser.  Pour en savoir plus, consultez le<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> .</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Performances optimisées</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">Le logiciel SANtricity optimisé pour les performances fournit des données (avec des IOP élevées, un débit élevé et une faible latence) à toutes vos applications d'analyse de données, de vidéosurveillance et de sauvegarde.  Accélérez les performances des applications à IOPS élevé et à faible latence et des applications à bande passante élevée et à débit élevé.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Maximiser la disponibilité</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Effectuez toutes vos tâches de gestion pendant que le stockage reste en ligne.  Ajustez les configurations, effectuez la maintenance ou augmentez la capacité sans perturber les E/S.  Bénéficiez d'une fiabilité de premier ordre grâce à des fonctionnalités automatisées, une configuration en ligne, une technologie de pointe de pools de disques dynamiques (DPP) et bien plus encore.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Repose en paix</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">Le logiciel SANtricity offre une protection supérieure des données, une surveillance proactive et une sécurité certifiée, le tout via l'interface System Manager intégrée et facile à utiliser.  Simplifiez les tâches de gestion du stockage.  Bénéficiez de la flexibilité dont vous avez besoin pour un réglage avancé de tous les systèmes de stockage de la série E.  Gérez votre système NetApp E-Series, à tout moment et en tout lieu.  Notre interface Web intégrée rationalise votre flux de travail de gestion.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>de NetApp est un orchestrateur de stockage dynamique open source pour Docker et Kubernetes qui simplifie la création, la gestion et la consommation de stockage persistant.  Trident, une application native Kubernetes, s'exécute directement dans un cluster Kubernetes.  Trident permet aux clients de déployer de manière transparente des images de conteneurs DL sur le stockage NetApp et offre une expérience de niveau entreprise pour les déploiements de conteneurs IA.  Les utilisateurs de Kubernetes (tels que les développeurs ML et les scientifiques des données) peuvent créer, gérer et automatiser l'orchestration et le clonage pour tirer parti des fonctionnalités avancées de gestion des données de NetApp optimisées par la technologie NetApp .</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>est un service NetApp pour une synchronisation rapide et sécurisée des données.  Que vous ayez besoin de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, BlueXP Copy and Sync déplace les fichiers là où vous en avez besoin rapidement et en toute sécurité.  Une fois vos données transférées, elles sont entièrement disponibles pour une utilisation sur la source et la cible.  BlueXP Copy and Sync synchronise en continu les données, en fonction de votre calendrier prédéfini, en déplaçant uniquement les deltas, de sorte que le temps et l'argent consacrés à la réplication des données sont minimisés.  BlueXP Copy and Sync est un outil logiciel en tant que service (SaaS) extrêmement simple à configurer et à utiliser.  Les transferts de données déclenchés par BlueXP Copy and Sync sont effectués par des courtiers de données.  Vous pouvez déployer les courtiers de données BlueXP Copy and Sync dans AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">Les serveurs Lenovo ThinkSystem sont dotés de matériel, de logiciels et de services innovants qui résolvent les défis actuels des clients et offrent une approche de conception modulaire, évolutive et adaptée aux besoins pour relever les défis de demain.  Ces serveurs capitalisent sur les meilleures technologies standard de leur catégorie, associées aux innovations Lenovo différenciées pour offrir la plus grande flexibilité possible dans les serveurs x86.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Les principaux avantages du déploiement des serveurs Lenovo ThinkSystem incluent :</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Des conceptions hautement évolutives et modulaires pour évoluer avec votre entreprise</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Une résilience de pointe pour économiser des heures d'arrêts imprévus coûteux</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Technologies flash rapides pour des latences plus faibles, des temps de réponse plus rapides et une gestion des données plus intelligente en temps réel</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Dans le domaine de l’IA, Lenovo adopte une approche pratique pour aider les entreprises à comprendre et à adopter les avantages du ML et de l’IA pour leurs charges de travail.  Les clients Lenovo peuvent explorer et évaluer les offres Lenovo AI dans les centres d'innovation Lenovo AI pour comprendre pleinement la valeur de leur cas d'utilisation particulier.  Pour améliorer le délai de rentabilisation, cette approche centrée sur le client fournit aux clients une preuve de concept pour des plateformes de développement de solutions prêtes à l'emploi et optimisées pour l'IA.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">L'informatique de pointe permet d'analyser les données des appareils IoT à la périphérie du réseau avant d'être envoyées au centre de données ou au cloud.  Le Lenovo ThinkSystem SE350, comme illustré dans la figure ci-dessous, est conçu pour répondre aux exigences uniques du déploiement en périphérie, en mettant l'accent sur la flexibilité, la connectivité, la sécurité et la gestion à distance dans un format compact, robuste et respectueux de l'environnement.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Doté du processeur Intel Xeon D avec la flexibilité nécessaire pour prendre en charge l'accélération des charges de travail d'IA de pointe, le SE350 est spécialement conçu pour relever le défi des déploiements de serveurs dans divers environnements en dehors du centre de données.</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">Inférence MLPerf v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf est la suite de référence leader du secteur pour l'évaluation des performances de l'IA.  Il couvre de nombreux domaines de l’IA appliquée, notamment la classification d’images, la détection d’objets, l’imagerie médicale et le traitement du langage naturel (NLP).  Dans cette validation, nous avons utilisé les charges de travail Inference v0.7, qui est la dernière itération de l'inférence MLPerf à la fin de cette validation.  Le<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> La suite comprend quatre nouveaux benchmarks pour les centres de données et les systèmes périphériques :</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.*  Représentation d'encodeur bidirectionnel à partir de transformateurs (BERT) affinée pour répondre aux questions en utilisant l'ensemble de données SQuAD.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.*  Le modèle de recommandation d'apprentissage profond (DLRM) est un modèle de personnalisation et de recommandation formé pour optimiser les taux de clics (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.*  L'architecture 3D U-Net est formée sur l'ensemble de données de segmentation des tumeurs cérébrales (BraTS).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* Recurrent Neural Network Transducer (RNN-T) est un modèle de reconnaissance automatique de la parole (ASR) formé sur un sous-ensemble de LibriSpeech.  Les résultats et le code d'inférence MLPerf sont accessibles au public et publiés sous licence Apache.  MLPerf Inference dispose d'une division Edge, qui prend en charge les scénarios suivants :</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Flux unique.*  Ce scénario imite les systèmes dans lesquels la réactivité est un facteur critique, comme les requêtes d’IA hors ligne effectuées sur les smartphones.  Les requêtes individuelles sont envoyées au système et les temps de réponse sont enregistrés.  Le 90e percentile de latence de toutes les réponses est indiqué comme résultat.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multiflux.*  Cette référence est destinée aux systèmes qui traitent les entrées de plusieurs capteurs.  Pendant le test, les requêtes sont envoyées à un intervalle de temps fixe.  Une contrainte QoS (latence maximale autorisée) est imposée.  Le test indique le nombre de flux que le système peut traiter tout en respectant la contrainte QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Hors ligne.*  Il s’agit du scénario le plus simple couvrant les applications de traitement par lots et la mesure est le débit en échantillons par seconde.  Toutes les données sont disponibles pour le système et le benchmark mesure le temps nécessaire pour traiter tous les échantillons.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">Lenovo a publié les scores d'inférence MLPerf pour SE350 avec T4, le serveur utilisé dans ce document.  Voir les résultats sur<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> dans la section « Edge, Division fermée » dans l'entrée #0.7-145.</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">La configuration utilisée pour la validation peut être ajustée pour s'adapter à d'autres cas d'utilisation.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Ajustements d'architecture</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">La configuration utilisée pour cette validation peut être ajustée pour s'adapter à d'autres cas d'utilisation.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Réglages du processeur</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Nous avons utilisé un processeur Skylake Intel Xeon Platinum 8360Y pour cette validation, comme recommandé par Lenovo.  Nous nous attendons à ce que le processeur Cascade Lake équivalent, un processeur Intel Xeon Gold 6330, offre des performances similaires, car cette charge de travail n'est pas liée au processeur.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Augmentation de la capacité de stockage</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">En fonction de vos besoins en capacité de stockage, vous pouvez augmenter le stockage partagé (volume NFS) à la demande, à condition de disposer d'étagères de disques et de modèles de contrôleur supplémentaires.  Vous pouvez le faire à partir de l'interface de ligne de commande ou de l'interface Web NetApp du contrôleur de stockage en tant qu'utilisateur administrateur.</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Cette solution NetApp et Lenovo est une architecture évolutive flexible, idéale pour l’entrée dans l’IA d’entreprise de niveau intermédiaire.  Le stockage NetApp offre des performances identiques ou supérieures à celles du stockage SSD local et offre les avantages suivants aux scientifiques des données, aux ingénieurs de données et aux décideurs informatiques.</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">La solution NetApp et Lenovo validée ici est une architecture évolutive flexible, idéale pour l’entrée dans l’IA d’entreprise de niveau intermédiaire.</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">Le stockage NetApp offre des performances identiques ou supérieures à celles du stockage SSD local et offre les avantages suivants aux scientifiques des données, aux ingénieurs de données et aux décideurs informatiques :</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Calcul et stockage évolutifs indépendamment pour minimiser les coûts et améliorer l'utilisation des ressources.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Flux de travail de développement et de déploiement rationalisés à l'aide d'instantanés et de clones intégrés pour des espaces de travail utilisateur instantanés et peu encombrants, un contrôle de version intégré et un déploiement automatisé.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Protection des données de niveau entreprise pour la reprise après sinistre et la continuité des activités.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, ingénieur marketing technique, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, administrateur, systèmes de laboratoire d'IA, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Page produit des baies NetApp All Flash</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Page NetApp AFF A400</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Page produit du logiciel de gestion de données NetApp ONTAP</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SR670 V2 et les détails de provisionnement du stockage.</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SR670 V2 et les détails de provisionnement du stockage NetApp .</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Nous avons utilisé les composants de solution répertoriés dans le tableau suivant pour cette validation.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Deux serveurs SR670 V2 équipés chacun de huit cartes GPU NVIDIA A100 80 Go</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Chaque serveur contient 2 processeurs Intel Xeon Platinum 8360Y (28 cœurs physiques) et 1 To de RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 avec CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Système de stockage NetApp AFF (paire HA)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Logiciel NetApp ONTAP 9.10.1</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 groupe d'interfaces (ifgrp) par contrôleur, avec quatre adresses IP logiques pour les points de montage</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">Dans cette validation, nous avons utilisé ResNet v2.0 avec l'ensemble de base ImageNet tel que spécifié par MLPerf v2.0.  L'ensemble de données est stocké dans un système de stockage NetApp AFF avec le protocole NFS.  Les SR670 ont été connectés au système de stockage NetApp AFF A400 via un commutateur 100 GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet est un ensemble de données d'images fréquemment utilisé.  Il contient près de 1,3 million d'images pour une taille totale de 144 Go.  La taille moyenne de l'image est de 108 Ko.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">La figure suivante illustre la topologie du réseau de la configuration testée.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Ce graphique représente la couche de calcul, un Lenovo ThinkSystem SR670 V2, la couche réseau, un commutateur Ethernet Lenovo et la couche de stockage, un contrôleur de stockage NetApp AFF A400 .  Toutes les connexions réseau sont incluses.</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">Le tableau suivant répertorie la configuration de stockage.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Taille des agrégats</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Taille du volume</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Point de montage du système d'exploitation</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9,9 To</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 To</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">Le dossier /a400-100g contient l'ensemble de données utilisé pour la validation ResNet.</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">Cette section décrit les résultats détaillés de la procédure de test.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procédure de test et résultats détaillés</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Formation à la reconnaissance d'images avec ResNet dans ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Nous avons exécuté le benchmark ResNet50 avec un et deux serveurs SR670 V2.  Ce test a utilisé le conteneur MXNet 22.04-py3 NGC pour exécuter la formation.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Nous avons utilisé la procédure de test suivante dans cette validation :</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Nous avons vidé le cache de l'hôte avant d'exécuter le script pour nous assurer que les données n'étaient pas déjà mises en cache :</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Nous avons exécuté le script de référence avec l’ensemble de données ImageNet dans le stockage du serveur (stockage SSD local) ainsi que sur le système de stockage NetApp AFF .</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Nous avons validé les performances du réseau et du stockage local à l'aide de<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Pour l'exécution sur un seul nœud, nous avons utilisé la commande suivante :</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">Pour les exécutions distribuées, nous avons utilisé le modèle de parallélisation du serveur de paramètres.  Nous avons utilisé deux serveurs de paramètres par nœud et nous avons défini le nombre d'époques pour qu'il soit le même que pour l'exécution à nœud unique.  Nous avons fait cela parce que la formation distribuée prend souvent plus d’époques en raison d’une synchronisation imparfaite entre les processus.  Le nombre différent d’époques peut fausser les comparaisons entre les cas à nœud unique et les cas distribués.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Vitesse de lecture des données : stockage local ou réseau</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">La vitesse de lecture a été testée en utilisant le<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande sur l'un des fichiers de l'ensemble de données ImageNet.  Plus précisément, nous avons exécuté les commandes suivantes pour les données locales et réseau :</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Les deux valeurs sont similaires, ce qui démontre que le stockage réseau peut fournir des données à un débit similaire au stockage local.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Cas d'utilisation partagé : tâches multiples, indépendantes et simultanées</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Ce test a simulé le cas d’utilisation attendu pour cette solution : formation d’IA multi-tâches et multi-utilisateurs.  Chaque nœud a exécuté sa propre formation tout en utilisant le stockage réseau partagé.  Les résultats sont affichés dans la figure suivante, qui montre que le cas de solution a fourni d’excellentes performances avec tous les travaux exécutés essentiellement à la même vitesse que les travaux individuels.  Le débit total évolue linéairement avec le nombre de nœuds.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Cette figure montre les images agrégées par seconde.</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Cette figure montre le temps d'exécution en minutes.</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Ces graphiques présentent le temps d'exécution en minutes et les images agrégées par seconde pour les nœuds de calcul qui ont utilisé huit GPU de chaque serveur sur un réseau client 100 GbE, combinant à la fois le modèle de formation simultanée et le modèle de formation unique.  La durée moyenne d’exécution du modèle de formation était de 35 minutes et 9 secondes.  Les durées individuelles étaient de 34 minutes et 32 secondes, 36 minutes et 21 secondes, 34 minutes et 37 secondes, 35 minutes et 25 secondes et 34 minutes et 31 secondes.  Le nombre moyen d'images par seconde pour le modèle d'entraînement était de 22 573, et le nombre d'images individuelles par seconde était de 21 764 ; 23 438 ; 22 556 ; 22 564 ; et 22 547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">Sur la base de notre validation, un modèle de formation indépendant avec un temps d'exécution de données NetApp était de 34 minutes et 54 secondes avec 22 231 images/s.  Un modèle de formation indépendant avec une durée d'exécution de données locales (DAS) était de 34 minutes et 21 secondes avec 22 102 images/sec.  Au cours de ces exécutions, l'utilisation moyenne du GPU était de 96 %, comme observé sur nvidia-smi.  Notez que cette moyenne inclut la phase de test, pendant laquelle les GPU n'ont pas été utilisés, tandis que l'utilisation du CPU était de 40 % telle que mesurée par mpstat.  Cela démontre que le débit de livraison des données est suffisant dans chaque cas.</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Cette solution se concentre sur l'architecture de cluster d'entrée et de milieu de gamme utilisant le stockage NetApp et les serveurs Lenovo optimisés pour les charges de travail d'intelligence artificielle.  Il est destiné aux équipes de petite et moyenne taille pour lesquelles la plupart des tâches de calcul sont mono-nœud (GPU unique ou multi-GPU) ou sont réparties sur quelques nœuds de calcul.  Il ne s’agit pas d’une limitation majeure, car la plupart des tâches quotidiennes de formation de l’IA concernent un seul nœud.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810 : NetApp AFF A400 avec Lenovo ThinkSystem SR670 V2 pour la formation de modèles d'IA et de ML</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Cette solution présente une architecture de cluster de milieu de gamme utilisant le stockage NetApp et les serveurs Lenovo optimisés pour les charges de travail d'intelligence artificielle (IA).  Il est destiné aux petites et moyennes entreprises pour lesquelles la plupart des tâches de calcul sont à nœud unique (GPU unique ou multi-GPU) ou réparties sur quelques nœuds de calcul.  Cette solution s’aligne sur la plupart des tâches quotidiennes de formation à l’IA pour de nombreuses entreprises.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Ce document couvre les tests et la validation d'une configuration de calcul et de stockage composée de huit serveurs Lenovo SR670V2 à GPU, d'un système de stockage NetApp AFF A400 de milieu de gamme et d'un commutateur d'interconnexion 100 GbE.  Pour mesurer les performances, nous avons utilisé ResNet50 avec l'ensemble de données ImageNet, une taille de lot de 408, une demi-précision, CUDA et cuDNN.  Cette architecture offre une solution efficace et rentable pour les petites et moyennes entreprises qui débutent avec des initiatives d'IA nécessitant les capacités de niveau entreprise du stockage de données connecté au cloud NetApp ONTAP .</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Scientifiques des données, ingénieurs des données, administrateurs de données et développeurs de systèmes d'IA</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Architectes d'entreprise qui conçoivent des solutions pour le développement de modèles d'IA</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Les scientifiques et ingénieurs de données qui recherchent des moyens efficaces pour atteindre les objectifs de développement de l'apprentissage profond (DL) et de l'apprentissage automatique (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Les dirigeants d'entreprise et les décideurs OT/IT qui souhaitent obtenir le délai de mise sur le marché le plus rapide possible pour les initiatives d'IA</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Cette solution avec serveurs Lenovo ThinkSystem et NetApp ONTAP avec stockage AFF est conçue pour gérer la formation de l'IA sur de grands ensembles de données en utilisant la puissance de traitement des GPU aux côtés des CPU traditionnels.  Cette validation démontre des performances élevées et une gestion optimale des données avec une architecture évolutive qui utilise un, deux ou quatre serveurs Lenovo SR670 V2 avec un seul système de stockage NetApp AFF A400 .  La figure suivante fournit un aperçu architectural.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Cette image représente un commutateur Ethernet entouré du serveur de gestion, de quatre SR670 V2 avec huit GPU chacun et d'un système de stockage NetApp ONTAP .</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Performances hautement efficaces et rentables lors de l'exécution de plusieurs tâches de formation en parallèle</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Performances évolutives basées sur différents nombres de serveurs Lenovo et différents modèles de contrôleurs de stockage NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Protection robuste des données pour atteindre des objectifs de points de récupération (RPO) et de temps de récupération (RTO) faibles sans perte de données</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gestion optimisée des données avec des instantanés et des clones pour rationaliser les flux de travail de développement</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">Dans cette validation, nous avons effectué une formation de reconnaissance d'image comme spécifié par MLPerf v2.0.  Plus précisément, nous avons formé le modèle ResNet v2.0 avec l’ensemble de données ImageNet.  La mesure principale est le temps nécessaire pour atteindre la précision souhaitée.  Nous rapportons également la bande passante d'entraînement en images par seconde pour mieux évaluer l'efficacité de la mise à l'échelle.</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">Dans cette validation, nous avons effectué une formation de reconnaissance d'image comme spécifié par MLPerf v2.0.  Plus précisément, nous avons formé le modèle ResNet v2.0 avec l'ensemble de données ImageNet jusqu'à atteindre une précision de 76,1 %.  La mesure principale est le temps nécessaire pour atteindre la précision souhaitée.  Nous rapportons également la bande passante d'entraînement en images par seconde pour mieux évaluer l'efficacité de la mise à l'échelle.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">Le cas de test principal a évalué plusieurs processus de formation indépendants (un par nœud) exécutés simultanément.  Cela simule le cas d’utilisation principal, un système partagé utilisé par plusieurs scientifiques de données.  Le deuxième cas de test a évalué l’efficacité de la mise à l’échelle.</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">Cette section résume les résultats des tests dans cette solution.</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">Le tableau suivant résume les résultats de tous les tests effectués pour cette solution.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Description du test</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Résumé des résultats</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Formation à la reconnaissance d'images : plusieurs tâches simultanées</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Performances hautement efficaces.  Tous les travaux s'exécutaient à pleine vitesse même lorsque le cluster était entièrement utilisé.  Les systèmes de stockage NetApp ont fourni des performances de formation comparables au stockage SSD local tout en permettant un partage facile des données entre les serveurs.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Formation à la reconnaissance d'images : mise à l'échelle</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Très efficace pour jusqu'à quatre nœuds.  À ce stade, la mise à l’échelle était moins efficace mais toujours faisable.  L’utilisation d’un réseau informatique à plus grande vitesse améliore l’évolutivité.  Le système de stockage NetApp a fourni des performances de formation comparables au stockage SSD local tout en permettant un partage facile des données entre les serveurs.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">Cette section présente plus en détail les principaux composants de cette solution.</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">Les systèmes de stockage NetApp AFF permettent aux entreprises de répondre aux exigences de stockage d'entreprise avec des performances de pointe, une flexibilité supérieure, une intégration cloud et une gestion des données de premier ordre.  Conçus spécifiquement pour le flash, les systèmes AFF aident à accélérer, gérer et protéger les données critiques de l'entreprise.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Ce graphique représente l’avant du contrôleur de stockage NetApp AFF A400 .</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Ce graphique représente l’arrière du contrôleur de stockage NetApp AFF A400 .</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400 est un système de stockage flash NVMe de milieu de gamme qui comprend les fonctionnalités suivantes :</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">Capacité effective maximale : ~20 Po</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Évolutivité maximale : 2 à 24 nœuds (12 paires HA)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Prise en charge des hôtes FC 25 GbE et 16 Gb</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Connectivité RDMA 100 GbE sur Ethernet convergé (RoCE) vers les étagères de stockage d'extension NVMe</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">Les ports RoCE 100 GbE peuvent être utilisés pour la connexion au réseau hôte si les étagères NVMe ne sont pas connectées</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Étagères de stockage d'extension de connectivité SAS 12 Gbit/s complètes</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Disponible en deux configurations :</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet : 4 ports Ethernet 25 Gb (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Fibre Channel : 4 ports FC 16 Go (SFP+)</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">Lecture aléatoire à 100 % de 8 Ko à 0,4 ms, 400 000 IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Les fonctionnalités de NetApp AFF A250 pour les déploiements IA/ML d'entrée de gamme incluent les suivantes :</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacité effective maximale : 35 Po</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Échelle maximale : 2 à 24 nœuds (12 paires HA)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Construit sur la dernière version de NetApp ONTAP ONTAP 9.8 ou ultérieure</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Deux ports Ethernet 25 Gb pour l'interconnexion HA et cluster</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp propose également d'autres systèmes de stockage, tels que l' AFF A800 et AFF A700, qui offrent des performances et une évolutivité supérieures pour les déploiements d'IA/ML à plus grande échelle.</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser leur infrastructure et de passer à un centre de données prêt pour le cloud.  En s'appuyant sur des capacités de gestion de données de pointe, ONTAP permet la gestion et la protection des données avec un seul ensemble d'outils, quel que soit l'endroit où résident ces données.  Les données peuvent également être déplacées librement là où elles sont nécessaires : vers la périphérie, le cœur ou le cloud.  ONTAP 9 inclut de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données critiques et garantissent une infrastructure pérenne dans les architectures de cloud hybride.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Qualité de service (QoS) minimale, maximale et adaptative.*  Les contrôles QoS granulaires aident à maintenir les niveaux de performances des applications critiques dans les environnements hautement partagés.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*  Cette fonctionnalité hiérarchise automatiquement les données froides vers des options de stockage cloud publiques et privées, notamment Amazon Web Services (AWS), Azure et le stockage d'objets NetApp StorageGRID .</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*Performances et latence réduite.*  ONTAP offre le débit le plus élevé possible avec la latence la plus faible possible.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* Chiffrement de volume NetApp .*  ONTAP offre un cryptage natif au niveau du volume avec prise en charge de la gestion des clés intégrée et externe.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 permet de répondre aux besoins métiers exigeants et en constante évolution :</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Mise à l'échelle transparente et opérations non perturbatrices.*  ONTAP prend en charge l'ajout non perturbateur de capacité aux contrôleurs existants ainsi qu'aux clusters évolutifs.  Les clients peuvent passer aux dernières technologies, telles que NVMe et FC 32 Go, sans migrations de données ni pannes coûteuses.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Intégration avec les applications émergentes.*  ONTAP propose des services de données de niveau entreprise pour les plates-formes et applications de nouvelle génération telles qu'OpenStack, Hadoop et MongoDB en utilisant la même infrastructure qui prend en charge les applications d'entreprise existantes.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">Volumes NetApp FlexGroup</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">Les ensembles de données de formation sont généralement une collection de milliards de fichiers potentiels.  Les fichiers peuvent inclure du texte, de l'audio, de la vidéo et d'autres formes de données non structurées qui doivent être stockées et traitées pour être lues en parallèle.  Le système de stockage doit stocker de nombreux petits fichiers et doit lire ces fichiers en parallèle pour les E/S séquentielles et aléatoires.</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Un volume FlexGroup (figure suivante) est un espace de noms unique composé de plusieurs volumes membres constitutifs qui est géré et agit comme un FlexVol volume NetApp FlexVol pour les administrateurs de stockage.  Les fichiers d'un volume FlexGroup sont alloués à des volumes membres individuels et ne sont pas répartis sur des volumes ou des nœuds.  Ils permettent les capacités suivantes :</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Jusqu'à 20 pétaoctets de capacité et une faible latence prévisible pour les charges de travail à métadonnées élevées</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Jusqu'à 400 milliards de fichiers dans le même espace de noms</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Opérations parallélisées dans les charges de travail NAS sur les processeurs, les nœuds, les agrégats et les volumes FlexVol constitutifs</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">Cette image représente une paire HA de contrôleurs de stockage contenant de nombreux volumes avec des fichiers principaux dans un FlexGroup.</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Gamme Lenovo ThinkSystem</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Les principaux avantages du déploiement des serveurs Lenovo ThinkSystem sont les suivants :</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Des conceptions hautement évolutives et modulaires qui évoluent avec votre entreprise</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">Dans le domaine de l’IA, Lenovo adopte une approche pratique pour aider les entreprises à comprendre et à adopter les avantages du ML et de l’IA pour leurs charges de travail.  Les clients Lenovo peuvent explorer et évaluer les offres Lenovo AI dans les centres d'innovation Lenovo AI pour comprendre pleinement la valeur de leur cas d'utilisation particulier.  Pour améliorer le délai de rentabilisation, cette approche centrée sur le client fournit aux clients des preuves de concept pour des plateformes de développement de solutions prêtes à l'emploi et optimisées pour l'IA.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Le serveur rack Lenovo ThinkSystem SR670 V2 offre des performances optimales pour l'IA accélérée et le calcul haute performance (HPC).  Prenant en charge jusqu'à huit GPU, le SR670 V2 est adapté aux exigences de charge de travail intensives en calcul du ML, du DL et de l'inférence.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Cette image illustre trois configurations SR670.  Le premier montre quatre GPU SXM avec huit disques HS de 2,5 pouces et 2 emplacements d'E/S PCIe.  Le deuxième présente quatre emplacements GPU double largeur ou huit emplacements GPU simple largeur et deux emplacements E/S PCIe avec huit disques HS de 2,5 pouces ou quatre disques HS de 3,5 pouces.  Le troisième présente huit emplacements GPU double largeur avec six disques EDSFF HS et deux emplacements d'E/S PCIe.</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Avec les derniers processeurs Intel Xeon évolutifs prenant en charge les GPU haut de gamme (y compris le GPU NVIDIA A100 80 Go PCIe 8x), le ThinkSystem SR670 V2 offre des performances optimisées et accélérées pour les charges de travail d'IA et de HPC.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">Étant donné que davantage de charges de travail utilisent les performances des accélérateurs, la demande de densité GPU a augmenté.  Des secteurs tels que la vente au détail, les services financiers, l’énergie et la santé utilisent des GPU pour extraire de meilleures informations et stimuler l’innovation grâce aux techniques de ML, de DL et d’inférence.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">Le ThinkSystem SR670 V2 est une solution optimisée de niveau entreprise pour le déploiement de charges de travail HPC et IA accélérées en production, maximisant les performances du système tout en maintenant la densité du centre de données pour les clusters de supercalcul avec des plates-formes de nouvelle génération.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Les autres fonctionnalités incluent :</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Prise en charge des E/S RDMA directes du GPU dans lesquelles les adaptateurs réseau haut débit sont directement connectés aux GPU pour maximiser les performances d'E/S.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">Prise en charge du stockage direct GPU dans lequel les disques NVMe sont directement connectés aux GPU pour maximiser les performances de stockage.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf est la suite de référence leader du secteur pour l'évaluation des performances de l'IA.  Dans cette validation, nous avons utilisé son benchmark de classification d'images avec MXNet, l'un des frameworks d'IA les plus populaires.  Le script de formation MXNet_benchmarks a été utilisé pour piloter la formation de l'IA.  Le script contient des implémentations de plusieurs modèles conventionnels populaires et est conçu pour être aussi rapide que possible.  Il peut être exécuté sur une seule machine ou exécuté en mode distribué sur plusieurs hôtes.</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">Cet article présente une conception de référence validée de NetApp AIPod pour Enterprise RAG avec les technologies et les capacités combinées des processeurs Intel Xeon 6 et des solutions de gestion de données NetApp .  La solution démontre une application ChatQnA en aval exploitant un modèle linguistique de grande taille, fournissant des réponses précises et contextuellement pertinentes aux utilisateurs simultanés.  Les réponses sont récupérées à partir du référentiel de connaissances interne d'une organisation via un pipeline d'inférence RAG isolé.</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - Inférence RAG d'entreprise avec NetApp et Intel</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">Logo Intel</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">Un nombre croissant d’organisations exploitent des applications de génération augmentée de récupération (RAG) et des modèles de langage volumineux (LLM) pour interpréter les invites des utilisateurs et générer des réponses afin d’augmenter la productivité et la valeur commerciale.  Ces invites et réponses peuvent inclure du texte, du code, des images ou même des structures de protéines thérapeutiques récupérées à partir de la base de connaissances interne d'une organisation, des lacs de données, des référentiels de codes et des référentiels de documents.  Cet article couvre la conception de référence de la solution NetApp AIPod Mini, comprenant le stockage NetApp AFF et les serveurs équipés de processeurs Intel Xeon 6.  Il comprend le logiciel de gestion de données NetApp ONTAP combiné à Intel Advanced Matrix Extensions (Intel AMX) et au logiciel Intel AI for Enterprise Retrieval-augmented Generation (RAG) basé sur Open Platform for Enterprise AI (OPEA).  Le NetApp AIPod Mini pour RAG d'entreprise permet aux organisations d'augmenter un LLM public en une solution d'inférence d'IA générative privée (GenAI).  La solution démontre une inférence RAG efficace et rentable à l'échelle de l'entreprise, conçue pour améliorer la fiabilité et vous offrir un meilleur contrôle sur vos informations propriétaires.</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">Validation des partenaires de stockage Intel</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">Les serveurs équipés de processeurs Intel Xeon 6 sont conçus pour gérer des charges de travail d'inférence d'IA exigeantes, en utilisant Intel AMX pour des performances maximales.  Pour permettre des performances de stockage et une évolutivité optimales, la solution a été validée avec succès à l'aide de NetApp ONTAP, permettant aux entreprises de répondre aux besoins des applications RAG.  Cette validation a été réalisée sur des serveurs équipés de processeurs Intel Xeon 6.  Intel et NetApp ont un partenariat solide axé sur la fourniture de solutions d’IA optimisées, évolutives et alignées sur les exigences commerciales des clients.</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">Avantages de l'exécution de systèmes RAG avec NetApp</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">Les applications RAG impliquent la récupération de connaissances à partir des référentiels de documents des entreprises sous différents types tels que PDF, texte, CSV, Excel ou graphiques de connaissances.  Ces données sont normalement stockées dans des solutions telles qu'un stockage d'objets S3 ou NFS sur site comme source de données.  NetApp est un leader dans les technologies de gestion des données, de mobilité des données, de gouvernance des données et de sécurité des données dans l'écosystème de la périphérie, du centre de données et du cloud.  La gestion des données NetApp ONTAP fournit un stockage de niveau entreprise pour prendre en charge différents types de charges de travail d'IA, y compris l'inférence par lots et en temps réel, et offre certains des avantages suivants :</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">Vitesse et évolutivité.  Vous pouvez gérer de grands ensembles de données à grande vitesse pour le contrôle de version avec la possibilité de faire évoluer les performances et la capacité de manière indépendante.</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">Accès aux données.  La prise en charge multiprotocole permet aux applications clientes de lire des données à l'aide des protocoles de partage de fichiers S3, NFS et SMB.  Les buckets NAS ONTAP S3 peuvent faciliter l'accès aux données dans les scénarios d'inférence LLM multimodaux.</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">Fiabilité et confidentialité.  ONTAP offre une protection des données, une protection autonome contre les ransomwares NetApp intégrée (ARP) et un provisionnement dynamique du stockage. Il offre également un cryptage logiciel et matériel pour améliorer la confidentialité et la sécurité.  ONTAP est conforme à la norme FIPS 140-2 pour toutes les connexions SSL.</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">Ce document est destiné aux décideurs en matière d’IA, aux ingénieurs de données, aux chefs d’entreprise et aux cadres de service qui souhaitent profiter d’une infrastructure conçue pour fournir des solutions RAG et GenAI d’entreprise.  Une connaissance préalable de l'inférence de l'IA, des LLM, de Kubernetes, de la mise en réseau et de ses composants sera utile pendant la phase de mise en œuvre.</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">Technologies d'IA d'Intel</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Processeur Xeon 6</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">Avec Xeon 6 comme processeur hôte, les systèmes accélérés bénéficient de performances monothread élevées, d'une bande passante mémoire plus élevée, d'une fiabilité, d'une disponibilité et d'une facilité d'entretien (RAS) améliorées et de davantage de voies d'E/S.  Intel AMX accélère l'inférence pour INT8 et BF16 et offre une prise en charge des modèles formés FP16, avec jusqu'à 2 048 opérations à virgule flottante par cycle et par cœur pour INT8 et 1 024 opérations à virgule flottante par cycle et par cœur pour BF16/FP16.  Pour déployer une solution RAG utilisant des processeurs Xeon 6, une RAM minimale de 250 Go et un espace disque de 500 Go sont généralement recommandés.  Cependant, cela dépend fortement de la taille du modèle LLM.  Pour plus d'informations, reportez-vous à la documentation Intel<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block> fiche produit.</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300 300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">Figure 1 - Serveur de calcul avec processeurs Intel Xeon 6<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">Stockage NetApp AFF</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">Les systèmes NetApp AFF A-Series d'entrée de gamme et de milieu de gamme offrent des performances plus puissantes, une densité plus élevée et une plus grande efficacité.  Les systèmes NetApp AFF A20, AFF A30 et AFF A50 offrent un véritable stockage unifié qui prend en charge les blocs, les fichiers et les objets, basé sur un système d'exploitation unique capable de gérer, de protéger et de mobiliser de manière transparente les données pour les applications RAG au coût le plus bas dans le cloud hybride.</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">Figure 2 - Système NetApp AFF série A.<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Matériel*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*Quantité*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*Commentaire*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">Serveur basé sur Intel Xeon 6</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">Nœuds d'inférence RAG : avec processeurs Intel Xeon série 6900 ou Intel Xeon série 6700 à double socket et 250 Go à 3 To de RAM avec DDR5 (6 400 MHz) ou MRDIMM (8 800 MHz).  Serveur 2U.</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Serveur de plan de contrôle avec processeur Intel</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Plan de contrôle Kubernetes/serveur 1U.</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">Choix de commutateur Ethernet 100 Gb</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">Commutateur de centre de données.</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20 (ou AFF A30 ; AFF A50)</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">Capacité de stockage maximale : 9,3 Po.  Remarque : mise en réseau : ports 10/25/100 GbE.</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">Pour la validation de cette conception de référence, des serveurs équipés de processeurs Intel Xeon 6 de Supermicro (222HA-TN-OTO-37) et d'un commutateur 100GbE d'Arista (7280R3A) ont été utilisés.</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">Plateforme ouverte pour l'IA d'entreprise</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">L'Open Platform for Enterprise AI (OPEA) est une initiative open source dirigée par Intel en collaboration avec des partenaires de l'écosystème.  Il fournit une plate-forme modulaire de blocs de construction composables conçus pour accélérer le développement de systèmes d'IA génératifs de pointe, avec un fort accent sur RAG.  OPEA comprend un cadre complet comprenant des LLM, des magasins de données, des moteurs d'invite, des plans architecturaux RAG et une méthode d'évaluation en quatre étapes qui évalue les systèmes d'IA génératifs en fonction des performances, des fonctionnalités, de la fiabilité et de la préparation de l'entreprise.</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">À la base, l'OPEA comprend deux éléments clés :</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps : une boîte à outils basée sur les services composée de composants de microservices</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">Exemples GenAI : des solutions prêtes à être déployées comme ChatQnA qui illustrent des cas d'utilisation pratiques</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">Documentation du projet OPEA</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">Pour plus de détails, voir le<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">Intel AI for Enterprise inference optimisé par OPEA</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">OPEA pour Intel AI for Enterprise RAG simplifie la transformation de vos données d'entreprise en informations exploitables.  Alimenté par des processeurs Intel Xeon, il intègre des composants de partenaires industriels pour offrir une approche simplifiée du déploiement de solutions d'entreprise.  Il s'adapte de manière transparente aux cadres d'orchestration éprouvés, offrant la flexibilité et le choix dont votre entreprise a besoin.</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">S'appuyant sur les fondations d'OPEA, Intel AI for Enterprise RAG étend cette base avec des fonctionnalités clés qui améliorent l'évolutivité, la sécurité et l'expérience utilisateur.  Ces fonctionnalités incluent des capacités de maillage de services pour une intégration transparente avec les architectures modernes basées sur les services, une validation prête pour la production pour la fiabilité du pipeline et une interface utilisateur riche en fonctionnalités pour RAG en tant que service, permettant une gestion et une surveillance faciles des flux de travail.  De plus, Intel et le support de ses partenaires offrent l'accès à un vaste écosystème de solutions, associé à une gestion intégrée des identités et des accès (IAM) avec interface utilisateur et applications pour des opérations sécurisées et conformes.  Les garde-fous programmables offrent un contrôle précis du comportement du pipeline, permettant des paramètres de sécurité et de conformité personnalisés.</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">En savoir plus sur la configuration ONTAP S3</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP est la technologie fondamentale qui sous-tend les solutions de stockage de données critiques de NetApp.  ONTAP comprend diverses fonctionnalités de gestion et de protection des données, telles que la protection automatique contre les ransomwares contre les cyberattaques, des fonctionnalités de transport de données intégrées et des capacités d'efficacité de stockage.  Ces avantages s’appliquent à une gamme d’architectures, du sur site au multicloud hybride en NAS, SAN, objet et stockage défini par logiciel pour les déploiements LLM.  Vous pouvez utiliser un serveur de stockage d'objets ONTAP S3 dans un cluster ONTAP pour déployer des applications RAG, en tirant parti de l'efficacité du stockage et de la sécurité d' ONTAP, fournies par les utilisateurs autorisés et les applications clientes.  Pour plus d'informations, reportez-vous à<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">NetApp Trident sur Git</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">Le logiciel NetApp Trident est un orchestrateur de stockage open source et entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Red Hat OpenShift.  Trident fonctionne avec l'ensemble du portefeuille de stockage NetApp , y compris NetApp ONTAP , et prend également en charge les connexions NFS et iSCSI.  Pour plus d'informations, reportez-vous à<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Logiciel*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*Version*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">OPEA pour Intel AI pour Enterprise RAG</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">Plateforme RAG d'entreprise basée sur les microservices OPEA</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">Interface de stockage de conteneurs (pilote CSI)</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">Permet le provisionnement dynamique, les copies NetApp Snapshot et les volumes.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">Système d'exploitation sur un cluster à deux nœuds</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">Orchestration des conteneurs</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">Environnement pour exécuter le framework RAG</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">Stockage OS sur AFF A20.  Il comprend Vscan et ARP.</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">Déploiement de la solution</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">Pile logicielle</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">La solution est déployée sur un cluster Kubernetes composé de nœuds d’application basés sur Intel Xeon.  Au moins trois nœuds sont nécessaires pour implémenter la haute disponibilité de base pour le plan de contrôle Kubernetes.  Nous avons validé la solution en utilisant la disposition de cluster suivante.</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">Tableau 3 - Disposition du cluster Kubernetes</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nœud</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Rôle</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Serveurs avec processeurs Intel Xeon 6 et 1 To de RAM</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">Nœud d'application, nœud de plan de contrôle</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">Serveur générique</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">Nœud de plan de contrôle</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600 600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">La figure suivante illustre une « vue de la pile logicielle » de la solution.<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">Étapes de déploiement</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">Déployer un dispositif de stockage ONTAP</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">Documentation des systèmes matériels ONTAP</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">Déployez et provisionnez votre appliance de stockage NetApp ONTAP .  Se référer à la<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">Configurer une SVM ONTAP pour l'accès NFS et S3</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Configurez une machine virtuelle de stockage ONTAP (SVM) pour l’accès NFS et S3 sur un réseau accessible par vos nœuds Kubernetes.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">Documentation ONTAP .</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">Pour créer une SVM à l’aide d’ ONTAP System Manager, accédez à Stockage &gt; Machines virtuelles de stockage, puis cliquez sur le bouton + Ajouter.  Lorsque vous activez l'accès S3 pour votre SVM, choisissez l'option permettant d'utiliser un certificat signé par une autorité de certification externe, et non un certificat généré par le système.  Vous pouvez utiliser un certificat auto-signé ou un certificat signé par une autorité de certification publiquement approuvée.  Pour plus de détails, reportez-vous à la<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">La capture d’écran suivante illustre la création d’un SVM à l’aide d’ ONTAP System Manager.  Modifiez les détails selon vos besoins en fonction de votre environnement.</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">Figure 4 - Création de SVM à l'aide d' ONTAP System Manager.<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">Configurer les autorisations S3</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">Configurez les paramètres utilisateur/groupe S3 pour le SVM que vous avez créé à l’étape précédente.  Assurez-vous d’avoir un utilisateur avec un accès complet à toutes les opérations de l’API S3 pour ce SVM.  Reportez-vous à la documentation ONTAP S3 pour plus de détails.</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">Remarque : cet utilisateur sera nécessaire pour le service d’ingestion de données de l’application Intel AI for Enterprise RAG.  Si vous avez créé votre SVM à l'aide d' ONTAP System Manager, System Manager aura automatiquement créé un utilisateur nommé<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> et une politique nommée<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> lorsque vous avez créé votre SVM, mais aucune autorisation ne vous aura été attribuée<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> .</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">Pour modifier les autorisations de cet utilisateur, accédez à Stockage &gt; Machines virtuelles de stockage, cliquez sur le nom de la SVM que vous avez créée à l'étape précédente, cliquez sur Paramètres, puis sur l'icône en forme de crayon à côté de « S3 ».  Donner<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> accès complet à toutes les opérations de l'API S3, créez un nouveau groupe qui associe<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> avec le<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> politique telle que décrite dans la capture d'écran suivante.</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">Figure 5 - Autorisations S3.</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">Créer un bucket S3</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">Créez un bucket S3 dans la SVM que vous avez créée précédemment.  Pour créer un SVM à l’aide d’ ONTAP System Manager, accédez à Stockage &gt; Buckets et cliquez sur le bouton + Ajouter.  Pour plus de détails, reportez-vous à la documentation ONTAP S3.</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">La capture d’écran suivante illustre la création d’un bucket S3 à l’aide d’ ONTAP System Manager.</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">Figure 6 – Créer un bucket S3.<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">Configurer les autorisations du compartiment S3</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">Configurez les autorisations pour le compartiment S3 que vous avez créé à l’étape précédente.  Assurez-vous que l’utilisateur que vous avez configuré à une étape précédente dispose des autorisations suivantes :<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">Documentation ONTAP S3</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">Pour modifier les autorisations du compartiment S3 à l’aide d’ ONTAP System Manager, accédez à Stockage &gt; Compartiments, cliquez sur le nom de votre compartiment, cliquez sur Autorisations, puis sur Modifier.  Se référer à la<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">La capture d’écran suivante illustre les autorisations de compartiment nécessaires dans ONTAP System Manager.</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">Figure 7 - Autorisations du compartiment S3.<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">Créer une règle de partage de ressources inter-origines de bucket</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">À l'aide de l'interface de ligne de commande ONTAP , créez une règle de partage de ressources inter-origines (CORS) pour le bucket que vous avez créé à l'étape précédente :</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">Cette règle permet à l'application Web OPEA pour Intel AI for Enterprise RAG d'interagir avec le bucket à partir d'un navigateur Web.</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">Déployer des serveurs</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">Déployez vos serveurs et installez Ubuntu 22.04 LTS sur chaque serveur.  Une fois Ubuntu installé, installez les utilitaires NFS sur chaque serveur.  Pour installer les utilitaires NFS, exécutez la commande suivante :</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">Installer Kubernetes</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Documentation de Kubespray</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">Installez Kubernetes sur vos serveurs à l’aide de Kubespray.  Se référer à la<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">Installer le pilote Trident CSI</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Documentation d'installation de Trident</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">Installez le pilote NetApp Trident CSI dans votre cluster Kubernetes.  Se référer à la<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">Créer un back-end Trident</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Documentation du back-end de Trident</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">Créez un back-end Trident pour le SVM que vous avez créé précédemment.  Lors de la création de votre back-end, utilisez le<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> conducteur.  Se référer à la<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">Créer une classe de stockage</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">Créez une classe de stockage Kubernetes correspondant au back-end Trident que vous avez créé à l’étape précédente.  Reportez-vous à la documentation de la classe de stockage Trident pour plus de détails.</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">Déploiement de l'IA Intel pour le RAG d'entreprise</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">Installez OPEA pour Intel AI for Enterprise RAG dans votre cluster Kubernetes.  Se référer à la<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block> documentation pour plus de détails.  Assurez-vous de prendre note des modifications requises du fichier de configuration qui sont décrites plus loin dans ce document.  Vous devez effectuer ces modifications avant d’exécuter le playbook d’installation afin que l’application Intel AI for Enterprise RAG fonctionne correctement avec votre système de stockage ONTAP .</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">Activer l'utilisation d' ONTAP S3</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">Lors de l'installation d'OPEA pour Intel AI for Enterprise RAG, modifiez votre fichier de configuration principal pour permettre l'utilisation d' ONTAP S3 comme référentiel de données source.</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">Pour activer l'utilisation d' ONTAP S3, définissez les valeurs suivantes dans le<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block> section.</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">Remarque : par défaut, l’application Intel AI for Enterprise RAG ingère les données de tous les compartiments existants dans votre SVM.  Si vous avez plusieurs buckets dans votre SVM, vous pouvez modifier le<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block> champ afin que les données soient ingérées uniquement à partir de certains compartiments.</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">Configurer les paramètres de synchronisation planifiée</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">Lors de l'installation de l'application OPEA pour Intel AI for Enterprise RAG, activez<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> afin que l'application ingère automatiquement les fichiers nouveaux ou mis à jour à partir de vos buckets S3.</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">Quand<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> est activé, l'application vérifie automatiquement vos buckets S3 sources pour les fichiers nouveaux ou mis à jour.  Tous les fichiers nouveaux ou mis à jour trouvés dans le cadre de ce processus de synchronisation sont automatiquement ingérés et ajoutés à la base de connaissances RAG.  L'application vérifie vos buckets sources en fonction d'un intervalle de temps prédéfini.  L'intervalle de temps par défaut est de 60 secondes, ce qui signifie que l'application vérifie les modifications toutes les 60 secondes.  Vous souhaiterez peut-être modifier cet intervalle en fonction de vos besoins spécifiques.</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">Pour activer<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> et définissez l'intervalle de synchronisation, définissez les valeurs suivantes dans<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">Modifier les modes d'accès au volume</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">Dans<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block> , pour chaque volume du<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> liste, changer le<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> à<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> .</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">(Facultatif) Désactiver la vérification du certificat SSL</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">Si vous avez utilisé un certificat auto-signé lors de l’activation de l’accès S3 pour votre SVM, vous devez désactiver la vérification du certificat SSL.  Si vous avez utilisé un certificat signé par une autorité de certification publiquement approuvée, vous pouvez ignorer cette étape.</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">Pour désactiver la vérification du certificat SSL, définissez les valeurs suivantes dans<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">Accédez à OPEA pour Intel AI pour l'interface utilisateur RAG d'entreprise</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">Documentation sur le déploiement d'Intel AI for Enterprise RAG</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">Accédez à l'interface utilisateur RAG d'OPEA pour Intel AI for Enterprise.  Se référer à la<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">Figure 8 - OPEA pour Intel AI pour l'interface utilisateur RAG d'entreprise.<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">Ingérer des données pour RAG</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">Vous pouvez désormais ingérer des fichiers à inclure dans l’augmentation des requêtes basée sur RAG.  Il existe plusieurs options pour ingérer des fichiers.  Choisissez l'option appropriée à vos besoins.</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">Remarque : une fois qu’un fichier a été ingéré, l’application OPEA pour Intel AI for Enterprise RAG recherche automatiquement les mises à jour du fichier et ingère les mises à jour en conséquence.</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*Option 1 : télécharger directement dans votre bucket S3 Pour ingérer plusieurs fichiers à la fois, nous vous recommandons de télécharger les fichiers dans votre bucket S3 (le bucket que vous avez créé précédemment) en utilisant le client S3 de votre choix.  Les clients S3 populaires incluent AWS CLI, Amazon SDK pour Python (Boto3), s3cmd, S3 Browser, Cyberduck et Commander One.  Si les fichiers sont d'un type pris en charge, tous les fichiers que vous téléchargez dans votre compartiment S3 seront automatiquement ingérés par l'application OPEA pour Intel AI for Enterprise RAG.</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">Remarque : au moment de la rédaction de cet article, les types de fichiers suivants sont pris en charge : PDF, HTML, TXT, DOC, DOCX, PPT, PPTX, MD, XML, JSON, JSONL, YAML, XLS, XLSX, CSV, TIFF, JPG, JPEG, PNG et SVG.</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">Vous pouvez utiliser l’interface utilisateur OPEA pour Intel AI for Enterprise RAG pour confirmer que vos fichiers ont été correctement ingérés.  Reportez-vous à la documentation de l'interface utilisateur Intel AI for Enterprise RAG pour plus de détails.  Notez que l’application peut prendre un certain temps pour ingérer un grand nombre de fichiers.</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*Option 2 : Télécharger à l'aide de l'interface utilisateur Si vous devez ingérer uniquement un petit nombre de fichiers, vous pouvez les ingérer à l'aide de l'interface utilisateur RAG d'OPEA pour Intel AI for Enterprise.  Reportez-vous à la documentation de l'interface utilisateur Intel AI for Enterprise RAG pour plus de détails.</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">Figure 9 - Interface utilisateur d'ingestion de données.<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">Exécuter des requêtes de chat</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">Vous pouvez désormais « discuter » avec l'application OPEA pour Intel AI for Enterprise RAG en utilisant l'interface utilisateur de chat incluse.  Lorsqu'elle répond à vos requêtes, l'application exécute RAG en utilisant vos fichiers ingérés.  Cela signifie que l'application recherche automatiquement les informations pertinentes dans vos fichiers ingérés et intègre ces informations lorsqu'elle répond à vos requêtes.</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">Dans le cadre de nos efforts de validation, nous avons effectué des tests de performances en coordination avec Intel.  Ces tests ont permis d’établir les recommandations de dimensionnement décrites dans le tableau suivant.</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">Caractérisations</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valeur</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">Taille du modèle</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">20 milliards de paramètres</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Llama-8B, Llama-13B, Mistral 7B, Qwen 14B, DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">Taille d'entrée</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">~2 000 jetons</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">~4 pages</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">Taille de sortie</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">Utilisateurs simultanés</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">« Utilisateurs simultanés » fait référence aux demandes d'invite qui soumettent des requêtes en même temps.</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_Remarque : les conseils de dimensionnement présentés ci-dessus sont basés sur la validation des performances et les résultats des tests recueillis à l’aide de processeurs Intel Xeon 6 avec 96 cœurs.  Pour les clients ayant des exigences similaires en matière de jetons d'E/S et de taille de modèle, nous recommandons d'utiliser des serveurs équipés de processeurs Xeon 6 à 96 ou 128 cœurs.</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">Les systèmes RAG d’entreprise et les LLM sont des technologies qui fonctionnent ensemble pour aider les organisations à fournir des réponses précises et contextuelles.  Ces réponses impliquent une recherche d’informations basée sur une vaste collection de données privées et internes à l’entreprise.  En utilisant RAG, les API, les intégrations vectorielles et les systèmes de stockage hautes performances pour interroger les référentiels de documents contenant des données d'entreprise, les données sont traitées plus rapidement et en toute sécurité.  Le NetApp AIPod Mini combine l'infrastructure de données intelligente de NetApp avec les capacités de gestion des données ONTAP et les processeurs Intel Xeon 6, Intel AI for Enterprise RAG et la pile logicielle OPEA pour aider à déployer des applications RAG hautes performances et mettre les organisations sur la voie du leadership en matière d'IA.</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">Reconnaissance</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">Ce document est l'œuvre de Sathish Thyagarajan et Michael Ogelsby, membres de l'équipe d'ingénierie des solutions NetApp .  Les auteurs souhaitent également remercier l'équipe produit Enterprise AI d'Intel (Ajay Mungara, Mikolaj Zyczynski, Igor Konopko, Ramakrishna Karamsetty, Michal Prostko, Shreejan Mistry et Ned Fiori) ainsi que les autres membres de l'équipe de NetApp(Lawrence Bunka, Bobby Oommen et Jeff Liborio) pour leur soutien et leur aide continus lors de la validation de cette solution.</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">Nomenclature</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">Ce qui suit est la nomenclature utilisée pour la validation fonctionnelle de cette solution et peut être utilisée comme référence.  Tout serveur ou composant réseau (ou même un réseau existant avec de préférence une bande passante de 100 GbE) qui correspond à la configuration suivante peut être utilisé.</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">Pour le serveur d'applications :</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*Référence*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*Description du produit*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">Hyper SuperServer SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">BÉLIER</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">Mémoire RDIMM ECC MEM-DR564MC-ER64(x16) 64 Go DDR5-6400 2RX4 (16 Go)</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960 Go 1DWPD TLC D, 80 mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">Alimentation à sortie unique redondante WS-1K63A-1R(x2)1U 692W/1600W.  Dissipation thermique de 2361 BTU/h avec une température maximale de 59 °C (environ)</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">Pour le serveur de contrôle :</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">OPTIMISÉ 1U X13SCH-SYS, CSE-813MF2TS-R0RCNBP, PWS-602A-1R</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16 Go DDR5-4800 1Rx8 (16 Go) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">Pour le commutateur réseau :</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">Stockage NetApp AFF :</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">Système AFF A20 HA, -C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">Jumper Crd, en cabine, C13-C14, -C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">Alimentation, 1600 W, titane, -C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">Câble, 100 GbE, QSFP28-QSFP28, Cu, 2 m, -C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">Câble, 25 GbE, SFP28-SFP28, Cu, 0,5 m, -C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">Rail, 4 poteaux, mince, trou rond/carré, petit, réglable, 24-32, -C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">Pack de disques 2 x 1,92 To, NVMe4, SED, -C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">Module d'E/S, 2PT, 100 GbE, -C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">Module d'E/S, 4 PT, 10/25 GbE, -C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW, package de base ONTAP , par To, Flash, A20, -C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">Projet OPEA</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">Manuel de déploiement d'OPEA Enterprise RAG</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851 : Lac de données NetApp StorageGRID pour les charges de travail de conduite autonome – Conception de solutions</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 démontre l'utilisation du stockage d'objets NetApp StorageGRID comme référentiel de données et système de gestion pour le développement de logiciels d'apprentissage automatique (ML) et d'apprentissage profond (DL).  Cet article décrit le flux de données et les exigences du développement de logiciels de véhicules autonomes ainsi que les fonctionnalités de StorageGRID qui rationalisent le cycle de vie des données.  Cette solution s’applique à tout flux de travail de pipeline de données à plusieurs étapes typique des processus de développement ML et DL.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Mentions légales</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Les mentions légales donnent accès aux déclarations de droits d'auteur, aux marques déposées, aux brevets et bien plus encore.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Copyright</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marques de commerce</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, le logo NETAPP et les marques répertoriées sur la page Marques NetApp sont des marques commerciales de NetApp, Inc. Les autres noms de sociétés et de produits peuvent être des marques commerciales de leurs propriétaires respectifs.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevets</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Une liste actuelle des brevets détenus par NetApp est disponible à l'adresse suivante :</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Politique de confidentialité</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Pour cette validation, nous avons effectué des inférences pour un cas d’utilisation de détection d’images en utilisant un ensemble d’images brutes.  Nous avons ensuite effectué la même tâche d’inférence sur le même ensemble d’images avec l’obfuscation Protopia ajoutée avant l’inférence.  Nous avons répété la tâche en utilisant différentes valeurs d'ALPHA pour le composant d'obfuscation Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Comparaison de la précision des inférences</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Pour cette validation, nous avons effectué des inférences pour un cas d’utilisation de détection d’images en utilisant un ensemble d’images brutes.  Nous avons ensuite effectué la même tâche d’inférence sur le même ensemble d’images avec l’obfuscation Protopia ajoutée avant l’inférence.  Nous avons répété la tâche en utilisant différentes valeurs d'ALPHA pour le composant d'obfuscation Protopia.  Dans le contexte de l'obfuscation Protopia, la valeur ALPHA représente la quantité d'obfuscation appliquée, une valeur ALPHA plus élevée représentant un niveau d'obfuscation plus élevé.  Nous avons ensuite comparé la précision des inférences entre ces différentes exécutions.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Les deux tableaux suivants fournissent des détails sur notre cas d’utilisation et décrivent les résultats.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia travaille directement avec les clients pour déterminer la valeur ALPHA appropriée pour un cas d'utilisation spécifique.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Ensemble de données FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Obfuscation de Protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALPHA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Précision</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Non</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">S/O</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0,9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Oui</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0,05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0,9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0,1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0,9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0,2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0,9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0,4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0,9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0,6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0,8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0,8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0,8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0,9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0,8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0,95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">Où trouver des informations supplémentaires et des remerciements</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI — Inférence confidentielle</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">Serveur d'inférence NVIDIA Triton</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentation du serveur d'inférence NVIDIA Triton</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBox dans PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, chef de produit principal, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, ingénieur marketing technique, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, directeur de la technologie et professeur, Protopia AI</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Les données existent dans trois états : au repos, en transit et en cours de calcul.  Un élément important de tout service d’inférence d’IA devrait être la protection des données contre les menaces tout au long du processus.  La protection des données pendant l’inférence est essentielle car le processus peut exposer des informations privées sur les clients externes et sur l’entreprise fournissant le service d’inférence.</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">Les données existent dans trois états : au repos, en transit et en cours de calcul.  Un élément important de tout service d’inférence d’IA devrait être la protection des données contre les menaces tout au long du processus.  La protection des données pendant l’inférence est essentielle car le processus peut exposer des informations privées sur les clients externes et sur l’entreprise fournissant le service d’inférence.  Protopia AI est une solution logicielle non intrusive pour l'inférence confidentielle de l'IA sur le marché actuel.  Avec Protopia, l’IA est alimentée uniquement par les informations transformées dans les enregistrements de données qui sont essentielles à la réalisation de la tâche d’IA/ML en cours et rien de plus.  Cette transformation stochastique n’est pas une forme de masquage et est basée sur la modification mathématique de la représentation des données en utilisant un bruit organisé.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">Les systèmes de stockage NetApp dotés de fonctionnalités ONTAP offrent des performances identiques ou supérieures à celles du stockage SSD local et, combinés à la boîte à outils NetApp DataOps, offrent les avantages suivants aux scientifiques des données, aux ingénieurs de données, aux développeurs d'IA/ML et aux décideurs informatiques d'entreprise :</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Protection des données de niveau entreprise et gouvernance des données pour la reprise après sinistre, la continuité des activités et les exigences réglementaires.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Appel simplifié des opérations de gestion des données ; prenez rapidement des copies instantanées des espaces de travail des scientifiques de données pour la sauvegarde et la traçabilité à partir de la boîte à outils NetApp DataOps dans les blocs-notes Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">La solution NetApp et Protopia fournit une architecture flexible et évolutive, idéale pour les déploiements d'inférence d'IA de niveau entreprise.  Il permet la protection des données et garantit la confidentialité des informations sensibles lorsque les exigences d'inférence d'IA confidentielles peuvent être satisfaites avec des pratiques d'IA responsables dans les déploiements sur site et dans le cloud hybride.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Cette section décrit l’environnement de validation de la conception de la solution.</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">Le tableau suivant décrit l’environnement de validation de la conception de la solution.</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">Pilote CSI NetApp Trident</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Boîte à outils NetApp DataOps pour Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Ce document décrit une solution de conception validée dans trois scénarios différents avec et sans obscurcissement d'image, pertinents pour préserver la confidentialité et déployer une solution d'IA responsable.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928 : IA responsable et inférence confidentielle – NetApp AI avec Protopia Image and Data Transformation</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Les interprétations visuelles sont devenues partie intégrante de la communication avec l’émergence de la capture et du traitement d’images.  L’intelligence artificielle (IA) dans le traitement d’images numériques offre de nouvelles opportunités commerciales, comme dans le domaine médical pour l’identification du cancer et d’autres maladies, dans l’analyse visuelle géospatiale pour l’étude des risques environnementaux, dans la reconnaissance de formes, dans le traitement vidéo pour la lutte contre la criminalité, etc.  Mais cette opportunité s’accompagne également de responsabilités extraordinaires.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Plus les organisations confient de décisions à l’IA, plus elles acceptent les risques liés à la confidentialité et à la sécurité des données, ainsi qu’aux questions juridiques, éthiques et réglementaires.  L’IA responsable permet une pratique qui permet aux entreprises et aux organisations gouvernementales de renforcer la confiance et la gouvernance, ce qui est crucial pour l’IA à grande échelle dans les grandes entreprises.  Ce document décrit une solution d'inférence d'IA validée par NetApp dans trois scénarios différents en utilisant les technologies de gestion de données NetApp avec le logiciel d'obscurcissement des données Protopia pour privatiser les données sensibles et réduire les risques et les préoccupations éthiques.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Des millions d’images sont générées chaque jour à l’aide de divers appareils numériques, tant par les consommateurs que par les entreprises.  L’explosion massive des données et de la charge de travail informatique qui en résulte incite les entreprises à se tourner vers les plateformes de cloud computing pour gagner en évolutivité et en efficacité.  Parallèlement, des préoccupations en matière de confidentialité des informations sensibles contenues dans les données d’image surviennent lors du transfert vers un cloud public.  Le manque de garanties de sécurité et de confidentialité devient le principal obstacle au déploiement des systèmes d’IA de traitement d’images.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">droit à l'effacement</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Loi sur la protection des renseignements personnels</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">De plus, il y a le<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> par le RGPD, le droit d'un individu de demander à une organisation d'effacer toutes ses données personnelles.  Il y a aussi le<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block> , qui établit un code de pratiques équitables en matière d’information.  Les images numériques telles que les photographies peuvent constituer des données personnelles au sens du RGPD, qui régit la manière dont les données doivent être collectées, traitées et effacées.  Le non-respect de ces règles constitue un manquement au RGPD, ce qui peut entraîner de lourdes amendes pour violation des règles de conformité, ce qui peut être gravement préjudiciable aux organisations.  Les principes de confidentialité sont l’un des piliers de la mise en œuvre d’une IA responsable qui garantit l’équité dans les prédictions des modèles d’apprentissage automatique (ML) et d’apprentissage profond (DL) et réduit les risques associés à la violation de la confidentialité ou de la conformité réglementaire.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Ce document décrit une solution de conception validée dans trois scénarios différents avec et sans obscurcissement d'image, pertinents pour préserver la confidentialité et déployer une solution d'IA responsable :</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Scénario 1.*  Inférence à la demande dans le notebook Jupyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Scénario 2.*  Inférence par lots sur Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Scénario 3.*  Serveur d'inférence NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Pour cette solution, nous utilisons le Face Detection Data Set and Benchmark (FDDB), un ensemble de données de régions de visage conçu pour étudier le problème de la détection de visage sans contrainte, combiné au framework d'apprentissage automatique PyTorch pour la mise en œuvre de FaceBoxes.  Cet ensemble de données contient les annotations de 5171 visages dans un ensemble de 2845 images de différentes résolutions.  En outre, ce rapport technique présente certains des domaines de solution et des cas d’utilisation pertinents recueillis auprès des clients NetApp et des ingénieurs de terrain dans les situations où cette solution est applicable.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Ce rapport technique est destiné aux publics suivants :</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Dirigeants d'entreprise et architectes d'entreprise qui souhaitent concevoir et déployer une IA responsable et répondre aux problèmes de protection des données et de confidentialité concernant le traitement des images faciales dans les espaces publics.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Scientifiques des données, ingénieurs des données, chercheurs en IA/apprentissage automatique (ML) et développeurs de systèmes d'IA/ML qui visent à protéger et à préserver la confidentialité.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Architectes d'entreprise qui conçoivent des solutions d'obscurcissement des données pour les modèles et applications d'IA/ML conformes aux normes réglementaires telles que le RGPD, le CCPA ou la loi sur la confidentialité du ministère de la Défense (DoD) et des organisations gouvernementales.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Les scientifiques des données et les ingénieurs en IA recherchent des moyens efficaces de déployer des modèles d'apprentissage profond (DL) et d'inférence IA/ML/DL qui protègent les informations sensibles.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Cette solution est conçue pour gérer les charges de travail d'IA d'inférence en temps réel et par lots sur de grands ensembles de données en utilisant la puissance de traitement des GPU aux côtés des CPU traditionnels.  Cette validation démontre l’inférence préservant la confidentialité pour le ML et la gestion optimale des données requises pour les organisations recherchant des déploiements d’IA responsables.  Cette solution fournit une architecture adaptée à une plate-forme Kubernetes à nœud unique ou multi-nœuds pour le edge computing et le cloud computing interconnectés avec NetApp ONTAP AI au cœur sur site, NetApp DataOps Toolkit et le logiciel d'obfuscation Protopia utilisant Jupyter Lab et les interfaces CLI.  La figure suivante montre l’aperçu de l’architecture logique de Data Fabric optimisé par NetApp avec DataOps Toolkit et Protopia.</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Le logiciel d'obfuscation Protopia s'exécute de manière transparente sur la boîte à outils NetApp DataOps et transforme les données avant de quitter le serveur de stockage.</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Cette section fournit un aperçu des trois scénarios validés dans cette solution.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Plan de test et de validation</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Pour cette conception de solution, les trois scénarios suivants ont été validés :</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Une tâche d'inférence, avec et sans obscurcissement Protopia, dans un espace de travail JupyterLab qui a été orchestré à l'aide de NetApp DataOps Toolkit pour Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Un travail d'inférence par lots, avec et sans obscurcissement Protopia, sur Kubernetes avec un volume de données orchestré à l'aide de NetApp DataOps Toolkit pour Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Une tâche d'inférence utilisant une instance NVIDIA Triton Inference Server orchestrée à l'aide de NetApp DataOps Toolkit pour Kubernetes.  Nous avons appliqué l'obfuscation Protopia à l'image avant d'invoquer l'API d'inférence Triton pour simuler l'exigence courante selon laquelle toutes les données transmises sur le réseau doivent être obscurcies.  Ce flux de travail s'applique aux cas d'utilisation où les données sont collectées dans une zone de confiance mais doivent être transmises en dehors de cette zone de confiance pour l'inférence.  Sans l'obfuscation Protopia, il n'est pas possible de mettre en œuvre ce type de flux de travail sans que des données sensibles ne quittent la zone de confiance.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">Cette section décrit les tâches nécessaires pour terminer la validation.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prérequis</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Pour exécuter les tâches décrites dans cette section, vous devez avoir accès à un hôte Linux ou macOS avec les outils suivants installés et configurés :</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (configuré pour accéder à un cluster Kubernetes existant)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Les instructions d'installation et de configuration peuvent être trouvées<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> .</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Les instructions d'installation peuvent être trouvées<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> .</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Scénario 1 – Inférence à la demande dans JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Créez un espace de noms Kubernetes pour les charges de travail d’inférence AI/ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Utilisez la boîte à outils NetApp DataOps pour provisionner un volume persistant pour stocker les données sur lesquelles vous effectuerez l’inférence.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Utilisez la boîte à outils NetApp DataOps pour créer un nouvel espace de travail JupyterLab.  Montez le volume persistant qui a été créé à l'étape précédente en utilisant le<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> option.  Allouez les GPU NVIDIA à l'espace de travail si nécessaire en utilisant le<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> option.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">Dans l'exemple suivant, le volume persistant<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> est monté sur le conteneur d'espace de travail JupyterLab à<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> .  Lors de l'utilisation d'images de conteneur officielles du projet Jupyter,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> est présenté comme le répertoire de niveau supérieur dans l'interface Web JupyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Accédez à l'espace de travail JupyterLab en utilisant l'URL spécifiée dans la sortie du<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> commande.  Le répertoire de données représente le volume persistant qui a été monté sur l’espace de travail.</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Ouvrez le<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> répertoire et téléchargez les fichiers sur lesquels l'inférence doit être effectuée.  Lorsque des fichiers sont téléchargés dans le répertoire de données, ils sont automatiquement stockés sur le volume persistant qui a été monté sur l'espace de travail.  Pour télécharger des fichiers, cliquez sur l’icône Télécharger des fichiers, comme indiqué dans l’image suivante.</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Revenez au répertoire de niveau supérieur et créez un nouveau bloc-notes.</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Ajoutez du code d’inférence au bloc-notes.  L'exemple suivant montre le code d'inférence pour un cas d'utilisation de détection d'image.</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Ajoutez l’obfuscation Protopia à votre code d’inférence.  Protopia travaille directement avec les clients pour fournir une documentation spécifique au cas d'utilisation et n'entre pas dans le cadre de ce rapport technique.  L'exemple suivant montre le code d'inférence pour un cas d'utilisation de détection d'image avec l'obfuscation Protopia ajoutée.</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Scénario 2 – Inférence par lots sur Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Remplissez le nouveau volume persistant avec les données sur lesquelles vous effectuerez l’inférence.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Fonctionnalités de NetApp DataOps Toolkit S3 Data Mover</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">Il existe plusieurs méthodes pour charger des données sur un PVC.  Si vos données sont actuellement stockées sur une plateforme de stockage d'objets compatible S3, telle que NetApp StorageGRID ou Amazon S3, vous pouvez utiliser<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> .  Une autre méthode simple consiste à créer un espace de travail JupyterLab, puis à télécharger des fichiers via l'interface Web JupyterLab, comme indiqué dans les étapes 3 à 5 de la section «<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> ."</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Créez une tâche Kubernetes pour votre tâche d’inférence par lots.  L'exemple suivant montre un travail d'inférence par lots pour un cas d'utilisation de détection d'images.  Ce travail effectue des inférences sur chaque image d'un ensemble d'images et écrit les mesures de précision des inférences sur stdout.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Confirmez que le travail d’inférence s’est terminé avec succès.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Ajoutez l’obfuscation Protopia à votre travail d’inférence.  Vous pouvez trouver des instructions spécifiques au cas d'utilisation pour ajouter l'obfuscation Protopia directement à partir de Protopia, ce qui n'entre pas dans le cadre de ce rapport technique.  L'exemple suivant montre un travail d'inférence par lots pour un cas d'utilisation de détection de visage avec l'obfuscation Protopia ajoutée à l'aide d'une valeur ALPHA de 0,8.  Ce travail applique l'obfuscation Protopia avant d'effectuer l'inférence pour chaque image d'un ensemble d'images, puis écrit les mesures de précision de l'inférence sur stdout.</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">Comparaison de la précision des inférences.</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">Nous avons répété cette étape pour les valeurs ALPHA 0,05, 0,1, 0,2, 0,4, 0,6, 0,8, 0,9 et 0,95.  Vous pouvez voir les résultats dans<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Scénario 3 – Serveur d'inférence NVIDIA Triton</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Utilisez NetApp DataOps Toolkit pour provisionner un volume persistant à utiliser comme référentiel modèle pour le serveur d’inférence NVIDIA Triton.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">format</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">Stockez votre modèle sur le nouveau volume persistant dans un<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> qui est reconnu par le serveur d'inférence NVIDIA Triton.</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">Il existe plusieurs méthodes pour charger des données sur un PVC.  Une méthode simple consiste à créer un espace de travail JupyterLab, puis à télécharger des fichiers via l'interface Web JupyterLab, comme indiqué dans les étapes 3 à 5 de «<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> .  "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Utilisez NetApp DataOps Toolkit pour déployer une nouvelle instance de NVIDIA Triton Inference Server.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Utilisez un SDK client Triton pour effectuer une tâche d’inférence.  L'extrait de code Python suivant utilise le SDK client Python Triton pour effectuer une tâche d'inférence pour un cas d'utilisation de détection de visage.  Cet exemple appelle l’API Triton et transmet une image pour l’inférence.  Le serveur d'inférence Triton reçoit ensuite la demande, appelle le modèle et renvoie la sortie d'inférence dans le cadre des résultats de l'API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Ajoutez l’obfuscation Protopia à votre code d’inférence.  Vous pouvez trouver des instructions spécifiques au cas d'utilisation pour ajouter l'obfuscation Protopia directement à partir de Protopia ; cependant, ce processus n'entre pas dans le cadre de ce rapport technique.  L'exemple suivant montre le même code Python que celui présenté à l'étape 5 précédente, mais avec l'obfuscation Protopia ajoutée.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Notez que l'obfuscation Protopia est appliquée à l'image avant qu'elle ne soit transmise à l'API Triton.  Ainsi, l’image non obscurcie ne quitte jamais la machine locale.  Seule l’image obscurcie est transmise sur le réseau.  Ce flux de travail s'applique aux cas d'utilisation dans lesquels les données sont collectées dans une zone de confiance, mais doivent ensuite être transmises en dehors de cette zone de confiance pour l'inférence.  Sans l'obfuscation Protopia, il n'est pas possible de mettre en œuvre ce type de flux de travail sans que des données sensibles ne quittent la zone de confiance.</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Pour cette validation, nous avons appliqué l'obfuscation Protopia à une image de 1920 x 1080 pixels cinq fois et mesuré le temps nécessaire à l'étape d'obfuscation à chaque fois.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Vitesse d'obscurcissement</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">Nous avons utilisé PyTorch exécuté sur un seul GPU NVIDIA V100 pour appliquer l'obfuscation, et nous avons vidé le cache du GPU entre les exécutions.  L'étape d'obscurcissement a pris respectivement 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms et 4,84 ms pour être terminée sur les cinq exécutions.  La vitesse moyenne était de 5,072 ms.</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Cette section fournit un aperçu des différents composants techniques nécessaires pour compléter cette solution.</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopie</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI propose aujourd'hui sur le marché une solution discrète et logicielle pour l'inférence confidentielle.  La solution Protopia offre une protection inégalée pour les services d’inférence en minimisant l’exposition des informations sensibles.  L’IA est uniquement alimentée par les informations contenues dans l’enregistrement de données qui sont véritablement essentielles pour effectuer la tâche à accomplir et rien de plus.  La plupart des tâches d’inférence n’utilisent pas toutes les informations qui existent dans chaque enregistrement de données.  Que votre IA consomme des images, de la voix, de la vidéo ou même des données tabulaires structurées, Protopia fournit uniquement ce dont le service d'inférence a besoin.  La technologie de base brevetée utilise un bruit organisé mathématiquement pour transformer de manière stochastique les données et brouiller les informations qui ne sont pas nécessaires à un service ML donné.  Cette solution ne masque pas les données ; elle modifie plutôt la représentation des données en utilisant un bruit aléatoire organisé.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">La solution Protopia formule le problème de la modification de la représentation sous la forme d'une méthode de maximisation des perturbations basée sur le gradient qui conserve toujours les informations pertinentes dans l'espace des caractéristiques d'entrée par rapport à la fonctionnalité du modèle.  Ce processus de découverte est exécuté comme une étape de réglage fin à la fin de la formation du modèle ML.  Une fois que le passage génère automatiquement un ensemble de distributions de probabilité, une transformation de données à faible surcharge applique des échantillons de bruit de ces distributions aux données, les obscurcissant avant de les transmettre au modèle pour inférence.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">L'architecture de référence NetApp ONTAP AI, optimisée par les systèmes DGX A100 et les systèmes de stockage connectés au cloud NetApp , a été développée et vérifiée par NetApp et NVIDIA.  Il offre aux organisations informatiques une architecture qui offre les avantages suivants :</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Élimine les complexités de conception</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Permet une mise à l'échelle indépendante du calcul et du stockage</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Permet aux clients de démarrer petit et d'évoluer de manière transparente</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Offre une gamme d'options de stockage pour différents niveaux de performance et de coût</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI intègre étroitement les systèmes DGX A100 et les systèmes de stockage NetApp AFF A800 avec un réseau de pointe.  ONTAP AI simplifie les déploiements d’IA en éliminant la complexité de conception et les conjectures.  Les clients peuvent commencer petit et se développer sans interruption tout en gérant intelligemment les données de la périphérie au cœur, jusqu'au cloud et inversement.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">La figure suivante montre plusieurs variantes de la famille de solutions ONTAP AI avec les systèmes DGX A100.  Les performances du système AFF A800 sont vérifiées avec jusqu'à huit systèmes DGX A100.  En ajoutant des paires de contrôleurs de stockage au cluster ONTAP , l'architecture peut évoluer vers plusieurs racks pour prendre en charge de nombreux systèmes DGX A100 et des pétaoctets de capacité de stockage avec des performances linéaires.  Cette approche offre la flexibilité de modifier les ratios de calcul/stockage de manière indépendante en fonction de la taille des modèles DL utilisés et des mesures de performances requises.</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153 : NetApp ONTAP AI avec systèmes NVIDIA DGX A100 et commutateurs Ethernet Mellanox Spectrum.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Pour plus d'informations sur ONTAP AI, consultez<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser leur infrastructure et de passer à un centre de données prêt pour le cloud.  En s'appuyant sur des capacités de gestion de données de pointe, ONTAP permet la gestion et la protection des données avec un seul ensemble d'outils, quel que soit l'endroit où résident ces données.  Vous pouvez également déplacer librement les données là où elles sont nécessaires : vers la périphérie, le cœur ou le cloud.  ONTAP 9.11 inclut de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données critiques et permettent des capacités d'infrastructure de nouvelle génération dans les architectures de cloud hybride.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit est une bibliothèque Python qui permet aux développeurs, aux scientifiques des données, aux ingénieurs DevOps et aux ingénieurs de données d'effectuer facilement diverses tâches de gestion des données, telles que le provisionnement quasi instantané d'un nouveau volume de données ou d'un espace de travail JupyterLab, le clonage quasi instantané d'un volume de données ou d'un espace de travail JupyterLab et la prise quasi instantanée d'instantanés d'un volume de données ou d'un espace de travail JupyterLab à des fins de traçabilité ou de référence.  Cette bibliothèque Python peut fonctionner soit comme un utilitaire de ligne de commande, soit comme une bibliothèque de fonctions que vous pouvez importer dans n'importe quel programme Python ou notebook Jupyter.</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton Inference Server est un logiciel de service d'inférence open source qui permet de standardiser le déploiement et l'exécution des modèles pour fournir une IA rapide et évolutive en production.  Triton Inference Server rationalise l'inférence de l'IA en permettant aux équipes de déployer, d'exécuter et de mettre à l'échelle des modèles d'IA formés à partir de n'importe quel framework sur n'importe quelle infrastructure basée sur GPU ou CPU.  Triton Inference Server prend en charge tous les principaux frameworks, tels que TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO, etc.  Triton s'intègre à Kubernetes pour l'orchestration et la mise à l'échelle que vous pouvez utiliser dans toutes les principales plates-formes d'IA et Kubernetes du cloud public.  Il est également intégré à de nombreuses solutions logicielles MLOps.</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>est un framework ML open source.  Il s'agit d'une bibliothèque de tenseurs optimisée pour l'apprentissage en profondeur qui utilise des GPU et des CPU.  Le package PyTorch contient des structures de données pour les tenseurs multidimensionnels qui fournissent de nombreux utilitaires pour une sérialisation efficace des tenseurs parmi d'autres utilitaires utiles.  Il dispose également d'un homologue CUDA qui vous permet d'exécuter vos calculs de tenseur sur un GPU NVIDIA avec capacité de calcul.  Dans cette validation, nous utilisons la bibliothèque OpenCV-Python (cv2) pour valider notre modèle tout en tirant parti des concepts de vision par ordinateur les plus intuitifs de Python.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Performances et latence réduite.  ONTAP offre le débit le plus élevé possible avec la latence la plus faible possible.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Protection des données.  ONTAP fournit des fonctionnalités de protection des données intégrées avec une gestion commune sur toutes les plates-formes.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Authentification multi-locataire et multifactorielle.  ONTAP permet le partage des ressources d'infrastructure avec les plus hauts niveaux de sécurité.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Mise à l’échelle transparente et opérations non perturbatrices.  ONTAP prend en charge l'ajout non perturbateur de capacité aux contrôleurs existants et aux clusters évolutifs.  Les clients peuvent passer aux dernières technologies, telles que NVMe et FC 32 Go, sans migrations de données ni pannes coûteuses.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">Contrôle NetApp Astra</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Service de contrôle Astra</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">La gamme de produits NetApp Astra offre des services de gestion des données basés sur le stockage et les applications pour les applications Kubernetes sur site et dans le cloud public, optimisés par les technologies de stockage et de gestion des données NetApp .  Il vous permet de sauvegarder facilement les applications Kubernetes, de migrer des données vers un autre cluster et de créer instantanément des clones d'applications fonctionnels.  Si vous devez gérer des applications Kubernetes exécutées dans un cloud public, consultez la documentation pour<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> .  Astra Control Service est un service géré par NetApp qui fournit une gestion des données basée sur les applications des clusters Kubernetes dans Google Kubernetes Engine (GKE) et Azure Kubernetes Service (AKS).</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> de NetApp est un orchestrateur de stockage dynamique open source pour Docker et Kubernetes qui simplifie la création, la gestion et la consommation de stockage persistant.  Trident, une application native Kubernetes, s'exécute directement dans un cluster Kubernetes.  Trident permet aux clients de déployer de manière transparente des images de conteneurs DL sur le stockage NetApp et offre une expérience de niveau entreprise pour les déploiements de conteneurs IA.  Les utilisateurs de Kubernetes (développeurs ML, scientifiques des données, etc.) peuvent créer, gérer et automatiser l'orchestration et le clonage pour tirer parti des fonctionnalités avancées de gestion des données optimisées par la technologie NetApp .</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>est un service NetApp pour une synchronisation rapide et sécurisée des données.  Que vous ayez besoin de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, BlueXP Copy and Sync déplace les fichiers là où vous en avez besoin rapidement et en toute sécurité.  Une fois vos données transférées, elles sont entièrement disponibles pour une utilisation sur la source et la cible.  BlueXP Copy and Syncc synchronise en continu les données en fonction de votre calendrier prédéfini, en déplaçant uniquement les deltas, de sorte que le temps et l'argent consacrés à la réplication des données sont minimisés.  BlueXP Copy and Sync est un outil logiciel en tant que service (SaaS) extrêmement simple à configurer et à utiliser.  Les transferts de données déclenchés par BlueXP Copy and Sync sont effectués par des courtiers de données.  Vous pouvez déployer les courtiers de données BlueXP Copy and Sync dans AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">Classification NetApp BlueXP</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">Piloté par de puissants algorithmes d'IA,<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> fournit des contrôles automatisés et une gouvernance des données sur l'ensemble de votre parc de données.  Vous pouvez facilement identifier les économies de coûts, identifier les problèmes de conformité et de confidentialité et trouver des opportunités d’optimisation.  Le tableau de bord de classification BlueXP vous donne les informations nécessaires pour identifier les données en double afin d'éliminer la redondance, de cartographier les données personnelles, non personnelles et sensibles et d'activer les alertes pour les données sensibles et les anomalies.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">Le traitement d’images numériques présente de nombreux avantages, permettant à de nombreuses organisations de tirer le meilleur parti des données associées aux représentations visuelles.  Cette solution NetApp et Protopia fournit une conception d'inférence d'IA unique pour protéger et privatiser les données AI/ML tout au long du cycle de vie ML/DL.  Il permet aux clients de conserver la propriété des données sensibles, d'utiliser des modèles de déploiement de cloud public ou hybride pour l'évolutivité et l'efficacité en atténuant les préoccupations liées à la confidentialité et de déployer l'inférence de l'IA à la périphérie.</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Intelligence environnementale</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Les industries peuvent tirer parti de nombreuses façons de l’analyse géospatiale dans le domaine des risques environnementaux.  Les gouvernements et le ministère des Travaux publics peuvent tirer des informations exploitables sur la santé publique et les conditions météorologiques pour mieux conseiller le public lors d’une pandémie ou d’une catastrophe naturelle telle que les incendies de forêt.  Par exemple, vous pouvez identifier un patient positif au COVID dans les espaces publics, tels que les aéroports ou les hôpitaux, sans compromettre la vie privée de la personne concernée et alerter les autorités compétentes et le public à proximité des mesures de sécurité nécessaires.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Appareils portables Edge</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">Dans l’armée et sur les champs de bataille, vous pouvez utiliser l’inférence de l’IA en périphérie comme des appareils portables pour suivre la santé des soldats, surveiller le comportement des conducteurs et alerter les autorités sur la sécurité et les risques associés à l’approche des véhicules militaires tout en préservant et en protégeant la vie privée des soldats.  L'avenir de l'armée passe par la haute technologie avec l'Internet des objets de champ de bataille (IoBT) et l'Internet des objets militaires (IoMT) pour les équipements de combat portables qui aident les soldats à identifier les ennemis et à mieux performer au combat en utilisant l'informatique de pointe rapide.  La protection et la préservation des données visuelles collectées à partir d’appareils périphériques tels que les drones et les équipements portables sont essentielles pour tenir les pirates et l’ennemi à distance.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Opérations d'évacuation des non-combattants</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Les opérations d'évacuation des non-combattants (NEO) sont menées par le DoD pour aider à évacuer les citoyens et les ressortissants américains, le personnel civil du DoD et les personnes désignées (ressortissants du pays hôte (HN) et des pays tiers (TCN)) dont la vie est en danger vers un refuge sûr approprié.  Les contrôles administratifs en place utilisent en grande partie des processus manuels de contrôle des personnes évacuées.  Cependant, la précision, la sécurité et la rapidité de l’identification des personnes évacuées, du suivi des personnes évacuées et du filtrage des menaces pourraient potentiellement être améliorées en utilisant des outils d’IA/ML hautement automatisés combinés à des technologies d’obscurcissement vidéo IA/ML.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Santé et recherche biomédicale</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">Le traitement d'images est utilisé pour diagnostiquer des pathologies en vue d'une planification chirurgicale à partir d'images 3D obtenues par tomodensitométrie (TDM) ou imagerie par résonance magnétique (IRM).  Les règles de confidentialité HIPAA régissent la manière dont les données doivent être collectées, traitées et effacées par les organisations pour toutes les informations personnelles et images numériques telles que les photographies.  Pour que les données soient considérées comme partageables en vertu de la réglementation HIPAA Safe Harbor, les images photographiques complètes et toutes les images comparables doivent être supprimées.  Les techniques automatisées telles que les algorithmes de désidentification ou d'extraction du crâne utilisés pour masquer les traits du visage d'un individu à partir d'images CT/IRM structurelles sont devenues un élément essentiel du processus de partage de données pour les institutions de recherche biomédicale.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migration vers le cloud des analyses IA/ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">protection des données</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Les clients d’entreprise ont traditionnellement formé et déployé des modèles d’IA/ML sur site.  Pour des raisons d’économies d’échelle et d’efficacité, ces clients se développent pour déplacer les fonctions d’IA/ML vers des déploiements cloud publics, hybrides ou multicloud.  Cependant, ils sont limités par les données qui peuvent être exposées à d’autres infrastructures.  Les solutions NetApp répondent à une gamme complète de menaces de cybersécurité requises pour<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> et l'évaluation de la sécurité et, lorsqu'elles sont combinées à la transformation des données Protopia, minimisent les risques associés à la migration des charges de travail de traitement d'images AI/ML vers le cloud.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 Inférence IA à la périphérie</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Intelligence versus vie privée</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">Pour des cas d'utilisation supplémentaires pour l'informatique de pointe et l'inférence de l'IA dans d'autres secteurs, voir<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> et le blog NetApp AI,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> .</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">MLOps multicloud hybride avec Domino Data Lab et NetApp : où trouver des informations supplémentaires ?</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Où trouver des informations supplémentaires</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">Laboratoire de données Domino</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">Logiciel de gestion de données NetApp ONTAP</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">Solutions d'IA NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Josh Mineroff, directeur de SA pour les alliances technologiques, Domino Data Lab</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski, directeur technique de terrain, Domino Data Lab</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan, architecte de solutions, NetApp</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">Brian Young, directeur de l'alliance mondiale, partenaires de l'alliance technologique, NetApp</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">MLOps multicloud hybride avec Domino Data Lab et NetApp - Architecture</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">Cette solution combine les capacités de planification de charge de travail multicloud hybride de Domino Nexus avec les services de données NetApp pour créer une plate-forme MLOps de cloud hybride unifiée.  Voir le tableau suivant pour plus de détails.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Environnement</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">Plan de contrôle MLOps</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Plateforme d'IA Domino Enterprise avec Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">Environnements de calcul de la plateforme MLOps</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Plans de données Domino Nexus</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS, centre de données sur site</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">Plateforme de calcul sur site</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>avec<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">Centre de données sur site</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">Plateforme de calcul en nuage</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">Amazon Elastic Kubernetes Service (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>avec<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">Plateforme de données sur site</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">Dispositif de stockage NetApp</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>alimenté par<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">Plateforme de données cloud</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">MLOps multicloud hybride avec Domino Data Lab et NetApp : accédez aux mêmes données dans différents environnements</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">Accéder aux mêmes données dans différents environnements</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">Cette section décrit les tâches à effectuer pour accéder aux mêmes données dans différents environnements de calcul.  Dans la plateforme Domino MLOps, les environnements de calcul sont appelés « plans de données ».  Suivez les tâches décrites dans cette section si vos données résident sur un volume NetApp dans un plan de données, mais que vous devez y accéder dans un autre plan de données.  Ce type de scénario est souvent appelé « éclatement » ou, lorsque l’environnement de destination est le cloud, « éclatement du cloud ».  Cette capacité est souvent nécessaire lorsqu’il s’agit de gérer des ressources de calcul limitées ou sursouscrites.  Par exemple, si votre cluster de calcul sur site est sursouscrit, vous souhaiterez peut-être planifier les charges de travail vers le cloud où elles pourront être démarrées immédiatement.</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">Il existe deux options recommandées pour accéder à un volume NetApp qui réside dans un plan de données différent.  Ces options sont décrites dans les sous-sections ci-dessous.  Choisissez l’une de ces options en fonction de vos besoins spécifiques.  Les avantages et les inconvénients des deux options sont décrits dans le tableau suivant.</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">Option</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">Avantages</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">Inconvénients</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">Option 1 - Cache</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- Flux de travail simplifié - Possibilité de mettre en cache un sous-ensemble de données en fonction des besoins - Possibilité de réécrire les données à la source - Aucune copie distante à gérer</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- Augmentation de la latence lors de l'accès initial aux données à mesure que le cache est hydraté.</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">Option 2 - Miroir</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- Copie complète du volume source - Aucune latence accrue due à l'hydratation du cache (une fois l'opération de mise en miroir terminée)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- Doit attendre que l'opération de mise en miroir soit terminée avant d'accéder aux données - Doit gérer une copie à distance - Aucune possibilité de réécrire sur la source</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">Option 1 - Créer un cache d'un volume résidant dans un plan de données différent</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">Technologie NetApp FlexCache</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">Avec<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block> , vous pouvez créer un cache d'un volume NetApp qui réside dans un plan de données différent.  Par exemple, si vous disposez d’un volume NetApp dans votre plan de données local et que vous devez accéder à ce volume dans votre plan de données AWS, vous pouvez créer un cache du volume dans AWS.  Cette section décrit les tâches à effectuer pour créer un cache d’un volume NetApp résidant dans un plan de données différent.</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">Créer un volume FlexCache dans l'environnement de destination</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">Si l’environnement de destination est votre centre de données sur site, vous créerez le volume FlexCache sur votre système ONTAP sur site.  Si l'environnement de destination est AWS, vous créerez le volume FlexCache sur votre instance Amazon FSx ONTAP .</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">Tout d’abord, vous devez créer un volume FlexCache dans l’environnement de destination.</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">Documentation sur la BlueXP volume caching</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">Nous vous recommandons d'utiliser BlueXP pour créer le volume FlexCache .  Pour créer un volume FlexCache avec BlueXP, suivez les instructions décrites dans le<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> .</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">Si vous préférez ne pas utiliser BlueXP, vous pouvez utiliser ONTAP System Manager ou l' ONTAP CLI pour créer le volume FlexCache .  Pour créer un volume FlexCache avec System Manager, reportez-vous aux instructions décrites dans le<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> .  Pour créer un volume FlexCache avec l'interface de ligne de commande ONTAP , reportez-vous aux instructions décrites dans le<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> .</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">API BlueXP</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">API REST ONTAP</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">Collection Ansible ONTAP</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">Si vous souhaitez automatiser ce processus, vous pouvez utiliser le<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> , le<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block> , ou le<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block> .</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">System Manager n'est pas disponible dans Amazon FSx ONTAP.</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">Exposer le volume FlexCache à Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">Section « Exposer les volumes NetApp existants à Domino »</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">Ensuite, vous devez exposer le volume FlexCache à la plate-forme Domino MLOps.  Pour exposer le volume FlexCache à Domino, suivez les instructions décrites dans la sous-section « Exposer les volumes NFS existants qui n'ont pas été provisionnés par Trident» du<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> de cette solution.</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">Désormais, vous pourrez monter le volume FlexCache lors du lancement de tâches et d’espaces de travail dans le plan de données de destination, comme indiqué dans les captures d’écran suivantes.</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">Avant de créer le volume FlexCache</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">Après avoir exposé le volume FlexCache à Domino</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">Option 2 - Répliquer un volume résidant dans un plan de données différent</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">Technologie de réplication de données NetApp SnapMirror</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">Avec<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block> , vous pouvez créer une copie d'un volume NetApp qui réside dans un plan de données différent.  Par exemple, si vous disposez d’un volume NetApp dans votre plan de données local et que vous devez accéder à ce volume dans votre plan de données AWS, vous pouvez créer une copie du volume dans AWS.  Cette section décrit les tâches à effectuer pour créer une copie d’un volume NetApp résidant dans un plan de données différent.</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">Créer une relation SnapMirror</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">Tout d’abord, vous devez créer une relation SnapMirror entre votre volume source et un nouveau volume de destination dans l’environnement de destination.  Notez que le volume de destination sera créé dans le cadre du processus de création de la relation SnapMirror .</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">Documentation de BlueXP replication</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">Nous vous recommandons d'utiliser BlueXP pour créer la relation SnapMirror .  Pour créer une relation SnapMirror avec BlueXP, suivez les instructions décrites dans le<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> .</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">Si vous préférez ne pas utiliser BlueXP, vous pouvez utiliser ONTAP System Manager ou ONTAP CLI pour créer la relation SnapMirror .  Pour créer une relation SnapMirror avec le Gestionnaire système, reportez-vous aux instructions décrites dans le<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> .  Pour créer une relation SnapMirror avec l'interface de ligne de commande ONTAP , reportez-vous aux instructions décrites dans le<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> .</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">Rompre la relation SnapMirror</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">Ensuite, vous devez rompre la relation SnapMirror afin d’activer le volume de destination pour l’accès aux données.  Attendez que la réplication initiale soit terminée avant d’effectuer cette étape.</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">Vous pouvez déterminer si la réplication est terminée ou non en vérifiant l'état du miroir dans BlueXP, ONTAP System Manager ou l'interface de ligne de commande ONTAP .  Une fois la réplication terminée, l'état du miroir sera « snapmirrored ».</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">Nous vous recommandons d'utiliser BlueXP pour rompre la relation SnapMirror .  Pour rompre une relation SnapMirror avec BlueXP, suivez les instructions décrites dans le<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> .</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">Si vous préférez ne pas utiliser BlueXP, vous pouvez utiliser ONTAP System Manager ou ONTAP CLI pour rompre la relation SnapMirror .  Pour rompre une relation SnapMirror avec le Gestionnaire système, reportez-vous aux instructions décrites dans le<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> .  Pour rompre une relation SnapMirror avec l'interface de ligne de commande ONTAP , reportez-vous aux instructions décrites dans le<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> .</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">Exposer le volume de destination à Domino</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">Ensuite, vous devez exposer le volume de destination à la plate-forme Domino MLOps.  Pour exposer le volume de destination à Domino, suivez les instructions décrites dans la sous-section « Exposer les volumes NFS existants qui n'ont pas été provisionnés par Trident» du<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> de cette solution.</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">Désormais, vous pourrez monter le volume de destination lors du lancement de tâches et d’espaces de travail dans le plan de données de destination, comme indiqué dans les captures d’écran suivantes.</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">Avant de créer une relation SnapMirror</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">Après avoir exposé le volume de destination à Domino</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus est un panneau de contrôle unique qui vous permet d'exécuter des charges de travail de science des données et d'apprentissage automatique sur n'importe quel cluster de calcul, dans n'importe quel cloud, région ou sur site.</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">MLOps multicloud hybride avec Domino Data Lab et NetApp</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">Les organisations du monde entier adoptent actuellement l’IA pour transformer leurs activités et leurs processus.  De ce fait, l’infrastructure informatique prête pour l’IA est souvent rare.  Les entreprises adoptent des architectures MLOps multicloud hybrides afin de tirer parti des environnements de calcul disponibles dans différentes régions, centres de données et clouds, en équilibrant les coûts, la disponibilité et les performances.</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Nexus, de Domino Data Lab, est un plan de contrôle MLOps unifié qui vous permet d'exécuter des charges de travail de science des données et d'apprentissage automatique sur n'importe quel cluster de calcul, dans n'importe quel cloud, région ou sur site.  Il unifie les silos de science des données dans toute l'entreprise, vous permettant ainsi de créer, de déployer et de surveiller des modèles en un seul endroit.  De même, les capacités de gestion des données de cloud hybride de NetApp vous permettent d'apporter vos données à vos tâches et espaces de travail, quel que soit l'endroit où elles s'exécutent.  Lorsque vous associez Domino Nexus à NetApp, vous avez la possibilité de planifier des charges de travail sur plusieurs environnements sans avoir à vous soucier de la disponibilité des données.  En d’autres termes, vous avez la possibilité d’envoyer vos charges de travail et vos données vers l’environnement de calcul approprié, ce qui vous permet d’accélérer vos déploiements d’IA tout en respectant les réglementations relatives à la confidentialité et à la souveraineté des données.</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">Cette solution démontre le déploiement d'un plan de contrôle MLOps unifié intégrant un cluster Kubernetes sur site et un cluster Elastic Kubernetes Service (EKS) exécuté dans Amazon Web Services (AWS).</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">MLOps multicloud hybride avec Domino Data Lab et NetApp - Configuration initiale</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Configuration initiale</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">Cette section décrit les tâches de configuration initiales qui doivent être effectuées pour utiliser Domino Nexus avec les services de données NetApp dans un environnement hybride intégrant un centre de données sur site et AWS.</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">Avant d’effectuer les étapes décrites dans cette section, nous supposons que vous avez déjà effectué les tâches suivantes :</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">Vous avez déjà déployé et configuré votre plateforme de stockage NetApp ONTAP sur site. Pour plus d'informations, reportez-vous à la <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> .</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Page produit Amazon FSx ONTAP</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">Vous avez déjà provisionné une instance Amazon FSx ONTAP dans AWS. Pour plus d'informations, reportez-vous à la <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> .</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Guide d'administration Domino</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">Vous avez déjà provisionné un cluster Kubernetes dans votre centre de données sur site. Pour plus d'informations, reportez-vous à la <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">Vous avez déjà provisionné un cluster Amazon EKS dans AWS. Pour plus d'informations, reportez-vous à la <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">Documentation de NetApp Trident</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">Vous avez installé NetApp Trident dans votre cluster Kubernetes sur site.  De plus, vous avez configuré cette instance Trident pour utiliser votre plateforme de stockage NetApp ONTAP sur site lors du provisionnement et de la gestion des ressources de stockage. Pour plus d'informations, reportez-vous à la <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Vous avez installé NetApp Trident dans votre cluster Amazon EKS.  De plus, vous avez configuré cette instance Trident pour utiliser votre instance Amazon FSx ONTAP lors du provisionnement et de la gestion des ressources de stockage. Pour plus d'informations, reportez-vous à la <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Documentation sur le réseau privé virtuel (VPN) d'Amazon</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">Vous devez disposer d’une connectivité réseau bidirectionnelle entre votre centre de données sur site et votre cloud privé virtuel (VPC) dans AWS.  Pour plus de détails sur les différentes options de mise en œuvre, reportez-vous à la<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> .</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">Installer la plateforme Domino Enterprise AI dans AWS</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">Pour installer la plateforme Domino Enterprise MLOps dans AWS, suivez les instructions décrites dans<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> .  Vous devez déployer Domino dans le même cluster Amazon EKS que celui que vous avez précédemment provisionné.  De plus, NetApp Trident doit déjà être installé et configuré dans ce cluster EKS, et vous devez spécifier une classe de stockage gérée par Trident comme classe de stockage partagée dans votre fichier de configuration d'installation domino.yml.</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Guide de référence de configuration d'installation de Domino</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">Se référer à la<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> pour plus de détails sur la façon de spécifier une classe de stockage partagé dans votre fichier de configuration d'installation domino.yml.</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">Rapport technique TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>décrit le déploiement de Domino dans AWS avec Amazon FSx ONTAP et peut constituer une référence utile pour résoudre les problèmes qui surviennent.</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Activer Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">Ensuite, vous devez activer Domino Nexus.  Se référer à la<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> pour plus de détails.</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">Déployez un plan de données Domino dans votre centre de données sur site</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">Ensuite, vous devez déployer un plan de données Domino dans votre centre de données sur site.  Vous devez déployer ce plan de données dans le cluster Kubernetes local que vous avez précédemment provisionné.  De plus, NetApp Trident doit déjà être installé et configuré dans ce cluster Kubernetes.  Se référer à la<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> pour plus de détails.</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">MLOps multicloud hybride avec Domino Data Lab et NetApp - Présentation technologique</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Aperçu de la technologie</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">Cette section fournit un aperçu technologique pour Hybrid Multicloud MLOps avec Domino Data Lab et NetApp.</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab alimente les entreprises axées sur les modèles avec sa plateforme d'IA d'entreprise de premier plan, à laquelle font confiance plus de 20 % des entreprises du Fortune 100.  Domino accélère le développement et le déploiement des travaux de science des données tout en augmentant la collaboration et la gouvernance.  Avec Domino, les entreprises du monde entier peuvent développer de meilleurs médicaments, cultiver des cultures plus productives, construire de meilleures voitures et bien plus encore.  Fondée en 2013, Domino est soutenue par Coatue Management, Great Hill Partners, Highland Capital, Sequoia Capital et d'autres investisseurs de premier plan.</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino permet aux entreprises et à leurs data scientists de créer, déployer et gérer l'IA sur une plateforme unifiée de bout en bout, rapidement, de manière responsable et rentable.  Les équipes peuvent accéder à toutes les données, outils, calculs, modèles et projets dont elles ont besoin dans n'importe quel environnement, afin de pouvoir collaborer, réutiliser les travaux antérieurs, suivre les modèles en production pour améliorer la précision, standardiser avec les meilleures pratiques et rendre l'IA responsable et gouvernée.</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*Ouvert et flexible :* accédez au plus vaste écosystème d'outils et d'infrastructures open source et commerciaux pour les meilleures innovations et sans dépendance envers un fournisseur.</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*Système d'enregistrement :* plateforme centrale pour les opérations et les connaissances en matière d'IA dans toute l'entreprise, permettant les meilleures pratiques, la collaboration interfonctionnelle, une innovation plus rapide et une efficacité accrue.</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*Intégré :* les flux de travail et l'automatisation intégrés, conçus pour les processus, les contrôles et la gouvernance de l'entreprise, répondent à vos besoins en matière de conformité et de réglementation.</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*Multicloud hybride :* exécutez des charges de travail d'IA à proximité de vos données n'importe où (sur site, hybride, n'importe quel cloud ou multicloud) pour un coût réduit, des performances optimales et une conformité optimale.</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus est un panneau de contrôle unique qui vous permet d'exécuter des charges de travail de science des données et d'apprentissage automatique sur n'importe quel cluster de calcul, dans n'importe quel cloud, région ou sur site.  Il unifie les silos de science des données dans toute l'entreprise, vous permettant ainsi de créer, de déployer et de surveiller des modèles en un seul endroit.</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP unifie tous les services de stockage et de données de NetApp dans un seul outil qui vous permet de créer, de protéger et de gérer votre parc de données multicloud hybride.  Il offre une expérience unifiée pour les services de stockage et de données dans les environnements sur site et dans le cloud, et permet une simplicité opérationnelle grâce à la puissance d'AIOps, avec les paramètres de consommation flexibles et la protection intégrée requis pour le monde actuel axé sur le cloud.</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">Connexion au Cloud.  ONTAP est le logiciel de gestion de stockage le plus connecté au cloud, avec des options de stockage défini par logiciel et des instances cloud natives dans tous les clouds publics.</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP est un service AWS propriétaire entièrement géré qui fournit un stockage de fichiers hautement fiable, évolutif, performant et riche en fonctionnalités, basé sur le système de fichiers ONTAP populaire de NetApp. FSx ONTAP combine les fonctionnalités, les performances, les capacités et les opérations API familières des systèmes de fichiers NetApp avec l'agilité, l'évolutivité et la simplicité d'un service AWS entièrement géré.</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident permet la consommation et la gestion des ressources de stockage sur toutes les plates-formes de stockage NetApp populaires, dans le cloud public ou sur site, y compris ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), le logiciel Element (NetApp HCI, SolidFire), le service Azure NetApp Files et Google Cloud NetApp Volumes sur Google Cloud.  Trident est un orchestrateur de stockage dynamique compatible Container Storage Interface (CSI) qui s'intègre nativement à Kubernetes.</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes est une plate-forme d'orchestration de conteneurs open source et distribuée, conçue à l'origine par Google et désormais maintenue par la Cloud Native Computing Foundation (CNCF).  Kubernetes permet l'automatisation des fonctions de déploiement, de gestion et de mise à l'échelle des applications conteneurisées et constitue la plate-forme d'orchestration de conteneurs dominante dans les environnements d'entreprise.</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) est un service Kubernetes géré dans le cloud AWS.  Amazon EKS gère automatiquement la disponibilité et l'évolutivité des nœuds du plan de contrôle Kubernetes responsables de la planification des conteneurs, de la gestion de la disponibilité des applications, du stockage des données de cluster et d'autres tâches clés.  Avec Amazon EKS, vous pouvez profiter de toutes les performances, de l'évolutivité, de la fiabilité et de la disponibilité de l'infrastructure AWS, ainsi que des intégrations avec les services de réseau et de sécurité AWS.</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">MLOps multicloud hybride avec Domino Data Lab et NetApp : exposez les volumes NetApp existants à Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">Exposer les volumes NetApp existants à Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">Cette section décrit les tâches à effectuer pour exposer les volumes NetApp ONTAP NFS existants à la plate-forme Domino MLOps.  Ces mêmes étapes s’appliquent à la fois sur site et dans AWS.</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">Pourquoi exposer les volumes NetApp ONTAP à Domino ?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">L'utilisation des volumes NetApp conjointement avec Domino offre les avantages suivants :</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">Vous pouvez exécuter des charges de travail sur des ensembles de données extrêmement volumineux en tirant parti des capacités d'évolutivité horizontale de NetApp ONTAP.</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">Vous pouvez exécuter des charges de travail sur plusieurs nœuds de calcul sans avoir à copier vos données sur les nœuds individuels.</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">Vous pouvez profiter des capacités de déplacement et de synchronisation des données multicloud hybrides de NetApp afin d'accéder à vos données sur plusieurs centres de données et/ou clouds.</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">Vous souhaitez pouvoir créer rapidement et facilement un cache de vos données dans un autre centre de données ou cloud.</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Exposer les volumes NFS existants qui n'ont pas été provisionnés par Trident</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">Si votre volume NetApp ONTAP NFS existant n’a pas été provisionné par Trident, suivez les étapes décrites dans cette sous-section.</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">Créer des PV et des PVC dans Kubernetes</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">Pour les volumes sur site, créez le PV et le PVC dans votre cluster Kubernetes sur site.  Pour les volumes Amazon FSx ONTAP , créez le PV et le PVC dans Amazon EKS.</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">Exemple NFS PV/PVC</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">Tout d’abord, vous devez créer un volume persistant (PV) et une revendication de volume persistant (PVC) dans votre cluster Kubernetes.  Pour créer le PV et le PVC, utilisez le<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> à partir du guide d'administration Domino et mettez à jour les valeurs pour refléter votre environnement.  Assurez-vous de spécifier les valeurs correctes pour le<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> ,<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> , et<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> champs.  De plus, nous vous recommandons de donner à vos PV et PVC des noms uniques qui représentent la nature des données stockées sur le volume ONTAP NFS correspondant.  Par exemple, si le volume contient des images de défauts de fabrication, vous pouvez nommer le PV,<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> , et le PVC,<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> .</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Enregistrer un volume de données externe dans Domino</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">instructions</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">Ensuite, vous devez enregistrer un volume de données externe dans Domino.  Pour enregistrer un volume de données externe, reportez-vous à la<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> dans le guide d'administration Domino.  Lors de l'enregistrement du volume, assurez-vous de sélectionner « NFS » dans le menu déroulant « Type de volume ».  Après avoir sélectionné « NFS », vous devriez voir votre PVC dans la liste « Volumes disponibles ».</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Exposer les volumes existants qui ont été provisionnés par Trident</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">Si votre volume existant a été provisionné par Trident, suivez les étapes décrites dans cette sous-section.</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">Modifier le PVC existant</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">Si votre volume a été provisionné par Trident, vous disposez déjà d'une réclamation de volume persistant (PVC) correspondant à votre volume.  Afin d'exposer ce volume à Domino, vous devez éditer le PVC et ajouter l'étiquette suivante à la liste des étiquettes dans le<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> champ:</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">Ensuite, vous devez enregistrer un volume de données externe dans Domino.  Pour enregistrer un volume de données externe, reportez-vous à la<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> dans le guide d'administration Domino.  Lors de l'enregistrement du volume, assurez-vous de sélectionner « Générique » dans le menu déroulant « Type de volume ».  Après avoir sélectionné « Générique », vous devriez voir votre PVC dans la liste « Volumes disponibles ».</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise avec NetApp et VMware : où trouver des informations supplémentaires ?</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise avec VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, directeur principal, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, administrateur système, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, ingénieur marketing technique, NetApp</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise avec NetApp et VMware - Architecture</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Cette solution s'appuie sur une architecture éprouvée et familière comprenant des systèmes certifiés NetApp, VMware et NVIDIA.  Voir le tableau suivant pour plus de détails.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Logiciels d'IA et d'analyse de données</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise pour VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Plateforme de virtualisation</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Plateforme de calcul</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Systèmes certifiés NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Plateforme de gestion des données</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise est une suite de logiciels d'IA et d'analyse de données native du cloud de bout en bout, optimisée pour que chaque organisation puisse réussir avec l'IA.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise avec NetApp et VMware</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Pour les architectes et les administrateurs informatiques, les outils d’IA peuvent être compliqués et peu familiers.  De plus, de nombreuses plateformes d’IA ne sont pas adaptées aux entreprises.  NVIDIA AI Enterprise, optimisé par NetApp et VMware, a été créé pour fournir une architecture d'IA rationalisée et de classe entreprise.</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise avec NetApp et VMware - Utilisation du logiciel NVIDIA NGC - Configuration</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">Installation</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">Cette section décrit les tâches de configuration initiales qui doivent être effectuées pour utiliser le logiciel d'entreprise NVIDIA NGC dans un environnement NVIDIA AI Enterprise.</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">Avant d'effectuer les étapes décrites dans cette section, nous supposons que vous avez déjà déployé le logiciel hôte NVIDIA AI Entrprise en suivant les instructions décrites sur le<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block> page.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Créer une machine virtuelle invitée Ubuntu avec vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guide de déploiement de NVIDIA AI Enterprise</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">Tout d’abord, vous devez créer une machine virtuelle invitée Ubuntu 20.04 avec vGPU.  Pour créer une machine virtuelle invitée Ubuntu 20.04 avec vGPU, suivez les instructions décrites dans le<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> .</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Téléchargez et installez le logiciel invité NVIDIA</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">Guide de démarrage rapide de NVIDIA AI Enterprise</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Ensuite, vous devez installer le logiciel invité NVIDIA requis dans la machine virtuelle invitée que vous avez créée à l’étape précédente.  Pour télécharger et installer le logiciel invité NVIDIA requis dans la machine virtuelle invitée, suivez les instructions décrites dans les sections 5.1 à 5.4 du<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Lors de l'exécution des tâches de vérification décrites dans la section 5.4, vous devrez peut-être utiliser une balise de version d'image de conteneur CUDA différente, car l'image de conteneur CUDA a été mise à jour depuis la rédaction du guide.  Dans notre validation, nous avons utilisé « nvidia/cuda:11.0.3-base-ubuntu20.04 ».</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Télécharger le(s) conteneur(s) du framework IA/Analytics</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">Ensuite, vous devez télécharger les images de conteneur d’IA ou de framework d’analyse nécessaires à partir de NVIDIA NGC afin qu’elles soient disponibles dans votre machine virtuelle invitée.  Pour télécharger les conteneurs de framework dans la machine virtuelle invitée, suivez les instructions décrites dans le<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> .</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Installer et configurer la boîte à outils NetApp DataOps</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Ensuite, vous devez installer NetApp DataOps Toolkit pour les environnements traditionnels dans la machine virtuelle invitée.  La boîte à outils NetApp DataOps peut être utilisée pour gérer les volumes de données évolutifs sur votre système ONTAP directement à partir du terminal dans la machine virtuelle invitée.  Pour installer NetApp DataOps Toolkit dans la machine virtuelle invitée, effectuez les tâches suivantes.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Installer pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Déconnectez-vous du terminal VM invité, puis reconnectez-vous.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configurez la boîte à outils NetApp DataOps.  Pour terminer cette étape, vous aurez besoin des détails d’accès API pour votre système ONTAP .  Vous devrez peut-être les obtenir auprès de votre administrateur de stockage.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Créer un modèle de machine virtuelle invitée</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Enfin, vous devez créer un modèle de VM basé sur votre VM invitée.  Vous pourrez utiliser ce modèle pour créer rapidement des machines virtuelles invitées pour utiliser le logiciel NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Pour créer un modèle de machine virtuelle basé sur votre machine virtuelle invitée, connectez-vous à VMware vSphere, cliquez avec le bouton droit sur le nom de la machine virtuelle invitée, choisissez « Cloner », choisissez « Cloner vers un modèle... », puis suivez l'assistant.</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise avec NetApp et VMware - Configuration initiale</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">Cette section décrit les tâches de configuration initiales qui doivent être effectuées pour utiliser NVIDIA AI Enterprise avec NetApp et VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matrice de support des produits NVIDIA AI Enterprise</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentation des solutions NetApp et VMware</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">Avant d’effectuer les étapes décrites dans cette section, nous supposons que vous avez déjà déployé VMware vSphere et NetApp ONTAP.  Se référer à la<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block> pour plus de détails sur les versions de vSphere prises en charge.  Se référer à la<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block> pour plus de détails sur le déploiement de VMware vSphere avec NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Installer le logiciel hôte NVIDIA AI Enterprise</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Pour installer le logiciel hôte NVIDIA AI Entrprise, suivez les instructions décrites dans les sections 1 à 4 du<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise avec NetApp et VMware - Présentation de la technologie</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">Cette section fournit un aperçu technologique de NVIDIA AI Enterprise avec NetApp et VMware.</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise est une suite de logiciels d'IA et d'analyse de données cloud native de bout en bout, optimisée, certifiée et prise en charge par NVIDIA pour s'exécuter sur VMware vSphere avec les systèmes certifiés NVIDIA.  Ce logiciel facilite le déploiement, la gestion et la mise à l’échelle simples et rapides des charges de travail d’IA dans l’environnement cloud hybride moderne.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC héberge un catalogue de logiciels optimisés pour GPU permettant aux praticiens de l'IA de développer leurs solutions d'IA.  Il donne également accès à divers services d'IA, notamment NVIDIA Base Command pour la formation des modèles, NVIDIA Fleet Command pour déployer et surveiller les modèles, et le registre privé NGC pour accéder et gérer en toute sécurité les logiciels d'IA propriétaires.  Les clients NVIDIA AI Enterprise peuvent également demander de l’assistance via le portail NGC.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere est la plateforme de virtualisation de VMware, qui transforme les centres de données en infrastructures informatiques agrégées incluant des ressources CPU, de stockage et réseau. vSphere gère ces infrastructures comme un environnement d'exploitation unifié et fournit aux administrateurs les outils nécessaires pour gérer les centres de données qui y participent.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Les deux composants principaux de vSphere sont ESXi et vCenter Server.  ESXi est la plateforme de virtualisation sur laquelle les administrateurs créent et exécutent des machines virtuelles et des appliances virtuelles. vCenter Server est le service qui leur permet de gérer plusieurs hôtes connectés à un réseau et de regrouper les ressources des hôtes.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit est un outil basé sur Python qui simplifie la gestion des espaces de travail de développement/formation et des serveurs d'inférence soutenus par un stockage NetApp hautes performances et évolutif.  Les principales fonctionnalités comprennent :</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Clonez presque instantanément des espaces de travail JupyterLab de grande capacité afin de permettre l'expérimentation ou l'itération rapide.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Enregistrez presque instantanément des instantanés d'espaces de travail JupyterLab haute capacité pour la sauvegarde et/ou la traçabilité/l'établissement de référence.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Provisionnez, clonez et capturez des instantanés de volumes de données haute capacité et hautes performances de manière quasi instantanée.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise avec NetApp et VMware - Utiliser le logiciel NVIDIA NGC - Exemple de cas d'utilisation - Formation TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Exemple de cas d'utilisation : tâche d'entraînement TensorFlow</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">Cette section décrit les tâches à effectuer pour exécuter une tâche de formation TensorFlow dans un environnement NVIDIA AI Enterprise.</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">Avant d'effectuer les étapes décrites dans cette section, nous supposons que vous avez déjà créé un modèle de machine virtuelle invitée en suivant les instructions décrites dans le<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block> page.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Créer une machine virtuelle invitée à partir d'un modèle</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Tout d’abord, vous devez créer une nouvelle machine virtuelle invitée à partir du modèle que vous avez créé dans la section précédente.  Pour créer une nouvelle machine virtuelle invitée à partir de votre modèle, connectez-vous à VMware vSphere, cliquez avec le bouton droit sur le nom du modèle, choisissez « Nouvelle machine virtuelle à partir de ce modèle... », puis suivez l'assistant.</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Créer et monter un volume de données</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Ensuite, vous devez créer un nouveau volume de données sur lequel stocker votre ensemble de données d’entraînement.  Vous pouvez créer rapidement un nouveau volume de données à l’aide de NetApp DataOps Toolkit.  L'exemple de commande qui suit montre la création d'un volume nommé « imagenet » d'une capacité de 2 To.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Avant de pouvoir remplir votre volume de données avec des données, vous devez le monter dans la machine virtuelle invitée.  Vous pouvez monter rapidement un volume de données à l’aide de NetApp DataOps Toolkit.  L'exemple de commande qui suit montre le montage du volume qui a été créé à l'étape précédente.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Remplir le volume de données</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Une fois le nouveau volume provisionné et monté, l’ensemble de données de formation peut être récupéré à partir de l’emplacement source et placé sur le nouveau volume.  Cela impliquera généralement d'extraire les données d'un lac de données S3 ou Hadoop et nécessitera parfois l'aide d'un ingénieur de données.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Exécuter la tâche d'entraînement TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Vous êtes maintenant prêt à exécuter votre tâche de formation TensorFlow.  Pour exécuter votre tâche de formation TensorFlow, effectuez les tâches suivantes.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Extrayez l’image du conteneur NVIDIA NGC Enterprise TensorFlow.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Lancez une instance du conteneur TensorFlow d’entreprise NVIDIA NGC.  Utilisez l'option « -v » pour attacher votre volume de données au conteneur.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Exécutez votre programme de formation TensorFlow dans le conteneur.  L'exemple de commande qui suit montre l'exécution d'un exemple de programme de formation ResNet-50 inclus dans l'image du conteneur.</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">MLOps Open Source avec NetApp - Déploiement d'Apache Airflow</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Déploiement d'Apache Airflow</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">Cette section décrit les tâches que vous devez effectuer pour déployer Airflow dans votre cluster Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Il est possible de déployer Airflow sur d’autres plateformes que Kubernetes.  Le déploiement d’Airflow sur des plateformes autres que Kubernetes n’entre pas dans le cadre de cette solution.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Avant d’effectuer l’exercice de déploiement décrit dans cette section, nous supposons que vous avez déjà effectué les tâches suivantes :</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Vous disposez déjà d’un cluster Kubernetes fonctionnel.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Documentation Trident</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Vous avez déjà installé et configuré NetApp Trident dans votre cluster Kubernetes.  Pour plus de détails sur Trident, reportez-vous au<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> .</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Installer Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">instructions d'installation</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow est déployé à l'aide de Helm, un gestionnaire de packages populaire pour Kubernetes.  Avant de déployer Airflow, vous devez installer Helm sur l’hôte de saut de déploiement.  Pour installer Helm sur l'hôte de saut de déploiement, suivez les instructions<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> dans la documentation officielle de Helm.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Définir la classe de stockage Kubernetes par défaut</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Déploiement de Kubeflow</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Avant de déployer Airflow, vous devez désigner une StorageClass par défaut dans votre cluster Kubernetes.  Le processus de déploiement Airflow tente de provisionner de nouveaux volumes persistants à l’aide de la StorageClass par défaut.  Si aucune StorageClass n’est désignée comme StorageClass par défaut, le déploiement échoue.  Pour désigner une StorageClass par défaut au sein de votre cluster, suivez les instructions décrites dans le<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> section.  Si vous avez déjà désigné une StorageClass par défaut dans votre cluster, vous pouvez ignorer cette étape.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Utilisez Helm pour déployer Airflow</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Pour déployer Airflow dans votre cluster Kubernetes à l'aide de Helm, effectuez les tâches suivantes à partir de l'hôte de saut de déploiement :</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">instructions de déploiement</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Déployez Airflow à l'aide de Helm en suivant les<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> pour le tableau officiel du flux d'air sur l'Artifact Hub.  Les exemples de commandes qui suivent montrent le déploiement d’Airflow à l’aide de Helm.  Modifier, ajouter et/ou supprimer des valeurs dans le<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> fichier selon vos besoins en fonction de votre environnement et de la configuration souhaitée.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Vérifiez que tous les modules Airflow sont opérationnels.  Le démarrage de tous les modules peut prendre quelques minutes.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Obtenez l’URL du service Web Airflow en suivant les instructions imprimées sur la console lorsque vous avez déployé Airflow à l’aide de Helm à l’étape 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Confirmez que vous pouvez accéder au service Web Airflow.</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">MLOps Open Source avec NetApp : utilisez la boîte à outils NetApp DataOps avec Airflow</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">Utilisez la boîte à outils NetApp DataOps avec Airflow</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">Le<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block> peut être utilisé en conjonction avec Airflow.  L'utilisation de NetApp DataOps Toolkit avec Airflow vous permet d'intégrer des opérations de gestion de données NetApp , telles que la création d'instantanés et de clones, dans des flux de travail automatisés orchestrés par Airflow.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Exemples de flux d'air</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">Se référer à la<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block> section dans le référentiel GitHub NetApp DataOps Toolkit pour plus de détails sur l'utilisation de la boîte à outils avec Airflow.</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">Architecture MLOps Open Source avec NetApp</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">Cette solution ne dépend pas d’un matériel spécifique.  La solution est compatible avec tout dispositif de stockage physique NetApp , instance définie par logiciel ou service cloud pris en charge par NetApp Trident.  Les exemples incluent un système de stockage NetApp AFF , Amazon FSx ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes ou une instance NetApp Cloud Volumes ONTAP .  De plus, la solution peut être implémentée sur n’importe quel cluster Kubernetes à condition que la version Kubernetes utilisée soit prise en charge par NetApp Trident et les autres composants de la solution en cours d’implémentation.  Pour obtenir la liste des versions de Kubernetes prises en charge par Trident, consultez le<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .  Consultez les tableaux suivants pour plus de détails sur les environnements qui ont été utilisés pour valider les différents composants de cette solution.</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Environnement de validation Apache Airflow</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Composant logiciel</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apache Airflow</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Diagramme de flux d'air Apache Helm</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1, déployé via<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block> 8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1,18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21,01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">Environnement de validation JupyterHub</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">Graphique Helm de JupyterHub</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5, déployé via<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block> 3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1,29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24,02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">Environnement de validation MLflow</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">MLflow</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">Diagramme Helm MLflow</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1, déployé via<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block> 1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Environnement de validation Kubeflow</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">déployerKF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7, déployé via<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block> 0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1,26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23,07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Support</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">contacter NetApp</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp n'offre pas de support d'entreprise pour Apache Airflow, JupyterHub, MLflow, Kubeflow ou Kubernetes.  Si vous êtes intéressé par une plateforme MLOps entièrement prise en charge,<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> à propos des solutions MLOps entièrement prises en charge que NetApp propose conjointement avec des partenaires.</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">MLOps Open Source avec NetApp - Présentation technologique</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">Cette section se concentre sur l’aperçu technologique pour OpenSource MLOps avec NetApp.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Intelligence artificielle</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">L’IA est une discipline informatique dans laquelle les ordinateurs sont entraînés à imiter les fonctions cognitives de l’esprit humain.  Les développeurs d’IA forment les ordinateurs à apprendre et à résoudre des problèmes d’une manière similaire, voire supérieure, à celle des humains.  L’apprentissage profond et l’apprentissage automatique sont des sous-domaines de l’IA.  Les organisations adoptent de plus en plus l’IA, le ML et le DL pour répondre à leurs besoins commerciaux critiques.  Voici quelques exemples :</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analyser de grandes quantités de données pour découvrir des informations commerciales jusqu'alors inconnues</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interagir directement avec les clients en utilisant le traitement du langage naturel</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatisation de divers processus et fonctions métier</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">Les charges de travail de formation et d’inférence de l’IA moderne nécessitent des capacités de calcul massivement parallèles.  Par conséquent, les GPU sont de plus en plus utilisés pour exécuter des opérations d’IA, car les capacités de traitement parallèle des GPU sont largement supérieures à celles des CPU à usage général.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">Conteneurs</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Les conteneurs sont des instances d'espace utilisateur isolées qui s'exécutent sur un noyau de système d'exploitation hôte partagé.  L’adoption des conteneurs augmente rapidement.  Les conteneurs offrent de nombreux avantages de sandboxing d’application identiques à ceux des machines virtuelles (VM).  Cependant, comme les couches d’hyperviseur et de système d’exploitation invité sur lesquelles s’appuient les machines virtuelles ont été éliminées, les conteneurs sont beaucoup plus légers.  La figure suivante illustre une visualisation des machines virtuelles par rapport aux conteneurs.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Site Web Docker</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">Les conteneurs permettent également de conditionner efficacement les dépendances des applications, les temps d'exécution, etc., directement avec une application.  Le format de packaging de conteneur le plus couramment utilisé est le conteneur Docker.  Une application qui a été conteneurisée au format de conteneur Docker peut être exécutée sur n’importe quelle machine capable d’exécuter des conteneurs Docker.  Cela est vrai même si les dépendances de l'application ne sont pas présentes sur la machine, car toutes les dépendances sont regroupées dans le conteneur lui-même.  Pour plus d'informations, visitez le<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> .</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Site Web Kubernetes</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes est une plate-forme d'orchestration de conteneurs open source et distribuée, conçue à l'origine par Google et désormais maintenue par la Cloud Native Computing Foundation (CNCF).  Kubernetes permet l’automatisation des fonctions de déploiement, de gestion et de mise à l’échelle des applications conteneurisées.  Ces dernières années, Kubernetes est devenu la plateforme d’orchestration de conteneurs dominante.  Pour plus d'informations, visitez le<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> .</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>permet la consommation et la gestion des ressources de stockage sur toutes les plates-formes de stockage NetApp populaires, dans le cloud public ou sur site, y compris ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), le service Azure NetApp Files et Google Cloud NetApp Volumes.  Trident est un orchestrateur de stockage dynamique compatible Container Storage Interface (CSI) qui s'intègre nativement à Kubernetes.</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">Le<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block> est un outil basé sur Python qui simplifie la gestion des espaces de travail de développement/formation et des serveurs d'inférence soutenus par un stockage NetApp hautes performances et évolutif.  Les principales fonctionnalités comprennent :</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">Provisionnez rapidement de nouveaux espaces de travail haute capacité soutenus par un stockage NetApp hautes performances et évolutif.</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">Clonez presque instantanément des espaces de travail de grande capacité afin de permettre l'expérimentation ou l'itération rapide.</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">Enregistrez presque instantanément des instantanés d'espaces de travail de grande capacité à des fins de sauvegarde et/ou de traçabilité/de référence.</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow est une plate-forme de gestion de flux de travail open source qui permet la création, la planification et la surveillance programmatiques de flux de travail d'entreprise complexes.  Il est souvent utilisé pour automatiser les flux de travail ETL et de pipeline de données, mais il ne se limite pas à ces types de flux de travail.  Le projet Airflow a été lancé par Airbnb mais est depuis devenu très populaire dans l'industrie et relève désormais des auspices de l'Apache Software Foundation.  Airflow est écrit en Python, les flux de travail Airflow sont créés via des scripts Python et Airflow est conçu selon le principe de la « configuration en tant que code ».  De nombreux utilisateurs d’Airflow en entreprise exécutent désormais Airflow sur Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Graphes acycliques dirigés (DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">Dans Airflow, les flux de travail sont appelés graphes acycliques dirigés (DAG).  Les DAG sont constitués de tâches exécutées en séquence, en parallèle ou une combinaison des deux, selon la définition du DAG.  Le planificateur Airflow exécute des tâches individuelles sur un ensemble de travailleurs, en adhérant aux dépendances au niveau des tâches spécifiées dans la définition DAG.  Les DAG sont définis et créés via des scripts Python.</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Carnet Jupyter</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Site Web Jupyter</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Les notebooks Jupyter sont des documents de type wiki qui contiennent du code en direct ainsi que du texte descriptif.  Les notebooks Jupyter sont largement utilisés dans la communauté de l'IA et du ML comme moyen de documenter, de stocker et de partager des projets d'IA et de ML.  Pour plus d'informations sur Jupyter Notebooks, visitez le<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> .</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Serveur de blocs-notes Jupyter</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Un serveur Jupyter Notebook est une application Web open source qui permet aux utilisateurs de créer des Jupyter Notebooks.</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">Site Web JupyterHub</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub est une application multi-utilisateurs qui permet à un utilisateur individuel de provisionner et d'accéder à son propre serveur Jupyter Notebook.  Pour plus d'informations sur JupyterHub, visitez le<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> .</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">Site Web MLflow</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow est une plate-forme de gestion du cycle de vie de l'IA open source populaire.  Les principales fonctionnalités de MLflow incluent le suivi des expériences AI/ML et un référentiel de modèles AI/ML.  Pour plus d'informations sur MLflow, visitez le<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> .</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Site Web de Kubeflow</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow est une boîte à outils d'IA et de ML open source pour Kubernetes qui a été initialement développée par Google.  Le projet Kubeflow rend les déploiements de workflows d'IA et de ML sur Kubernetes simples, portables et évolutifs.  Kubeflow fait abstraction des subtilités de Kubernetes, permettant aux scientifiques des données de se concentrer sur ce qu'ils connaissent le mieux : la science des données.  Voir la figure suivante pour une visualisation.  Kubeflow est une bonne option open source pour les organisations qui préfèrent une plateforme MLOps tout-en-un.  Pour plus d'informations, visitez le<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> .</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Pipelines Kubeflow</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">documentation officielle de Kubeflow</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Les pipelines Kubeflow sont un composant clé de Kubeflow.  Kubeflow Pipelines est une plate-forme et une norme permettant de définir et de déployer des workflows d'IA et de ML portables et évolutifs. Pour plus d'informations, consultez le<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> .</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Bloc-notes Kubeflow</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow simplifie le provisionnement et le déploiement des serveurs Jupyter Notebook sur Kubernetes.  Pour plus d'informations sur Jupyter Notebooks dans le contexte de Kubeflow, consultez le<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> .</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">Katib</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib est un projet natif de Kubernetes pour l'apprentissage automatique automatisé (AutoML).  Katib prend en charge le réglage des hyperparamètres, l'arrêt précoce et la recherche d'architecture neuronale (NAS).  Katib est un projet indépendant des frameworks d'apprentissage automatique (ML).  Il peut ajuster les hyperparamètres des applications écrites dans n'importe quel langage choisi par les utilisateurs et prend en charge nativement de nombreux frameworks ML, tels que TensorFlow, MXNet, PyTorch, XGBoost et autres.  Katib prend en charge de nombreux algorithmes AutoML différents, tels que l'optimisation bayésienne, les estimateurs d'arbre de Parzen, la recherche aléatoire, la stratégie d'évolution d'adaptation de matrice de covariance, l'hyperbande, la recherche d'architecture neuronale efficace, la recherche d'architecture différentiable et bien d'autres.  Pour plus d'informations sur Jupyter Notebooks dans le contexte de Kubeflow, consultez le<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> .</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">Mise à l’échelle transparente et opérations non perturbatrices.  ONTAP prend en charge l'ajout non perturbateur de capacité aux contrôleurs existants et aux clusters évolutifs.  Les clients peuvent passer aux dernières technologies sans migrations de données ni pannes coûteuses.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Copies instantanées NetApp</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Une copie NetApp Snapshot est une image en lecture seule, à un instant T, d'un volume.  L'image consomme un espace de stockage minimal et entraîne une surcharge de performances négligeable, car elle enregistre uniquement les modifications apportées aux fichiers créés depuis la dernière copie instantanée, comme illustré dans la figure suivante.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Les copies instantanées doivent leur efficacité à la technologie de virtualisation du stockage ONTAP de base, le Write Anywhere File Layout (WAFL).  Comme une base de données, WAFL utilise des métadonnées pour pointer vers des blocs de données réels sur le disque.  Mais, contrairement à une base de données, WAFL n’écrase pas les blocs existants.  Il écrit les données mises à jour dans un nouveau bloc et modifie les métadonnées.  C'est parce ONTAP référence les métadonnées lorsqu'il crée une copie Snapshot, plutôt que de copier des blocs de données, que les copies Snapshot sont si efficaces.  Cela élimine le temps de recherche que les autres systèmes doivent accomplir pour localiser les blocs à copier, ainsi que le coût de réalisation de la copie elle-même.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Vous pouvez utiliser une copie instantanée pour récupérer des fichiers individuels ou des LUN ou pour restaurer l'intégralité du contenu d'un volume.  ONTAP compare les informations du pointeur dans la copie Snapshot avec les données sur le disque pour reconstruire l'objet manquant ou endommagé, sans temps d'arrêt ni coût de performance significatif.</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Technologie NetApp FlexClone</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">La technologie NetApp FlexClone fait référence aux métadonnées Snapshot pour créer des copies inscriptibles à un instant T d'un volume.  Les copies partagent des blocs de données avec leurs parents, ne consommant aucun stockage, à l'exception de ce qui est nécessaire pour les métadonnées jusqu'à ce que des modifications soient écrites sur la copie, comme illustré dans la figure suivante.  Alors que la création de copies traditionnelles peut prendre des minutes, voire des heures, le logiciel FlexClone vous permet de copier presque instantanément même les plus grands ensembles de données.  Cela le rend idéal pour les situations dans lesquelles vous avez besoin de plusieurs copies d'ensembles de données identiques (un espace de travail de développement, par exemple) ou de copies temporaires d'un ensemble de données (test d'une application par rapport à un ensemble de données de production).</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Technologie de réplication de données NetApp SnapMirror</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">Le logiciel NetApp SnapMirror est une solution de réplication unifiée économique et facile à utiliser sur l'ensemble de la structure de données.  Il réplique les données à grande vitesse sur LAN ou WAN.  Il vous offre une haute disponibilité des données et une réplication rapide des données pour les applications de tous types, y compris les applications critiques pour l'entreprise dans les environnements virtuels et traditionnels.  Lorsque vous répliquez des données sur un ou plusieurs systèmes de stockage NetApp et mettez à jour en permanence les données secondaires, vos données sont maintenues à jour et disponibles à tout moment.  Aucun serveur de réplication externe n'est requis.  Consultez la figure suivante pour un exemple d’architecture qui exploite la technologie SnapMirror .</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">Le logiciel SnapMirror exploite l'efficacité du stockage NetApp ONTAP en envoyant uniquement les blocs modifiés sur le réseau.  Le logiciel SnapMirror utilise également la compression réseau intégrée pour accélérer les transferts de données et réduire l'utilisation de la bande passante du réseau jusqu'à 70 %.  Avec la technologie SnapMirror , vous pouvez exploiter un flux de données de réplication mince pour créer un référentiel unique qui conserve à la fois le miroir actif et les copies ponctuelles antérieures, réduisant ainsi le trafic réseau jusqu'à 50 %.</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>est un service NetApp pour une synchronisation rapide et sécurisée des données.  Que vous ayez besoin de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, BlueXP Copy and Sync déplace les fichiers là où vous en avez besoin rapidement et en toute sécurité.</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">Une fois vos données transférées, elles sont entièrement disponibles pour une utilisation sur la source et la cible.  BlueXP Copy and Sync peut synchroniser les données à la demande lorsqu'une mise à jour est déclenchée ou synchroniser les données en continu selon un calendrier prédéfini.  Quoi qu'il en soit, BlueXP Copy and Sync ne déplace que les deltas, donc le temps et l'argent consacrés à la réplication des données sont minimisés.</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync est un outil logiciel en tant que service (SaaS) extrêmement simple à configurer et à utiliser.  Les transferts de données déclenchés par BlueXP Copy and Sync sont effectués par des courtiers de données.  Les courtiers de données BlueXP Copy and Sync peuvent être déployés dans AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>est un logiciel basé sur le client pour les migrations de données vers NetApp et NetApp vers NetApp et les informations sur les systèmes de fichiers.  XCP est conçu pour évoluer et atteindre des performances maximales en utilisant toutes les ressources système disponibles pour gérer des ensembles de données à volume élevé et des migrations hautes performances.  XCP vous aide à obtenir une visibilité complète sur le système de fichiers avec la possibilité de générer des rapports.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">Volumes NetApp ONTAP FlexGroup</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Un ensemble de données de formation peut être une collection de milliards de fichiers potentiellement.  Les fichiers peuvent inclure du texte, de l'audio, de la vidéo et d'autres formes de données non structurées qui doivent être stockées et traitées pour être lues en parallèle.  Le système de stockage doit stocker un grand nombre de petits fichiers et doit lire ces fichiers en parallèle pour les E/S séquentielles et aléatoires.</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Un volume FlexGroup est un espace de noms unique qui comprend plusieurs volumes membres constitutifs, comme illustré dans la figure suivante.  Du point de vue d'un administrateur de stockage, un volume FlexGroup est géré et agit comme un FlexVol volume NetApp FlexVol.  Les fichiers d'un volume FlexGroup sont alloués à des volumes membres individuels et ne sont pas répartis sur des volumes ou des nœuds.  Ils permettent les capacités suivantes :</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">Les volumes FlexGroup offrent plusieurs pétaoctets de capacité et une faible latence prévisible pour les charges de travail à métadonnées élevées.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Ils prennent en charge jusqu'à 400 milliards de fichiers dans le même espace de noms.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Ils prennent en charge les opérations parallélisées dans les charges de travail NAS sur les processeurs, les nœuds, les agrégats et les volumes FlexVol constitutifs.</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">Cette solution vise à démontrer plusieurs outils et frameworks open source différents qui peuvent être intégrés dans un flux de travail MLOps.  Ces différents outils et frameworks peuvent être utilisés ensemble ou seuls selon les exigences et le cas d'utilisation.</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">MLOps Open Source avec NetApp</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby, NetApp Sufian Ahmad, NetApp Rick Huang, NetApp Mohan Acharya, NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">Les entreprises et organisations de toutes tailles et de nombreux secteurs se tournent vers l’intelligence artificielle (IA) pour résoudre des problèmes du monde réel, fournir des produits et services innovants et obtenir un avantage sur un marché de plus en plus concurrentiel.  De nombreuses organisations se tournent vers des outils MLOps open source afin de suivre le rythme rapide de l’innovation dans le secteur.  Ces outils open source offrent des capacités avancées et des fonctionnalités de pointe, mais ne tiennent souvent pas compte de la disponibilité et de la sécurité des données.  Malheureusement, cela signifie que les scientifiques de données hautement qualifiés sont obligés de passer beaucoup de temps à attendre d’avoir accès aux données ou à attendre que des opérations rudimentaires liées aux données soient terminées.  En associant des outils MLOps open source populaires à une infrastructure de données intelligente de NetApp, les organisations peuvent accélérer leurs pipelines de données, ce qui, à son tour, accélère leurs initiatives d'IA.  Ils peuvent exploiter pleinement leurs données tout en garantissant qu’elles restent protégées et sécurisées.  Cette solution démontre l’association des capacités de gestion des données NetApp avec plusieurs outils et frameworks open source populaires afin de relever ces défis.</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">La liste suivante met en évidence certaines fonctionnalités clés activées par cette solution :</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">Les utilisateurs peuvent rapidement provisionner de nouveaux volumes de données haute capacité et des espaces de travail de développement soutenus par un stockage NetApp hautes performances et évolutif.</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">Les utilisateurs peuvent cloner presque instantanément des volumes de données de grande capacité et des espaces de travail de développement afin de permettre l’expérimentation ou l’itération rapide.</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">Les utilisateurs peuvent enregistrer presque instantanément des instantanés de volumes de données de grande capacité et d'espaces de travail de développement à des fins de sauvegarde et/ou de traçabilité/base de référence.</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Carnets Jupyter</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">Un flux de travail MLOps typique intègre des espaces de travail de développement, prenant généralement la forme de<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> ; suivi des expériences ; pipelines de formation automatisés ; pipelines de données ; et inférence/déploiement.  Cette solution met en évidence plusieurs outils et cadres différents qui peuvent être utilisés indépendamment ou conjointement pour traiter les différents aspects du flux de travail.  Nous démontrons également l’association des capacités de gestion des données NetApp avec chacun de ces outils.  Cette solution vise à offrir des blocs de construction à partir desquels une organisation peut construire un flux de travail MLOps personnalisé et spécifique à ses cas d'utilisation et à ses exigences.</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">Les outils/frameworks suivants sont couverts dans cette solution :</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">La liste suivante décrit les modèles courants de déploiement de ces outils indépendamment ou conjointement.</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">Déployer JupyterHub, MLflow et Apache Airflow conjointement - JupyterHub pour<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> MLflow pour le suivi des expériences et Apache Airflow pour la formation automatisée et les pipelines de données.</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">Déployer Kubeflow et Apache Airflow conjointement - Kubeflow pour<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , suivi des expériences, pipelines de formation automatisés et inférence ; et Apache Airflow pour les pipelines de données.</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">Déployez Kubeflow en tant que solution de plateforme MLOps tout-en-un pour<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , suivi des expériences, formation automatisée et pipelines de données, et inférence.</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">MLOps Open Source avec NetApp - Déploiement JupyterHub</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">Déploiement de JupyterHub</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">Cette section décrit les tâches que vous devez effectuer pour déployer JupyterHub dans votre cluster Kubernetes.</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">Il est possible de déployer JupyterHub sur d’autres plateformes que Kubernetes.  Le déploiement de JupyterHub sur des plateformes autres que Kubernetes n'entre pas dans le cadre de cette solution.</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Vous avez déjà installé et configuré NetApp Trident dans votre cluster Kubernetes.  Pour plus de détails sur Trident, reportez-vous au<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub est déployé à l'aide de Helm, un gestionnaire de packages populaire pour Kubernetes.  Avant de déployer JupyterHub, vous devez installer Helm sur votre nœud de contrôle Kubernetes.  Pour installer Helm, suivez les instructions<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> dans la documentation officielle de Helm.</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">Avant de déployer JupyterHub, vous devez désigner une StorageClass par défaut dans votre cluster Kubernetes.  Pour désigner une StorageClass par défaut au sein de votre cluster, suivez les instructions décrites dans le<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> section.  Si vous avez déjà désigné une StorageClass par défaut dans votre cluster, vous pouvez ignorer cette étape.</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">Déployer JupyterHub</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">Après avoir terminé les étapes ci-dessus, vous êtes maintenant prêt à déployer JupyterHub.  Le déploiement de JupyterHub nécessite les étapes suivantes :</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">Configurer le déploiement de JupyterHub</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">Avant le déploiement, il est recommandé d’optimiser le déploiement de JupyterHub pour votre environnement respectif.  Vous pouvez créer un fichier *config.yaml* et l'utiliser lors du déploiement à l'aide du graphique Helm.</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">Un exemple de fichier *config.yaml* peut être trouvé à l'adresse<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">Dans ce fichier config.yaml, vous pouvez définir le paramètre *(singleuser.storage.dynamic.storageClass)* pour NetApp Trident StorageClass.  Il s’agit de la classe de stockage qui sera utilisée pour provisionner les volumes pour les espaces de travail des utilisateurs individuels.</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">Ajout de volumes partagés</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">Si vous souhaitez utiliser un volume partagé pour tous les utilisateurs JupyterHub, vous pouvez ajuster votre *config.yaml* en conséquence.  Par exemple, si vous avez un PersistentVolumeClaim partagé appelé jupyterhub-shared-volume, vous pouvez le monter en tant que /home/shared dans tous les pods utilisateur comme suit :</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">Il s'agit d'une étape facultative, vous pouvez ajuster ces paramètres selon vos besoins.</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">Déployer JupyterHub avec Helm Chart</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Informez Helm du référentiel de graphiques JupyterHub Helm.</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">Cela devrait afficher une sortie comme :</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">Installez maintenant le graphique configuré par votre config.yaml en exécutant cette commande à partir du répertoire qui contient votre config.yaml :</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">Dans cet exemple :</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; est défini sur my-jupyterhub, qui sera le nom de votre version JupyterHub.  &lt;k8s-namespace&gt; est défini sur my-namespace, qui est l'espace de noms dans lequel vous souhaitez installer JupyterHub.  L'indicateur --create-namespace est utilisé pour créer l'espace de noms s'il n'existe pas déjà.  L'indicateur --values spécifie le fichier config.yaml qui contient les options de configuration souhaitées.</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">Vérifier le déploiement</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">Pendant que l’étape 2 est en cours d’exécution, vous pouvez voir les pods créés à partir de la commande suivante :</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">Attendez que le hub et le pod proxy entrent dans l’état d’exécution.</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">Accéder à JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">Trouvez l'IP que nous pouvons utiliser pour accéder au JupyterHub.  Exécutez la commande suivante jusqu'à ce que l'adresse IP EXTERNE du service proxy-public soit disponible comme dans l'exemple de sortie.</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">Nous avons utilisé le service NodePort dans notre fichier config.yaml, vous pouvez l'ajuster en fonction de votre environnement en fonction de votre configuration (par exemple LoadBalancer).</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">Pour utiliser JupyterHub, saisissez l'adresse IP externe du service proxy-public dans un navigateur.</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">MLOps Open Source avec NetApp : utilisez la boîte à outils NetApp DataOps avec JupyterHub</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">Utilisez la boîte à outils NetApp DataOps avec JupyterHub</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">Le<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> peut être utilisé en conjonction avec JupyterHub.  L'utilisation de NetApp DataOps Toolkit avec JupyterHub permet aux utilisateurs finaux de créer des instantanés de volume pour la sauvegarde de l'espace de travail et/ou la traçabilité de l'ensemble de données vers le modèle directement à partir d'un bloc-notes Jupyter.</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">Avant de pouvoir utiliser DataOps Toolkit avec JupyterHub, vous devez accorder les autorisations appropriées au compte de service Kubernetes que JupyterHub attribue aux pods Jupyter Notebook Server des utilisateurs individuels.  JupyterHub utilise le compte de service spécifié par le<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variable dans votre fichier de configuration de graphique JupyterHub Helm.</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">Créer un rôle de cluster pour la boîte à outils DataOps</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">Tout d’abord, créez un rôle de cluster nommé « netapp-dataops » qui dispose des autorisations d’API Kubernetes requises pour créer des instantanés de volume.</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">Attribuer un rôle de cluster au compte de service du serveur Notebook</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">Créez une liaison de rôle qui attribue le rôle de cluster « netapp-dataops-snapshots » au compte de service approprié dans l’espace de noms approprié.  Par exemple, si vous avez installé JupyterHub dans l'espace de noms « jupyterhub » et que vous avez spécifié le compte de service « par défaut » via le<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> variable, vous attribueriez le rôle de cluster « netapp-dataops-snapshots » au compte de service « default » dans l'espace de noms « jupyterhub », comme indiqué dans l'exemple suivant.</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Créer des instantanés de volume dans Jupyter Notebook</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">Désormais, les utilisateurs de JupyterHub peuvent utiliser NetApp DataOps Toolkit pour créer des instantanés de volume directement à partir d'un Jupyter Notebook, comme illustré dans l'exemple suivant.</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">Ingérer des données avec NetApp SnapMirror</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">Ingérer des données dans JupyterHub avec NetApp SnapMirror</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror est une technologie de réplication qui vous permet de répliquer des données entre des systèmes de stockage NetApp .  SnapMirror peut être utilisé pour ingérer des données provenant d'environnements distants dans JupyterHub.</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">Exemple de flux de travail et démonstration</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">cet article de blog Tech ONTAP</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">Se référer à<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block> pour un exemple détaillé de flux de travail et une démonstration de l'utilisation de NetApp SnapMirror pour ingérer des données dans JupyterHub.</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">MLOps Open Source avec NetApp - Déploiement Kubeflow</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">Cette section décrit les tâches que vous devez effectuer pour déployer Kubeflow dans votre cluster Kubernetes.</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">Vous disposez déjà d’un cluster Kubernetes fonctionnel et vous exécutez une version de Kubernetes prise en charge par la version de Kubeflow que vous envisagez de déployer.  Pour obtenir la liste des versions de Kubernetes prises en charge, reportez-vous aux dépendances de votre version de Kubeflow dans le<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> .</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Avant de déployer Kubeflow, nous vous recommandons de désigner une StorageClass par défaut dans votre cluster Kubernetes.  Le processus de déploiement de Kubeflow peut tenter de provisionner de nouveaux volumes persistants à l’aide de la StorageClass par défaut.  Si aucune StorageClass n’est désignée comme StorageClass par défaut, le déploiement peut échouer.  Pour désigner une StorageClass par défaut au sein de votre cluster, effectuez la tâche suivante à partir de l’hôte de saut de déploiement.  Si vous avez déjà désigné une StorageClass par défaut dans votre cluster, vous pouvez ignorer cette étape.</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">Désignez l’une de vos StorageClasses existantes comme StorageClass par défaut.  Les exemples de commandes qui suivent montrent la désignation d'une StorageClass nommée<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block> comme StorageClass par défaut.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">Le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Le type de backend Trident a une taille de PVC minimale assez grande.  Par défaut, Kubeflow tente de provisionner des PVC dont la taille ne dépasse pas quelques Go.  Par conséquent, vous ne devez pas désigner une StorageClass qui utilise le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Type de backend comme StorageClass par défaut pour les besoins du déploiement de Kubeflow.</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Options de déploiement de Kubeflow</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Il existe de nombreuses options différentes pour déployer Kubeflow.  Se référer à la<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block> pour obtenir une liste des options de déploiement, et choisissez l'option qui correspond le mieux à vos besoins.</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">À des fins de validation, nous avons déployé Kubeflow 1.7 en utilisant<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1.</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">MLOps Open Source avec NetApp : utilisez la boîte à outils NetApp DataOps avec Kubeflow</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">Utilisez la boîte à outils NetApp DataOps avec Kubeflow</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Boîte à outils NetApp Data Science pour Kubernetes</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">Le<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block> peut être utilisé en conjonction avec Kubeflow.  L'utilisation de NetApp Data Science Toolkit avec Kubeflow offre les avantages suivants :</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">Les scientifiques des données peuvent effectuer des opérations avancées de gestion des données NetApp , telles que la création d'instantanés et de clones, directement à partir d'un bloc-notes Jupyter.</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">Les opérations avancées de gestion des données NetApp , telles que la création d’instantanés et de clones, peuvent être intégrées dans des flux de travail automatisés à l’aide du framework Kubeflow Pipelines.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Exemples de Kubeflow</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">Se référer à la<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block> section dans le référentiel GitHub NetApp Data Science Toolkit pour plus de détails sur l'utilisation de la boîte à outils avec Kubeflow.</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">MLOps Open Source avec NetApp : provisionnez un espace de travail Jupyter Notebook pour les scientifiques de données ou les développeurs.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Fournir un espace de travail Jupyter Notebook pour une utilisation par un data scientist ou un développeur</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow est capable de provisionner rapidement de nouveaux serveurs Jupyter Notebook pour agir comme espaces de travail de data scientist.  Pour plus d'informations sur les notebooks Jupyter dans le contexte de Kubeflow, consultez le<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> .</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">MLOps Open Source avec NetApp - Exemple de workflow - Entraîner un modèle de reconnaissance d'images avec Kubeflow et la boîte à outils NetApp DataOps</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">Exemple de workflow : Entraîner un modèle de reconnaissance d'images à l'aide de Kubeflow et de la boîte à outils NetApp DataOps</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">Cette section décrit les étapes impliquées dans la formation et le déploiement d'un réseau neuronal pour la reconnaissance d'images à l'aide de Kubeflow et de NetApp DataOps Toolkit.  Ceci est destiné à servir d'exemple pour montrer un travail de formation qui intègre le stockage NetApp .</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Créez un Dockerfile avec les configurations requises à utiliser pour les étapes de train et de test dans le pipeline Kubeflow.  Voici un exemple de Dockerfile -</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">En fonction de vos besoins, installez toutes les bibliothèques et packages requis pour exécuter le programme.  Avant de former le modèle d’apprentissage automatique, il est supposé que vous disposez déjà d’un déploiement Kubeflow fonctionnel.</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">Entraîner un petit NN sur des données MNIST à l'aide de pipelines PyTorch et Kubeflow</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">Nous utilisons l’exemple d’un petit réseau neuronal formé sur des données MNIST.  L'ensemble de données MNIST se compose d'images manuscrites de chiffres de 0 à 9.  Les images ont une taille de 28x28 pixels.  L'ensemble de données est divisé en 60 000 images de train et 10 000 images de validation.  Le réseau neuronal utilisé pour cette expérience est un réseau à propagation directe à 2 couches.  La formation est exécutée à l’aide de Kubeflow Pipelines. Se référer à la documentation<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block> pour plus d'informations.  Notre pipeline Kubeflow intègre l'image Docker de la section Prérequis.</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Visualisation de l'exécution du pipeline Kubeflow</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Visualiser les résultats à l'aide de Tensorboard</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Panneau Tensorboard</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">Une fois le modèle formé, nous pouvons visualiser les résultats à l’aide de Tensorboard.<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> est disponible en tant que fonctionnalité sur le tableau de bord Kubeflow.  Vous pouvez créer un tensorboard personnalisé pour votre travail.  Un exemple ci-dessous montre le graphique de la précision de l'entraînement par rapport au nombre d'époques et de la perte d'entraînement par rapport au nombre d'époques.</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">Graphique Tensorboard pour la perte d'entraînement et la précision</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Expérimenter avec des hyperparamètres à l'aide de Katib</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>est un outil au sein de Kubeflow qui peut être utilisé pour expérimenter les hyperparamètres du modèle.  Pour créer une expérience, définissez d’abord une métrique/un objectif souhaité.  Il s’agit généralement de la précision du test.  Une fois la métrique définie, choisissez les hyperparamètres avec lesquels vous souhaitez jouer (optimiseur/taux d'apprentissage/nombre de couches).  Katib effectue un balayage d'hyperparamètres avec les valeurs définies par l'utilisateur pour trouver la meilleure combinaison de paramètres qui satisfont la métrique souhaitée.  Vous pouvez définir ces paramètres dans chaque section de l'interface utilisateur.  Alternativement, vous pouvez définir un fichier *YAML* avec les spécifications nécessaires.  Ci-dessous, une illustration d'une expérience Katib -</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">Tableau de bord de l'expérience Katib avec hyperparamètres</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">Vérification d'essai réussie</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">Utilisez les instantanés NetApp pour enregistrer les données à des fins de traçabilité</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">Pendant la formation du modèle, nous souhaiterons peut-être enregistrer un instantané de l'ensemble de données de formation à des fins de traçabilité.  Pour ce faire, nous pouvons ajouter une étape d’instantané au pipeline comme indiqué ci-dessous.  Pour créer l'instantané, nous pouvons utiliser le<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> .</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Code pour créer un pipeline Snapshot dans Kubeflow</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">Exemple de boîte à outils NetApp DataOps pour Kubeflow</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">Se référer à la <block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block> pour plus d'informations.</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">MLOps Open Source avec NetApp - Déploiement MLflow</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">Déploiement de MLflow</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">Cette section décrit les tâches que vous devez effectuer pour déployer MLflow dans votre cluster Kubernetes.</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">Il est possible de déployer MLflow sur d’autres plateformes que Kubernetes.  Le déploiement de MLflow sur des plateformes autres que Kubernetes n’entre pas dans le cadre de cette solution.</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow est déployé à l'aide de Helm, un gestionnaire de packages populaire pour Kubernetes.  Avant de déployer MLflow, vous devez installer Helm sur votre nœud de contrôle Kubernetes.  Pour installer Helm, suivez les instructions<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> dans la documentation officielle de Helm.</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">Avant de déployer MLflow, vous devez désigner une StorageClass par défaut dans votre cluster Kubernetes.  Pour désigner une StorageClass par défaut au sein de votre cluster, suivez les instructions décrites dans le<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> section.  Si vous avez déjà désigné une StorageClass par défaut au sein de votre cluster, vous pouvez ignorer cette étape.</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">Déployer MLflow</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">Une fois les prérequis remplis, vous pouvez commencer le déploiement de MLflow à l'aide du graphique Helm.</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">Configurer le déploiement du graphique Helm MLflow.</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Avant de déployer MLflow à l'aide du graphique Helm, nous pouvons configurer le déploiement pour utiliser la classe de stockage NetApp Trident et modifier d'autres paramètres en fonction de nos besoins à l'aide d'un fichier *config.yaml*.  Un exemple de fichier *config.yaml* peut être trouvé à l'adresse :<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">Vous pouvez définir la classe de stockage Trident sous le paramètre *global.defaultStorageClass* dans le fichier config.yaml (par exemple storageClass : « ontap-flexvol »).</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Installation du Helm Chart</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">Le graphique Helm peut être installé avec le fichier *config.yaml* personnalisé pour MLflow à l'aide de la commande suivante :</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">La commande déploie MLflow sur le cluster Kubernetes dans la configuration personnalisée via le fichier *config.yaml* fourni.  MLflow est déployé dans l'espace de noms donné et un nom de version aléatoire est donné via Kubernetes pour la version.</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Une fois le déploiement du graphique Helm terminé, vous pouvez vérifier si le service est accessible en utilisant :</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">Remplacez *jupyterhub* par l'espace de noms que vous avez utilisé lors du déploiement.</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">Vous devriez voir les services suivants :</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">Nous avons modifié le fichier config.yaml pour utiliser le service NodePort pour accéder à MLflow sur le port 30002.</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">Accéder à MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">Une fois que tous les services liés à MLflow sont opérationnels, vous pouvez y accéder en utilisant l'adresse IP NodePort ou LoadBalancer donnée (par exemple<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> )</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">MLOps Open Source avec NetApp - Traçabilité des jeux de données aux modèles avec NetApp et MLflow</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">Traçabilité des ensembles de données aux modèles avec NetApp et MLflow</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">Le<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> peut être utilisé en conjonction avec les capacités de suivi des expériences de MLflow afin de mettre en œuvre la traçabilité de l'ensemble de données au modèle ou de l'espace de travail au modèle.</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">Pour implémenter la traçabilité de l'ensemble de données au modèle ou de l'espace de travail au modèle, créez simplement un instantané de votre ensemble de données ou de votre volume d'espace de travail à l'aide de la boîte à outils DataOps dans le cadre de votre exécution de formation, comme illustré dans l'exemple de code suivant.  Ce code enregistrera le nom du volume de données et le nom de l'instantané en tant que balises associées à l'exécution d'entraînement spécifique que vous enregistrez sur votre serveur de suivi d'expérience MLflow.</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">MLOps Open Source avec NetApp : Exécutez une charge de travail d'IA distribuée synchrone</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Exécuter une charge de travail d'IA distribuée synchrone</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Pour exécuter une tâche IA et ML multinœud synchrone dans votre cluster Kubernetes, effectuez les tâches suivantes sur l'hôte de saut de déploiement.  Ce processus vous permet de tirer parti des données stockées sur un volume NetApp et d’utiliser plus de GPU qu’un seul nœud de travail ne peut en fournir.  Consultez la figure suivante pour une représentation d’un travail d’IA distribué synchrone.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Les tâches distribuées synchrones peuvent aider à augmenter les performances et la précision de la formation par rapport aux tâches distribuées asynchrones.  Une discussion sur les avantages et les inconvénients des tâches synchrones par rapport aux tâches asynchrones n’entre pas dans le cadre de ce document.</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">Exécuter une charge de travail d'IA à nœud unique</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">Les exemples de commandes suivants montrent la création d'un worker qui participe à l'exécution distribuée synchrone du même travail de référence TensorFlow qui a été exécuté sur un seul nœud dans l'exemple de la section<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .  Dans cet exemple spécifique, un seul travailleur est déployé car le travail est exécuté sur deux nœuds de travail.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">documentation officielle de Kubernetes</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Cet exemple de déploiement de travailleur nécessite huit GPU et peut donc s'exécuter sur un seul nœud de travail GPU doté de huit GPU ou plus.  Si vos nœuds de travail GPU comportent plus de huit GPU, pour optimiser les performances, vous souhaiterez peut-être augmenter ce nombre pour qu'il soit égal au nombre de GPU dont disposent vos nœuds de travail.  Pour plus d'informations sur les déploiements Kubernetes, consultez le<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> .</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">Un déploiement Kubernetes est créé dans cet exemple car ce travailleur conteneurisé spécifique ne se terminerait jamais tout seul.  Par conséquent, il n’est pas logique de le déployer en utilisant la construction de tâche Kubernetes.  Si votre worker est conçu ou écrit pour s'exécuter de manière autonome, il peut être judicieux d'utiliser la construction de tâche pour déployer votre worker.</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">Le pod spécifié dans cet exemple de spécification de déploiement reçoit un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Cette valeur signifie que le pod utilise la pile réseau du nœud de travail hôte au lieu de la pile réseau virtuelle que Kubernetes crée habituellement pour chaque pod.  Cette annotation est utilisée dans ce cas car la charge de travail spécifique s'appuie sur Open MPI, NCCL et Horovod pour exécuter la charge de travail de manière distribuée synchrone.  Par conséquent, il nécessite un accès à la pile réseau de l'hôte.  Une discussion sur Open MPI, NCCL et Horovod sort du cadre de ce document.  Que cela soit ou non<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> L'annotation est nécessaire en fonction des exigences de la charge de travail spécifique que vous exécutez.  Pour plus d'informations sur le<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> champ, voir le<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> .</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Confirmez que le déploiement de travail que vous avez créé à l’étape 1 a été lancé avec succès.  Les exemples de commandes suivants confirment qu'un seul pod de travail a été créé pour le déploiement, comme indiqué dans la définition de déploiement, et que ce pod est actuellement en cours d'exécution sur l'un des nœuds de travail GPU.</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">Créez une tâche Kubernetes pour un maître qui démarre, participe et suit l’exécution de la tâche multinœud synchrone.  Les exemples de commandes suivants créent un maître qui lance, participe et suit l'exécution distribuée synchrone du même travail de référence TensorFlow qui a été exécuté sur un seul nœud dans l'exemple de la section<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Cet exemple de tâche principale demande huit GPU et peut donc s'exécuter sur un seul nœud de travail GPU doté de huit GPU ou plus.  Si vos nœuds de travail GPU comportent plus de huit GPU, pour optimiser les performances, vous souhaiterez peut-être augmenter ce nombre pour qu'il soit égal au nombre de GPU dont disposent vos nœuds de travail.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Le pod maître spécifié dans cet exemple de définition de tâche reçoit un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> , tout comme le groupe de travailleurs a reçu un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> à l'étape 1.  Consultez l’étape 1 pour plus de détails sur la raison pour laquelle cette valeur est nécessaire.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Confirmez que le travail principal que vous avez créé à l’étape 3 s’exécute correctement.  L'exemple de commande suivant confirme qu'un seul pod maître a été créé pour le travail, comme indiqué dans la définition du travail, et que ce pod est actuellement en cours d'exécution sur l'un des nœuds de travail GPU.  Vous devriez également voir que le pod de travail que vous avez vu à l’origine à l’étape 1 est toujours en cours d’exécution et que les pods maître et de travail s’exécutent sur des nœuds différents.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Confirmez que le travail principal que vous avez créé à l’étape 3 se termine avec succès.  Les exemples de commandes suivants confirment que le travail s'est terminé avec succès.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Supprimez le déploiement du travailleur lorsque vous n’en avez plus besoin.  Les exemples de commandes suivants montrent la suppression de l’objet de déploiement Worker créé à l’étape 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Lorsque vous supprimez l’objet de déploiement de travail, Kubernetes supprime automatiquement tous les pods de travail associés.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Facultatif :* Nettoyez les artefacts du travail principal.  Les exemples de commandes suivants montrent la suppression de l’objet de travail principal créé à l’étape 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Lorsque vous supprimez l’objet de tâche principal, Kubernetes supprime automatiquement tous les pods principaux associés.</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">MLOps Open Source avec NetApp : Exécutez une charge de travail d'IA à nœud unique</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Pour exécuter une tâche d’IA et de ML à nœud unique dans votre cluster Kubernetes, effectuez les tâches suivantes à partir de l’hôte de saut de déploiement.  Avec Trident, vous pouvez rapidement et facilement rendre un volume de données, contenant potentiellement des pétaoctets de données, accessible à une charge de travail Kubernetes.  Pour rendre un tel volume de données accessible depuis un pod Kubernetes, spécifiez simplement un PVC dans la définition du pod.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">Cette section suppose que vous avez déjà conteneurisé (au format de conteneur Docker) la charge de travail IA et ML spécifique que vous tentez d'exécuter dans votre cluster Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Site Web ImageNet</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">Les exemples de commandes suivants montrent la création d’une tâche Kubernetes pour une charge de travail de référence TensorFlow qui utilise l’ensemble de données ImageNet.  Pour plus d'informations sur l'ensemble de données ImageNet, consultez le<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> .</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Cet exemple de tâche nécessite huit GPU et peut donc s'exécuter sur un seul nœud de travail GPU doté de huit GPU ou plus.  Cet exemple de travail peut être soumis dans un cluster pour lequel un nœud de travail comportant huit GPU ou plus n'est pas présent ou est actuellement occupé par une autre charge de travail.  Si tel est le cas, le travail reste dans un état en attente jusqu'à ce qu'un tel nœud de travail soit disponible.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">De plus, afin de maximiser la bande passante de stockage, le volume contenant les données de formation nécessaires est monté deux fois dans le pod créé par cette tâche.  Un autre volume est également monté dans la nacelle.  Ce deuxième volume servira à stocker les résultats et les métriques.  Ces volumes sont référencés dans la définition du travail en utilisant les noms des PVC.  Pour plus d'informations sur les tâches Kubernetes, consultez le<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> .</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">Un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume avec un<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valeur de<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> est monté sur<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> dans le pod créé par cet exemple de travail.  La taille par défaut du<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> le volume virtuel créé automatiquement par l'environnement d'exécution du conteneur Docker peut parfois être insuffisant pour les besoins de TensorFlow.  Montage d'un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> le volume comme dans l'exemple suivant fournit un volume suffisamment grand<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volume virtuel.  Pour plus d'informations sur<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volumes, voir le<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> .</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Le conteneur unique spécifié dans cet exemple de définition de tâche reçoit un<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  Cette valeur signifie que le conteneur dispose effectivement d'un accès root sur l'hôte.  Cette annotation est utilisée dans ce cas car la charge de travail spécifique en cours d’exécution nécessite un accès root.  Plus précisément, une opération de vidage du cache effectuée par la charge de travail nécessite un accès root.  Que cela soit ou non<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> L'annotation est nécessaire en fonction des exigences de la charge de travail spécifique que vous exécutez.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Confirmez que la tâche que vous avez créée à l’étape 1 s’exécute correctement.  L'exemple de commande suivant confirme qu'un seul pod a été créé pour le travail, comme spécifié dans la définition du travail, et que ce pod est actuellement en cours d'exécution sur l'un des nœuds de travail GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Confirmez que la tâche que vous avez créée à l’étape 1 se termine avec succès.  Les exemples de commandes suivants confirment que le travail s'est terminé avec succès.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Facultatif :* Nettoyer les artefacts de travail.  Les exemples de commandes suivants montrent la suppression de l’objet de travail créé à l’étape 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Lorsque vous supprimez l’objet de travail, Kubernetes supprime automatiquement tous les pods associés.</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">MLOps Open Source avec NetApp : exemples de backends Trident pour les déploiements NetApp AIPod</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">Exemples de backends Trident pour les déploiements NetApp AIPod</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Avant de pouvoir utiliser Trident pour provisionner dynamiquement des ressources de stockage au sein de votre cluster Kubernetes, vous devez créer un ou plusieurs backends Trident .  Les exemples qui suivent représentent différents types de backends que vous souhaiterez peut-être créer si vous déployez des composants de cette solution sur un<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Pour plus d'informations sur les backends, et par exemple sur les backends pour d'autres plateformes/environnements, consultez le<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp recommande de créer un backend Trident compatible FlexGroup pour votre AIPod.</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">Les exemples de commandes qui suivent montrent la création d'un backend Trident compatible FlexGroup pour une machine virtuelle de stockage AIPod (SVM).  Ce backend utilise le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> pilote de stockage.  ONTAP prend en charge deux principaux types de volumes de données : FlexVol et FlexGroup.  Les volumes FlexVol sont limités en taille (au moment de la rédaction de cet article, la taille maximale dépend du déploiement spécifique).  Les volumes FlexGroup , en revanche, peuvent évoluer de manière linéaire jusqu'à 20 Po et 400 milliards de fichiers, fournissant un espace de noms unique qui simplifie considérablement la gestion des données.  Par conséquent, les volumes FlexGroup sont optimaux pour les charges de travail d’IA et de ML qui reposent sur de grandes quantités de données.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Si vous travaillez avec une petite quantité de données et que vous souhaitez utiliser des volumes FlexVol au lieu de volumes FlexGroup , vous pouvez créer des backends Trident qui utilisent le<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> pilote de stockage au lieu du<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> pilote de stockage.</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp recommande également de créer un backend Trident compatible FlexVol .  Vous souhaiterez peut-être utiliser des volumes FlexVol pour héberger des applications persistantes, stocker des résultats, des sorties, des informations de débogage, etc.  Si vous souhaitez utiliser des volumes FlexVol , vous devez créer un ou plusieurs backends Trident compatibles FlexVol .  Les exemples de commandes qui suivent montrent la création d'un seul backend Trident compatible FlexVol .</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">MLOps Open Source avec NetApp - Exemples d'opérations Trident</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Exemple d'opérations Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Cette section comprend des exemples de diverses opérations que vous souhaiterez peut-être effectuer avec Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importer un volume existant</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">S'il existe des volumes existants sur votre système/plateforme de stockage NetApp que vous souhaitez monter sur des conteneurs au sein de votre cluster Kubernetes, mais qui ne sont pas liés aux PVC du cluster, vous devez importer ces volumes.  Vous pouvez utiliser la fonctionnalité d’importation de volume Trident pour importer ces volumes.</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">Les exemples de commandes qui suivent montrent l’importation d’un volume nommé<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> .  Pour plus d'informations sur les PVC, consultez le<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .  Pour plus d'informations sur la fonctionnalité d'importation de volume, consultez le<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">Un<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valeur de<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> est spécifié dans les exemples de fichiers de spécifications PVC.  Pour plus d'informations sur le<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> champ, voir le<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Provisionner un nouveau volume</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Vous pouvez utiliser Trident pour provisionner un nouveau volume sur votre système ou plate-forme de stockage NetApp .</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">Provisionner un nouveau volume à l'aide de kubectl</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">Les exemples de commandes suivants montrent le provisionnement d’un nouveau FlexVol volume à l’aide de kubectl.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">Un<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valeur de<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> est spécifié dans l'exemple de fichier de définition PVC suivant.  Pour plus d'informations sur le<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> champ, voir le<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">Provisionner un nouveau volume à l'aide de la boîte à outils NetApp DataOps</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">documentation</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">Vous pouvez également utiliser NetApp DataOps Toolkit pour Kubernetes pour provisionner un nouveau volume sur votre système ou plateforme de stockage NetApp .  La boîte à outils NetApp DataOps pour Kubernetes utilise Trident pour provisionner les volumes mais simplifie le processus pour l'utilisateur.  Se référer à la<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block> pour plus de détails.</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">MLOps Open Source avec NetApp : exemples de classes de stockage Kubernetes pour les déploiements NetApp AIPod</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">Exemples de classes de stockage Kubernetes pour les déploiements NetApp AIPod</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Avant de pouvoir utiliser Trident pour provisionner dynamiquement des ressources de stockage au sein de votre cluster Kubernetes, vous devez créer une ou plusieurs StorageClasses Kubernetes.  Les exemples qui suivent représentent différents types de StorageClasses que vous souhaiterez peut-être créer si vous déployez des composants de cette solution sur un<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  Pour plus d'informations sur les StorageClasses, et par exemple sur les StorageClasses pour d'autres plates-formes/environnements, consultez le<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">NFS sur RDMA</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp recommande de créer une StorageClass pour le backend Trident compatible FlexGroup que vous avez créé dans la section<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , étape 1.  Les exemples de commandes qui suivent montrent la création de plusieurs StorageClasses qui correspondent à l'exemple de Backend qui a été créé dans la section<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , étape 1 - une étape qui utilise<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block> et un qui ne le fait pas.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentation Kubernetes</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">Pour qu'un volume persistant ne soit pas supprimé lorsque le PersistentVolumeClaim (PVC) correspondant est supprimé, l'exemple suivant utilise un<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valeur de<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block> .  Pour plus d'informations sur le<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> terrain, voir le site officiel<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block> .</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">Remarque : les exemples de StorageClasses suivants utilisent une taille de transfert maximale de 262 144.  Pour utiliser cette taille de transfert maximale, vous devez configurer la taille de transfert maximale sur votre système ONTAP en conséquence.  Se référer à la<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block> pour plus de détails.</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">Remarque : pour utiliser NFS sur RDMA, vous devez configurer NFS sur RDMA sur votre système ONTAP .  Se référer à la<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block> pour plus de détails.</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">Remarque : dans l’exemple suivant, un backend spécifique est spécifié dans le champ storagePool du fichier de définition StorageClass.</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">Exemples de backends Trident pour les déploiements AIPod</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp recommande également de créer une StorageClass qui correspond au backend Trident compatible FlexVol que vous avez créé dans la section<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> , étape 2.  Les exemples de commandes qui suivent montrent la création d’une seule StorageClass pour les volumes FlexVol .</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">Remarque : dans l’exemple suivant, aucun backend particulier n’est spécifié dans le champ storagePool du fichier de définition StorageClass.  Lorsque vous utilisez Kubernetes pour administrer des volumes à l'aide de cette StorageClass, Trident tente d'utiliser tout backend disponible qui utilise le<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> conducteur.</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">Clonez presque instantanément des espaces de travail JupyterLab de grande capacité afin de permettre l'expérimentation ou l'itération rapide.</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">Enregistrez presque instantanément des instantanés d'espaces de travail JupyterLab haute capacité pour la sauvegarde et/ou la traçabilité/l'établissement de référence.</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">Provisionnez, clonez et capturez des instantanés quasi instantanément de volumes de données haute capacité et hautes performances.</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">conclusion - solution de base de données vectorielle pour netapp</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">Cette section conclut la solution de base de données vectorielle pour NetApp.</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">En conclusion, ce document fournit un aperçu complet du déploiement et de la gestion des bases de données vectorielles, telles que Milvus et pgvector, sur les solutions de stockage NetApp .  Nous avons discuté des directives d'infrastructure pour exploiter le stockage d'objets NetApp ONTAP et StorageGRID et validé la base de données Milvus dans AWS FSx ONTAP via le magasin de fichiers et d'objets.</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">Nous avons exploré la dualité fichier-objet de NetApp, démontrant son utilité non seulement pour les données des bases de données vectorielles, mais également pour d'autres applications.  Nous avons également souligné comment SnapCenter, le produit de gestion d'entreprise de NetApp, offre des fonctionnalités de sauvegarde, de restauration et de clonage pour les données de bases de données vectorielles, garantissant ainsi l'intégrité et la disponibilité des données.</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">Le document examine également comment la solution Hybrid Cloud de NetApp offre une réplication et une protection des données dans les environnements sur site et cloud, offrant une expérience de gestion des données transparente et sécurisée.  Nous avons fourni des informations sur la validation des performances des bases de données vectorielles telles que Milvus et pgvecto sur NetApp ONTAP, offrant des informations précieuses sur leur efficacité et leur évolutivité.</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">Enfin, nous avons discuté de deux cas d'utilisation d'IA générative : RAG avec LLM et ChatAI interne de NetApp.  Ces exemples pratiques soulignent les applications et les avantages concrets des concepts et des pratiques décrits dans ce document.  Dans l’ensemble, ce document sert de guide complet pour quiconque souhaite tirer parti des puissantes solutions de stockage de NetApp pour la gestion des bases de données vectorielles.</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">L'auteur souhaite remercier sincèrement les contributeurs ci-dessous, ainsi que les autres personnes qui ont fourni leurs commentaires et leurs commentaires pour rendre ce document utile aux clients et aux NetApp .</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan, ingénieur marketing technique, ONTAP AI &amp; Analytics, NetApp</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, ingénieur marketing technique, NetApp</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ Mahajan, directeur principal, NetApp</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott, responsable de l'ingénierie des performances des charges de travail, NetApp</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan, directeur principal, gestion des produits FSX, NetApp</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon, chef de produit senior, équipe produit FSx, NetApp</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Documentation Milvus -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Documentation autonome Milvus -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">Documentation produit NetApp<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">documentation d'installclustr</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">Avril 2024</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">Préparation des données vers une solution de base de données vectorielle pour NetApp</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">Annexe B : prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">Cette section fournit un exemple de script Python utilisé pour préparer les données de la base de données vectorielle.</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">procédure de déploiement de base de données vectorielle - solution de base de données vectorielle pour NetApp</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">Cette section décrit la procédure de déploiement de la solution de base de données vectorielle pour NetApp.</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">Procédure de déploiement</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">Dans cette section de déploiement, nous avons utilisé la base de données vectorielle Milvus avec Kubernetes pour la configuration du laboratoire comme ci-dessous.</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">Le stockage NetApp fournit le stockage au cluster pour conserver les données des clients et les données du cluster Milvus.</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">Configuration du stockage NetApp – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">Veuillez suivre les étapes ci-dessous pour NFS (Network File System) :</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">Créez un volume FlexGroup pour NFSv4.  Dans notre configuration pour cette validation, nous avons utilisé 48 SSD, 1 SSD dédié au volume racine du contrôleur et 47 SSD répartis pour NFSv4]].Vérifiez que la politique d'exportation NFS pour le volume FlexGroup dispose d'autorisations de lecture/écriture pour le réseau de nœuds Kubernetes (K8s).  Si ces autorisations ne sont pas en place, accordez des autorisations de lecture/écriture (rw) pour le réseau de nœuds K8s.</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">Sur tous les nœuds K8s, créez un dossier et montez le volume FlexGroup sur ce dossier via une interface logique (LIF) sur chaque nœud K8s.</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">Veuillez suivre les étapes ci-dessous pour NAS S3 (Network Attached Storage Simple Storage Service) :</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">Créez un volume FlexGroup pour NFS.</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">Créez un bucket NAS en définissant son type sur « nas » et en fournissant le chemin d’accès au volume NFSv3.  Il est également possible d’utiliser un bucket S3 à cette fin.</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">Configuration du stockage NetApp – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">Installez le logiciel storageGRID.</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">Créez un locataire et un bucket.</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">Créez un utilisateur avec l'autorisation requise.</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">Veuillez vérifier plus de détails dans<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml – solution de base de données vectorielle pour NetApp</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">Annexe D : docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">Cette section comprend un exemple de code YAML pour la solution de base de données vectorielle pour NetApp.</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">Protection de base de données vectorielle avec SnapCenter - solution de base de données vectorielle pour NetApp</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">Protection de la base de données vectorielle à l'aide de SnapCenter</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">Cette section décrit comment assurer la protection des données pour la base de données vectorielle à l'aide de NetApp SnapCenter.</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">Protection de base de données vectorielle à l'aide de NetApp SnapCenter.</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">Par exemple, dans l’industrie de la production cinématographique, les clients possèdent souvent des données intégrées critiques telles que des fichiers vidéo et audio.  La perte de ces données, due à des problèmes tels que des pannes de disque dur, peut avoir un impact significatif sur leurs opérations, mettant potentiellement en péril des entreprises de plusieurs millions de dollars.  Nous avons rencontré des cas où un contenu inestimable a été perdu, entraînant des perturbations et des pertes financières importantes.  Assurer la sécurité et l’intégrité de ces données essentielles est donc d’une importance primordiale dans ce secteur.  Dans cette section, nous examinons comment SnapCenter protège les données de la base de données vectorielle et les données Milvus résidant dans ONTAP.  Pour cet exemple, nous avons utilisé un bucket NAS (milvusdbvol1) dérivé d'un volume NFS ONTAP (vol1) pour les données client et un volume NFS distinct (vectordbpv) pour les données de configuration du cluster Milvus. Veuillez vérifier le<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> pour le flux de travail de sauvegarde Snapcenter</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">Configurez l’hôte qui sera utilisé pour exécuter les commandes SnapCenter .</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">Boutique d'automatisation NetApp</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">Installez et configurez le plugin de stockage.  À partir de l'hôte ajouté, sélectionnez « Plus d'options ».  Accédez au plugin de stockage téléchargé et sélectionnez-le dans le<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> .  Installez le plugin et enregistrez la configuration.</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">Configurer le système de stockage et le volume : ajoutez le système de stockage sous « Système de stockage » et sélectionnez la SVM (machine virtuelle de stockage).  Dans cet exemple, nous avons choisi « vs_nvidia ».</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">Établissez une ressource pour la base de données vectorielle, en intégrant une politique de sauvegarde et un nom d’instantané personnalisé.</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">Activez la sauvegarde du groupe de cohérence avec les valeurs par défaut et activez SnapCenter sans cohérence du système de fichiers.</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">Dans la section Empreinte de stockage, sélectionnez les volumes associés aux données client de la base de données vectorielle et aux données du cluster Milvus.  Dans notre exemple, il s'agit de « vol1 » et « vectordbpv ».</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">Créez une politique de protection de la base de données vectorielle et protégez les ressources de la base de données vectorielle à l'aide de la politique.</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Insérez des données dans le bucket NAS S3 à l’aide d’un script Python.  Dans notre cas, nous avons modifié le script de sauvegarde fourni par Milvus, à savoir « prepare_data_netapp.py », et exécuté la commande « sync » pour vider les données du système d'exploitation.</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">Vérifiez les données dans le bucket NAS S3.  Dans notre exemple, les fichiers avec l'horodatage « 2024-04-08 21:22 » ont été créés par le script « prepare_data_netapp.py ».</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">Lancer une sauvegarde à l'aide de l'instantané du groupe de cohérence (CG) à partir de la ressource « milvusdb »</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">Pour tester la fonctionnalité de sauvegarde, nous avons soit ajouté une nouvelle table après le processus de sauvegarde, soit supprimé certaines données du NFS (bucket NAS S3).</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">Pour ce test, imaginez un scénario dans lequel quelqu’un a créé une nouvelle collection inutile ou inappropriée après la sauvegarde.  Dans un tel cas, nous devrions rétablir la base de données vectorielle à son état antérieur à l’ajout de la nouvelle collection.  Par exemple, de nouvelles collections telles que « hello_milvus_netapp_sc_testnew » et « hello_milvus_netapp_sc_testnew2 » ont été insérées.</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">Exécutez une restauration complète du bucket NAS S3 à partir de l’instantané précédent.</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Utilisez un script Python pour vérifier les données des collections « hello_milvus_netapp_sc_test » et « hello_milvus_netapp_sc_test2 ».</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">Vérifiez que la collection inutile ou inappropriée n'est plus présente dans la base de données.</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">En conclusion, l'utilisation de SnapCenter de NetApp pour protéger les données de bases de données vectorielles et les données Milvus résidant dans ONTAP offre des avantages significatifs aux clients, en particulier dans les secteurs où l'intégrité des données est primordiale, comme la production cinématographique.  La capacité de SnapCenter à créer des sauvegardes cohérentes et à effectuer des restaurations complètes des données garantit que les données critiques, telles que les fichiers vidéo et audio intégrés, sont protégées contre les pertes dues à des pannes de disque dur ou à d'autres problèmes.  Cela permet non seulement d’éviter les perturbations opérationnelles, mais également de se prémunir contre des pertes financières importantes.</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">Dans cette section, nous avons démontré comment SnapCenter peut être configuré pour protéger les données résidant dans ONTAP, y compris la configuration des hôtes, l'installation et la configuration des plugins de stockage et la création d'une ressource pour la base de données vectorielle avec un nom d'instantané personnalisé.  Nous avons également montré comment effectuer une sauvegarde à l’aide de l’instantané du groupe de cohérence et vérifier les données dans le bucket NAS S3.</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">De plus, nous avons simulé un scénario dans lequel une collection inutile ou inappropriée a été créée après la sauvegarde.  Dans de tels cas, la capacité de SnapCenter à effectuer une restauration complète à partir d'un instantané précédent garantit que la base de données vectorielle peut être rétablie à son état avant l'ajout de la nouvelle collection, préservant ainsi l'intégrité de la base de données.  Cette capacité à restaurer des données à un moment précis est inestimable pour les clients, leur offrant l’assurance que leurs données sont non seulement sécurisées mais également correctement conservées.  Ainsi, le produit SnapCenter de NetApp offre aux clients une solution robuste et fiable pour la protection et la gestion des données.</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">Reprise après sinistre avec NetApp SnapMirror : solution de base de données vectorielle pour NetApp</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">Reprise après sinistre avec NetApp SnapMirror</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">Cette section décrit la reprise après sinistre (DR) avec SnapMirror pour la solution de base de données vectorielle pour NetApp.</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">La reprise après sinistre est essentielle pour maintenir l’intégrité et la disponibilité d’une base de données vectorielle, en particulier compte tenu de son rôle dans la gestion de données de grande dimension et l’exécution de recherches de similarité complexes.  Une stratégie de reprise après sinistre bien planifiée et mise en œuvre garantit que les données ne sont pas perdues ou compromises en cas d’incidents imprévus, tels que des pannes matérielles, des catastrophes naturelles ou des cyberattaques.  Cela est particulièrement important pour les applications s’appuyant sur des bases de données vectorielles, où la perte ou la corruption des données pourrait entraîner des perturbations opérationnelles et des pertes financières importantes.  De plus, un plan de reprise après sinistre robuste garantit également la continuité des activités en minimisant les temps d’arrêt et en permettant la restauration rapide des services.  Ceci est réalisé grâce au produit de réplication de données NetApp SnapMirrror sur différents emplacements géographiques, à des sauvegardes régulières et à des mécanismes de basculement.  Par conséquent, la reprise après sinistre n’est pas seulement une mesure de protection, mais un élément essentiel d’une gestion responsable et efficace des bases de données vectorielles.</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">SnapMirror de NetApp fournit la réplication des données d'un contrôleur de stockage NetApp ONTAP vers un autre, principalement utilisé pour la reprise après sinistre (DR) et les solutions hybrides.  Dans le contexte d’une base de données vectorielle, cet outil facilite la transition fluide des données entre les environnements sur site et cloud.  Cette transition est réalisée sans nécessiter de conversion de données ni de refactorisation d’application, améliorant ainsi l’efficacité et la flexibilité de la gestion des données sur plusieurs plates-formes.</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">La solution hybride NetApp dans un scénario de base de données vectorielle peut apporter davantage d'avantages :</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">Évolutivité : la solution cloud hybride de NetApp offre la possibilité de faire évoluer vos ressources en fonction de vos besoins.  Vous pouvez utiliser des ressources sur site pour des charges de travail régulières et prévisibles et des ressources cloud telles qu'Amazon Amazon FSx ONTAP pour NetApp ONTAP et Google Cloud NetApp Volume (NetApp Volumes) pour les heures de pointe ou les charges inattendues.</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">Efficacité des coûts : le modèle de cloud hybride de NetApp vous permet d'optimiser vos coûts en utilisant des ressources sur site pour les charges de travail régulières et en payant uniquement pour les ressources cloud lorsque vous en avez besoin.  Ce modèle de paiement à l’utilisation peut être très rentable avec une offre de service NetApp instaclustr.  Pour les fournisseurs de services cloud sur site et majeurs, instaclustr fournit une assistance et des conseils.</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">Flexibilité : le cloud hybride de NetApp vous offre la flexibilité de choisir où traiter vos données.  Par exemple, vous pouvez choisir d’effectuer des opérations vectorielles complexes sur site, où vous disposez d’un matériel plus puissant, et des opérations moins intensives dans le cloud.</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">Continuité des activités : en cas de sinistre, le fait de disposer de vos données dans un cloud hybride NetApp peut garantir la continuité des activités.  Vous pouvez rapidement passer au cloud si vos ressources sur site sont affectées.  Nous pouvons exploiter NetApp SnapMirror pour déplacer les données du site vers le cloud et vice versa.</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">Innovation : les solutions de cloud hybride de NetApp peuvent également permettre une innovation plus rapide en fournissant un accès à des services et technologies cloud de pointe.  Les innovations NetApp dans le cloud telles qu'Amazon Amazon FSx ONTAP pour NetApp ONTAP, Azure NetApp Files et Google Cloud NetApp Volumes sont des produits innovants et des NAS préférés des fournisseurs de services cloud.</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr avec pgvector – solution de base de données vectorielle pour NetApp</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">Base de données vectorielle avec Instaclustr utilisant PostgreSQL : pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">Cette section décrit les spécificités de la manière dont le produit instaclustr s'intègre à la fonctionnalité postgreSQL sur pgvector dans la solution de base de données vectorielle pour NetApp.</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">blog</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">Dans cette section, nous examinons en détail la manière dont le produit instaclustr s'intègre à la fonctionnalité postgreSQL sur pgvector.  Nous avons un exemple de « Comment améliorer la précision et les performances de votre LLM avec PGVector et PostgreSQL : Introduction aux intégrations et au rôle de PGVector ».  Veuillez vérifier le<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block> pour obtenir plus d'informations.</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">Introduction à la solution de base de données vectorielle pour NetApp</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">Cette section fournit une introduction à la solution de base de données vectorielle pour NetApp.</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">Les bases de données vectorielles répondent efficacement aux défis conçus pour gérer les complexités de la recherche sémantique dans les grands modèles de langage (LLM) et l'intelligence artificielle générative (IA).  Contrairement aux systèmes de gestion de données traditionnels, les bases de données vectorielles sont capables de traiter et de rechercher différents types de données, notamment des images, des vidéos, du texte, de l'audio et d'autres formes de données non structurées, en utilisant le contenu des données elles-mêmes plutôt que des étiquettes ou des balises.</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">Les limites des systèmes de gestion de bases de données relationnelles (SGBDR) sont bien documentées, en particulier leurs difficultés avec les représentations de données à haute dimension et les données non structurées courantes dans les applications d'IA.  Les SGBDR nécessitent souvent un processus long et sujet aux erreurs d'aplatissement des données dans des structures plus faciles à gérer, ce qui entraîne des retards et des inefficacités dans les recherches.  Les bases de données vectorielles sont toutefois conçues pour contourner ces problèmes, en offrant une solution plus efficace et plus précise pour la gestion et la recherche de données complexes et de grande dimension, facilitant ainsi l'avancement des applications d'IA.</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">Ce document sert de guide complet pour les clients qui utilisent actuellement ou prévoient d'utiliser des bases de données vectorielles, détaillant les meilleures pratiques d'utilisation des bases de données vectorielles sur des plates-formes telles que NetApp ONTAP, NetApp StorageGRID, Amazon FSx ONTAP pour NetApp ONTAP et SnapCenter.  Le contenu fourni ici couvre une gamme de sujets :</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">Directives d'infrastructure pour les bases de données vectorielles, comme Milvus, fournies par le stockage NetApp via NetApp ONTAP et le stockage d'objets StorageGRID .</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">Validation de la base de données Milvus dans AWS FSx ONTAP via un magasin de fichiers et d'objets.</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">Plonge dans la dualité fichier-objet de NetApp, démontrant son utilité pour les données dans les bases de données vectorielles ainsi que pour d'autres applications.</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">Comment le produit de gestion de la protection des données de NetApp, SnapCenter, offre des fonctionnalités de sauvegarde et de restauration pour les données de bases de données vectorielles.</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">Comment le cloud hybride de NetApp offre la réplication et la protection des données dans les environnements sur site et cloud.</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">Fournit des informations sur la validation des performances des bases de données vectorielles telles que Milvus et pgvector sur NetApp ONTAP.</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">Deux cas d'utilisation spécifiques : Retrieval Augmented Generation (RAG) avec Large Language Models (LLM) et ChatAI de l'équipe informatique de NetApp , offrant ainsi des exemples pratiques des concepts et pratiques décrits.</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">base de données vectorielle - solution de base de données vectorielle pour NetApp</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">Base de données vectorielles</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">Cette section couvre la définition et l’utilisation d’une base de données vectorielle dans les solutions NetApp AI.</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">Une base de données vectorielle est un type de base de données spécialisé conçu pour gérer, indexer et rechercher des données non structurées à l'aide d'intégrations provenant de modèles d'apprentissage automatique.  Au lieu d'organiser les données dans un format tabulaire traditionnel, il organise les données sous forme de vecteurs de grande dimension, également appelés plongements vectoriels.  Cette structure unique permet à la base de données de gérer des données complexes et multidimensionnelles de manière plus efficace et plus précise.</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">L’une des principales capacités d’une base de données vectorielle est son utilisation de l’IA générative pour effectuer des analyses.  Cela inclut les recherches de similarité, où la base de données identifie les points de données qui ressemblent à une entrée donnée, et la détection d'anomalies, où elle peut repérer les points de données qui s'écartent considérablement de la norme.</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">De plus, les bases de données vectorielles sont bien adaptées pour gérer des données temporelles ou des données horodatées.  Ce type de données fournit des informations sur « ce » qui s'est produit et quand cela s'est produit, dans l'ordre et par rapport à tous les autres événements au sein d'un système informatique donné.  Cette capacité à gérer et à analyser des données temporelles rend les bases de données vectorielles particulièrement utiles pour les applications qui nécessitent une compréhension des événements au fil du temps.</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">Avantages de la base de données vectorielle pour le ML et l'IA :</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">Recherche à haute dimension : les bases de données vectorielles excellent dans la gestion et la récupération de données à haute dimension, qui sont souvent générées dans les applications d'IA et de ML.</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">Évolutivité : ils peuvent évoluer efficacement pour gérer de grands volumes de données, soutenant ainsi la croissance et l'expansion des projets d'IA et de ML.</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">Flexibilité : les bases de données vectorielles offrent un haut degré de flexibilité, permettant l’hébergement de divers types et structures de données.</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">Performances : Ils offrent une gestion et une récupération de données hautes performances, essentielles à la rapidité et à l'efficacité des opérations d'IA et de ML.</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">Indexation personnalisable : les bases de données vectorielles offrent des options d'indexation personnalisables, permettant une organisation et une récupération optimisées des données en fonction de besoins spécifiques.</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">Bases de données vectorielles et cas d'utilisation.</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">Cette section fournit diverses bases de données vectorielles et les détails de leurs cas d'utilisation.</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss et ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">Ce sont des bibliothèques qui servent d’outils essentiels dans le domaine de la recherche vectorielle.  Ces bibliothèques offrent des fonctionnalités essentielles à la gestion et à la recherche de données vectorielles, ce qui en fait des ressources inestimables dans ce domaine spécialisé de la gestion des données.</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">Il s'agit d'un moteur de recherche et d'analyse largement utilisé, qui a récemment intégré des capacités de recherche vectorielle.  Cette nouvelle fonctionnalité améliore ses fonctionnalités, lui permettant de gérer et de rechercher plus efficacement les données vectorielles.</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">Pomme de pin</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">Il s’agit d’une base de données vectorielle robuste dotée d’un ensemble unique de fonctionnalités.  Il prend en charge les vecteurs denses et clairsemés dans sa fonctionnalité d'indexation, ce qui améliore sa flexibilité et son adaptabilité.  L’un de ses principaux atouts réside dans sa capacité à combiner des méthodes de recherche traditionnelles avec une recherche vectorielle dense basée sur l’IA, créant ainsi une approche de recherche hybride qui exploite le meilleur des deux mondes.</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Principalement basé sur le cloud, Pinecone est conçu pour les applications d'apprentissage automatique et s'intègre bien à une variété de plates-formes, notamment GCP, AWS, Open AI, GPT-3, GPT-3.5, GPT-4, Catgut Plus, Elasticsearch, Haystack, et plus encore.  Il est important de noter que Pinecone est une plate-forme à source fermée et est disponible en tant qu'offre de logiciel en tant que service (SaaS).</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">Compte tenu de ses capacités avancées, Pinecone est particulièrement bien adapté au secteur de la cybersécurité, où ses capacités de recherche hautement dimensionnelle et de recherche hybride peuvent être exploitées efficacement pour détecter et répondre aux menaces.</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">Chroma</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">Il s'agit d'une base de données vectorielle dotée d'une API principale avec quatre fonctions principales, dont l'une comprend un magasin de vecteurs de documents en mémoire.  Il utilise également la bibliothèque Face Transformers pour vectoriser les documents, améliorant ainsi sa fonctionnalité et sa polyvalence.  Chroma est conçu pour fonctionner à la fois dans le cloud et sur site, offrant une flexibilité en fonction des besoins des utilisateurs.  Il excelle particulièrement dans les applications liées à l'audio, ce qui en fait un excellent choix pour les moteurs de recherche basés sur l'audio, les systèmes de recommandation musicale et d'autres cas d'utilisation liés à l'audio.</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">Tisser</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">Il s'agit d'une base de données vectorielle polyvalente qui permet aux utilisateurs de vectoriser leur contenu à l'aide de ses modules intégrés ou de modules personnalisés, offrant une flexibilité en fonction des besoins spécifiques.  Il propose des solutions entièrement gérées et auto-hébergées, répondant à une variété de préférences de déploiement.</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">L’une des principales caractéristiques de Weaviate est sa capacité à stocker à la fois des vecteurs et des objets, améliorant ainsi ses capacités de gestion des données.  Il est largement utilisé pour une gamme d’applications, notamment la recherche sémantique et la classification des données dans les systèmes ERP.  Dans le secteur du e-commerce, il alimente les moteurs de recherche et de recommandation.  Weaviate est également utilisé pour la recherche d'images, la détection d'anomalies, l'harmonisation automatisée des données et l'analyse des menaces de cybersécurité, démontrant ainsi sa polyvalence dans plusieurs domaines.</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis est une base de données vectorielle hautes performances connue pour son stockage rapide en mémoire, offrant une faible latence pour les opérations de lecture-écriture.  Cela en fait un excellent choix pour les systèmes de recommandation, les moteurs de recherche et les applications d’analyse de données qui nécessitent un accès rapide aux données.</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis prend en charge diverses structures de données pour les vecteurs, notamment les listes, les ensembles et les ensembles triés.  Il fournit également des opérations vectorielles telles que le calcul des distances entre les vecteurs ou la recherche d'intersections et d'unions.  Ces fonctionnalités sont particulièrement utiles pour la recherche de similarité, le clustering et les systèmes de recommandation basés sur le contenu.</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">En termes d'évolutivité et de disponibilité, Redis excelle dans la gestion des charges de travail à haut débit et offre la réplication des données.  Il s’intègre également bien avec d’autres types de données, y compris les bases de données relationnelles traditionnelles (SGBDR).  Redis inclut une fonctionnalité de publication/abonnement (Pub/Sub) pour les mises à jour en temps réel, ce qui est bénéfique pour la gestion des vecteurs en temps réel.  De plus, Redis est léger et simple à utiliser, ce qui en fait une solution conviviale pour la gestion des données vectorielles.</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">Il s'agit d'une base de données vectorielle polyvalente qui offre une API semblable à un magasin de documents, un peu comme MongoDB.  Il se distingue par sa prise en charge d'une grande variété de types de données, ce qui en fait un choix populaire dans les domaines de la science des données et de l'apprentissage automatique.</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">L’une des fonctionnalités uniques de Milvus est sa capacité de multi-vectorisation, qui permet aux utilisateurs de spécifier au moment de l’exécution le type de vecteur à utiliser pour la recherche.  De plus, il utilise Knowwhere, une bibliothèque qui se trouve au-dessus d'autres bibliothèques comme Faiss, pour gérer la communication entre les requêtes et les algorithmes de recherche vectorielle.</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">Milvus offre également une intégration transparente avec les workflows d'apprentissage automatique, grâce à sa compatibilité avec PyTorch et TensorFlow.  Cela en fait un excellent outil pour une gamme d'applications, notamment le commerce électronique, l'analyse d'images et de vidéos, la reconnaissance d'objets, la recherche de similarité d'images et la récupération d'images basée sur le contenu.  Dans le domaine du traitement du langage naturel, Milvus est utilisé pour le regroupement de documents, la recherche sémantique et les systèmes de réponses aux questions.</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">Pour cette solution, nous avons choisi Milvus pour la validation de la solution.  Pour les performances, nous avons utilisé à la fois milvus et postgres (pgvecto.rs).</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">Pourquoi avons-nous choisi Milvus pour cette solution ?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">Open-Source : Milvus est une base de données vectorielle open source, encourageant le développement et les améliorations pilotés par la communauté.</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">Intégration de l'IA : elle exploite l'intégration de la recherche de similarité et des applications d'IA pour améliorer les fonctionnalités de la base de données vectorielle.</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">Gestion de gros volumes : Milvus a la capacité de stocker, d'indexer et de gérer plus d'un milliard de vecteurs d'intégration générés par des modèles de réseaux neuronaux profonds (DNN) et d'apprentissage automatique (ML).</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">Convivial : il est facile à utiliser, la configuration prenant moins d'une minute.  Milvus propose également des SDK pour différents langages de programmation.</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">Vitesse : Il offre des vitesses de récupération ultra-rapides, jusqu'à 10 fois plus rapides que certaines alternatives.</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">Évolutivité et disponibilité : Milvus est hautement évolutif, avec des options d'évolutivité et de mise à l'échelle selon les besoins.</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">Riche en fonctionnalités : il prend en charge différents types de données, le filtrage des attributs, la prise en charge des fonctions définies par l'utilisateur (UDF), les niveaux de cohérence configurables et le temps de trajet, ce qui en fait un outil polyvalent pour diverses applications.</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Présentation de l'architecture Milvus</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">Cette section fournit des composants et des services de niveau supérieur utilisés dans l'architecture Milvus.  * Couche d'accès – Elle est composée d'un groupe de proxys sans état et sert de couche frontale du système et de point de terminaison pour les utilisateurs.  * Service de coordination – il attribue les tâches aux nœuds de travail et agit comme le cerveau du système.  Il dispose de trois types de coordinateurs : coordonnées racine, coordonnées de données et coordonnées de requête.  * Nœuds de travail : il suit les instructions du service de coordination et exécute les commandes DML/DDL déclenchées par l'utilisateur. Il dispose de trois types de nœuds de travail tels que le nœud de requête, le nœud de données et le nœud d'index.  * Stockage : il est responsable de la persistance des données.  Il comprend un stockage méta, un courtier de journaux et un stockage d'objets.  Le stockage NetApp tel que ONTAP et StorageGRID fournit un stockage d'objets et un stockage basé sur des fichiers à Milvus pour les données client et les données de base de données vectorielles.</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus avec Amazon FSx ONTAP pour NetApp ONTAP - solution de base de données vectorielle pour NetApp</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus avec Amazon FSx ONTAP pour NetApp ONTAP - dualité fichier et objet</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">Cette section décrit la configuration du cluster milvus avec Amazon FSx ONTAP pour la solution de base de données vectorielle pour NetApp.</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus avec Amazon FSx ONTAP pour NetApp ONTAP – dualité fichier et objet</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">Dans cette section, pourquoi nous devons déployer une base de données vectorielle dans le cloud ainsi que les étapes pour déployer une base de données vectorielle (milvus autonome) dans Amazon FSx ONTAP pour NetApp ONTAP dans des conteneurs Docker.</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">Le déploiement d’une base de données vectorielle dans le cloud offre plusieurs avantages importants, en particulier pour les applications qui nécessitent la gestion de données de grande dimension et l’exécution de recherches de similarité.  Tout d’abord, le déploiement basé sur le cloud offre une évolutivité, permettant un ajustement facile des ressources pour correspondre aux volumes de données et aux charges de requêtes croissants.  Cela garantit que la base de données peut gérer efficacement la demande accrue tout en maintenant des performances élevées.  Deuxièmement, le déploiement dans le cloud offre une haute disponibilité et une reprise après sinistre, car les données peuvent être répliquées sur différents emplacements géographiques, minimisant ainsi le risque de perte de données et garantissant un service continu même en cas d’événements inattendus.  Troisièmement, il offre une rentabilité optimale, car vous ne payez que pour les ressources que vous utilisez et pouvez augmenter ou diminuer votre capacité en fonction de la demande, évitant ainsi le besoin d'un investissement initial substantiel en matériel.  Enfin, le déploiement d’une base de données vectorielle dans le cloud peut améliorer la collaboration, car les données peuvent être consultées et partagées de n’importe où, facilitant le travail en équipe et la prise de décision basée sur les données.  Veuillez vérifier l'architecture du milvus autonome avec Amazon FSx ONTAP pour NetApp ONTAP utilisé dans cette validation.</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">Créez une instance Amazon FSx ONTAP pour NetApp ONTAP et notez les détails du VPC, des groupes de sécurité VPC et du sous-réseau.  Ces informations seront nécessaires lors de la création d'une instance EC2.  Vous pouvez trouver plus de détails ici -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">Créez une instance EC2 en vous assurant que le VPC, les groupes de sécurité et le sous-réseau correspondent à ceux de l'instance Amazon FSx ONTAP pour NetApp ONTAP .</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">Installez nfs-common à l'aide de la commande « apt-get install nfs-common » et mettez à jour les informations du package à l'aide de « sudo apt-get update ».</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">Créez un dossier de montage et montez Amazon FSx ONTAP pour NetApp ONTAP dessus.</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">Installez Docker et Docker Compose à l'aide de « apt-get install ».</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Configurez un cluster Milvus basé sur le fichier docker-compose.yaml, qui peut être téléchargé à partir du site Web de Milvus.</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">Dans la section « volumes » du fichier docker-compose.yml, mappez le point de montage NetApp NFS au chemin du conteneur Milvus correspondant, en particulier dans etcd, minio et standalone.Check<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> pour plus de détails sur les changements dans yml</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">Vérifiez les dossiers et fichiers montés.</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">Exécutez « docker-compose up -d » à partir du répertoire contenant le fichier docker-compose.yml.</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Vérifiez l'état du conteneur Milvus.</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">Pour valider la fonctionnalité de lecture et d'écriture de la base de données vectorielle et de ses données dans Amazon FSx ONTAP pour NetApp ONTAP, nous avons utilisé le SDK Python Milvus et un exemple de programme de PyMilvus.  Installez les packages nécessaires en utilisant « apt-get install python3-numpy python3-pip » et installez PyMilvus en utilisant « pip3 install pymilvus ».</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">Validez les opérations d’écriture et de lecture de données depuis Amazon FSx ONTAP pour NetApp ONTAP dans la base de données vectorielle.</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">Vérifiez l'opération de lecture à l'aide du script verify_data_netapp.py.</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">Si le client souhaite accéder (lire) aux données NFS testées dans la base de données vectorielle via le protocole S3 pour les charges de travail d'IA, cela peut être validé à l'aide d'un programme Python simple.  Un exemple de cela pourrait être une recherche de similarité d'images provenant d'une autre application comme mentionné dans l'image qui se trouve au début de cette section.</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">Cette section montre efficacement comment les clients peuvent déployer et exploiter une configuration Milvus autonome dans des conteneurs Docker, en utilisant NetApp FSx ONTAP d'Amazon pour le stockage de données NetApp ONTAP .  Cette configuration permet aux clients d’exploiter la puissance des bases de données vectorielles pour gérer des données de grande dimension et exécuter des requêtes complexes, le tout dans l’environnement évolutif et efficace des conteneurs Docker.  En créant une instance Amazon FSx ONTAP pour NetApp ONTAP et une instance EC2 correspondante, les clients peuvent garantir une utilisation optimale des ressources et une gestion des données.  La validation réussie des opérations d'écriture et de lecture de données de FSx ONTAP dans la base de données vectorielle offre aux clients l'assurance d'opérations de données fiables et cohérentes.  De plus, la possibilité de répertorier (lire) les données des charges de travail d'IA via le protocole S3 offre une meilleure accessibilité aux données.  Ce processus complet offre donc aux clients une solution robuste et efficace pour gérer leurs opérations de données à grande échelle, en exploitant les capacités d'Amazon FSx ONTAP pour NetApp ONTAP.</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">Configuration du cluster Milvus : solution de base de données vectorielle pour NetApp</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">Configuration du cluster Milvus avec Kubernetes sur site</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">Cette section décrit la configuration du cluster Milvus pour la solution de base de données vectorielle pour NetApp.</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">Configuration du cluster Milvus avec Kubernetes sur site</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">Les défis des clients sont de pouvoir évoluer indépendamment en termes de stockage et de calcul, de gestion efficace de l'infrastructure et de gestion des données. Kubernetes et les bases de données vectorielles forment ensemble une solution puissante et évolutive pour la gestion des opérations de données volumineuses.  Kubernetes optimise les ressources et gère les conteneurs, tandis que les bases de données vectorielles gèrent efficacement les données de grande dimension et les recherches de similarité.  Cette combinaison permet un traitement rapide de requêtes complexes sur de grands ensembles de données et s'adapte de manière transparente aux volumes de données croissants, ce qui la rend idéale pour les applications Big Data et les charges de travail d'IA.</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">Dans cette section, nous détaillons le processus d’installation d’un cluster Milvus sur Kubernetes, en utilisant un contrôleur de stockage NetApp pour les données du cluster et les données client.</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Pour installer un cluster Milvus, des volumes persistants (PV) sont nécessaires pour stocker les données de divers composants du cluster Milvus.  Ces composants incluent etcd (trois instances), pulsar-bookie-journal (trois instances), pulsar-bookie-ledgers (trois instances) et pulsar-zookeeper-data (trois instances).</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">ce lien</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">Dans le cluster Milvus, nous pouvons utiliser Pulsar ou Kafka pour le moteur sous-jacent prenant en charge le stockage fiable et la publication/l'abonnement des flux de messages du cluster Milvus.  Pour Kafka avec NFS, NetApp a apporté des améliorations à ONTAP 9.12.1 et versions ultérieures. Ces améliorations, ainsi que les modifications apportées à NFSv4.1 et Linux incluses dans RHEL 8.7 ou 9.1 et versions ultérieures, résolvent le problème de « renommage inutile » qui peut survenir lors de l'exécution de Kafka sur NFS. Si vous souhaitez obtenir des informations plus détaillées sur l'exécution de Kafka avec la solution NetApp NFS, veuillez consulter :<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> .</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">Nous avons créé un seul volume NFS à partir de NetApp ONTAP et établi 12 volumes persistants, chacun avec 250 Go de stockage.  La taille de stockage peut varier en fonction de la taille du cluster ; par exemple, nous avons un autre cluster où chaque PV dispose de 50 Go.  Veuillez vous référer ci-dessous à l'un des fichiers PV YAML pour plus de détails ; nous avions 12 de ces fichiers au total.  Dans chaque fichier, le storageClassName est défini sur « default », et le stockage et le chemin sont uniques à chaque PV.</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">Exécutez la commande « kubectl apply » pour chaque fichier PV YAML pour créer les volumes persistants, puis vérifiez leur création à l'aide de « kubectl get pv ».</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Pour stocker les données client, Milvus prend en charge les solutions de stockage d'objets telles que MinIO, Azure Blob et S3.  Dans ce guide, nous utilisons S3.  Les étapes suivantes s’appliquent à la fois au magasin d’objets ONTAP S3 et StorageGRID .  Nous utilisons Helm pour déployer le cluster Milvus.  Téléchargez le fichier de configuration, values.yaml, à partir de l'emplacement de téléchargement de Milvus.  Veuillez vous référer à l'annexe pour le fichier values.yaml que nous avons utilisé dans ce document.</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">Assurez-vous que la « classe de stockage » est définie sur « par défaut » dans chaque section, y compris celles du journal, etcd, zookeeper et bookkeeper.</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">Dans la section MinIO, désactivez MinIO.</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">Créez un bucket NAS à partir du stockage d'objets ONTAP ou StorageGRID et incluez-les dans un S3 externe avec les informations d'identification de stockage d'objets.</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Avant de créer le cluster Milvus, assurez-vous que le PersistentVolumeClaim (PVC) ne dispose d'aucune ressource préexistante.</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Utilisez Helm et le fichier de configuration values.yaml pour installer et démarrer le cluster Milvus.</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">Vérifiez l’état des PersistentVolumeClaims (PVC).</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">Vérifiez l'état des pods.</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">Veuillez vous assurer que l'état des pods est « en cours d'exécution » et fonctionne comme prévu</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Écriture et lecture de données de test dans le stockage d'objets Milvus et NetApp .</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">Écrivez des données à l'aide du programme Python « prepare_data_netapp_new.py ».</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">Lisez les données à l'aide du fichier Python « verify_data_netapp.py ».</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">Sur la base de la validation ci-dessus, l'intégration de Kubernetes avec une base de données vectorielle, comme démontré par le déploiement d'un cluster Milvus sur Kubernetes à l'aide d'un contrôleur de stockage NetApp , offre aux clients une solution robuste, évolutive et efficace pour la gestion des opérations de données à grande échelle.  Cette configuration offre aux clients la possibilité de gérer des données de grande dimension et d’exécuter des requêtes complexes rapidement et efficacement, ce qui en fait une solution idéale pour les applications Big Data et les charges de travail d’IA.  L'utilisation de volumes persistants (PV) pour divers composants de cluster, ainsi que la création d'un volume NFS unique à partir de NetApp ONTAP, garantissent une utilisation optimale des ressources et une gestion des données.  Le processus de vérification de l'état des PersistentVolumeClaims (PVC) et des pods, ainsi que le test de l'écriture et de la lecture des données, offrent aux clients l'assurance d'opérations de données fiables et cohérentes.  L’utilisation du stockage d’objets ONTAP ou StorageGRID pour les données client améliore encore l’accessibilité et la sécurité des données.  Dans l’ensemble, cette configuration offre aux clients une solution de gestion de données résiliente et performante, capable de s’adapter de manière transparente à leurs besoins croissants en matière de données.</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">Présentation de la solution de base de données vectorielle pour NetApp</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">Cette section fournit un aperçu de la solution de base de données vectorielle NetApp .</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">Cette solution présente les avantages et les capacités distinctifs que NetApp apporte pour relever les défis auxquels sont confrontés les clients de bases de données vectorielles.  En tirant parti de NetApp ONTAP, StorageGRID, des solutions cloud de NetApp et de SnapCenter, les clients peuvent ajouter une valeur significative à leurs opérations commerciales.  Ces outils non seulement répondent aux problèmes existants, mais améliorent également l’efficacité et la productivité, contribuant ainsi à la croissance globale de l’entreprise.</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">Pourquoi NetApp?</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">Les offres de NetApp, telles que ONTAP et StorageGRID, permettent la séparation du stockage et du calcul, permettant une utilisation optimale des ressources en fonction d'exigences spécifiques.  Cette flexibilité permet aux clients de faire évoluer leur stockage de manière indépendante à l’aide des solutions de stockage NetApp .</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP fournit une prise en charge native du stockage NAS et d'objets auprès des principaux fournisseurs de services cloud tels qu'AWS, Azure et Google Cloud.  Cette large compatibilité garantit une intégration transparente, permettant la mobilité des données client, l'accessibilité globale, la reprise après sinistre, l'évolutivité dynamique et des performances élevées.</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">Grâce aux solides capacités de gestion des données de NetApp, les clients peuvent être assurés que leurs données sont bien protégées contre les risques et menaces potentiels.  NetApp accorde la priorité à la sécurité des données, offrant ainsi aux clients la tranquillité d'esprit quant à la sécurité et à l'intégrité de leurs précieuses informations.</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">Validation des performances des bases de données vectorielles : solution de base de données vectorielles pour NetApp</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">Validation des performances de la base de données vectorielle</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">Cette section met en évidence la validation des performances qui a été effectuée sur la base de données vectorielles.</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Validation des performances</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">La validation des performances joue un rôle essentiel dans les bases de données vectorielles et les systèmes de stockage, servant de facteur clé pour garantir un fonctionnement optimal et une utilisation efficace des ressources.  Les bases de données vectorielles, connues pour gérer des données de grande dimension et exécuter des recherches de similarité, doivent maintenir des niveaux de performances élevés pour traiter des requêtes complexes rapidement et avec précision.  La validation des performances permet d’identifier les goulots d’étranglement, d’affiner les configurations et de garantir que le système peut gérer les charges attendues sans dégradation du service.  De même, dans les systèmes de stockage, la validation des performances est essentielle pour garantir que les données sont stockées et récupérées efficacement, sans problèmes de latence ni goulots d’étranglement susceptibles d’avoir un impact sur les performances globales du système.  Il permet également de prendre des décisions éclairées sur les mises à niveau ou les modifications nécessaires à l’infrastructure de stockage.  Par conséquent, la validation des performances est un aspect crucial de la gestion du système, contribuant de manière significative au maintien d’une qualité de service élevée, de l’efficacité opérationnelle et de la fiabilité globale du système.</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">Dans cette section, nous visons à approfondir la validation des performances des bases de données vectorielles, telles que Milvus et pgvecto.rs, en nous concentrant sur leurs caractéristiques de performances de stockage telles que le profil d'E/S et le comportement du contrôleur de stockage NetApp à la prise en charge des charges de travail RAG et d'inférence au sein du cycle de vie LLM.  Nous évaluerons et identifierons les différenciateurs de performances lorsque ces bases de données seront combinées avec la solution de stockage ONTAP .  Notre analyse sera basée sur des indicateurs de performance clés, tels que le nombre de requêtes traitées par seconde (QPS).</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">Veuillez consulter la méthodologie utilisée pour milvus et les progrès ci-dessous.</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus (autonome et cluster)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">version</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">Système de fichiers</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">XFS sur les LUN iSCSI</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">Générateur de charge de travail</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDB-Bench</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">Ensembles de données</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">Ensemble de données LAION * 10 millions d'intégrations * 768 dimensions * Taille de l'ensemble de données d'environ 300 Go</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * Version – 9.14.1 * 4 x 100GbE – pour milvus et 2x 100GbE pour postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">VectorDB-Bench avec cluster autonome Milvus</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">nous avons effectué la validation des performances suivante sur le cluster autonome milvus avec vectorDB-Bench.  La connectivité réseau et serveur du cluster autonome milvus est ci-dessous.</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">Dans cette section, nous partageons nos observations et résultats des tests de la base de données autonome Milvus. .  Nous avons sélectionné DiskANN comme type d’index pour ces tests. .  L'ingestion, l'optimisation et la création d'index pour un ensemble de données d'environ 100 Go ont pris environ 5 heures.  Pendant la majeure partie de cette durée, le serveur Milvus, équipé de 20 cœurs (ce qui équivaut à 40 vcpu lorsque Hyper-Threading est activé), fonctionnait à sa capacité CPU maximale de 100 %. Nous avons constaté que DiskANN est particulièrement important pour les grands ensembles de données qui dépassent la taille de la mémoire système. .  Dans la phase de requête, nous avons observé un taux de requêtes par seconde (QPS) de 10,93 avec un rappel de 0,9987.  La latence du 99e percentile pour les requêtes a été mesurée à 708,2 millisecondes.</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">Du point de vue du stockage, la base de données a émis environ 1 000 opérations/s pendant les phases d’ingestion, d’optimisation post-insertion et de création d’index.  Dans la phase de requête, il a demandé 32 000 opérations/sec.</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">La section suivante présente les mesures de performances de stockage.</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">Phase de charge de travail</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">Métrique</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">Ingestion de données et optimisation post-insertion</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">Op E/S par sec</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1 000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">Latence</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 unités d'utilisation</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Charge de travail</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">Mix lecture/écriture, principalement écriture</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">Taille des E/S</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 Ko</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">Requête</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">Pic à 32 000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">Lecture à 100 % en cache</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">Principalement 8 Ko</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">Le résultat de vectorDB-bench est ci-dessous.</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">D'après la validation des performances de l'instance autonome Milvus, il est évident que la configuration actuelle est insuffisante pour prendre en charge un ensemble de données de 5 millions de vecteurs avec une dimensionnalité de 1536. Nous avons déterminé que le stockage possède des ressources adéquates et ne constitue pas un goulot d'étranglement dans le système.</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">VectorDB-Bench avec cluster Milvus</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">Dans cette section, nous discutons du déploiement d’un cluster Milvus dans un environnement Kubernetes.  Cette configuration Kubernetes a été construite sur un déploiement VMware vSphere, qui hébergeait les nœuds maître et de travail Kubernetes.</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">Les détails des déploiements VMware vSphere et Kubernetes sont présentés dans les sections suivantes.</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">Dans cette section, nous présentons nos observations et résultats issus des tests de la base de données Milvus.  * Le type d'index utilisé était DiskANN.  * Le tableau ci-dessous fournit une comparaison entre les déploiements autonomes et en cluster lorsque l'on travaille avec 5 millions de vecteurs à une dimensionnalité de 1536.  Nous avons observé que le temps nécessaire à l’ingestion des données et à l’optimisation post-insertion était plus faible dans le déploiement en cluster.  La latence du 99e percentile pour les requêtes a été réduite de six fois dans le déploiement du cluster par rapport à la configuration autonome.  * Bien que le taux de requêtes par seconde (QPS) soit plus élevé dans le déploiement du cluster, il n'était pas au niveau souhaité.</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">Les images ci-dessous fournissent une vue de diverses mesures de stockage, notamment la latence du cluster de stockage et le nombre total d'IOPS (opérations d'entrée/sortie par seconde).</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">La section suivante présente les principales mesures de performances de stockage.</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">Pic à 147 000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">Sur la base de la validation des performances du Milvus autonome et du cluster Milvus, nous présentons les détails du profil d'E/S de stockage.  * Nous avons observé que le profil d’E/S reste cohérent dans les déploiements autonomes et en cluster.  * La différence observée dans les IOPS de pointe peut être attribuée au plus grand nombre de clients dans le déploiement du cluster.</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">vectorDB-Bench avec Postgres (pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">Nous avons effectué les actions suivantes sur PostgreSQL (pgvecto.rs) en utilisant VectorDB-Bench : Les détails concernant la connectivité réseau et serveur de PostgreSQL (en particulier, pgvecto.rs) sont les suivants :</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">Dans cette section, nous partageons nos observations et résultats des tests de la base de données PostgreSQL, en particulier à l'aide de pgvecto.rs.  * Nous avons sélectionné HNSW comme type d'index pour ces tests car au moment des tests, DiskANN n'était pas disponible pour pgvecto.rs.  * Au cours de la phase d’ingestion des données, nous avons chargé l’ensemble de données Cohere, qui se compose de 10 millions de vecteurs d’une dimensionnalité de 768.  Ce processus a pris environ 4,5 heures.  * Dans la phase de requête, nous avons observé un taux de requêtes par seconde (QPS) de 1 068 avec un rappel de 0,6344.  La latence du 99e percentile pour les requêtes a été mesurée à 20 millisecondes.  Pendant la majeure partie de l’exécution, le processeur client fonctionnait à 100 % de sa capacité.</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">Les images ci-dessous fournissent une vue de diverses mesures de stockage, notamment la latence du cluster de stockage et le nombre total d'IOPS (opérations d'entrée/sortie par seconde).</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">Comparaison des performances entre Milvus et Postgres sur Vector DB Bench</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">Sur la base de notre validation des performances de Milvus et PostgreSQL à l'aide de VectorDBBench, nous avons observé ce qui suit :</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">Type d'indice : HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">Ensemble de données : Cohere avec 10 millions de vecteurs à 768 dimensions</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">Nous avons constaté que pgvecto.rs atteignait un taux de requêtes par seconde (QPS) de 1 068 avec un rappel de 0,6344, tandis que Milvus atteignait un taux de QPS de 106 avec un rappel de 0,9842.</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">Si la haute précision dans vos requêtes est une priorité, Milvus surpasse pgvecto.rs car il récupère une proportion plus élevée d'éléments pertinents par requête.  Cependant, si le nombre de requêtes par seconde est un facteur plus crucial, pgvecto.rs dépasse Milvus.  Il est important de noter, cependant, que la qualité des données récupérées via pgvecto.rs est inférieure, avec environ 37 % des résultats de recherche étant des éléments non pertinents.</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">Observation basée sur nos validations de performance :</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">Sur la base de nos validations de performances, nous avons fait les observations suivantes :</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">Dans Milvus, le profil d'E/S ressemble beaucoup à une charge de travail OLTP, telle que celle observée avec Oracle SLOB.  Le benchmark se compose de trois phases : l'ingestion des données, la post-optimisation et la requête.  Les étapes initiales sont principalement caractérisées par des opérations d'écriture de 64 Ko, tandis que la phase de requête implique principalement des lectures de 8 Ko.  Nous nous attendons à ce ONTAP gère efficacement la charge d'E/S Milvus.</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">Le profil d’E/S PostgreSQL ne présente pas de charge de travail de stockage difficile.  Étant donné l'implémentation en mémoire actuellement en cours, nous n'avons observé aucune E/S disque pendant la phase de requête.</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN apparaît comme une technologie cruciale pour la différenciation du stockage.  Il permet une mise à l'échelle efficace de la recherche de base de données vectorielle au-delà de la limite de la mémoire système.  Cependant, il est peu probable d'établir une différenciation des performances de stockage avec des indices de base de données vectoriels en mémoire tels que HNSW.</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">Il convient également de noter que le stockage ne joue pas un rôle critique pendant la phase de requête lorsque le type d'index est HSNW, qui est la phase de fonctionnement la plus importante pour les bases de données vectorielles prenant en charge les applications RAG.  L’implication ici est que les performances de stockage n’ont pas d’impact significatif sur les performances globales de ces applications.</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">Il s'agit d'une page abstraite pour une solution de base de données vectorielle avec Netapp.</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">Solution de base de données vectorielle avec NetApp</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam et Rodrigo Nascimento, NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">Ce document fournit une exploration approfondie du déploiement et de la gestion des bases de données vectorielles, telles que Milvus et pgvecto, une extension PostgreSQL open source, en utilisant les solutions de stockage de NetApp.  Il détaille les directives d'infrastructure pour l'utilisation du stockage d'objets NetApp ONTAP et StorageGRID et valide l'application de la base de données Milvus dans AWS FSx ONTAP.  Le document explique la dualité fichier-objet de NetApp et son utilité pour les bases de données vectorielles et les applications qui prennent en charge les intégrations vectorielles.  Il met l'accent sur les capacités de SnapCenter, le produit de gestion d'entreprise de NetApp, en offrant des fonctionnalités de sauvegarde et de restauration pour les bases de données vectorielles, garantissant l'intégrité et la disponibilité des données.  Le document approfondit davantage la solution de cloud hybride de NetApp, en discutant de son rôle dans la réplication et la protection des données dans les environnements sur site et dans le cloud.  Il comprend des informations sur la validation des performances des bases de données vectorielles sur NetApp ONTAP et se termine par deux cas d'utilisation pratiques sur l'IA générative : RAG avec LLM et ChatAI interne de NetApp.  Ce document sert de guide complet pour exploiter les solutions de stockage de NetApp pour la gestion des bases de données vectorielles.</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">L'architecture de référence se concentre sur les points suivants :</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">Exigences technologiques</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">Présentation de la vérification des solutions</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">lien : vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html [Milvus avec Amazon FSx ONTAP pour NetApp ONTAP – dualité fichier et objet]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">Cas d'utilisation de bases de données vectorielles</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">Annexe A : values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">Annexe C : verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">Besoin technologique : solution de base de données vectorielle pour NetApp</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">Cette section fournit un aperçu des exigences relatives à la solution de base de données vectorielle NetApp .</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">Les configurations matérielles et logicielles décrites ci-dessous ont été utilisées pour la majorité des validations effectuées dans ce document, à l'exception des performances.  Ces configurations servent de guide pour vous aider à configurer votre environnement.  Veuillez toutefois noter que les composants spécifiques peuvent varier en fonction des exigences individuelles des clients.</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3,49 To SSD-NVM * Deux volumes de groupe flexibles : métadonnées et données.  * Le volume NFS de métadonnées dispose de 12 volumes persistants de 250 Go.  * Les données sont un volume ONTAP NAS S3</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6 x FUJITSU PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 processeurs * Processeur Intel(R) Xeon(R) Gold 6142 à 2,60 GHz * Mémoire physique de 256 Go * 1 port réseau 100 GbE</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7,68 To</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">amas de Milvus</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* GRAPHIQUE - milvus-4.1.11.  * Version APP – 2.3.4 * Bundles dépendants tels que bookkeeper, zookeeper, pulsar, etcd, proxy, querynode, worker</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* Cluster K8s à 5 nœuds * 1 nœud maître et 4 nœuds travailleurs * Version – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">cas d'utilisation - solution de base de données vectorielle pour NetApp</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">Cette section fournit un aperçu des cas d’utilisation de la solution de base de données vectorielle NetApp .</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">Dans cette section, nous discutons de deux cas d'utilisation tels que la récupération augmentée avec de grands modèles de langage et le chatbot informatique NetApp .</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">Génération augmentée de récupération (RAG) avec de grands modèles de langage (LLM)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">L'opérateur NVIDIA Enterprise RAG LLM est un outil utile pour la mise en œuvre de RAG dans l'entreprise.  Cet opérateur peut être utilisé pour déployer un pipeline RAG complet.  Le pipeline RAG peut être personnalisé pour utiliser Milvus ou pgvecto comme base de données vectorielle pour stocker les intégrations de la base de connaissances.  Reportez-vous à la documentation pour plus de détails.</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">Figure 1) Enterprise RAG optimisé par NVIDIA NeMo Microservices et NetApp</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">Cas d'utilisation du chatbot informatique NetApp</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">Le chatbot de NetApp sert d’autre cas d’utilisation en temps réel pour la base de données vectorielle.  Dans ce cas, NetApp Private OpenAI Sandbox fournit une plate-forme efficace, sécurisée et efficiente pour gérer les requêtes des utilisateurs internes de NetApp.  En intégrant des protocoles de sécurité rigoureux, des systèmes de gestion de données efficaces et des capacités de traitement d'IA sophistiquées, il garantit des réponses précises et de haute qualité aux utilisateurs en fonction de leurs rôles et responsabilités au sein de l'organisation via l'authentification SSO.  Cette architecture met en évidence le potentiel de fusion de technologies avancées pour créer des systèmes intelligents axés sur l’utilisateur.</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">Le cas d’utilisation peut être divisé en quatre sections principales.</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">Authentification et vérification de l'utilisateur :</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">Les requêtes des utilisateurs passent d'abord par le processus NetApp Single Sign-On (SSO) pour confirmer l'identité de l'utilisateur.</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">Après une authentification réussie, le système vérifie la connexion VPN pour garantir une transmission de données sécurisée.</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">Transmission et traitement des données :</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">Une fois le VPN validé, les données sont envoyées à MariaDB via les applications Web NetAIChat ou NetAICreate.  MariaDB est un système de base de données rapide et efficace utilisé pour gérer et stocker les données des utilisateurs.</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">MariaDB envoie ensuite les informations à l’instance NetApp Azure, qui connecte les données utilisateur à l’unité de traitement de l’IA.</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">Interaction avec OpenAI et filtrage de contenu :</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">L’instance Azure envoie les questions de l’utilisateur à un système de filtrage de contenu.  Ce système nettoie la requête et la prépare pour le traitement.</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">L’entrée nettoyée est ensuite envoyée au modèle de base Azure OpenAI, qui génère une réponse basée sur l’entrée.</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">Génération et modération des réponses :</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">La réponse du modèle de base est d’abord vérifiée pour garantir qu’elle est exacte et qu’elle répond aux normes de contenu.</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">Après avoir passé le contrôle, la réponse est renvoyée à l'utilisateur.  Ce processus garantit que l’utilisateur reçoit une réponse claire, précise et appropriée à sa requête.</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - solution de base de données vectorielle pour NetApp</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">Annexe A : Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">Cette section fournit un exemple de code YAML pour les valeurs utilisées dans la solution de base de données vectorielle NetApp .</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">Présentation de la vérification de la solution - Solution de base de données vectorielle pour NetApp</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">Nous avons réalisé une validation complète de la solution axée sur cinq domaines clés, dont les détails sont décrits ci-dessous.  Chaque section examine les défis auxquels sont confrontés les clients, les solutions fournies par NetApp et les avantages qui en découlent pour le client.</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>Les défis des clients sont de pouvoir évoluer de manière indépendante en matière de stockage et de calcul, de gestion efficace des infrastructures et de gestion des données.  Dans cette section, nous détaillons le processus d’installation d’un cluster Milvus sur Kubernetes, en utilisant un contrôleur de stockage NetApp pour les données du cluster et les données client.</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">lien:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus avec Amazon FSx ONTAP pour NetApp ONTAP – dualité fichier et objet] Dans cette section, pourquoi nous devons déployer une base de données vectorielle dans le cloud ainsi que les étapes pour déployer une base de données vectorielle (milvus autonome) dans Amazon FSx ONTAP pour NetApp ONTAP dans des conteneurs Docker.</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>Dans cette section, nous examinons comment SnapCenter protège les données de la base de données vectorielle et les données Milvus résidant dans ONTAP.  Pour cet exemple, nous avons utilisé un bucket NAS (milvusdbvol1) dérivé d'un volume NFS ONTAP (vol1) pour les données client et un volume NFS distinct (vectordbpv) pour les données de configuration du cluster Milvus.</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>Dans cette section, nous discutons de l'importance de la reprise après sinistre (DR) pour la base de données vectorielle et de la manière dont le produit de reprise après sinistre NetApp Snapmirror fournit une solution DR à la base de données vectorielle.</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>Dans cette section, nous visons à approfondir la validation des performances des bases de données vectorielles, telles que Milvus et pgvecto.rs, en nous concentrant sur leurs caractéristiques de performances de stockage telles que le profil d'E/S et le comportement du contrôleur de stockage NetApp à la prise en charge des charges de travail RAG et d'inférence au sein du cycle de vie LLM.  Nous évaluerons et identifierons les différenciateurs de performances lorsque ces bases de données seront combinées avec la solution de stockage ONTAP .  Notre analyse sera basée sur des indicateurs de performance clés, tels que le nombre de requêtes traitées par seconde (QPS).</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py – solution de base de données vectorielle pour NetApp</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">Cette section contient un exemple de script Python qui peut être utilisé pour valider la base de données vectorielle dans la solution de base de données vectorielle NetApp .</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">Regardez des vidéos sur les solutions d'IA avec NetApp</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">Découvrez comment NetApp renforce les initiatives d’IA et d’apprentissage automatique.  Ces listes de lecture vidéo organisées présentent les solutions d'IA NetApp et les flux de travail MLOps, mettant en évidence les stratégies de déploiement, l'automatisation et la gestion des données pour des analyses avancées.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">Solutions d'IA NetApp</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">Regardez la playlist des solutions d'IA de NetApp</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">Liste de lecture vidéo complète couvrant l'infrastructure de l'IA, les systèmes convergés et les déploiements d'IA d'entreprise.<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">Opérations d'apprentissage automatique (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">Regardez la playlist MLOps</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">Série de vidéos sur les workflows MLOps, les pipelines de données et les meilleures pratiques opérationnelles.<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Série de vidéos et de démonstrations présentant les fonctionnalités de nombreuses solutions NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Solutions NetApp : vidéos et démonstrations</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Aperçu des vidéos et des démonstrations mettant en évidence les fonctionnalités spécifiques de nombreuses solutions NetApp.</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">Journal des modifications récentes apportées aux supports des solutions d'intelligence artificielle NetApp .</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">Quoi de neuf dans les solutions d'intelligence artificielle NetApp</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">Découvrez les nouveautés en matière de solutions d’intelligence artificielle.</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">18 août 2025</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">Famille de solutions NetApp</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">Le site NetApp Solutions est désormais le<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block> , qui comprend les sites suivants :</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">Solutions d'intelligence artificielle NetApp</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">Solutions de conteneurs NetApp</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">Solutions de gestion de données NetApp</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">Solutions de base de données NetApp</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">Solutions de cloud public et hybride NetApp</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">Solutions NetApp pour SAP</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">Solutions de virtualisation NetApp</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp fournit des solutions d’IA complètes qui combinent une gestion des données de niveau entreprise, des architectures de référence validées et des partenariats stratégiques pour accélérer vos initiatives d’IA et soutenir les résultats commerciaux critiques.  Du déploiement de l'infrastructure à l'automatisation MLOps, nos solutions s'adaptent de manière transparente aux environnements de périphérie, de centre de données et de cloud hybride.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">Commencer</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">Quoi de neuf</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">Blogs</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">Vidéos et démos</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">Infrastructure d'IA et systèmes convergés</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NetApp AIPod avec systèmes NVIDIA DGX</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">NVIDIA DGX SuperPOD avec série EF</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod avec Lenovo pour NVIDIA OVX</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">Système de fichiers parallèle BeeGFS avec série E</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">Cas d'utilisation et applications de l'IA</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">AIPod Mini pour l'inférence RAG</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">Inférence de l'IA à la périphérie</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">Solutions de bases de données vectorielles</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">Charges de travail liées à la conduite autonome</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">Quantum StorNext avec série E</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps et gestion des données</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">MLOps open source avec NetApp</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">MLOps multicloud hybride avec Domino Data Lab</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">FSx ONTAP pour MLOps</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">Solutions d'IA Big Data et cloud hybride</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">Solutions de données cloud hybrides</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Solutions Apache Spark</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka avec stockage NetApp ONTAP</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID avec Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">Maison au bord du lac Dremio avec stockage NetApp</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">Demandes de solutions et commentaires</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automatisation des demandes</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">Proposer une nouvelle solution</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">Fournir un retour sur la solution</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">Rationalisez vos flux de travail IA/ML avec les solutions complètes de gestion des données et de MLOps de NetApp.  Des plateformes open source aux outils de niveau entreprise, nos solutions permettent un développement, un déploiement et une mise à l'échelle efficaces de modèles dans des environnements de cloud hybride tout en garantissant la cohérence et les performances des données.</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">Solutions NetApp MLOps et de gestion des données</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">Plateformes MLOps open source</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">Configuration de NetApp Trident pour AIPod</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Déploiement et intégration d'Apache Airflow</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">Déploiement et opérations de données de JupyterHub</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">Déploiement et traçabilité de MLflow</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">Workflows MLOps avancés</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Déploiement et notebooks Kubeflow</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Entraînez des modèles de reconnaissance d'images avec Kubeflow</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">Exécution de la charge de travail de l'IA sur un seul nœud</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">Exécution de la charge de travail de l'IA distribuée</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">Ingestion de données avec SnapMirror</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">Solutions MLOps d'entreprise</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">MLOps hybrides avec Domino Data Lab</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Accès aux données inter-environnements avec Domino</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">Intégration du logiciel NVIDIA NGC</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Intégration Cloud MLOps et AWS</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">Amazon FSx pour ONTAP MLOps</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">Intégrer FSx ONTAP en tant que S3 privé dans SageMaker</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">Formation sur les modèles FSx ONTAP pour SageMaker</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">Créez un pipeline MLOps simplifié avec FSx</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">Bases de données vectorielles et applications d'IA</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">Solution de base de données vectorielle avec NetApp</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Configuration du cluster Milvus avec Kubernetes</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">Protection de la base de données vectorielle avec SnapCenter</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">Validation des performances de la base de données vectorielle</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">Cas d'utilisation de bases de données vectorielles</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">Outils de gestion et de stockage des données</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">Lac de données StorageGRID pour la conduite autonome</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">Reprise après sinistre avec SnapMirror</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">Déployez une infrastructure d’IA prête pour l’entreprise avec les architectures de référence validées et les systèmes convergés de NetApp.  Des solutions NetApp AIPod aux plates-formes de stockage hautes performances, nos conceptions offrent les performances, l'évolutivité et la fiabilité nécessaires aux charges de travail IA/ML exigeantes.</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">Infrastructure d'IA et systèmes convergés NetApp</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">Architectures de référence NetApp AIPod</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">Architecture AIPod</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">Détails du déploiement de AIPod</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">Guide de validation et de dimensionnement de AIPod</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">Stockage haute performance pour les charges de travail d'IA</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">NVIDIA DGX SuperPOD avec stockage série EF</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">IBM Spectrum Scale avec stockage E-Series</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP avec Lenovo ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">Explorez les implémentations d'IA du monde réel avec les solutions NetApp , des systèmes RAG d'entreprise et de l'inférence de périphérie aux pratiques d'IA responsables et aux stratégies de migration de données.  Ces cas d’utilisation démontrent comment NetApp permet aux organisations de déployer des applications d’IA dans divers environnements tout en maintenant la sécurité, les performances et l’évolutivité.</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">Cas d'utilisation et applications de l'IA NetApp</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">Explorez les implémentations d'IA du monde réel avec les solutions NetApp , des systèmes RAG d'entreprise et de l'inférence de périphérie aux pratiques d'IA responsables et aux stratégies de migration de données.  Ces cas d’utilisation démontrent comment NetApp permet aux applications d’IA de fonctionner dans divers environnements tout en maintenant la sécurité, les performances et l’évolutivité.</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">Applications et cas d'utilisation de l'IA d'entreprise</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">NetApp AIPod Mini pour RAG d'entreprise</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">IA générative et valeur NetApp</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">Inférence d'IA Edge avec NetApp et Lenovo</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">Migration de l'analyse des Big Data vers l'IA</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">IA responsable</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">IA responsable avec la transformation d'images Protopia</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">Solutions de stockage et d'infrastructure d'IA</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">Concevez Quantum StorNext avec les systèmes de la série E</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">Déployer Quantum StorNext avec les systèmes de la série E</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Transformez votre infrastructure d'analyse de données avec les solutions éprouvées de NetApp pour les charges de travail Big Data, notamment Apache Spark, Hadoop, Kafka et les architectures de lac de données modernes qui s'étendent de la périphérie au cloud.</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">Solutions d'analyse de données modernes NetApp</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">Les solutions d’analyse de données modernes NetApp sont un ensemble de capacités stratégiques et technologiques qui démontrent les capacités du stockage NetApp dans l’espace de l’IA.</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Solutions Apache Kafka</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">Charges de travail Apache Kafka avec stockage NetApp NFS</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka avec contrôleurs de stockage NetApp ONTAP</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Bonnes pratiques pour Confluent Kafka</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">Validation des performances de Kafka avec AWS</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Solutions Apache Spark et Hadoop</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">Solutions de stockage NetApp pour Apache Spark</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">Déployer la charge de travail Apache Spark avec le stockage NetApp</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">Solutions de données cloud hybrides NetApp pour Spark et Hadoop</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">Cas d'utilisation et architectures</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Résultats des tests Apache Spark</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">Gestion des données dans le cloud et IA</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">Gestion des données dans le cloud avec la dualité fichier-objet NetApp et AWS SageMaker</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Analyse des Big Data : des données à l'intelligence artificielle</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP pour MLOps</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Solution cloud hybride Apache Spark</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">Plateformes modernes de lac de données et d'analyse</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">Solution hybride iceberg lakehouse de nouvelle génération de NetApp et Dremio</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 et Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">Ressources supplémentaires</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">Différentes solutions pour différentes stratégies d'analyse</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog : Apache Spark joue dans le jeu d'analyse de données NetApp</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog : Utiliser XCP pour la migration de données d'un lac de données et d'un HPC vers ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV : Playlist d'analyse des Big Data</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">Solutions d'intelligence artificielle</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">Vidéos</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">Configuration de NetApp Trident</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">Backends Trident pour les déploiements AIPod</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">Classes de stockage Kubernetes pour les déploiements AIPod</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Déploiement d'Apache Airflow</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">Déploiement de JupyterHub</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">Ingérer des données avec NetApp SnapMirror</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">Déploiement de MLflow</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">Traçabilité des ensembles de données aux modèles avec NetApp et MLflow</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Déploiement de Kubeflow</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Provisionner l'espace de travail Jupyter Notebook</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">Entraîner un modèle de reconnaissance d'images - exemple de workflow</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Exemples d'opérations Trident</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">Exemples de tâches hautes performances pour les déploiements AIPod</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">Exécuter une charge de travail d'IA à nœud unique</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">Exécuter une charge de travail d'IA distribuée synchrone</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">MLOps hybrides avec Domino Data Lab et NetApp</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">Configuration initiale</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">Exposer les volumes NetApp existants à Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">Accéder aux mêmes données dans différents environnements</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">Informations Complémentaires</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">Utiliser le logiciel NVIDIA NGC</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">Exemple de cas d'utilisation : tâche d'entraînement TensorFlow</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">Partie 1 - Intégrer Amazon FSx for NetApp ONTAP en tant que compartiment S3 privé dans AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">Partie 2 - Exploiter Amazon FSx for NetApp ONTAP comme source de données pour la formation de modèles dans SageMaker</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">Partie 3 - Construire un pipeline MLOps simplifié</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">NetApp StorageGRID Data Lake pour les charges de travail de conduite autonome</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">Solution de base de données vectorielle avec NetApp</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">Base de données vectorielles</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">Exigences technologiques</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">Protection de la base de données vectorielle à l'aide de SnapCenter</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">Reprise après sinistre à l'aide de SnapMirror</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">Base de données vectorielle avec Instaclustr utilisant PostGreSQL : pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">Annexe B : prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">Annexe D : docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">Infrastructures convergées de l'IA</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVA-1173 NetApp AIPod avec systèmes NVIDIA DGX</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">Composants matériels</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">Composants logiciels</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">Exemple de détails de déploiement</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">Guide de validation et de dimensionnement</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">Conclusion et informations complémentaires</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NVIDIA DGX SuperPOD avec NetApp EF-Series</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">BeeGFS sur NetApp avec stockage E-Series</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">Déployer IBM Spectrum Scale avec le stockage E-Series</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP et Lenovo ThinkSystem pour l'IA</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP et Lenovo ThinkSystem SR670 pour l'IA</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">Cas d'utilisation de l'IA</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">NetApp AIPod Mini pour l'inférence RAG</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">IA responsable et inférence confidentielle - NetApp AI avec Protopia Image Transformation</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Déplacer des données d'un environnement Big Data vers un environnement IA</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Inférence IA en périphérie – NetApp avec Lenovo ThinkSystem – Conception de solutions</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Guide de conception des systèmes Quantum StorNext avec NetApp E-Series</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Guide de déploiement des systèmes Quantum StorNext avec NetApp E-Series</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">Analyse de données moderne</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">Solution NetApp pour le problème de renommage stupide dans la charge de travail NFS vers Kafka</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">Aperçu et validation des performances dans AWS - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">Présentation et validation des performances dans AWS - FSx pour NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">Aperçu des performances et validation avec AFF sur site</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Validation des performances confluentes</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Résumé des cas d'utilisation</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">Conversion GPFS vers NFS : étapes détaillées</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Clusters confluents à rééquilibrage automatique</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Solutions de données cloud hybrides NetApp - Spark et Hadoop basées sur les cas d'utilisation des clients</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Cas d'utilisation 1 - Sauvegarde des données Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Cas d'utilisation 2 - Sauvegarde et reprise après sinistre du cloud vers les locaux</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Cas d'utilisation 3 : Activation de DevTest sur des données Hadoop existantes</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Cas d'utilisation 4 - Protection des données et connectivité multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Cas d'utilisation 5 - Accélérer les charges de travail analytiques</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">Solution Iceberg Lakehouse hybride de nouvelle génération de NetApp et Dremio</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">Cas d'utilisation client</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Différentes solutions pour différentes stratégies d'analyse Présentation de la solution</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Fonctionnalités de StorageGRID pour Splunk SmartStore</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">Hiérarchisation et économies de coûts</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">Performances d'un SmartStore sur un seul site</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Charge de travail Apache Spark avec solution de stockage NetApp (Guide de déploiement)</block>
  <block id="74916818f2584b32e727fdc509b2f992" category="cell">P4X-GNR6980P-SRPL2-UCC</block>
  <block id="abaa679b5e80256d8e1d4fd65296a270" category="cell">Processeur Intel Xeon 6980P 2 cœurs 128C 2 Go 504 Mo 500 W SGX512</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3,3G 24 Mo 95 W 1700 mAh</block>
  <block id="fe1394c0024b947430d8383108eb2177" category="summary">NVIDIA DGX SuperPOD avec NetApp AFF A90</block>
  <block id="bf8899c5267692573fb1304655fb765a" category="doc">Systèmes de stockage NetApp AFF A90 avec NVIDIA DGX SuperPOD</block>
  <block id="7fa0ca2a0d7f53f3c8e59fc6c3e9ed2e" category="section-title">Déploiement de l'ANV</block>
  <block id="8be806d9daf2bc32156e83bc0d005ec1" category="paragraph">Les systèmes de stockage NVIDIA DGX SuperPOD avec NetApp AFF A90 combinent les performances de calcul de classe mondiale des systèmes NVIDIA DGX avec les systèmes de stockage connectés au cloud NetApp pour permettre des flux de travail basés sur les données pour l'apprentissage automatique (ML), l'intelligence artificielle (IA) et le calcul technique haute performance (HPC).  Ce document décrit les détails de configuration et de déploiement pour l'intégration des systèmes de stockage AFF A90 dans l'architecture DGX SuperPOD.</block>
  <block id="9b418007fd18dc2176e46adcd30db45f" category="inline-image-macro">Logo Nvidia</block>
  <block id="c94ba3511d0db1d6babbf53090c19530" category="paragraph"><block ref="c94ba3511d0db1d6babbf53090c19530" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6091ca16495cdce90805252a1c12f4e6" category="section-title">Résumé du programme</block>
  <block id="c6f9b4ccfaf7da44e6c0c60854f0949d" category="paragraph">NVIDIA DGX SuperPOD™ offre une solution de centre de données IA clé en main pour les organisations, offrant de manière transparente des capacités informatiques, des outils logiciels, une expertise et une innovation continue de classe mondiale.  DGX SuperPOD fournit tout ce dont les clients ont besoin pour déployer des charges de travail AI/ML et HPC avec un temps de configuration minimal et une productivité maximale.  La figure 1 montre les composants de haut niveau du DGX SuperPOD.</block>
  <block id="d144add61531a9bfe79e667824356b40" category="paragraph">Figure 1) NVIDIA DGX SuperPOD avec systèmes de stockage NetApp AFF A90 .</block>
  <block id="bbd4822469057d9beafe8509a7ebee14" category="paragraph"><block ref="bbd4822469057d9beafe8509a7ebee14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283d31c0198ed7454a249b3e2b6eb174" category="paragraph">DGX SuperPOD offre les avantages suivants :</block>
  <block id="3ff8aa027f2fe1f296899270ebbb43fd" category="list-text">Performances éprouvées pour les charges de travail IA/ML et HPC</block>
  <block id="ca127ea10cbbac4cda1fefa3e946e9ba" category="list-text">Pile matérielle et logicielle intégrée, de la gestion et de la surveillance de l'infrastructure aux modèles et outils d'apprentissage en profondeur pré-construits.</block>
  <block id="a4cb23a9ac5d711552fe29021242bf26" category="list-text">Services dédiés allant de l'installation et de la gestion de l'infrastructure à la mise à l'échelle des charges de travail et à la rationalisation de l'IA de production.</block>
  <block id="96cffe8fd08355ee862ba83cb15407d9" category="paragraph">Alors que les organisations adoptent des initiatives d’intelligence artificielle (IA) et d’apprentissage automatique (ML), la demande de solutions d’infrastructure robustes, évolutives et efficaces n’a jamais été aussi grande.  Au cœur de ces initiatives se trouve le défi de gérer et de former des modèles d’IA de plus en plus complexes tout en garantissant la sécurité des données, l’accessibilité et l’optimisation des ressources. </block>
  <block id="61b865c697c4f21886d14a618df70f6d" category="paragraph">Cette solution offre les principaux avantages suivants :</block>
  <block id="aa88ccfa825dadd9cbb9acc84e508b2c" category="list-text">*Évolutivité*</block>
  <block id="4738ea23a01f5635ce1c45dabb47da5c" category="list-text">*Gestion et accès aux données*</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="list-text">*Sécurité*</block>
  <block id="3c858853158f1a99c39a781718ec762c" category="inline-link">GUIDE DE CONCEPTION NVA-1175</block>
  <block id="bc3456dcc61fc69ddf5057eb2521a503" category="inline-link">+++ Architecture de référence NVIDIA DGX SuperPOD +++</block>
  <block id="0db7341d4a6ac5f5ae439217ea22f2cf" category="paragraph">NVIDIA DGX SuperPOD comprend les serveurs, le réseau et le stockage nécessaires pour offrir des performances éprouvées pour les charges de travail d'IA exigeantes.  Les systèmes NVIDIA DGX™ H200 et B200 offrent une puissance de calcul de classe mondiale, et les commutateurs réseau Ethernet NVIDIA Quantum InfiniBand et Spectrum™ offrent une latence ultra-faible et des performances réseau de pointe.  Grâce à l'ajout des capacités de gestion des données et de performances de pointe du stockage NetApp ONTAP , les clients peuvent mettre en œuvre des initiatives d'IA/ML plus rapidement et avec moins de migration de données et de frais administratifs.  Pour plus d'informations sur les composants spécifiques de cette solution, veuillez vous référer au<block ref="a5c1176c129a896b2b922e5580efc58f" category="inline-link-rx"></block> et<block ref="1910ffa640b224c818fe3ba99c94129a" category="inline-link-rx"></block> documentation.</block>
  <block id="c18232c17d0f8ffeae2d726834c91f89" category="paragraph">NVIDIA DGX SuperPOD est conçu pour répondre aux exigences de performances et d'évolutivité des charges de travail les plus exigeantes.</block>
  <block id="36ff5f6df178e197d3123e478db8410b" category="list-text">Apprentissage automatique à grande échelle à l’aide d’outils d’analyse traditionnels.</block>
  <block id="2d12f254287ce40df1f66968734498ba" category="list-text">Formation de modèles d'intelligence artificielle pour les grands modèles linguistiques, la vision par ordinateur/la classification d'images, la détection de fraude et d'innombrables autres cas d'utilisation.</block>
  <block id="d8f31668d0cecb0b54a6d01e2f76c6cf" category="list-text">Calcul haute performance tel que l'analyse sismique, la dynamique des fluides numérique et la visualisation à grande échelle.</block>
  <block id="f0414b39a05dd4079562350e267bf1b3" category="inline-link">+++ Architecture de référence NVIDIA DGX SuperPOD +++</block>
  <block id="5f5d88c3d3b4a5616e3937b4fe349866" category="paragraph">DGX SuperPOD est basé sur le concept d'une unité évolutive (SU) qui comprend tous les composants nécessaires pour fournir la connectivité et les performances requises et éliminer tous les goulots d'étranglement dans l'infrastructure.  Les clients peuvent commencer avec un ou plusieurs SU et ajouter des SU supplémentaires selon leurs besoins pour répondre à leurs besoins.  Pour plus d'informations, veuillez vous référer au<block ref="b3bda9bcc3402290297547b224b66efa" category="inline-link-rx"></block> .  Ce document décrit les composants de stockage et la configuration d'un seul SU.</block>
  <block id="353fc344c9bee691edbf50c13067653c" category="paragraph">Le tableau 1 répertorie les composants matériels requis pour implémenter les composants de stockage pour 1SU.  Veuillez vous référer à l'annexe A pour les pièces et quantités spécifiques pour 1 à 4 unités évolutives.</block>
  <block id="6cef63cf1d59b401d88755cbea01a416" category="paragraph">Tableau 1) Configuration matérielle requise.</block>
  <block id="46f0306a597ab13c222e7d6551ce9f96" category="cell">Système de stockage NetApp AFF A90</block>
  <block id="c28cb49992003622546cc5f9509cfcff" category="cell">Commutateur d'interconnexion de cluster de stockage NetApp</block>
  <block id="9097f0013a59ba655e2c83bd26ae1ce7" category="cell">Câbles répartiteurs NVIDIA 800 Go -&gt; 4x 200 Go</block>
  <block id="aec453803363ab0e5ca6f6df8d465def" category="inline-link">+++Notes de version de DGX SuperPOD+++</block>
  <block id="b6ffed0f516d3b52a4910321a2a889ba" category="paragraph">Le tableau 2 répertorie les composants logiciels et les versions minimales requis pour intégrer le système de stockage AFF A90 avec DGX SuperPOD.  DGX SuperPOD implique également d'autres composants logiciels qui ne sont pas répertoriés ici.  Veuillez vous référer à la<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="c50cf4cacfaa91c82ab6a24e939cbaca" category="paragraph">Tableau 2) Configuration logicielle requise.</block>
  <block id="518f98e82df6bde3bef11b7aa885a289" category="cell">9.16.1 ou supérieur</block>
  <block id="df6c5bc905afa2504396faf036b87927" category="cell">Gestionnaire de commandes de base NVIDIA</block>
  <block id="6fe49606da6092b118e02ef2d0ef0d6c" category="cell">10.24.11 ou supérieur</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">Système d'exploitation NVIDIA DGX</block>
  <block id="ba2b41c4ccfe23325bd590218a62fa8a" category="cell">6.3.1 ou supérieur</block>
  <block id="be49cc02b8372e6202cf52fbe8204ead" category="cell">Pilote NVIDIA OFED</block>
  <block id="cf439b0da4b623c11f90db3c956758b1" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS ou supérieur</block>
  <block id="c220bcc9beaaaf29d1905f9819577f0b" category="cell">Système d'exploitation NVIDIA Cumulus</block>
  <block id="f7bfb037c565dcf0f80631851ee87307" category="cell">5,10 ou supérieur</block>
  <block id="ea1eee49815915fc6500c0bfc1fcef31" category="paragraph">L'intégration du stockage NetApp ONTAP avec DGX SuperPOD implique les tâches suivantes :</block>
  <block id="dc8a828d28f4f811808cdb82b54453ec" category="list-text">Configuration réseau pour les systèmes de stockage NetApp AFF A90 avec RoCE</block>
  <block id="37c6bfb67043d31447903c4665d6ed11" category="list-text">Installation et configuration du système de stockage</block>
  <block id="4cafd7b33984b4cb34f95fe4314e4a49" category="list-text">Configuration du client DGX avec NVIDIA Base Command™ Manager</block>
  <block id="b8088d3f2b3972d6f986cf0a37543617" category="section-title">Préparation du site et installation de base</block>
  <block id="bf0615788eed920e4e9f1a96749cfb34" category="inline-link">+++ Documentation d'installation du matériel AFF A90 +++</block>
  <block id="e1006e935ca66a5f59a3fd40689fff46" category="paragraph">La préparation du site et l'installation de base du cluster de stockage AFF A90 seront effectuées par NetApp Professional Services pour tous les déploiements DGX SuperPOD dans le cadre du service de déploiement standard.  NetApp PS confirmera que les conditions du site sont appropriées pour l'installation et installera le matériel dans les racks désignés.  Ils connecteront également les connexions réseau OOB et termineront la configuration de base du cluster à l'aide des informations réseau fournies par le client.  Annexe A – Nomenclature et élévations des racks comprend les élévations de racks standard à titre de référence.  Pour plus d'informations sur l'installation de l'A90, veuillez vous référer au<block ref="7ddd605a062e7b77012eccf1c4bcffd7" category="inline-link-rx"></block> .</block>
  <block id="321c92980ad0e1d922d02a2f704ca782" category="paragraph">Une fois le déploiement standard terminé, NetApp PS effectuera la configuration avancée de la solution de stockage à l'aide des procédures ci-dessous, y compris l'intégration avec Base Command Manager pour la connectivité et le réglage du client.</block>
  <block id="00720789d4f50564af280240dfe0c1a0" category="section-title">Câblage du système de stockage à la structure de stockage DGX SuperPOD</block>
  <block id="93f38c7fefe0798b27b29ac2727c9aff" category="paragraph">Le système de stockage AFF A90 est connecté aux commutateurs de stockage à l'aide de quatre ports Ethernet 200 Gb par contrôleur, avec deux connexions à chaque commutateur.  Les ports de commutation 800 Gb sur les commutateurs NVIDIA Spectrum SN5600 sont divisés en 4 ports 200 Gb utilisant les configurations DAC ou de répartiteur optique appropriées répertoriées dans l'annexe A. Les ports individuels de chaque port de commutation sont répartis sur le contrôleur de stockage pour éliminer les points de défaillance uniques.  La figure 2 ci-dessous montre le câblage des connexions de la structure de stockage :</block>
  <block id="428c881d379aed620164886a529bf2ac" category="paragraph">Figure 2) Câblage du réseau de stockage.</block>
  <block id="e97080670de5db4003a6abdd37d81eb5" category="paragraph"><block ref="e97080670de5db4003a6abdd37d81eb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb83bbea93dbe46008125af94bc508be" category="section-title">Câblage du système de stockage au réseau en bande DGX SuperPOD</block>
  <block id="3c4e3bd6ddc8a3cd692e2866674ec982" category="paragraph">NetApp ONTAP inclut des fonctionnalités multi-locataires de pointe qui lui permettent de fonctionner à la fois comme système de stockage hautes performances dans l'architecture DGX SuperPOD et de prendre en charge les répertoires personnels, les partages de fichiers de groupe et les artefacts de cluster Base Command Manager.  Pour une utilisation sur le réseau en bande, chaque contrôleur AFF A90 est connecté aux commutateurs réseau en bande avec une connexion Ethernet 200 Gb par contrôleur, et les ports sont configurés dans une configuration LACP MLAG.  La figure 3 ci-dessous montre le câblage du système de stockage vers les réseaux en bande et OOB.</block>
  <block id="651c2d0bd757128b4d9ed91fc5026a3d" category="paragraph">Figure 3) Câblage réseau en bande et hors bande.</block>
  <block id="92bf4c084f930281026def79beae3794" category="paragraph"><block ref="92bf4c084f930281026def79beae3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76edc3dadc8deca645fd525182eaad33" category="section-title">Configurer ONTAP pour DGX SuperPOD</block>
  <block id="41905234b7d34b88a1559733c741d5aa" category="inline-link">+++ Documentation ONTAP +++</block>
  <block id="d4b2d66f490475665ea833d8f89c2cfd" category="paragraph">Cette solution exploite plusieurs machines virtuelles de stockage (SVM) pour héberger des volumes pour un accès au stockage hautes performances ainsi que des répertoires personnels des utilisateurs et d'autres artefacts de cluster sur une SVM de gestion.  Chaque SVM est configuré avec des interfaces réseau sur les réseaux de stockage ou en bande et des volumes FlexGroup pour le stockage des données.  Pour garantir les performances du Data SVM, une politique de qualité de service de stockage est mise en œuvre.  Pour plus d'informations sur les FlexGroups, les machines virtuelles de stockage et les fonctionnalités ONTAP QoS, veuillez vous référer au<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> .</block>
  <block id="fec48034cdf04f518f58b4f727f55543" category="section-title">Configurer le stockage de base</block>
  <block id="7e4b30d10f60fcb3bdf4c3382d601615" category="section-title">Configurer un seul agrégat sur chaque contrôleur</block>
  <block id="3c6858e020c27b4eb574d124f73c04d3" category="paragraph">Répétez les étapes ci-dessus pour chaque nœud du cluster.</block>
  <block id="241ba9d616774bbadf9c9f28ee386505" category="section-title">Configurer ifgrps sur chaque contrôleur pour le réseau en bande</block>
  <block id="610c7975125c56dc62b000999926f4d8" category="section-title">Configurer les ports physiques pour RoCE</block>
  <block id="ff00a412cfca01b43041104775ac8460" category="paragraph">L'activation de NFS sur RDMA nécessite une configuration pour garantir que le trafic réseau est correctement étiqueté au niveau du client et du serveur, puis géré de manière appropriée par le réseau à l'aide de RDMA sur Ethernet convergé (RoCE).  Cela inclut la configuration du contrôle de flux prioritaire (PFC) et la configuration de la file d'attente CoS PFC à utiliser.  NetApp ONTAP configure également automatiquement le code DSCP 26 pour s'aligner sur la configuration QoS du réseau lorsque les commandes ci-dessous sont exécutées.</block>
  <block id="e9dc479a2f60169b39fb74cc86d13a43" category="section-title">Créer une SVM de gestion</block>
  <block id="ce25292d4b04b878f74951ed7b5fb173" category="section-title">Créer et configurer la SVM de gestion</block>
  <block id="c110d2ffde8993db523c41f0c524e68e" category="section-title">Configurer le service NFS sur la SVM de gestion</block>
  <block id="5441effcbbef51defcc1340e745e28ad" category="section-title">Créer des sous-réseaux IP pour les interfaces réseau en bande</block>
  <block id="919d6feabfd1e5f5f04bedfd487f50c8" category="paragraph">*Remarque :* les informations sur le sous-réseau IP doivent être fournies par le client au moment du déploiement pour l'intégration dans les réseaux clients existants.</block>
  <block id="2bc9e41900e064c3368d9eca2dba546c" category="section-title">Créer des interfaces réseau sur chaque nœud pour SVM en bande</block>
  <block id="44db41cf8b74978388680587aa8b7d55" category="section-title">Créer des volumes FlexGroup pour la SVM de gestion</block>
  <block id="20d5f1ad8803160edb381217d776701e" category="section-title">Créer une politique d'exportation pour Management SVM</block>
  <block id="1624c693fdd8f06e52c87d0b2b576a19" category="section-title">Créer des données SVM</block>
  <block id="9ff068915b90e059d15444fe8dc13aaa" category="section-title">Créer et configurer Data SVM</block>
  <block id="cb7d25e4139e72b33ef687ed8a0ae945" category="section-title">Configurer le service NFS sur Data SVM avec RDMA activé</block>
  <block id="ca1f913932acc2aad423357d56f86ea7" category="section-title">Créer des sous-réseaux IP pour les interfaces réseau Data SVM</block>
  <block id="3c2060cdeb230d3f42a725b2a9ca7e23" category="section-title">Créer des interfaces réseau sur chaque nœud pour Data SVM</block>
  <block id="ca648b8fb4bf1f54cbf7a626468eada3" category="section-title">Configurer les interfaces réseau Data SVM pour RDMA</block>
  <block id="afb51d28a404c42df2a054df2c6da14b" category="section-title">Créer une politique d'exportation sur les données SVM</block>
  <block id="d9a6b253dd081b231d9d1a14cec7a227" category="section-title">Créer des routes statiques sur les données SVM</block>
  <block id="4f3e59209435398e52c0df85d0034275" category="section-title">Créer un volume FlexGroup avec GDD pour Data SVM</block>
  <block id="08ec3810f1dcb452442911f8d8173b1a" category="paragraph">La distribution granulaire des données (GDD) permet de distribuer des fichiers de données volumineux sur plusieurs volumes et contrôleurs constituants FlexGroup afin de permettre des performances maximales pour les charges de travail à fichier unique.  NetApp recommande d'activer GDD sur les volumes de données pour tous les déploiements DGX SuperPOD.</block>
  <block id="7eb2bd842a06eb48d9bbfe4f644731d9" category="section-title">Désactiver l'efficacité du stockage pour le volume de données principal</block>
  <block id="8a0cdebf4e36c1af6ac542485413a77b" category="paragraph">efficacité du volume désactivée -vserver spod_data -volume spod_data</block>
  <block id="46e5a2d41b69706b3dcd5e89c34e7c5e" category="section-title">Créer une politique de qualité de service minimale pour les données SVM</block>
  <block id="065d35d3d9a4319f54773a754b2c0e6c" category="section-title">Appliquer la politique QoS pour les données SVM</block>
  <block id="2cc5056a61a5f1643bf387d49d197728" category="section-title">Configuration du serveur DGX avec NVIDIA Base Command Manager</block>
  <block id="e546e9d0da56999b5973de8a7ad71572" category="paragraph">Pour préparer les clients DGX à utiliser le système de stockage AFF A90 , effectuez les tâches suivantes.  Ce processus suppose que les interfaces réseau et les routes statiques pour la structure de stockage ont déjà été configurées sur les nœuds du système DGX.  Les tâches suivantes seront effectuées par les services professionnels NetApp dans le cadre du processus de configuration avancée.</block>
  <block id="f9a9381a56f728d139ee191de307ef5f" category="section-title">Configurer l'image du serveur DGX avec les paramètres de noyau requis et d'autres paramètres</block>
  <block id="256b6f56d994f129832d2b7567bb951f" category="paragraph">NetApp ONTAP utilise des protocoles NFS standard et ne nécessite l'installation d'aucun logiciel supplémentaire sur les systèmes DGX.  Afin de fournir des performances optimales aux systèmes clients, plusieurs modifications de l'image système DGX sont nécessaires.  Les deux étapes suivantes sont effectuées après être entré dans le mode chroot de l'image BCM à l'aide de la commande ci-dessous :</block>
  <block id="45fb2f19f77fc1d9d4dfdd092f805b42" category="section-title">Configurer les paramètres de mémoire virtuelle du système dans /etc/sysctl.conf</block>
  <block id="13b4c0be439ee4875352c0ff2a039c13" category="paragraph">La configuration par défaut du système Linux fournit des paramètres de mémoire virtuelle qui ne fournissent pas nécessairement des performances optimales.  Dans le cas des systèmes DGX B200 avec 2 To de RAM, les paramètres par défaut autorisent 40 Go d'espace tampon, ce qui crée des modèles d'E/S incohérents et permet au client de surcharger le système de stockage lors du vidage du tampon.  Les paramètres ci-dessous limitent l'espace tampon du client à 5 Go et forcent le vidage plus souvent pour créer un flux d'E/S cohérent qui ne surcharge pas le système de stockage.</block>
  <block id="c35419f49457a55135a16f4a73d4fb6b" category="paragraph">Après être entré dans le mode chroot de l'image, modifiez le fichier /etc/sysctl.s/90-cm-sysctl.conf et ajoutez les lignes suivantes :</block>
  <block id="4caebde52be0001b1e59098dd149b653" category="paragraph">Enregistrez et fermez le fichier /etc/sysctl.conf.</block>
  <block id="d05565dbb5b9175c4df06e8d9d029a18" category="section-title">Configurer d’autres paramètres système avec un script qui s’exécute après le redémarrage</block>
  <block id="4e1ff13d493c47a47dde7cb5a24aceeb" category="paragraph">Certains paramètres nécessitent que le système d’exploitation soit entièrement en ligne pour s’exécuter et ne sont pas persistants après un redémarrage.  Pour effectuer ces paramètres dans un environnement Base Command Manager, créez un fichier /root/ntap_dgx_config.sh et entrez les lignes suivantes :</block>
  <block id="191be9d79602632b279bc3126e49847d" category="paragraph">*Enregistrez et fermez le fichier.  Modifiez les autorisations sur le fichier pour qu'il soit exécutable :*</block>
  <block id="13036c88d00af2d37c1d8e1ae332f79e" category="paragraph">Créez une tâche cron qui est exécutée par root au démarrage en modifiant la ligne suivante :</block>
  <block id="a4d911dee959cadc8c53c92d6361fc05" category="paragraph">Voir l'exemple de fichier crontab ci-dessous :</block>
  <block id="e813523727c040149e1ecad0358d60b8" category="paragraph">Quittez le mode chroot de l'image BCM en entrant exit ou Ctrl-D.</block>
  <block id="70f4c658a41ea1900dd94027c0ffa103" category="section-title">Configurer la catégorie DGX de BaseCommand Manager pour les points de montage client</block>
  <block id="9df3dcf41d131b1d0097435f6b290ba4" category="paragraph">Pour configurer les clients DGX qui montent le système de stockage AFF A90 , la catégorie de client BCM utilisée par les systèmes DGX doit être modifiée pour inclure les informations et options pertinentes.  Les étapes ci-dessous décrivent comment configurer le point de montage NFS.</block>
  <block id="dcde3a7bf8f0a03f480df9078bfa9297" category="paragraph">Le NVIDIA DGX SuperPOD avec les systèmes de stockage NetApp * AFF A90 * représente une avancée significative dans les solutions d'infrastructure d'IA.  En répondant aux principaux défis liés à la sécurité, à la gestion des données, à l’utilisation des ressources et à l’évolutivité, il permet aux organisations d’accélérer leurs initiatives d’IA tout en maintenant l’efficacité opérationnelle, la protection des données et la collaboration.  L'approche intégrée de la solution élimine les goulots d'étranglement courants dans les pipelines de développement de l'IA, permettant aux scientifiques et aux ingénieurs des données de se concentrer sur l'innovation plutôt que sur la gestion de l'infrastructure.</block>
  <block id="77b69988a6b247bd3829a8e03ff332a6" category="inline-link">Guide de conception des systèmes de stockage NVA-1175 NVIDIA DGX SuperPOD avec NetApp AFF A90</block>
  <block id="78200c657113173ee4bd06de792e86af" category="list-text"><block ref="78200c657113173ee4bd06de792e86af" category="inline-link-rx"></block></block>
  <block id="4b70410b9d727a1fc1d60d4483d86325" category="inline-link">Architecture de référence NVIDIA DGX B200 SuperPOD</block>
  <block id="54dbc563049b479cfef99d1d872020e4" category="list-text"><block ref="54dbc563049b479cfef99d1d872020e4" category="inline-link-rx"></block></block>
  <block id="d5023dae85155f754c6bfd520cbdc150" category="inline-link">+++ Architecture de référence NVIDIA DGX H200 SuperPOD+++</block>
  <block id="5d4678ba7793147c6b3109fcdbe3294f" category="list-text"><block ref="5d4678ba7793147c6b3109fcdbe3294f" category="inline-link-rx"></block></block>
  <block id="0018465bd63e2711758aea9e68126f6d" category="inline-link">+++ Logiciel NVIDIA BaseCommand+++</block>
  <block id="dd2a70a6cd8d74ddbed24590bf9efd37" category="list-text"><block ref="dd2a70a6cd8d74ddbed24590bf9efd37" category="inline-link-rx"></block></block>
  <block id="a2433670a2f11bda41782875f82e4c0e" category="inline-link">+++ Commutateurs Ethernet NVIDIA Spectrum SN5600+++</block>
  <block id="197d7b18bb595fa0c4339f599bb57c70" category="list-text"><block ref="197d7b18bb595fa0c4339f599bb57c70" category="inline-link-rx"></block></block>
  <block id="61345f1959bf0e90ce956f7fe87b97e6" category="inline-link">+++ Notes de version de NVIDIA DGX SuperPOD +++</block>
  <block id="a42d326cc55152a32997b9b244e9e4ea" category="list-text"><block ref="a42d326cc55152a32997b9b244e9e4ea" category="inline-link-rx"></block></block>
  <block id="18b5a5e73e5f66fb20d8f46f70d0c0ba" category="inline-link">+++ Installation de NetApp AFF A90 +++</block>
  <block id="cc99b2a6b638db71f55772efa9ae5a44" category="list-text"><block ref="cc99b2a6b638db71f55772efa9ae5a44" category="inline-link-rx"></block></block>
  <block id="326b3ec244c0b719f75faee5d63eda19" category="inline-link">+++ Documentation des solutions d'IA NetApp +++</block>
  <block id="2a6b527a76b4dd02f63188fa855840f7" category="list-text"><block ref="2a6b527a76b4dd02f63188fa855840f7" category="inline-link-rx"></block></block>
  <block id="7d3cb5a08ca45610a4bc66221efd1e06" category="inline-link">+++ Logiciel NetApp ONTAP +++</block>
  <block id="7de45c9a3f46892f98b68ddb83483727" category="list-text"><block ref="7de45c9a3f46892f98b68ddb83483727" category="inline-link-rx"></block></block>
  <block id="b20609bf792bc04f91d5af3f95c34249" category="inline-link">+++ Installation et maintenance des systèmes de stockage AFF NetApp +++</block>
  <block id="f4f8a0ca5a3908b7ff3dc9977384172c" category="list-text"><block ref="f4f8a0ca5a3908b7ff3dc9977384172c" category="inline-link-rx"></block></block>
  <block id="784cd7f14efdcfe6b12e47d3ac14c2ea" category="list-text"><block ref="784cd7f14efdcfe6b12e47d3ac14c2ea" category="inline-link-rx"></block></block>
  <block id="2af6b6d1a0f9284afbd220786019c104" category="inline-link">+++Qu'est-ce que pNFS+++</block>
  <block id="40b22abaae26a9e924653fdf64192dd5" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(document plus ancien avec d'excellentes informations sur pNFS)</block>
  <block id="8b609f2b56884902c05d97d442f1d533" category="section-title">Annexe A : Nomenclature et élévations des racks</block>
  <block id="97ac09ecf630c90bdc4eae789d1cb26e" category="paragraph">Le tableau 3 indique le numéro de pièce et les quantités des composants NetApp nécessaires au déploiement du stockage pour une, deux, trois et quatre unités évolutives.</block>
  <block id="a399f4735d9b76eb2c734ce8b23a4051" category="paragraph">Tableau 3) Nomenclature NetApp pour 1, 2, 3 et 4 SU.</block>
  <block id="12671d03ae10ac5096ddbf709e44e260" category="cell">Partie #</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Article</block>
  <block id="4b35db9f95e91ac3ce4b119c8d590dc3" category="cell">Quantité pour 1SU</block>
  <block id="10ae8487d40b09fd13a32fd5b761dff2" category="cell">Quantité pour 2SU</block>
  <block id="4f4a383868a5c8f1aff4d21e301cf77d" category="cell">Quantité pour 3SU</block>
  <block id="7e3f2097d4da066bf518435f0d22d629" category="cell">Quantité pour 4SU</block>
  <block id="a9eadd771f7974cbfb4a0f82da15155e" category="cell">AFF-A90A-100-C</block>
  <block id="a5b8692ce33078554d4df65b88479996" category="cell">Système de stockage AFF A90</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="109799441719d48125200028617a078c" category="cell">X4025A-2-A-C</block>
  <block id="ae1ffcee034fa197d7e6a3d49392ad1b" category="cell">Pack de disques 2x7,6 To</block>
  <block id="0a09c8844ba8f0936c20bd791130d6b6" category="cell">144</block>
  <block id="58a2fc6ed39fd083f55d4182bf88826d" category="cell">192</block>
  <block id="01fc28c75297fac48aca3e18491846a8" category="cell">X50131A-C</block>
  <block id="ef52c5c3e61828c1957bb235e48b9aaf" category="cell">Module d'E/S, 2PT, 100/200/400 GbE</block>
  <block id="76dc611d6ebaafc66cc0879c71b5db5c" category="cell">128</block>
  <block id="da07ac8264b7cdb99a4eb96ab4d91111" category="cell">X50130A-C</block>
  <block id="02104e3c4b3f8d428381d1c68b10320d" category="cell">Module d'E/S, 2PT, 100 GbE</block>
  <block id="90d67d58a9628ba253eee43c6dbc9559" category="cell">X-02659-00</block>
  <block id="eaba4c24f91259319d86e2dc6a375c2c" category="cell">Kit, 4 poteaux, trous carrés ou ronds, rail de 24 à 32 pouces</block>
  <block id="a08f2932fed05b33c4945eca514134dc" category="cell">X1558A-R6</block>
  <block id="3229af69927999e5df543d1f9fb22eb5" category="cell">Cordon d'alimentation pour armoire, 48 po, + C13-C14, 10 A/250 V</block>
  <block id="98f13708210194c475687be6106a3b84" category="cell">20</block>
  <block id="d645920e395fedad7bbbed0eca3fe2e0" category="cell">40</block>
  <block id="f033ab37c30201f73f142449d037028d" category="cell">80</block>
  <block id="e6aa165cded1f8e32159470ff027af2f" category="cell">X190200-CS</block>
  <block id="7e011d9eef19544d7078d2a70563144a" category="cell">Commutateur de cluster, N9336C 36 points PTSX10/25/40/100G</block>
  <block id="76dedba1bf45af402ab07ddd57ff749e" category="cell">X66211A-2</block>
  <block id="2a1aeb324c9e886af32f12ad5049c6f7" category="cell">Câble 100 GbE QSFP28-QSFP28, cuivre, 2 m</block>
  <block id="e2fd227baa44b6632aa7c2fef9002b8a" category="cell">X66211A-05</block>
  <block id="0dff9249f8d94512b43527f1f5b044c9" category="cell">Câble, 100 GbE, QSFP28-QSFP28, Cuivre, 0,5 m</block>
  <block id="6e421f2c1b8bf174d208a91d7f5dc0ae" category="cell">X6561-R6</block>
  <block id="95c7e45248e11b15430ec3c5d1d3dcc1" category="cell">Câble Ethernet CAT6 RJ45 5 m</block>
  <block id="e369853df766fa44e1ed0ff613f563bd" category="cell">34</block>
  <block id="3295c76acbf4caaed33c36b1b5fc2cb1" category="cell">66</block>
  <block id="2a108c75662ccb5a38e6db46a016aa40" category="paragraph">Le tableau 4 indique le numéro de pièce et la quantité de câbles NVIDIA nécessaires pour connecter les systèmes de stockage AFF A90 aux commutateurs SN5600 dans les réseaux de stockage hautes performances et en bande.</block>
  <block id="c71399ea2a367ce779897d49ca77b4a0" category="paragraph">Tableau 4) Câbles NVIDIA requis pour connecter les systèmes de stockage AFF A90 aux commutateurs SN5600 dans les réseaux de stockage hautes performances et en bande.</block>
  <block id="5557f1218ab08d91639048aab26f1de0" category="cell">MCP7Y40-N003</block>
  <block id="2b11e18cd1f4ae786c28a6a1bce455ed" category="cell">DAC 3m 26ga 2x400G à 4x200G OSFP à 4xQSFP112</block>
  <block id="19ca14e7ea6328a42e0eb13d585e4c22" category="cell">36</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="cell">OU</block>
  <block id="84686a1d557f4fefd53eaff2d691796d" category="cell">MMS4X00-NS</block>
  <block id="e67c53a2100e086542158b7496d248a7" category="cell">Émetteur-récepteur multimode OSFP 2x400G 2xSR4 à deux ports, double MPO-12/APC</block>
  <block id="bbf6b7b52739d4479aae0bd6508ac746" category="cell">MFP7E20-N0XX</block>
  <block id="718b622b69fc995a4d3738ecaf2953b0" category="cell">Répartiteurs de fibres multimodes 400G-&gt; 2x200G XX = 03, 05, 07, 10, 15, 20, 30, 40, 50) mètres</block>
  <block id="7b55b9077a4e94ce71aba3fbb4b1ebcd" category="cell">MMA1Z00-NS400</block>
  <block id="1d1c4e0c3b72af208b18fbbfbf63c17b" category="cell">Émetteur-récepteur QSFP112 multimode SR4 400G à port unique, simple MPO-12/APC</block>
  <block id="098103233c14421a2092214651f99ac3" category="section-title">Élévations des racks</block>
  <block id="64441b5a3bcfb8a874107dfe4766feb6" category="paragraph">Les figures 4 à 6 montrent des exemples d'élévations de rack pour 1 à 4 SU.</block>
  <block id="c22e6da1b1ce3c83fb3004d53e804737" category="paragraph">Figure 4) Élévations des racks pour 1 SU et 2 SU.</block>
  <block id="7ef24ed03ec40ae9ef02f5c904953418" category="paragraph"><block ref="7ef24ed03ec40ae9ef02f5c904953418" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64769808ba101c666bcd29615cc1e9d3" category="paragraph">Figure 5) Élévations du rack pour 3 SU.</block>
  <block id="02a5df2de00e7145cadd3753d42d3dc1" category="paragraph"><block ref="02a5df2de00e7145cadd3753d42d3dc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d7011e8983f361d68e382e119c1819" category="paragraph">Figure 6) Élévations des racks pour 4 SU.</block>
  <block id="381008e8bad1425034ca5fa30cd57133" category="paragraph"><block ref="381008e8bad1425034ca5fa30cd57133" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9376ca935750f1ee987d9b2ce256bfbf" category="paragraph">Les systèmes de stockage NVIDIA DGX SuperPOD™ avec NetApp AFF® A90 combinent les performances de calcul de classe mondiale des systèmes NVIDIA DGX avec les systèmes de stockage connectés au cloud NetApp pour permettre des flux de travail basés sur les données pour l'apprentissage automatique (ML), l'intelligence artificielle (IA) et le calcul technique haute performance (HPC).  Ce document décrit l'architecture de haut niveau de la solution DGX SuperPOD utilisant les systèmes de stockage NetApp AFF A90 avec une structure de stockage Ethernet.</block>
  <block id="180ea794b48cd487087e5b1dd21023f0" category="paragraph">Grâce aux performances informatiques éprouvées de NVIDIA DGX SuperPOD combinées aux capacités de sécurité des données, de gouvernance des données et de multi-location de pointe de NetApp, les clients peuvent déployer l'infrastructure la plus efficace et la plus agile pour les charges de travail de nouvelle génération.  Ce document décrit l'architecture de haut niveau et les fonctionnalités clés qui aident les clients à accélérer la mise sur le marché et le retour sur investissement des initiatives d'IA/ML.</block>
  <block id="98e7b017fa4951d28f1516c0bee63969" category="section-title">Résumé du programme</block>
  <block id="0e7a454160d4f81e5b82fe865851c0b5" category="paragraph">NVIDIA DGX SuperPOD offre une solution de centre de données IA clé en main pour les organisations, offrant de manière transparente des outils informatiques, des outils logiciels, une expertise et une innovation continue de classe mondiale.  DGX SuperPOD fournit tout ce dont les clients ont besoin pour déployer des charges de travail AI/ML et HPC avec un temps de configuration minimal et une productivité maximale.  La figure 1 montre les composants de haut niveau du DGX SuperPOD.</block>
  <block id="0df8fda8ee1a402c3eb7dc7582d3a710" category="paragraph"><block ref="0df8fda8ee1a402c3eb7dc7582d3a710" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d91208793b9a449dbecfd553707c79d6" category="list-text">Pile matérielle et logicielle intégrée, de la gestion et de la surveillance de l'infrastructure aux modèles et outils d'apprentissage en profondeur pré-construits.</block>
  <block id="84245e1cf723377c5a2991885cd57409" category="list-text">Services dédiés allant de l'installation et de la gestion de l'infrastructure à la mise à l'échelle des charges de travail et à la rationalisation de l'IA de production</block>
  <block id="5d8430a9387a385c7ee9a8b83ff28b12" category="paragraph">Alors que les organisations adoptent des initiatives d’intelligence artificielle (IA) et d’apprentissage automatique (ML), la demande de solutions d’infrastructure robustes, évolutives et efficaces n’a jamais été aussi grande.  Au cœur de ces initiatives se trouve le défi de gérer et de former des modèles d’IA de plus en plus complexes tout en garantissant la sécurité des données, l’accessibilité et l’optimisation des ressources.  L’évolution de l’IA agentique et les exigences sophistiquées en matière de formation de modèles ont créé des demandes sans précédent en matière d’infrastructures de calcul et de stockage.  Les organisations doivent désormais gérer des ensembles de données massifs, prendre en charge plusieurs charges de travail de formation simultanées et maintenir des environnements informatiques hautes performances tout en garantissant la protection des données et la conformité réglementaire.  Les solutions d’infrastructure traditionnelles ont souvent du mal à répondre à ces demandes, ce qui entraîne des inefficacités opérationnelles et des retards dans la rentabilisation des projets d’IA.  Cette solution offre les principaux avantages suivants :</block>
  <block id="1844a1480427b3b276783fd66fc58226" category="list-text">*Évolutivité.*  Les systèmes de stockage NVIDIA DGX SuperPOD avec NetApp AFF A90 offrent une évolutivité inégalée grâce à son architecture modulaire et à ses capacités d'extension flexibles.  Les organisations peuvent faire évoluer de manière transparente leur infrastructure d’IA en ajoutant des nœuds de calcul DGX et des systèmes de stockage AFF A90 sans perturber les charges de travail existantes ni nécessiter de reconfigurations complexes.</block>
  <block id="02a63d3f709e7b79dac689e7724d8821" category="list-text">*Gestion et accès aux données.*  Les systèmes de stockage NVIDIA DGX SuperPOD avec NetApp AFF A90 sont basés sur NetApp ONTAP qui excelle dans la gestion des données grâce à sa suite complète de fonctionnalités de niveau entreprise.  Grâce aux fonctionnalités d'instantané et de FlexClone d'ONTAP, les équipes peuvent créer instantanément des copies peu encombrantes d'ensembles de données et de bases de données vectorielles pour le développement et les tests parallèles.  Les technologies de réplication FlexCache et Snapmirror permettent des pipelines de données rationalisés, économes en espace et automatisés à partir de sources de données dans toute l'entreprise, et l'accès multiprotocole aux données à l'aide de protocoles NAS et d'objets permet de nouveaux flux de travail optimisés pour les tâches d'ingestion et d'ingénierie des données.</block>
  <block id="3b5ce4caaf6acea212e6608eb826a52c" category="list-text">*Sécurité.*  Les systèmes de stockage NetApp AFF A90 offrent une sécurité de niveau entreprise grâce à plusieurs couches de protection.  Au niveau de l’infrastructure, la solution met en œuvre des mécanismes de contrôle d’accès robustes, notamment le contrôle d’accès basé sur les rôles (RBAC), l’authentification multifacteur et des capacités de journalisation d’audit détaillées.  Le cadre de cryptage complet de la plateforme protège les données au repos et en transit, en utilisant des protocoles et des algorithmes standard de l'industrie pour protéger la propriété intellectuelle et maintenir la conformité aux exigences réglementaires.  Les outils de surveillance de sécurité intégrés offrent une visibilité en temps réel sur les menaces de sécurité potentielles, tandis que les mécanismes de réponse automatisés aident à atténuer les risques avant qu'ils ne puissent avoir un impact sur les opérations.</block>
  <block id="d2374eb265fd2592ef7b4b817140ba67" category="paragraph">Cette solution est destinée aux organisations disposant de charges de travail HPC et AI/ML qui nécessitent une intégration plus poussée dans de vastes parcs de données et des outils et processus d'infrastructure informatique traditionnels.</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">Le public cible de la solution comprend les groupes suivants :</block>
  <block id="f79b8cf1009178e9a2fd45c1f4ae4ef7" category="list-text">Les décideurs informatiques et métiers planifient l'infrastructure la plus efficace pour mettre en œuvre les initiatives d'IA/ML avec le délai de mise sur le marché et le retour sur investissement les plus rapides.</block>
  <block id="c328ed7f0a74043c4e73f7ea491b4eb7" category="list-text">Scientifiques et ingénieurs de données qui souhaitent maximiser l'efficacité des parties critiques axées sur les données du flux de travail IA/ML.</block>
  <block id="fa7b81174ad3677e1ed9da1ea8185c4d" category="list-text">Architectes et ingénieurs informatiques qui doivent fournir une infrastructure fiable et sécurisée permettant des flux de données automatisés et la conformité aux normes de gouvernance des données et des processus existantes.</block>
  <block id="dad37ea926873ef3d5ee869827ddc40c" category="paragraph">NVIDIA DGX SuperPOD comprend les serveurs, le réseau et le stockage nécessaires pour offrir des performances éprouvées pour les charges de travail d'IA exigeantes.  Les systèmes NVIDIA DGX™ H200 et NVIDIA DGX B200 offrent une puissance de calcul de classe mondiale, et les commutateurs réseau NVIDIA Quantum et Spectrum™ InfiniBand offrent une latence ultra-faible et des performances réseau de pointe.  Grâce à l'ajout des capacités de gestion des données et de performances de pointe du stockage NetApp ONTAP , les clients peuvent mettre en œuvre des initiatives d'IA/ML plus rapidement et avec moins de migration de données et de frais administratifs.  Les sections suivantes décrivent les composants de stockage du DGX SuperPOD avec les systèmes de stockage AFF A90 .</block>
  <block id="4caba5452d50c27473615492a421d0b7" category="section-title">Systèmes de stockage NetApp AFF A90 avec NetApp ONTAP</block>
  <block id="5b01f10375ddf0fa7a318292fb1ab544" category="paragraph">Le logiciel de gestion de données NetApp AFF A90 optimisé par NetApp ONTAP offre une protection des données intégrée, des fonctionnalités anti-ransomware et les hautes performances, l'évolutivité et la résilience nécessaires pour prendre en charge les charges de travail commerciales les plus critiques. Il élimine les perturbations des opérations critiques, minimise le réglage des performances et protège vos données contre les attaques de ransomware.  Les systèmes NetApp AFF A90 offrent-</block>
  <block id="5f443413f7f04549bcfdd089e04a0c3a" category="list-text">*Performance.* L' AFF A90 gère facilement les charges de travail de nouvelle génération telles que l'apprentissage en profondeur, l'IA et l'analyse à grande vitesse, ainsi que les bases de données d'entreprise traditionnelles telles qu'Oracle, SAP HANA, Microsoft SQL Server et les applications virtualisées. Avec NFS sur RDMA, pNFS et le trunking de session, les clients peuvent atteindre le niveau élevé de performances réseau requis pour les applications de nouvelle génération en utilisant l'infrastructure réseau du centre de données existante et les protocoles standard de l'industrie sans logiciel propriétaire.  La distribution granulaire des données permet de distribuer des fichiers individuels sur chaque nœud du cluster de stockage et, lorsqu'elle est combinée avec pNFS, offre un accès parallèle hautes performances aux ensembles de données contenus dans un seul fichier volumineux.</block>
  <block id="ae299319707718bf9587df62a89ca873" category="list-text">*Intelligence.*  Accélérez la transformation numérique avec un écosystème prêt pour l'IA, basé sur une intelligence basée sur les données, une infrastructure à l'épreuve du temps et des intégrations approfondies avec NVIDIA et l'écosystème MLOps.  Grâce aux fonctionnalités d'instantané et de FlexClone d'ONTAP, les équipes peuvent créer instantanément des copies peu encombrantes d'ensembles de données pour le développement et les tests parallèles.  Les technologies de réplication FlexCache et Snapmirror permettent des pipelines de données rationalisés, peu encombrants et automatisés à partir de sources de données dans toute l'entreprise.  L'accès multiprotocole aux données à l'aide de protocoles NAS et d'objets permet de nouveaux flux de travail optimisés pour les tâches d'ingestion et d'ingénierie des données.  Les points de contrôle des données et de la formation peuvent être hiérarchisés vers un stockage à moindre coût pour éviter de remplir le stockage principal.  Les clients peuvent gérer, protéger et mobiliser les données de manière transparente, au moindre coût, dans un cloud hybride avec un système d'exploitation de stockage unique et la suite de services de données la plus riche du secteur.</block>
  <block id="3a6d4fa926afe309c404561a18033103" category="list-text">*Sécurité.*  Le NVIDIA DGX SuperPOD avec NetApp ONTAP Storage offre une sécurité de niveau entreprise grâce à plusieurs couches de protection.  Au niveau de l’infrastructure, la solution met en œuvre des mécanismes de contrôle d’accès robustes, notamment le contrôle d’accès basé sur les rôles (RBAC), l’authentification multifacteur et des capacités de journalisation d’audit détaillées.  Le cadre de cryptage complet de la plateforme protège les données au repos et en transit, en utilisant des protocoles et des algorithmes standard de l'industrie pour protéger la propriété intellectuelle et maintenir la conformité aux exigences réglementaires.  Les outils de surveillance de sécurité intégrés offrent une visibilité en temps réel sur les menaces de sécurité potentielles, tandis que les mécanismes de réponse automatisés aident à atténuer les risques avant qu'ils ne puissent avoir un impact sur les opérations.  NetApp ONTAP est le seul stockage d'entreprise renforcé validé pour stocker des données top secrètes.</block>
  <block id="5a79514564c762f34f82d2f86ba269f6" category="list-text">*Multi-location*.  NetApp ONTAP offre la plus large gamme de fonctionnalités pour permettre une utilisation multi-locataire sécurisée des ressources de stockage.  Les machines virtuelles de stockage offrent une délégation administrative basée sur le locataire avec des contrôles RBAC. Des contrôles QoS complets garantissent les performances des charges de travail critiques tout en permettant une utilisation maximale, et des fonctionnalités de sécurité telles que les clés gérées par le locataire pour le chiffrement au niveau du volume garantissent la sécurité des données sur les supports de stockage partagés.</block>
  <block id="234fe3186330a0015f240eaa46026f52" category="inline-link">+++ Livre blanc ONTAP RASS+++</block>
  <block id="aa2c50d70660a4e07e28a4a1e62cbbeb" category="list-text">*Fiabilité.*  NetApp élimine les perturbations des opérations critiques grâce à des fonctionnalités avancées de fiabilité, de disponibilité, de facilité d'entretien et de gestion (RASM), offrant ainsi la disponibilité la plus élevée disponible.  Pour plus d'informations, consultez le<block ref="06c9743ea9b1147ff9ba8b6afddf02b3" category="inline-link-rx"></block> .  De plus, la santé du système peut être optimisée grâce à des analyses prédictives basées sur l’IA fournies par Active IQ et Data Infrastructure Insights.</block>
  <block id="dbefda683c705de53408671cbbab4e34" category="section-title">Systèmes NVIDIA DGX B200</block>
  <block id="c2e6165182afeb3c2d3013f3389087b6" category="inline-link">+++NVIDIA+++</block>
  <block id="2ed6f2103f37f8b4eec016533f493515" category="inline-link">+++NVLink(™)+++</block>
  <block id="1697b07c98d5b223a74b615c776f0b65" category="inline-link">+++ NVIDIA Blackwell+++</block>
  <block id="5e923560ec7f11fe71232bd344d8d81a" category="inline-link">+++architecture+++</block>
  <block id="f7be9a2901218b858c97cd4113fbc2aa" category="paragraph">NVIDIA DGX™ B200 est une plateforme d'IA unifiée pour les pipelines de développement et de déploiement pour les entreprises de toute taille à n'importe quelle étape de leur parcours d'IA.  Équipé de huit GPU NVIDIA Blackwell interconnectés avec la cinquième génération<block ref="8d33a92989a52a298d52379f9acef95c" category="inline-link-rx"></block><block ref="66ff52a072f2c292b9f50112a8543358" category="inline-link-rx"></block> Le DGX B200 offre des performances de pointe, offrant 3 fois les performances de formation et 15 fois les performances d'inférence des générations précédentes.  Tirer parti de la<block ref="113af14b044c5bd4dc15be4b6100b100" category="inline-link-rx"></block><block ref="adaec91c8092748fe326913de2b3a1f0" category="inline-link-rx"></block> DGX B200 peut gérer diverses charges de travail, notamment des modèles linguistiques volumineux, des systèmes de recommandation et des chatbots, ce qui le rend idéal pour les entreprises cherchant à accélérer leur transformation en IA.</block>
  <block id="f94ad1ea1a52dd514a5e42a7eec71e94" category="section-title">Commutateurs Ethernet NVIDIA Spectrum SN5600</block>
  <block id="a1bd19971bc35fdd30c6a0b2eee21865" category="paragraph">Le commutateur intelligent SN5600 à feuille, à colonne vertébrale et à super colonne vertébrale offre 64 ports de 800 GbE dans un format 2U dense.  Le SN5600 permet à la fois des conceptions standard de type feuille/colonne vertébrale avec des commutateurs de type top-of-rack (ToR) ainsi que des topologies de type end-of-row (EoR).  Le SN5600 offre une connectivité diversifiée dans des combinaisons de 1 à 800 GbE et bénéficie d'un débit total de pointe de 51,2 Tb/s.</block>
  <block id="ffe61852985d936bb555e1c150a3feca" category="section-title">Logiciel NVIDIA Base Command</block>
  <block id="040380b5657454a9d0ce1064c83dd667" category="paragraph">NVIDIA Base Command™ alimente la plateforme NVIDIA DGX, permettant aux organisations de tirer parti du meilleur de l'innovation NVIDIA AI.  Grâce à lui, chaque organisation peut exploiter tout le potentiel de son infrastructure DGX avec une plate-forme éprouvée qui comprend la gestion des flux de travail de l'IA, la gestion des clusters de niveau entreprise, des bibliothèques qui accélèrent l'infrastructure de calcul, de stockage et de réseau, ainsi que des logiciels système optimisés pour l'exécution des charges de travail de l'IA.  La figure 2 montre la pile logicielle NVIDIA Base Command.</block>
  <block id="9620c8c92a535942ede6a202c5bf5b0d" category="paragraph">Figure 2) Logiciel de commande de base NVIDIA .</block>
  <block id="2e15a851530c5d474531243cfd838752" category="paragraph"><block ref="2e15a851530c5d474531243cfd838752" category="inline-image-macro-rx" type="image"></block></block>
  <block id="651beb53a2e8224545ff56fc0d0efd02" category="paragraph">NVIDIA Base Command Manager offre un déploiement rapide et une gestion de bout en bout pour les clusters hétérogènes d'IA et de calcul haute performance (HPC) en périphérie, dans le centre de données et dans les environnements multicloud et hybrides.  Il automatise le provisionnement et l'administration de clusters dont la taille varie de quelques nœuds à des centaines de milliers, prend en charge les systèmes accélérés par GPU NVIDIA et d'autres systèmes, et permet l'orchestration avec Kubernetes.  L'intégration des systèmes de stockage NetApp AFF A90 avec DGX SuperPOD nécessite une configuration minimale de Base Command Manager pour le réglage du système et les paramètres de montage pour des performances optimales, mais aucun logiciel supplémentaire n'est requis pour fournir un accès multi-chemins hautement disponible entre les systèmes DGX et le système de stockage AFF A90 .</block>
  <block id="24f67e93854c90d735466339a375c002" category="paragraph">NVIDIA DGX SuperPOD est conçu pour répondre aux exigences de performances des charges de travail les plus exigeantes à la plus grande échelle.</block>
  <block id="cfc814162b41538ad397b897a24c4937" category="list-text">Formation de modèles d'intelligence artificielle pour les grands modèles linguistiques, la vision par ordinateur/la classification d'images, la détection de fraude et d'innombrables autres cas d'utilisation.</block>
  <block id="607aa89216cc994d4e20cfce8695d306" category="list-text">Calcul haute performance tel que l'analyse sismique, la dynamique des fluides numérique et la visualisation à grande échelle.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Architecture de la solution</block>
  <block id="d0eadc16af6d6df8893f37be51ed2bc6" category="paragraph">DGX SuperPOD est basé sur le concept d'une unité évolutive (SU) qui comprend 32 systèmes DGX B200 et tous les autres composants nécessaires pour fournir la connectivité requise et éliminer tout goulot d'étranglement des performances dans l'infrastructure.  Les clients peuvent commencer avec un ou plusieurs SU et ajouter des SU supplémentaires selon leurs besoins pour répondre à leurs besoins.  Ce document décrit la configuration de stockage pour un seul SU et le tableau 1 montre les composants nécessaires pour des configurations plus grandes.</block>
  <block id="2a4a6621abe5b6f39b1534ead593f20a" category="inline-link">+++ Architecture de référence NVIDIA DGX SuperPOD +++</block>
  <block id="60696b15e8be9fd24231177ac611836f" category="paragraph">L'architecture de référence DGX SuperPOD comprend plusieurs réseaux et le système de stockage AFF A90 est connecté à plusieurs d'entre eux.  Pour plus d'informations sur la mise en réseau DGX SuperPOD, veuillez vous référer au<block ref="562b92094dd1a3e9b7e68b6a6fb7de81" category="inline-link-rx"></block> .</block>
  <block id="fdd68d018aab06584c6bc4e8351fa72b" category="paragraph">Pour cette solution, la structure de stockage haute performance est un réseau Ethernet basé sur le commutateur NVIDIA Spectrum SN5600 avec 64 ports 800 Go dans une configuration Spine/Leaf.  Le réseau In-band fournit un accès utilisateur à d'autres fonctions telles que les répertoires personnels et les partages de fichiers généraux et est également basé sur les commutateurs SN5600, et le réseau hors bande (OOB) est destiné à l'accès administrateur système au niveau du périphérique à l'aide des commutateurs SN2201.</block>
  <block id="3a812cac2db0a2d9638c3b252cc24b8e" category="paragraph">La structure de stockage est une architecture feuille-épine où les systèmes DGX se connectent à une paire de commutateurs feuille et le système de stockage se connecte à une autre paire de commutateurs feuille.  Plusieurs ports 800 Gb sont utilisés pour connecter chaque commutateur feuille à une paire de commutateurs spine, créant ainsi plusieurs chemins à large bande passante à travers le réseau pour des performances globales et une redondance.  Pour la connectivité au système de stockage AFF A90 , chaque port 800 Go est divisé en quatre ports 200 Go à l'aide des câbles de dérivation en cuivre ou optiques appropriés.  Pour prendre en charge les clients montant le système de stockage avec NFS sur RDMA, la structure de stockage est configurée pour RDMA sur Ethernet convergé (RoCE), ce qui garantit une livraison de paquets sans perte sur le réseau.  La figure 3 montre la topologie du réseau de stockage de cette solution.</block>
  <block id="6a53d316acbe58b01a749e96481412aa" category="paragraph">Figure 3) Topologie de la structure de stockage.</block>
  <block id="00031e516cb8c09c104ebdb164264d7f" category="paragraph"><block ref="00031e516cb8c09c104ebdb164264d7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316d243b972562ec3f8d06fcd980b1d6" category="paragraph">Le système de stockage NetApp AFF A90 est un châssis 4RU contenant 2 contrôleurs qui fonctionnent comme partenaires haute disponibilité (paire HA) l'un pour l'autre, avec jusqu'à 48 disques SSD au format 2,5 pouces.  Chaque contrôleur est connecté aux deux commutateurs de stockage SN5600 à l'aide de quatre connexions Ethernet 200 Gb, et il existe 2 interfaces IP logiques sur chaque port physique.  Le cluster de stockage prend en charge NFS v4.1 avec Parallel NFS (pNFS) qui permet aux clients d'établir des connexions directement à chaque contrôleur du cluster.  De plus, la jonction de session combine les performances de plusieurs interfaces physiques en une seule session, permettant même aux charges de travail à thread unique d'accéder à plus de bande passante réseau que ce qui est possible avec la liaison Ethernet traditionnelle. La combinaison de toutes ces fonctionnalités avec RDMA permet au système de stockage AFF A90 de fournir une faible latence et un débit élevé qui évolue de manière linéaire pour les charges de travail exploitant NVIDIA GPUDirect Storage™.</block>
  <block id="2ecf799238706280879a7218f5c9384f" category="paragraph">Pour la connectivité au réseau en bande, les contrôleurs AFF A90 disposent d'interfaces Ethernet 200 Gb supplémentaires configurées dans un groupe d'interfaces LACP fournissant des services NFS v3 et v4 généraux ainsi qu'un accès S3 aux systèmes de fichiers partagés si vous le souhaitez.  Tous les contrôleurs et commutateurs de cluster de stockage sont connectés au réseau OOB pour un accès administratif à distance.</block>
  <block id="242354762ac710a9d168daccad8ea40d" category="paragraph">Pour permettre des performances et une évolutivité élevées, les contrôleurs de stockage forment un cluster de stockage qui permet de combiner l'ensemble des performances et de la capacité des nœuds du cluster dans un seul espace de noms appelé FlexGroup avec des données réparties sur les disques de chaque nœud du cluster.  Avec la nouvelle fonctionnalité de distribution de données granulaires publiée dans ONTAP 9.16.1, les fichiers individuels sont séparés et distribués dans le FlexGroup pour permettre les niveaux de performances les plus élevés pour les charges de travail à fichier unique.  La figure 4 ci-dessous montre comment pNFS et la jonction de session NFS fonctionnent avec FlexGroups et GDD pour permettre un accès parallèle aux fichiers volumineux en exploitant chaque interface réseau et chaque disque du système de stockage.</block>
  <block id="c3c4a8bbb2b351b3bf984cb2d6864b94" category="paragraph">Figure 4) pNFS, jonction de session, FlexGroups et GDD.</block>
  <block id="4f30b88a042ae485248ebaa1099b4a91" category="paragraph"><block ref="4f30b88a042ae485248ebaa1099b4a91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ac50512926081a099344a18f27b3818" category="paragraph">Cette solution exploite plusieurs machines virtuelles de stockage (SVM) pour héberger des volumes pour un accès au stockage hautes performances ainsi que des répertoires personnels des utilisateurs et d'autres artefacts de cluster sur une SVM de gestion.  Chaque SVM est configuré avec des interfaces réseau et des volumes FlexGroup et une politique QoS est mise en œuvre pour garantir les performances du SVM de données.  Pour plus d'informations sur les FlexGroups, les machines virtuelles de stockage et les fonctionnalités ONTAP QoS, veuillez vous référer au<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> .</block>
  <block id="2a57ec7828afba5c513d03e967cb3884" category="section-title">Configuration matérielle requise pour la solution</block>
  <block id="b761a63ce0a1bd27710c7207a50b8577" category="paragraph">Le tableau 1 répertorie les composants matériels de stockage nécessaires pour implémenter une, deux, quatre ou huit unités évolutives.  Pour connaître les exigences matérielles détaillées pour les serveurs et la mise en réseau, veuillez consulter le<block ref="b8ab7d3cc54802757d9a49bb252840ab" category="inline-link-rx"></block> .</block>
  <block id="a7504f8a3068ecf26f816d83dfcae5a8" category="cell">Taille de la SU</block>
  <block id="eb94f28ae18769ccde6259223dde0683" category="cell">Systèmes AFF A90</block>
  <block id="258b220fa2ed31020ab102479476e757" category="cell">Commutateurs d'interconnexion de cluster de stockage</block>
  <block id="9254819941449b706e4282e2f2e6a7b9" category="cell">Capacité utilisable (typique avec un SSD de 3,8 To)</block>
  <block id="eb17bb52c3b173b3911725d1c9a194f0" category="cell">Capacité maximale utilisable (avec SSD NVMe de 15,3 To)</block>
  <block id="c9d196f41b3911fefebc23e6efbc32f4" category="cell">RU (typique)</block>
  <block id="1fec42eb0945f00ee2125c78858d7366" category="cell">Puissance (typique)</block>
  <block id="f04a7a4ef42eb207cec5a3d7fcc9d3fa" category="cell">555 To</block>
  <block id="104bf07415681a49e985f5dd5895d4d6" category="cell">13.75PB</block>
  <block id="4f10ff6d954a760dbf5b59fb54597722" category="cell">7 300 watts</block>
  <block id="830daef3058bf009b39d03050f58f3f4" category="cell">27.5PB</block>
  <block id="62aa76bddc36c76968deb0ae09c8063f" category="cell">14 600 watts</block>
  <block id="76a4dd9b098f9a8877b8b79d0c80c5d3" category="cell">2PB</block>
  <block id="3b07c527868f20c47db7e08e0e02ced5" category="cell">55PB</block>
  <block id="f4680500c767e37e35c38315af80e9f9" category="cell">29 200 watts</block>
  <block id="e79a79f20fe06b0beb657745cf11949a" category="cell">4PB</block>
  <block id="1609fc8f39b0baac216cbb19fb420ef2" category="cell">110PB</block>
  <block id="ec8956637a99787bd197eacd77acce5e" category="cell">102</block>
  <block id="bc6012118a1ec87da87af67c6b3a0f74" category="cell">58 400 watts</block>
  <block id="0f37a7e60b292d864a5ac969ec04cc27" category="paragraph">*REMARQUE :* NetApp recommande un minimum de 24 disques par paire AFF A90 HA pour des performances maximales.  Des disques internes supplémentaires, des disques de plus grande capacité et des étagères de disques d'extension externes permettent une capacité globale beaucoup plus élevée sans impact sur les performances du système.</block>
  <block id="d3469c07f7acce56e0d039ec0b164141" category="paragraph">Le tableau 2 répertorie les composants logiciels et les versions nécessaires pour intégrer le système de stockage AFF A90 avec DGX SuperPOD.  DGX SuperPOD implique également d'autres composants logiciels qui ne sont pas répertoriés ici.  Veuillez vous référer à la<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block> pour plus de détails.</block>
  <block id="0bd0e673df4c14cae45a11fac30c530b" category="cell">9.16.1</block>
  <block id="dbc8a3aaafc47a649eed1dcc0bc5155e" category="cell">10.24.11</block>
  <block id="c6d4f54ff5f7e221a70cdd46daa396b3" category="cell">6.3.1</block>
  <block id="09e619b353cb3d3ca08701e294bb9047" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS</block>
  <block id="51eed8fde1839744a1b920b0dacb0a0a" category="cell">5,10</block>
  <block id="f11a60eea5a7abfd75bb28890eaef1ec" category="paragraph">Cette solution de stockage a été validée en plusieurs étapes par NetApp et NVIDIA pour garantir que les performances et l'évolutivité répondent aux exigences de NVIDIA DGX SuperPOD.  La configuration a été validée à l’aide d’une combinaison de charges de travail synthétiques et de charges de travail ML/DL réelles pour vérifier à la fois les performances maximales et l’interopérabilité des applications.  Le tableau 3 ci-dessous fournit des exemples de charges de travail typiques et de leurs exigences en matière de données qui sont couramment observées dans les déploiements DGX SuperPOD.</block>
  <block id="e203df30cd7f31417aee170026e44f70" category="paragraph">Tableau 3) Exemples de charge de travail SuperPOD.</block>
  <block id="a0db49ba470c1c9ae2128c3470339153" category="cell">Niveau</block>
  <block id="0ba48588b95eb9052082d27db3380801" category="cell">Description du travail</block>
  <block id="c8ceada943dc5d58578660bf60d0762a" category="cell">Taille de l'ensemble de données</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Standard</block>
  <block id="c7f0dd1953999823199f993b956164f6" category="cell">Plusieurs tâches de formation LLM ou de réglage fin simultanées et points de contrôle périodiques, où les exigences de calcul dominent considérablement les exigences d'E/S de données.</block>
  <block id="f2db8117278a7bff3e0e0bff0571726d" category="cell">La plupart des ensembles de données peuvent tenir dans le cache mémoire des systèmes de calcul locaux pendant la formation.  Les ensembles de données sont à modalité unique et les modèles comportent des millions de paramètres.</block>
  <block id="53123044b4b65d0ad1b7ed0cfa4c3480" category="cell">Amélioré</block>
  <block id="c9e72abf53e870d36e47df81d7f139bf" category="cell">Plusieurs tâches de formation multimodales simultanées et points de contrôle périodiques, où les performances d'E/S de données sont un facteur important pour le temps de formation de bout en bout.</block>
  <block id="981d20fc47284a9be8695e715a3d1d47" category="cell">Les ensembles de données sont trop volumineux pour tenir dans le cache mémoire des systèmes de calcul locaux, ce qui nécessite davantage d'E/S pendant la formation, mais pas suffisamment pour éviter le besoin d'E/S fréquentes.  Les ensembles de données ont plusieurs modalités et les modèles ont des milliards (ou plus) de paramètres.</block>
  <block id="255eebee8e38299d9f7282ffa8b76db3" category="paragraph">Le tableau 4 présente les directives de performances pour les exemples de charges de travail ci-dessus.  Ces valeurs représentent le débit de stockage qui peut être généré par ces charges de travail dans des conditions idéales.</block>
  <block id="fe54d8f94c652ba49e4aba03f3107a9c" category="paragraph">Tableau 4) Directives de performance du DGX SuperPOD.</block>
  <block id="f5bab93f6f25cd702dcbcb4aad615260" category="cell">Caractéristiques de performance</block>
  <block id="94f3edd272dbb778616c50e083536c63" category="cell">Standard (GBps)</block>
  <block id="abaf1dc2e3d5bf424c74cd4566b0f1a3" category="cell">Amélioré (GBps)</block>
  <block id="c5b9e837f1006565fbb01cd3b64d3df7" category="cell">Lecture d'un seul système d'agrégation SU</block>
  <block id="3def184ad8f4755ff269862ea77393dd" category="cell">125</block>
  <block id="8eb042782ea4dd597d037482af02c144" category="cell">Écriture système agrégée SU unique</block>
  <block id="44f683a84163b3523afe57c2e008bc8c" category="cell">62</block>
  <block id="f53ce0357707bf3db713c9d71337529d" category="cell">Lecture du système d'agrégation 4 SU</block>
  <block id="b73ce398c39f506af761d2277d853a92" category="cell">160</block>
  <block id="cee631121c2ec9232f3a2f028ad5c89b" category="cell">500</block>
  <block id="bc96df788d872dc23329bae80cc02619" category="cell">Écriture système agrégée 4 SU</block>
  <block id="6c9882bbac1c7093bd25041881277658" category="cell">250</block>
  <block id="ef6f2913d5f1e19a1aa781a5d72d6caa" category="inline-link">Guide de déploiement des systèmes de stockage NVA-1175 NVIDIA DGX SuperPOD avec NetApp AFF A90</block>
  <block id="6f8af77cdc63a21a3e7b99a2511ed006" category="list-text"><block ref="6f8af77cdc63a21a3e7b99a2511ed006" category="inline-link-rx"></block></block>
  <block id="4498f6091821057a5b12bbe00bad6fb7" category="inline-link">Architecture de référence NVIDIA DGX B200 SuperPOD</block>
  <block id="e0ef89706b7f0268557664ed42040243" category="list-text"><block ref="e0ef89706b7f0268557664ed42040243" category="inline-link-rx"></block></block>
  <block id="076218ee0774bfaae3fcf92a3241a9fe" category="inline-link">Architecture de référence NVIDIA DGX H200 SuperPOD</block>
  <block id="b02d06e7da163e15a51f5a0277a72641" category="list-text"><block ref="b02d06e7da163e15a51f5a0277a72641" category="inline-link-rx"></block></block>
  <block id="e9cc843bc2157ef28fd2c0657e05a6f0" category="inline-link">Logiciel NVIDIA BaseCommand</block>
  <block id="5b147f17197401088429ad2165ca94db" category="list-text"><block ref="5b147f17197401088429ad2165ca94db" category="inline-link-rx"></block></block>
  <block id="f6f89e67f0d14eefc85ee96a3de66d60" category="list-text"><block ref="f6f89e67f0d14eefc85ee96a3de66d60" category="inline-link-rx"></block></block>
  <block id="8365b73ca224de7f689b1708ed448af9" category="inline-link">+++ Documentation des solutions d'IA NetApp +++</block>
  <block id="aed2dde7ddb9cf045a1de05c19aa6fe6" category="list-text"><block ref="aed2dde7ddb9cf045a1de05c19aa6fe6" category="inline-link-rx"></block></block>
  <block id="4245faba305e62f6fdc30b1ce8bf8ac3" category="inline-link">+++ Installation et maintenance des systèmes de stockage AFF NetApp +++</block>
  <block id="bf45808f34c6dcc540de81441ed8372a" category="list-text"><block ref="bf45808f34c6dcc540de81441ed8372a" category="inline-link-rx"></block></block>
  <block id="51af5c28c5aeade3eeee8efe1cf0c265" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(document plus ancien avec d'excellentes informations sur pNFS)</block>
  <block id="e84f1067b5e0c62707fee9cec31ec6e6" category="sidebar">Systèmes de stockage NetApp AFF A90 avec NVIDIA DGX SuperPOD - Conception</block>
  <block id="ebe830dbdb267fd10b3f4000455f19f2" category="sidebar">Systèmes de stockage NetApp AFF A90 avec NVIDIA DGX SuperPOD - Déploiement</block>
  <block id="596cf4cc4d5e162a19a0826844899146" category="section-title">*Alors, quel est l’intérêt pour les clients d’utiliser NetApp dans leurs environnements d’IA ?*</block>
  <block id="54cba921a12475f0e93be541d67490f1" category="paragraph">NetApp aide les organisations à faire face aux complexités créées par la croissance rapide des données et du cloud, la gestion multicloud et l’adoption de technologies de nouvelle génération, telles que l’IA. NetApp a combiné diverses fonctionnalités dans un logiciel de gestion de données intelligent et une infrastructure de stockage qui ont été bien équilibrés avec des performances élevées optimisées pour les charges de travail d'IA. Les solutions d'IA générative telles que les LLM doivent lire et traiter leurs ensembles de données sources du stockage vers la mémoire à plusieurs reprises pour favoriser l'intelligence.</block>
  <block id="7089718bb01d102d3ca66b75e734cc70" category="paragraph">NetApp est un leader en matière de mobilité des données, de gouvernance des données et de technologies de sécurité des données dans l'écosystème Edge-to-Core-to-Cloud, permettant aux clients d'entreprise de créer des solutions d'IA à grande échelle. NetApp, avec un solide réseau de partenaires, aide les directeurs des données, les ingénieurs en IA, les architectes d'entreprise et les scientifiques des données à concevoir un pipeline de données fluide pour la préparation des données, la protection des données et les responsabilités de gestion stratégique des données de la formation et de l'inférence des modèles d'IA, optimisant ainsi les performances et l'évolutivité du cycle de vie de l'IA/ML. Les technologies et fonctionnalités de données NetApp telles que NetApp ONTAP AI pour le pipeline de données d'apprentissage en profondeur, NetApp SnapMirror pour le transport transparent et efficace des données entre les points de terminaison de stockage et NetApp FlexCache pour le rendu en temps réel lorsque le flux de données passe du lot au temps réel et que l'ingénierie des données se produit à un moment opportun, apportent de la valeur au déploiement de modèles d'IA générative en temps réel. Alors que les entreprises de tous types adoptent de nouveaux outils d’IA, elles sont confrontées à des défis en matière de données, de la périphérie au centre de données en passant par le cloud, qui exigent des solutions d’IA évolutives, responsables et explicables.</block>
  <block id="9772b4cc8e96c8e8f4206d250991b4de" category="paragraph">En tant qu'autorité en matière de données sur le cloud hybride et multi-cloud, NetApp s'engage à créer un réseau de partenaires et de solutions communes qui peuvent aider dans tous les aspects de la construction d'un pipeline de données et de lacs de données pour la formation de modèles d'IA génératifs (pré-formation), le réglage fin, l'inférence basée sur le contexte et la surveillance de la dégradation des modèles des LLM.</block>
  <block id="1bdb9ad9a5ef7e6cc423c9885d4d8739" category="paragraph">L’une des pratiques courantes avec le déploiement de LLM après la préparation et le prétraitement des données consiste à sélectionner un modèle pré-entraîné qui a été formé sur un ensemble de données volumineux et diversifié. Dans le cadre du réglage fin, il peut s'agir d'un modèle de langage open source de grande taille tel que<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> entraîné sur 70 milliards de paramètres et 2 billions de jetons. Une fois le modèle pré-entraîné sélectionné, l’étape suivante consiste à l’affiner sur les données spécifiques au domaine. Cela implique d'ajuster les paramètres du modèle et de l'entraîner sur les nouvelles données pour s'adapter à un domaine et à une tâche spécifiques. Par exemple, BloombergGPT, un LLM propriétaire formé sur un large éventail de données financières au service du secteur financier.</block>
  <block id="fab051e778dea3863166cf91444b5bcf" category="paragraph">Les modèles spécifiques à un domaine, conçus et formés pour une tâche spécifique, ont généralement une précision et des performances supérieures dans leur champ d'application, mais une faible transférabilité entre d'autres tâches ou domaines. Lorsque l’environnement commercial et les données changent au cours d’une période donnée, la précision de prédiction du FM peut commencer à diminuer par rapport à ses performances lors des tests. C’est à ce moment-là que le recyclage ou le réglage fin du modèle devient crucial.</block>
  <block id="4ce18a58c4206acbac965ee866687247" category="paragraph">Le recyclage de modèles dans l'IA/ML traditionnel fait référence à la mise à jour d'un modèle ML déployé avec de nouvelles données, généralement effectuée pour éliminer deux types de dérives qui se produisent. (1) Dérive conceptuelle – lorsque le lien entre les variables d’entrée et les variables cibles change au fil du temps, puisque la description de ce que nous voulons prédire change, le modèle peut produire des prédictions inexactes. (2) Dérive des données – se produit lorsque les caractéristiques des données d'entrée changent, comme les changements dans les habitudes ou le comportement des clients au fil du temps et donc l'incapacité du modèle à répondre à ces changements.</block>
  <block id="602c876f12d2508496dc8bd8575b4ff1" category="paragraph">De la même manière, la reconversion s’applique aux FM/LLM, mais elle peut être beaucoup plus coûteuse (en millions de dollars), et n’est donc pas quelque chose que la plupart des organisations pourraient envisager. Il fait l’objet de recherches actives, toujours en émergence dans le domaine des LLMOps. Ainsi, au lieu de procéder à une nouvelle formation, lorsque la dégradation du modèle se produit dans les FM affinés, les entreprises peuvent opter pour un nouveau réglage fin (beaucoup moins cher) avec un ensemble de données plus récent. Pour une perspective de coût, vous trouverez ci-dessous un exemple de tableau de prix modèle d’Azure-OpenAI Services. Pour chaque catégorie de tâches, les clients peuvent affiner et évaluer les modèles sur des ensembles de données spécifiques.</block>
  <block id="71176ac8a95086c3af18e14dbe844fb0" category="summary">Déployez un environnement d'entraînement d'IA hybride utilisant l'orchestration Union.ai avec NetApp FlexCache pour permettre aux charges de travail d'entraînement GPU basées sur le cloud d'accéder aux données sur site de manière efficace et sécurisée.</block>
  <block id="ebe4896d0cefdc11a7145e4ba24679b4" category="doc">Déployez une formation hybride en IA avec Union.ai et NetApp FlexCache</block>
  <block id="aeb0127b1fad213a793e443cc4c034e1" category="paragraph">Découvrez comment déployer un environnement de formation IA hybride en utilisant l'orchestration Union.ai avec NetApp FlexCache et Trident pour le provisionnement du stockage Kubernetes.</block>
  <block id="0db9f14d36280e385cafd4a8e173ba9c" category="paragraph">David Espejo, Union.ai Sathish Thyagarajan, NetApp</block>
  <block id="236b0367f9d4648bcd56117f6b73c2c5" category="paragraph">La plateforme d'orchestration hybride d'Union.ai s'intègre parfaitement à NetApp ONTAP et FlexCache pour accélérer les flux de travail d'entraînement IA/ML.  Cette solution permet de conserver les données en toute sécurité sur site tout en tirant parti de la puissance de calcul GPU basée sur le cloud pour les charges de travail d'entraînement de l'IA.  NetApp FlexCache garantit que seules les données nécessaires sont mises en cache dans le cloud, permettant ainsi des pipelines d'IA/ML hybrides efficaces, sécurisés et évolutifs.</block>
  <block id="f237a6da02589b7944ad58fcc8dcf636" category="section-title">Cas d'utilisation client : Formation à l'IA dans le cloud hybride</block>
  <block id="e2c5205f6d8d8dc0fab0d0bce1569d9f" category="list-text">Données sur site : stockées sur NetApp ONTAP pour des raisons de conformité et de sécurité.</block>
  <block id="1801ce3ced3cc951feb620652dc6d4b1" category="list-text">Calcul en nuage : Entraînement GPU évolutif sur EKS/GKE/AKS.</block>
  <block id="10295e9d8bfdac4bb00b04c0bc0b0aed" category="list-text">Orchestration IA/ML : Union.ai coordonne le traitement des données et l’entraînement dans différents environnements.</block>
  <block id="21e9bccf6843ac1890de68780a7f2d40" category="list-text">Provisionnement du stockage : NetApp Trident automatise le provisionnement des PVC/PV.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">Valeur client</block>
  <block id="036bc3c4ad78a1ce748913d0e7508b1a" category="list-text">Exécutez des charges de travail d'IA sur des ensembles de données massifs grâce aux capacités d'extension horizontale de NetApp ONTAP.</block>
  <block id="1f7c5f457095fe04da60f8ba120a65e4" category="list-text">Déplacez et synchronisez des données entre votre infrastructure sur site et le cloud grâce aux fonctionnalités de cloud hybride de NetApp.</block>
  <block id="3bdc2120e1312d582041096be647b9bb" category="list-text">Mettez rapidement en cache les données sur site dans le cloud grâce à FlexCache.</block>
  <block id="feb2a9775b0ab9fb076eee862b34a0bf" category="list-text">Union.ai simplifie l'orchestration entre environnements grâce au versionnage, au suivi de la lignée et à la gestion des artefacts.</block>
  <block id="1a5a25d256a64f75ffbb6c69a682f597" category="list-text">Effectuez des formations dans le cloud tout en conservant les données sensibles sur site.</block>
  <block id="3cb632ece883ce8e1d1738b69db115ce" category="section-title">Activation du plugin – Prérequis</block>
  <block id="ec185b8a3ae00d2dc7bc400a8dd3c006" category="cell">*Exigence*</block>
  <block id="dc98ae2c28f9de9e5b906a8f45c3c581" category="cell">*Détails*</block>
  <block id="e8467e9b509c4924668c01eb7ab2adde" category="cell">Version ONTAP</block>
  <block id="19438dd3f06122a6b56a2b87636a35a0" category="cell">ONTAP 9.7+ (Licence FlexCache non requise)</block>
  <block id="50174c074d05aa14191d913ea21e3e51" category="cell">Licence FlexCache</block>
  <block id="774b9f24682d83dfc0b7a6d9acd6a45e" category="cell">Requis sur ONTAP 9.6 et versions antérieures</block>
  <block id="11b36d38ea31e3e3f39211d4c9ff85e9" category="cell">Clusters sur site et dans le cloud (EKS/GKE/AKS)</block>
  <block id="f13ee4a03ec985915aaeb699fd3d5314" category="cell">Installé sur les clusters sur site et dans le cloud</block>
  <block id="23b2341bc1ff8a41de6140e2e728ade5" category="cell">Union.ai</block>
  <block id="407d73d776263be9ef5a593de9cc8960" category="cell">Plan de contrôle déployé (Union Cloud ou auto-hébergé)</block>
  <block id="79629c9f5d632fe153b79bae51230230" category="cell">Connectivité inter-clusters (si les clusters ONTAP sont séparés)</block>
  <block id="d08ccf52b4cdd08e41cfb99ec42e0b29" category="cell">Autorisations</block>
  <block id="34a1c6a28726559a79202e58b5b1676b" category="paragraph">Accès administrateur aux clusters ONTAP et Kubernetes.</block>
  <block id="aa7462aeb4d0cda09f1955bc4ad68471" category="paragraph">✅Utilisez les identifiants ONTAP corrects (par exemple, vsadmin).</block>
  <block id="796fc083420089e3cd35a14b9bc38682" category="cell">Vous découvrez Union.ai ?</block>
  <block id="0a99c5455b15fcf14acd747ff433961a" category="cell">Consultez le guide d'accompagnement à la fin de ce document.</block>
  <block id="4ee2bcec265f41a5c011850eb9ea191a" category="section-title">Architecture de référence</block>
  <block id="63bb16834a3d897a73bbb3b676f4681f" category="paragraph">La figure suivante illustre le plan de contrôle Union.ai intégré au stockage NetApp pour l'entraînement hybride en IA.</block>
  <block id="f3ff7d4cb08d662ccb22a7e0d198e7bc" category="image-alt">Architecture hybride de formation d'IA avec Union.ai et NetApp</block>
  <block id="5b9cebc88c7af20d41a8fb5d5a5ec740" category="list-text">Plan de contrôle Union.ai : orchestre les flux de travail, gère les déplacements de données et s’intègre aux API NetApp .</block>
  <block id="62d1d515610a83be5bf46c2f24528f24" category="list-text">NetApp ONTAP + FlexCache: Assure une mise en cache efficace des données, sur site et dans le cloud.</block>
  <block id="bd86e4a74b09f477abb8e01446ebb353" category="list-text">Clusters d'entraînement hybrides : les tâches d'entraînement s'exécutent dans des clusters K8s cloud (par exemple, EKS) avec des données mises en cache à partir de l'environnement sur site.</block>
  <block id="20b2d2f7ff3d10f09ee1a0cfa5fdc77b" category="section-title">_Étape 1 : Créer un volume FlexCache</block>
  <block id="c320f12fadd143f86e468c946747b19d" category="paragraph">Utilisation du gestionnaire de système ONTAP</block>
  <block id="fbf67ba3555eeca4fc432c43b8b07927" category="list-text">Accédez à Stockage &gt; Volumes.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Cliquez sur Ajouter.</block>
  <block id="fa3a36a2d48d60ddb9b70c0c6908764b" category="list-text">Sélectionnez Plus d'options.</block>
  <block id="3afffa15dbb0847459b5d61d6c2f2aa9" category="list-text">Activer l'option « Ajouter comme cache pour un volume distant ».</block>
  <block id="953d07b2f3feae837ecfbd619c90b443" category="list-text">Choisissez vos volumes source (sur site) et de destination (cloud).</block>
  <block id="f71e6890a321cf5e86880fed490c270d" category="list-text">Définir le niveau de QoS ou de performance (facultatif).</block>
  <block id="f6831112fc67960a16905d831665e29f" category="list-text">Cliquez sur Créer.</block>
  <block id="c3eb411bcb9e224abacb05a02a4af9c4" category="paragraph">💡Si le kit d'outils NetApp DataOps ne fonctionne pas en raison de problèmes d'autorisation ou d'agrégation, créez directement le volume FlexCache à l'aide ONTAP System Manager ou de l'interface de ligne de commande (CLI).</block>
  <block id="6eac7b0a5cfc938d19f189c4a925ae85" category="section-title">_Étape 2 : Configurer Trident_</block>
  <block id="56c52a0dabd55220d0a00db845f7eb1f" category="paragraph">Installez Trident sur les deux clusters :</block>
  <block id="45d2098b426afc9ab859375c1adbe887" category="inline-link">+++ Guide d'installation de Trident +++</block>
  <block id="d250649bce56841bd7a8ae7e4a825154" category="paragraph">🔗 <block ref="d4fe2bbcee5aa3fc712cc2604ddb189d" category="inline-link-rx"></block></block>
  <block id="ce18e85a5244ef1099f883c207b32d36" category="paragraph">Créer un backend Trident</block>
  <block id="1d505b9bfd6afef0b98758bef1cef23c" category="paragraph">Si vous recevez une erreur 401 Non autorisé, vérifiez que l'utilisateur ONTAP dispose des autorisations API suffisantes et que le nom d'utilisateur (vsadmin) et le mot de passe corrects sont utilisés.</block>
  <block id="e5250cf37b377ddb3586661f3e7bdc3e" category="paragraph">Définir la classe de stockage</block>
  <block id="7e383433631a99b62111f529c2e90f6e" category="section-title">_Étape 3 : Déploiement des workflows Union.ai_</block>
  <block id="543a5300ad04692c61ad12509f36dfee" category="paragraph">Union utilise des PVC pour monter les volumes FlexCache dans les tâches d'entraînement.</block>
  <block id="e3651dc228e2bf15038a1eeea69840e1" category="paragraph">Exemple de PodTemplate</block>
  <block id="ef12d0a79902f644c4f92af29b9c7091" category="paragraph">Exemple de flux de travail</block>
  <block id="4066afa3aee701e50ae5ec4c8f86ca6e" category="paragraph">tâche d'importation d'union, flux de travail</block>
  <block id="12113988d854d53153ebe56debcfc262" category="section-title">Chargez et entraînez-vous sur les données provenant du PVC.</block>
  <block id="2f8434215e66e235733bbc8f7aa6c922" category="paragraph">L'opérateur syndiqué va :</block>
  <block id="a305c8fb2137d8a4a767905590079e89" category="list-text">Créer le PVC</block>
  <block id="1c35c5b70ea278327b331fdc5e5e8027" category="list-text">Monter le volume FlexCache</block>
  <block id="193acff0cdc88eae36fe646b68a073bd" category="list-text">Planifiez la tâche dans le cluster K8s du cloud</block>
  <block id="8ed435a788d105467da83bc0bcc93aa7" category="section-title">Étape 4 : Valider l'intégration</block>
  <block id="e5476676d28ebe3a7f7e5540ca5f4675" category="cell">*Tâche*</block>
  <block id="933aacf34a8192a52d32c97fadebd54a" category="cell">*Validation*</block>
  <block id="2c4159f4648782debbeab1c320c6eb36" category="cell">Support en PVC</block>
  <block id="f5e0baa9773049fb0fdfad4b1037b128" category="cell">Les modules d'entraînement devraient monter /data/flexcache avec succès</block>
  <block id="bcaba27319b0be3d4476ebc564abbebe" category="cell">Les tâches de formation peuvent lire/écrire dans FlexCache</block>
  <block id="0452805cb606d459124bcdb40e21d774" category="cell">Comportement du cache</block>
  <block id="4ccd4153d261ab04aea61d1689d17c9c" category="cell">Surveiller les succès/échecs du cache dans ONTAP.  Assurez-vous que les agrégats prennent en charge FlexCache.</block>
  <block id="f77ae91c297c4af9b7c0df16428dfecb" category="cell">Valider la latence et le débit pour les charges de travail d'entraînement</block>
  <block id="c4ce6fec594676e7db8a8772df23cea3" category="paragraph">Utilisez NetApp BlueXP ou l'interface de ligne de commande ONTAP pour surveiller les performances.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="section-title">Considérations de sécurité</block>
  <block id="1127e459f9563cd44a49304486317d03" category="list-text">Utiliser les points de terminaison VPC pour FSx pour NetApp ONTAP</block>
  <block id="aac467f7d3593eab984d0df820db3683" category="list-text">Activer le chiffrement en transit et au repos</block>
  <block id="fb6241aa3cd02fb81bc14120b0a0a835" category="list-text">Appliquer RBAC/IAM pour l'accès ONTAP</block>
  <block id="36b4de85d3df62f02a9c4618f7393d5f" category="list-text">Union.ai n'accède pas aux données des clients et ne les stocke pas.</block>
  <block id="77f95f9630cb5091cd2402072a3a11bf" category="section-title">Surveillance et optimisation</block>
  <block id="f8d8425485c22136939de6dcb7d3356a" category="cell">*Outil*</block>
  <block id="1463a95efc33a52765f03569e1e39a10" category="cell">*But*</block>
  <block id="b5edf5031e4afa6b0a76f28594c49ddd" category="cell">Surveiller l'utilisation et les performances de FlexCache</block>
  <block id="db06b456ce0e60d6d6cac92921fbb8d0" category="cell">Union.ai UI</block>
  <block id="b3f63fd65c8f5f7c899c10d3d4a4d5ff" category="cell">Suivi de l'état et des indicateurs du pipeline</block>
  <block id="046574dd59654b8d55254dd4939767ea" category="cell">Bois de Trident</block>
  <block id="7712a94ff94a189bd7789174ddb85aa3" category="cell">Déboguer les problèmes de PVC ou de backend</block>
  <block id="8f9f469b79a29bfaadaab8eaa7bf1636" category="paragraph">*Améliorations optionnelles*</block>
  <block id="ce4081657a64c83e483fc3ade088d080" category="list-text">Automatisation de la création de FlexCache à l'aide des API BlueXP</block>
  <block id="b0e97389c5c2b645585f1a4ed42f4062" category="list-text">Utilisez le SDK Union pour initialiser le cache avant l'entraînement.</block>
  <block id="a138a4f582ee5e74b8a702fd75b12caf" category="list-text">Ajouter des pipelines d'inférence par lots ou de déploiement de modèles après l'entraînement</block>
  <block id="15e720f9a639ae01b45177587e8ccbde" category="list-text">Si DataOps Toolkit échoue, utilisez la création manuelle de FlexCache via System Manager.</block>
  <block id="1199d4564ed2d91a9aaa1b96702c1582" category="paragraph">*Dépannage*</block>
  <block id="932191b39be7b845f279d774204fa0c7" category="cell">_Problème_</block>
  <block id="04389d6334aedcb0de87e1a666e3c947" category="cell">_Résolution_</block>
  <block id="b9f0ff9ef465f92292d9c7714cf0446b" category="cell">PVC bloqué en attente</block>
  <block id="7d55337975fd5793d327f0da49970ce3" category="cell">Vérifiez les journaux Trident et la configuration du backend</block>
  <block id="4c3472db990ec75b3639c13a00908586" category="cell">401 Non autorisé depuis l'API ONTAP</block>
  <block id="8f85964854ee5b9cb1a25336f9286a74" category="cell">Utilisez vsadmin et vérifiez les permissions.</block>
  <block id="2ee8b0581475d5ce36df44f0c44eab51" category="cell">Échec de l'opération : aucun espace de stockage approprié.</block>
  <block id="c9928a026f07daff3baa1cd570f13e02" category="cell">Assurez-vous que l'agrégat ONTAP prend en charge FlexCache/ FabricPool</block>
  <block id="06d6b9c5788c506f6f2f8d3f67d8df51" category="cell">Performances d'entraînement lentes</block>
  <block id="d03995cc9f7ad650494a9b56c2d58a9c" category="cell">Vérifier le taux d'accès au cache et la latence du réseau</block>
  <block id="bccf1526ca148033777fd0bd06e8f7ee" category="cell">Les données ne se synchronisent pas.</block>
  <block id="0e8d0a990b73463291ce4bfcba615908" category="cell">Valider l'intégrité des relations FlexCache dans ONTAP</block>
  <block id="e78b6e86c7e00b15c6dd9fdca8a5bdcc" category="paragraph">*Prochaines étapes*</block>
  <block id="dee0fee1df57aa918047c0cfb20ad55c" category="list-text">Valider FlexCache avec des données de test</block>
  <block id="2e4e08d271df2d2f43b686f4854cb7dc" category="list-text">Déploiement des pipelines de formation Union.ai</block>
  <block id="321c5de7cdf5e00eb0fdaca2b788e1ec" category="list-text">Surveiller et optimiser les performances</block>
  <block id="036c0cdd445e04bc18011ee63fe79f6b" category="list-text">Configuration spécifique au client</block>
  <block id="f8ec0f3aa329ebfedf13a79184b7867e" category="section-title">Liens connexes</block>
  <block id="40f1a76b84471f69f9e1889172b29883" category="inline-link">+++Documentation Union.ai+++</block>
  <block id="c91fc7e0181d836eb58c9b44f305b351" category="list-text"><block ref="c91fc7e0181d836eb58c9b44f305b351" category="inline-link-rx"></block></block>
  <block id="84d18427d4b09cf2972d9a3f3257769b" category="inline-link">+++ Présentation de NetApp FlexCache +++</block>
  <block id="1a605359e56e1853280e4dee015e7108" category="list-text"><block ref="1a605359e56e1853280e4dee015e7108" category="inline-link-rx"></block></block>
  <block id="da3e81cca1d4f971a54e502e43db83be" category="inline-link">+++ Pilote Trident CSI+++</block>
  <block id="23454a58dd19bdaab14ee6b38f7085c2" category="list-text"><block ref="23454a58dd19bdaab14ee6b38f7085c2" category="inline-link-rx"></block></block>
  <block id="703deb112695d2f3ddd729660eda475e" category="inline-link">+++FSx pour NetApp ONTAP+++</block>
  <block id="5c3ccbe0598da1ccd0f27d66924f35a0" category="list-text"><block ref="5c3ccbe0598da1ccd0f27d66924f35a0" category="inline-link-rx"></block></block>
  <block id="b88b18835512f2759d991ef53ab162b9" category="paragraph">Vous disposez désormais d'un environnement de formation hybride validé pour l'IA utilisant Union.ai et NetApp FlexCache.  Les tâches de formation peuvent s'exécuter dans le cloud tout en accédant aux données sur site de manière sécurisée et efficace, sans avoir à répliquer des ensembles de données entiers ni à compromettre la gouvernance.</block>
  <block id="ad33b54a429301c01188c2215540b441" category="section-title">*Union.ai - Guide d'utilisation*</block>
  <block id="8dddc2c8fe2555559a91e764d9235d6d" category="section-title">*Étape 1 : Choisir le modèle de déploiement*</block>
  <block id="108439501b55d62870c68f24142fe2a5" category="paragraph">*Option A : Union Cloud*</block>
  <block id="976f05b0299c51890060c29d6f4f45b3" category="inline-link">+++console.union.ai+++</block>
  <block id="609ccd1033d19392f6d6c02b595bb318" category="list-text">Visite:<block ref="83d678893a166e9c0f58ce02ef080fcc" category="inline-link-rx"></block></block>
  <block id="f08d2a267c4238d5dedd3060c425bea8" category="list-text">Créer une organisation → Créer un projet</block>
  <block id="8666a7638fa800278c371ca2f1820986" category="paragraph">*Option B : Auto-hébergé*</block>
  <block id="5078bc27c5748b853e709e2b526e1082" category="inline-link">+++Guide auto-hébergé+++</block>
  <block id="6df4df2571296ce37f0e789ec56f04a9" category="list-text">Suivre:<block ref="4be3c30c75fcef2d9efc975adc8528d7" category="inline-link-rx"></block></block>
  <block id="f545b6872fa4adefba8899ca2fc74491" category="list-text">Déploiement via Helm :</block>
  <block id="e473adcd16935db4753279dc28f9e821" category="paragraph">helm repo ajouter unionai<block ref="84236ba1097180095905520179dbd184" category="inline-link-rx"></block></block>
  <block id="00f612d5f2f9c5739afe7c75d82fb745" category="paragraph">helm install union unionai/union -n union-system -f values.yaml</block>
  <block id="d8a959014bb50434b6e09b8d7827f70c" category="section-title">*Étape 2 : Installer l’opérateur syndical*</block>
  <block id="7443eefd01ea12bf0e7f5acf24ead38f" category="paragraph">****kubectl apply -f<block ref="4919c1363aa43016b9853a86a6d26868" category="inline-link-rx"></block></block>
  <block id="9f2047b5710eb7331780470de4e2fca6" category="paragraph">kubectl get pods -n union-system</block>
  <block id="5c2133f8c5522052f26480f953cedc78" category="paragraph"></block>
  <block id="8edcef410da7878bbc80fbf71d8d4ca1" category="section-title">*Étape 3 : Installer Union CLI*</block>
  <block id="096327f6db51928112a49641fed0f8cd" category="paragraph">****pip install unionai</block>
  <block id="bbc7802cd83c61c2822be7e61e76bb58" category="paragraph">Connexion à l'union</block>
  <block id="36be1709489e578c13ff9335dc7eb7f4" category="section-title">*Étape 4 : Enregistrement du flux de travail*</block>
  <block id="770338800a5338d40910785b3f81deca" category="paragraph">**** Projet d'union pour créer une IA hybride</block>
  <block id="d51c04424d78429df18e885a2925e1c1" category="paragraph">union register training_pipeline.py --project hybrid-ai</block>
  <block id="7708565358c9d989222e9b05b65d3086" category="section-title">*Étape 5 : Exécuter et surveiller*</block>
  <block id="5293ce724d74996d1c0f39a743b87ca3" category="paragraph">**union run training_pipeline --project hybrid-ai</block>
  <block id="77d86bed8e4a63dae84e1b440af13a17" category="paragraph">formation de la surveillance syndicale_pipeline</block>
  <block id="1bcbb746e8103dcfa7f40479a1fc2611" category="inline-link">+++Union UI+++</block>
  <block id="fe70d0bdbb730c20766cb067c9162ca2" category="paragraph">Consultez les journaux dans le<block ref="5d901f07ac55ec91a8fb1758272f874b" category="inline-link-rx"></block></block>
  <block id="aa5cc28d71177bdfabbd066c40556228" category="section-title">*Étape 6 : Enregistrement du cluster de calcul (facultatif)*</block>
  <block id="8a850c847294bf4d916aa4d9595fbeab" category="paragraph">****Union Cluster Register --name cloud-k8s --kubeconfig ~/.kube/config</block>
  <block id="4f79c95b459644bc0e692dde2dd46094" category="section-title">*Étape 7 : Suivi des artefacts et de leur lignée*</block>
  <block id="91130ed55ade71de6d2e55d497681f4f" category="paragraph">L'Union effectue automatiquement le suivi :</block>
  <block id="701e52a8aaee5a831d2070361229690f" category="list-text">Paramètres d'entrée/sortie</block>
  <block id="cf5f81b1cd733c89e4b42fe6671710eb" category="list-text">Versions de données</block>
  <block id="6cb9ece998b6962dfad48664cca107df" category="list-text">Journaux et métriques</block>
  <block id="d97bb7d4317729f1d0601989dc9a0eb0" category="list-text">lignée d'exécution</block>
  <block id="1c99161556cba115d3a4b0cf426f65fc" category="section-title">3 décembre 2025</block>
  <block id="0fb14243c78c122f3acd551576ee673d" category="paragraph">Nouvelle solution :<block ref="06b6b8e975dd9eb86a80852e60ea5c25" category="inline-link-macro-rx"></block></block>
  <block id="cae14f8b661aea219fdaf3f4f0af08db" category="paragraph">Utilisez l'orchestration Union.ai avec NetApp FlexCache pour exécuter des charges de travail d'entraînement d'IA sur des GPU cloud tout en conservant les données sensibles sur site.  FlexCache ne met en cache dans le cloud que les données nécessaires pour une formation hybride efficace et sécurisée.</block>
  <block id="d156278e3dbb2cd83d1a870d6704c9b8" category="sidebar">NetApp + Union.ai : Guide technique de formation hybride en IA</block>
  <block id="ddf52cdc15133d3a9cb02a51bde98630" category="sidebar">Formation hybride en IA avec NetApp et Union.ai</block>
  <block id="9c1377c97790bfb53de65e24276a1216" category="sidebar">Formation hybride en IA avec Union.ai</block>
  <block id="bc35ee37767e4af0acfededb3169dea7" category="list-text">Exemples de clients Instaclustr et détails de leurs cas d'utilisation</block>
  <block id="0212a7ff5eedcd67a7b84fa1ba480bc2" category="paragraph"><block ref="f670d08dd43af20b7e913fb27609f01d" category="inline-link-rx"></block>,<block ref="a9adf060aa8097003033bb7f27b5067d" category="inline-link-rx"></block></block>
  <block id="32e89286d3b2abdbdfed4a3b70b56c4a" category="paragraph"><block ref="32e89286d3b2abdbdfed4a3b70b56c4a" category="inline-link-rx"></block></block>
  <block id="04811d6350cbb9ca8a0ee30a91752819" category="paragraph"><block ref="04811d6350cbb9ca8a0ee30a91752819" category="inline-link-rx"></block></block>
  <block id="51a14d08c34bcecf91444995375a1ff2" category="inline-link-macro">instaclust utilisant le stockage hiérarchisé de Kafka</block>
  <block id="e4fda4b7fc0596e39060f4d05d9a3104" category="paragraph">NetApp instaclustr prend également en charge Kafka avec stockage hiérarchisé à partir de la version 3.8.1. Veuillez consulter plus de détails ici <block ref="b7922a93a5920c465bcf40e7e8f14b82" category="inline-link-macro-rx"></block></block>
  <block id="1f2f31fd4bc8efc61a85e89732c2b1d8" category="paragraph">Instaclustr prend également en charge les fonctions d'auto-rééquilibrage et a été mis en œuvre chez plusieurs clients.</block>
  <block id="856aa9558f6aac1cc157b1d21fa78574" category="section-title">Connecteurs Instaclustr Kafka Connect</block>
  <block id="2b56b60f878922093facd42284848a0c" category="inline-link-macro">Plus de détails</block>
  <block id="66e7fcb114a635fe90c2f5b97045315d" category="inline-link-macro">leurs détails</block>
  <block id="621d9727aaaf7b26ac0502b35736098f" category="paragraph">Instaclustr prend en charge les connecteurs Kafka Connect et leurs détails - <block ref="5792c576643eef1089e675cecfec7f12" category="inline-link-macro-rx"></block>. Instaclustr fournit des connecteurs supplémentaires <block ref="46bc00f72c87fbc1de536d86c545b8a8" category="inline-link-macro-rx"></block></block>
</blocks>