---
sidebar: sidebar 
permalink: data-analytics/bda-ai-data-mover.html 
keywords: data mover, ai, hadoop, nipam, nfs, azure, 
summary: 'La solution de transfert de données pour l"IA est basée sur les besoins des clients pour traiter les données Hadoop issues des opérations d"IA.  NetApp déplace les données de HDFS vers NFS à l"aide de NIPAM.  Dans un cas d"utilisation, le client avait besoin de déplacer des données vers NFS sur site et un autre client avait besoin de déplacer des données du blob de stockage Windows Azure vers les Google Cloud NetApp Volumes afin de traiter les données des instances cloud GPU dans le cloud.' 
---
= Solution de transfert de données pour l'IA
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
La solution de transfert de données pour l'IA est basée sur les besoins des clients pour traiter les données Hadoop issues des opérations d'IA.  NetApp déplace les données de HDFS vers NFS à l'aide de NIPAM.  Dans un cas d'utilisation, le client avait besoin de déplacer des données vers NFS sur site et un autre client avait besoin de déplacer des données du blob de stockage Windows Azure vers les Google Cloud NetApp Volumes afin de traiter les données des instances cloud GPU dans le cloud.

Le diagramme suivant illustre les détails de la solution de transfert de données.

image:bda-ai-004.png["Figure montrant une boîte de dialogue d'entrée/sortie ou représentant un contenu écrit"]

Les étapes suivantes sont nécessaires pour créer la solution de transfert de données :

. ONTAP SAN fournit HDFS et NAS fournit le volume NFS via NIPAM au cluster de lac de données de production.
. Les données du client sont en HDFS et NFS.  Les données NFS peuvent être des données de production provenant d’autres applications utilisées pour l’analyse de Big Data et les opérations d’IA.
. La technologie NetApp FlexClone crée un clone du volume NFS de production et le provisionne sur le cluster AI sur site.
. Les données d'un LUN SAN HDFS sont copiées dans un volume NFS avec NIPAM et le `hadoop distcp` commande.  NIPAM utilise la bande passante de plusieurs interfaces réseau pour transférer des données.  Ce processus réduit le temps de copie des données afin que davantage de données puissent être transférées.
. Les deux volumes NFS sont provisionnés sur le cluster AI pour les opérations AI.
. Pour traiter les données NFS sur site avec des GPU dans le cloud, les volumes NFS sont mis en miroir sur NetApp Private Storage (NPS) avec la technologie NetApp SnapMirror et montés sur des fournisseurs de services cloud pour les GPU.
. Le client souhaite traiter des données dans les services EC2/EMR, HDInsight ou DataProc dans des GPU provenant de fournisseurs de services cloud.  Le moteur de transfert de données Hadoop déplace les données des services Hadoop vers les Google Cloud NetApp Volumes avec NIPAM et le `hadoop distcp` commande.
. Les données Google Cloud NetApp Volumes sont provisionnées sur AI via le protocole NFS. Les données traitées via AI peuvent être envoyées sur un emplacement local pour l'analyse de Big Data en plus du cluster NVIDIA via NIPAM, SnapMirror et NPS.


Dans ce scénario, le client dispose de données de nombre de fichiers important dans le système NAS à un emplacement distant qui sont nécessaires au traitement de l'IA sur le contrôleur de stockage NetApp sur site.  Dans ce scénario, il est préférable d’utiliser l’outil de migration XCP pour migrer les données à une vitesse plus rapide.

Le client utilisant un cas d'utilisation hybride peut utiliser BlueXP Copy and Sync pour migrer les données locales des données NFS, CIFS et S3 vers le cloud et vice versa pour le traitement de l'IA en utilisant des GPU tels que ceux d'un cluster NVIDIA .  BlueXP Copy and Sync et l'outil de migration XCP sont tous deux utilisés pour la migration des données NFS vers NetApp ONTAP NFS.
